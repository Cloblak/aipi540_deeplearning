{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "background_execution": "on",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cloblak/aipi540_deeplearning/blob/main/1D_CNN_Attempts/1D_TCN_04MAR_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alpaca_trade_api"
      ],
      "metadata": {
        "id": "Xj0pR3efRVrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0162abe9-135d-4383-d945-8ff1dec0e479"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alpaca_trade_api\n",
            "  Downloading alpaca_trade_api-1.5.1-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (2.23.0)\n",
            "Collecting msgpack==1.0.2\n",
            "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
            "\u001b[K     |████████████████████████████████| 273 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.21.5)\n",
            "Collecting aiohttp==3.7.4\n",
            "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 46.5 MB/s \n",
            "\u001b[?25hCollecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.24.3)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.3.5)\n",
            "Collecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting websocket-client<2,>=0.56.0\n",
            "  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting websockets<11,>=8.0\n",
            "  Downloading websockets-10.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 51.3 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (21.4.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (3.0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation==2.1.0->alpaca_trade_api) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.1->alpaca_trade_api) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->alpaca_trade_api) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->alpaca_trade_api) (2021.10.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation==2.1.0->alpaca_trade_api) (3.0.7)\n",
            "Installing collected packages: multidict, yarl, async-timeout, websockets, websocket-client, PyYAML, msgpack, deprecation, aiohttp, alpaca-trade-api\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.3\n",
            "    Uninstalling msgpack-1.0.3:\n",
            "      Successfully uninstalled msgpack-1.0.3\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.7.4 alpaca-trade-api-1.5.1 async-timeout-3.0.1 deprecation-2.1.0 msgpack-1.0.2 multidict-6.0.2 websocket-client-1.3.1 websockets-10.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features To Consider\n",
        " - Targets are only predicting sell within market hours, i.e. at 1530, target is prediciting price for 1100 the next day.  Data from pre and post market is taken into consideration, and a sell or buy will be indicated if the price will flucuate after close."
      ],
      "metadata": {
        "id": "hdKRKIogGAu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "import alpaca_trade_api as tradeapi\n",
        "from datetime import datetime, timedelta, tzinfo, timezone, time\n",
        "import os.path\n",
        "import ast\n",
        "import threading\n",
        "import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import warnings"
      ],
      "metadata": {
        "id": "J1fWNRnTQZX-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 182\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrI_WR501Iis",
        "outputId": "edfed4a8-0af3-40fe-cd2b-5fb1a90e28eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5490fa9bf0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAPER_API_KEY = \"PKE39LILN9SL1FMJMFV7\"\n",
        "PAPER_SECRET_KEY = \"TkU7fXH6WhP15MewgWlSnQG5RUoHGOPQ7yqlD6xq\"\n",
        "PAPER_BASE_URL = 'https://paper-api.alpaca.markets'"
      ],
      "metadata": {
        "id": "IXnO8ykgRIuv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api = tradeapi.REST(PAPER_API_KEY, PAPER_SECRET_KEY, PAPER_BASE_URL, api_version='v2')"
      ],
      "metadata": {
        "id": "_3XShkLcRQMs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepost_train_test_validate_offset_data(api, ticker, interval, train_days=180, test_days=60, validate_days=30, offset_days = 0):\n",
        "    ticker_data_dict = None\n",
        "    ticker_data_dict = {}\n",
        "    monthly_data_dict = None\n",
        "    monthly_data_dict = {}\n",
        "    interval_loop_data = None\n",
        "    interval_loop_data = pd.DataFrame()\n",
        "    stock_data = None\n",
        "    \n",
        "    days_to_collect = train_days + test_days + validate_days + offset_days\n",
        "\n",
        "    TZ = 'US/Eastern'\n",
        "\n",
        "    start = pd.to_datetime((datetime.now() - timedelta(days=days_to_collect)).strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "    end = pd.to_datetime(datetime.now().strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "\n",
        "    stock_data = api.get_bars(ticker, interval, start = start.isoformat(), end=end.isoformat(), adjustment=\"raw\").df\n",
        "    \n",
        "    interval_loop_data = interval_loop_data.append(stock_data)\n",
        "    df_start_ref = interval_loop_data.index[0]\n",
        "    start_str_ref = pd.to_datetime(start, utc=True)\n",
        "\n",
        "    while start_str_ref.value < ( pd.to_datetime(df_start_ref, utc=True) - pd.Timedelta(days=2.5)).value:\n",
        "        end_new = pd.to_datetime(interval_loop_data.index[0].strftime(\"%Y-%m-%d %H:%M\"), utc=True).isoformat()\n",
        "        stock_data_new = None\n",
        "        stock_data_new = api.get_bars(ticker, interval, start=start, end=end_new, adjustment=\"raw\").df\n",
        "        #stock_data_new = stock_data_new.reset_index()\n",
        "        interval_loop_data = interval_loop_data.append(stock_data_new).sort_values(by=['index'], ascending=True)\n",
        "        df_start_ref = interval_loop_data.index[0]\n",
        "        \n",
        "    stock_yr_min_df = interval_loop_data.copy()\n",
        "    stock_yr_min_df[\"Open\"] = stock_yr_min_df['open']\n",
        "    stock_yr_min_df[\"High\"]= stock_yr_min_df[\"high\"]\n",
        "    stock_yr_min_df[\"Low\"] = stock_yr_min_df[\"low\"]\n",
        "    stock_yr_min_df[\"Close\"] = stock_yr_min_df[\"close\"]\n",
        "    stock_yr_min_df[\"Volume\"] = stock_yr_min_df[\"volume\"]\n",
        "    stock_yr_min_df[\"VolumeWeightedAvgPrice\"] = stock_yr_min_df[\"vwap\"]\n",
        "    stock_yr_min_df[\"Time\"] = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    stock_yr_min_df.index = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    final_df = stock_yr_min_df.filter([\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"VolumeWeightedAvgPrice\"], axis = 1)\n",
        "    \n",
        "    first_day = final_df.index[0]\n",
        "    traintest_day = final_df.index[-1] - pd.Timedelta(days= test_days+validate_days+offset_days)\n",
        "    valtest_day = final_df.index[-1] - pd.Timedelta(days= test_days+offset_days)\n",
        "    last_day = final_df.index[-1] - pd.Timedelta(days= offset_days)\n",
        "    training_df =  final_df.loc[first_day:traintest_day] #(data_split - pd.Timedelta(days=1))]\n",
        "    validate_df = final_df.loc[traintest_day:valtest_day]\n",
        "    testing_df =  final_df.loc[valtest_day:last_day]\n",
        "    full_train = final_df.loc[first_day:last_day]\n",
        "    offset_df =  final_df.loc[last_day:]\n",
        "\n",
        "    return training_df, validate_df, testing_df, full_train, offset_df, final_df, traintest_day, valtest_day\n",
        "\n",
        "from datetime import date\n",
        "\n",
        "train_start = date(2017, 2, 18)\n",
        "train_end = date(2020, 3, 29)\n",
        "train_delta = train_end - train_start\n",
        "print(f'Number of days of Training Data {train_delta.days}')\n",
        "\n",
        "val_day_num = 400\n",
        "print(f'Number of days of Validation Data {val_day_num}')\n",
        "\n",
        "test_start = train_end + timedelta(val_day_num)\n",
        "test_end = date.today()\n",
        "test_delta = (test_end - test_start)\n",
        "print(f'Number of days of Holdout Test Data {test_delta.days}')\n",
        "\n",
        "ticker = \"WEAT\" # Ticker Symbol to Test\n",
        "interval = \"5Min\" # Interval of bars\n",
        "train_day_int = train_delta.days # Size of training set (Jan 2010 - Oct 2017)\n",
        "val_day_int = val_day_num # Size of validation set\n",
        "test_day_int = test_delta.days # Size of test set\n",
        "offset_day_int = 60 # Number of days to off set the training data\n",
        "train_raw, val_raw, test_raw, full_raw, offset_raw, complete_raw, traintest_day, testval_day = prepost_train_test_validate_offset_data(api, ticker, \n",
        "                                                                                     interval, \n",
        "                                                                                     train_days=train_day_int, \n",
        "                                                                                     test_days=test_day_int, \n",
        "                                                                                     validate_days=val_day_int,\n",
        "                                                                                     offset_days = offset_day_int)\n",
        "\n",
        "def timeFilterAndBackfill(df):\n",
        "  \"\"\" \n",
        "  Prep df to be filled out for each trading day:\n",
        "    Time Frame: 0930-1930\n",
        "    Backfilling NaNs\n",
        "    Adjusting Volume to Zero if no Trading data is present\n",
        "      - Assumption is that there were no trades duing that time \n",
        "\n",
        "  We will build over lapping arrays by 30 min to give ourselfs more\n",
        "  oppurtunities to predict during a given trading day \n",
        "  \"\"\"\n",
        "  \n",
        "  df = df.between_time('07:29','17:29') # intial sorting of data\n",
        "\n",
        "  TZ = 'US/Eastern' # define the correct timezone\n",
        "\n",
        "  start_dateTime = pd.Timestamp(year = df.index[0].year, \n",
        "                                month = df.index[0].month, \n",
        "                                day = df.index[0].day, \n",
        "                                hour = 7, minute = 25, tz = TZ)\n",
        "\n",
        "  end_dateTime = pd.Timestamp(year = df.index[-1].year, \n",
        "                              month = df.index[-1].month, \n",
        "                              day = df.index[-1].day, \n",
        "                              hour = 17, minute = 35, tz = TZ)\n",
        "\n",
        "  # build blank index that has ever 5 min interval represented\n",
        "  dateTime_index = pd.date_range(start_dateTime,\n",
        "                                end_dateTime, \n",
        "                                freq='5min').tolist()\n",
        "\n",
        "  dateTime_index_df = pd.DataFrame()\n",
        "  dateTime_index_df[\"Time\"] = dateTime_index \n",
        "  filtered_df = pd.merge_asof(dateTime_index_df, df,  \n",
        "                              on='Time').set_index(\"Time\").between_time('09:29','17:29')\n",
        "\n",
        "  # create the close array by back filling NA, to represent no change in close\n",
        "  closeset_list = []\n",
        "  prev_c = None\n",
        "\n",
        "  for c in filtered_df[\"Close\"]:\n",
        "\n",
        "    if prev_c == None:\n",
        "      if math.isnan(c):\n",
        "        prev_c = 0\n",
        "        closeset_list.append(0)\n",
        "      else:\n",
        "        prev_c = c\n",
        "        closeset_list.append(c)\n",
        "    \n",
        "    elif prev_c != None:\n",
        "      if c == prev_c:\n",
        "        closeset_list.append(c)\n",
        "      elif math.isnan(c):\n",
        "        closeset_list.append(prev_c)\n",
        "      else:\n",
        "        closeset_list.append(c)\n",
        "        prev_c = c\n",
        "    \n",
        "  filtered_df[\"Close\"] = closeset_list\n",
        "\n",
        "  # create the volume\n",
        "  volumeset_list = []\n",
        "  prev_v = None\n",
        "\n",
        "  for v in filtered_df[\"Volume\"]:\n",
        "    \n",
        "    if prev_v == None:\n",
        "      if math.isnan(v):\n",
        "        prev_v = 0\n",
        "        volumeset_list.append(0)\n",
        "      else:\n",
        "        prev_v = v\n",
        "        volumeset_list.append(v)\n",
        "\n",
        "    elif prev_v != None:\n",
        "      if v == prev_v:\n",
        "        volumeset_list.append(0)\n",
        "        prev_v = v\n",
        "      elif math.isnan(v):\n",
        "        volumeset_list.append(0)\n",
        "        prev_v = 0\n",
        "      else:\n",
        "        volumeset_list.append(v)\n",
        "        prev_v = v\n",
        "\n",
        "  filtered_df[\"Volume\"] = volumeset_list\n",
        "  \n",
        "  adjvolumeset_list = []\n",
        "  prev_v = None\n",
        "\n",
        "  for v in filtered_df[\"VolumeWeightedAvgPrice\"]:\n",
        "    if prev_v == None:\n",
        "      if math.isnan(v):\n",
        "        prev_v = 0\n",
        "        adjvolumeset_list.append(0)\n",
        "      else:\n",
        "        prev_v = v\n",
        "        adjvolumeset_list.append(v)\n",
        "    elif prev_v != None:\n",
        "      if v == prev_v:\n",
        "        adjvolumeset_list.append(0)\n",
        "        prev_v = v\n",
        "      elif math.isnan(v):\n",
        "        adjvolumeset_list.append(0)\n",
        "        prev_v = 0\n",
        "      else:\n",
        "        adjvolumeset_list.append(v)\n",
        "        prev_v = v\n",
        "\n",
        "  filtered_df[\"VolumeWeightedAvgPrice\"] = adjvolumeset_list\n",
        "\n",
        "  preped_df = filtered_df.backfill()\n",
        "\n",
        "  return preped_df  "
      ],
      "metadata": {
        "id": "tINNlljbRaDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e7a970-0b99-4138-d136-df7fb1651322"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of days of Training Data 1135\n",
            "Number of days of Validation Data 400\n",
            "Number of days of Holdout Test Data 305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw[0:300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "J6Cw_PVrh2lJ",
        "outputId": "a4f45699-6c44-4c48-ed0d-f3c1ace73b01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-02894622-c7c9-4c13-8b96-2e788c88b1a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeWeightedAvgPrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:30:00-05:00</th>\n",
              "      <td>2016-12-20 09:30:00-05:00</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.7900</td>\n",
              "      <td>6.8000</td>\n",
              "      <td>6405</td>\n",
              "      <td>6.813110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:35:00-05:00</th>\n",
              "      <td>2016-12-20 09:35:00-05:00</td>\n",
              "      <td>6.8012</td>\n",
              "      <td>6.8012</td>\n",
              "      <td>6.8012</td>\n",
              "      <td>6.8012</td>\n",
              "      <td>585</td>\n",
              "      <td>6.801200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:40:00-05:00</th>\n",
              "      <td>2016-12-20 09:40:00-05:00</td>\n",
              "      <td>6.8100</td>\n",
              "      <td>6.8293</td>\n",
              "      <td>6.8100</td>\n",
              "      <td>6.8293</td>\n",
              "      <td>300</td>\n",
              "      <td>6.822867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:45:00-05:00</th>\n",
              "      <td>2016-12-20 09:45:00-05:00</td>\n",
              "      <td>6.8279</td>\n",
              "      <td>6.8279</td>\n",
              "      <td>6.8279</td>\n",
              "      <td>6.8279</td>\n",
              "      <td>100</td>\n",
              "      <td>6.827900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:55:00-05:00</th>\n",
              "      <td>2016-12-20 09:55:00-05:00</td>\n",
              "      <td>6.8842</td>\n",
              "      <td>6.9000</td>\n",
              "      <td>6.8842</td>\n",
              "      <td>6.8861</td>\n",
              "      <td>2140</td>\n",
              "      <td>6.892169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-29 13:25:00-05:00</th>\n",
              "      <td>2016-12-29 13:25:00-05:00</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8572</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>800</td>\n",
              "      <td>6.851788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-29 13:30:00-05:00</th>\n",
              "      <td>2016-12-29 13:30:00-05:00</td>\n",
              "      <td>6.8690</td>\n",
              "      <td>6.8690</td>\n",
              "      <td>6.8690</td>\n",
              "      <td>6.8690</td>\n",
              "      <td>200</td>\n",
              "      <td>6.869000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-29 13:35:00-05:00</th>\n",
              "      <td>2016-12-29 13:35:00-05:00</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8421</td>\n",
              "      <td>6.8421</td>\n",
              "      <td>1350</td>\n",
              "      <td>6.842937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-29 13:40:00-05:00</th>\n",
              "      <td>2016-12-29 13:40:00-05:00</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8503</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8503</td>\n",
              "      <td>925</td>\n",
              "      <td>6.845846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-29 13:45:00-05:00</th>\n",
              "      <td>2016-12-29 13:45:00-05:00</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>100</td>\n",
              "      <td>6.850000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02894622-c7c9-4c13-8b96-2e788c88b1a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02894622-c7c9-4c13-8b96-2e788c88b1a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02894622-c7c9-4c13-8b96-2e788c88b1a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               Time    Open    High     Low  \\\n",
              "timestamp                                                                     \n",
              "2016-12-20 09:30:00-05:00 2016-12-20 09:30:00-05:00  6.8300  6.8300  6.7900   \n",
              "2016-12-20 09:35:00-05:00 2016-12-20 09:35:00-05:00  6.8012  6.8012  6.8012   \n",
              "2016-12-20 09:40:00-05:00 2016-12-20 09:40:00-05:00  6.8100  6.8293  6.8100   \n",
              "2016-12-20 09:45:00-05:00 2016-12-20 09:45:00-05:00  6.8279  6.8279  6.8279   \n",
              "2016-12-20 09:55:00-05:00 2016-12-20 09:55:00-05:00  6.8842  6.9000  6.8842   \n",
              "...                                             ...     ...     ...     ...   \n",
              "2016-12-29 13:25:00-05:00 2016-12-29 13:25:00-05:00  6.8500  6.8572  6.8500   \n",
              "2016-12-29 13:30:00-05:00 2016-12-29 13:30:00-05:00  6.8690  6.8690  6.8690   \n",
              "2016-12-29 13:35:00-05:00 2016-12-29 13:35:00-05:00  6.8500  6.8500  6.8421   \n",
              "2016-12-29 13:40:00-05:00 2016-12-29 13:40:00-05:00  6.8400  6.8503  6.8400   \n",
              "2016-12-29 13:45:00-05:00 2016-12-29 13:45:00-05:00  6.8500  6.8500  6.8500   \n",
              "\n",
              "                            Close  Volume  VolumeWeightedAvgPrice  \n",
              "timestamp                                                          \n",
              "2016-12-20 09:30:00-05:00  6.8000    6405                6.813110  \n",
              "2016-12-20 09:35:00-05:00  6.8012     585                6.801200  \n",
              "2016-12-20 09:40:00-05:00  6.8293     300                6.822867  \n",
              "2016-12-20 09:45:00-05:00  6.8279     100                6.827900  \n",
              "2016-12-20 09:55:00-05:00  6.8861    2140                6.892169  \n",
              "...                           ...     ...                     ...  \n",
              "2016-12-29 13:25:00-05:00  6.8500     800                6.851788  \n",
              "2016-12-29 13:30:00-05:00  6.8690     200                6.869000  \n",
              "2016-12-29 13:35:00-05:00  6.8421    1350                6.842937  \n",
              "2016-12-29 13:40:00-05:00  6.8503     925                6.845846  \n",
              "2016-12-29 13:45:00-05:00  6.8500     100                6.850000  \n",
              "\n",
              "[300 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildTargets_VolOnly(full_df = full_raw, train_observations = train_raw.shape[0], \n",
        "                         val_observations = val_raw.shape[0], \n",
        "                         test_observations = test_raw.shape[0], \n",
        "                         alph = .55, volity_int = 10):\n",
        "\n",
        "  \"\"\" \n",
        "  This function will take a complete set of train, val, and test data and return the targets.\n",
        "  Volitility will be calculated over the 252 5min incriments \n",
        "  The Target shift is looking at 2 hours shift from current time\n",
        "  \"\"\"\n",
        "\n",
        "  returns = np.log(full_df['Close']/(full_df['Close'].shift()))\n",
        "  returns.fillna(0, inplace=True)\n",
        "  volatility = returns.rolling(window=(volity_int)).std()*np.sqrt(volity_int)\n",
        "\n",
        "\n",
        "\n",
        "  return volatility\n",
        "  #return train_targets, val_targets, test_targets, full_targets\n",
        "\n",
        "volatility = buildTargets_VolOnly()\n",
        "\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "ax1 = fig.add_subplot(1, 1, 1)\n",
        "volatility.plot(ax=ax1, color = \"red\")\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Volatility', color = \"red\")\n",
        "ax1.set_title(f'Annualized volatility for {ticker}')\n",
        "ax2 = ax1.twinx()\n",
        "full_raw.Close.plot(ax=ax2, color = \"blue\")\n",
        "ax2.set_ylabel('Close', color = \"blue\")\n",
        "ax2.axvline(x=full_raw.index[train_raw.shape[0]])\n",
        "ax2.axvline(x=full_raw.index[val_raw.shape[0]+train_raw.shape[0]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fWqLBPQPbjYZ",
        "outputId": "677d6e7b-b238-4ef3-9298-4a717aac6e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = timeFilterAndBackfill(train_raw)\n",
        "val = timeFilterAndBackfill(val_raw)\n",
        "test = timeFilterAndBackfill(test_raw)\n",
        "\n",
        "train = train[train.index.dayofweek <= 4].copy()\n",
        "val = val[val.index.dayofweek <= 4].copy()\n",
        "test = test[test.index.dayofweek <= 4].copy()\n",
        "\n",
        "train[\"Open\"] = np.where((train[\"Volume\"] == 0), train[\"Close\"], train[\"Open\"])\n",
        "train[\"High\"] = np.where((train[\"Volume\"] == 0), train[\"Close\"], train[\"High\"])\n",
        "train[\"Low\"] = np.where((train[\"Volume\"] == 0), train[\"Close\"], train[\"Low\"])\n",
        "\n",
        "val[\"Open\"] = np.where((val[\"Volume\"] == 0), val[\"Close\"], val[\"Open\"])\n",
        "val[\"High\"] = np.where((val[\"Volume\"] == 0), val[\"Close\"], val[\"High\"])\n",
        "val[\"Low\"] = np.where((val[\"Volume\"] == 0), val[\"Close\"], val[\"Low\"])\n",
        "\n",
        "test[\"Open\"] = np.where((test[\"Volume\"] == 0), test[\"Close\"], test[\"Open\"])\n",
        "test[\"High\"] = np.where((test[\"Volume\"] == 0), test[\"Close\"], test[\"High\"])\n",
        "test[\"Low\"] = np.where((test[\"Volume\"] == 0), test[\"Close\"], test[\"Low\"])\n",
        "\n",
        "def strided_axis0(a, L, overlap=1):\n",
        "    if L==overlap:\n",
        "        raise Exception(\"Overlap arg must be smaller than length of windows\")\n",
        "    S = L - overlap\n",
        "    nd0 = ((len(a)-L)//S)+1\n",
        "    if nd0*S-S!=len(a)-L:\n",
        "        warnings.warn(\"Not all elements were covered\")\n",
        "    m,n = a.shape\n",
        "    s0,s1 = a.strides\n",
        "    return np.lib.stride_tricks.as_strided(a, shape=(nd0,L,n), strides=(S*s0,s0,s1))\n",
        "\n",
        "# OLDER CODE WITHOUT OVERLAP OF LABELING\n",
        "# def blockshaped(arr, nrows, ncols):\n",
        "#     \"\"\"\n",
        "#     Return an array of shape (n, nrows, ncols) where\n",
        "#     n * nrows * ncols = arr.size\n",
        "\n",
        "#     If arr is a 2D array, the returned array should look like n subblocks with\n",
        "#     each subblock preserving the \"physical\" layout of arr.\n",
        "#     \"\"\"\n",
        "#     h, w = arr.shape\n",
        "#     assert h % nrows == 0, f\"{h} rows is not evenly divisible by {nrows}\"\n",
        "#     assert w % ncols == 0, f\"{w} cols is not evenly divisible by {ncols}\"\n",
        "#     return np.flip(np.rot90((arr.reshape(h//nrows, nrows, -1, ncols)\n",
        "#                .swapaxes(1,2)\n",
        "#                .reshape(-1, nrows, ncols)), axes = (1, 2)), axis = 1)\n",
        "\n",
        "\n",
        "def blockshaped(arr, nrows, ncols, overlapping_5min_intervals = 12):\n",
        "    \"\"\"\n",
        "    Return an array of shape (n, nrows, ncols) where\n",
        "    n * nrows * ncols = arr.size\n",
        "\n",
        "    If arr is a 2D array, the returned array should look like n subblocks with\n",
        "    each subblock preserving the \"physical\" layout of arr.\n",
        "    \"\"\"\n",
        "\n",
        "    h, w = arr.shape\n",
        "    assert h % nrows == 0, f\"{h} rows is not evenly divisible by {nrows}\"\n",
        "    assert w % ncols == 0, f\"{w} cols is not evenly divisible by {ncols}\"\n",
        "\n",
        "    return np.flip(np.rot90((strided_axis0(arr, 24, overlap=overlapping_5min_intervals).reshape(-1, nrows, ncols)), axes = (1, 2)), axis = 1)\n",
        "\n",
        "train_tonp = train[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "val_tonp = val[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "test_tonp = test[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "train_array = train_tonp.to_numpy()\n",
        "val_array = val_tonp.to_numpy()\n",
        "test_array = test_tonp.to_numpy()\n",
        "\n",
        "X_train_pre_final = blockshaped(train_array, 24, 5, overlapping_5min_intervals = 12)\n",
        "X_val_pre_final = blockshaped(val_array, 24, 5, overlapping_5min_intervals = 12)\n",
        "X_test_pre_final = blockshaped(test_array, 24, 5, overlapping_5min_intervals = 12)\n",
        "\n",
        "# X_train_pre_final = blockshaped(train_array, 24, 5)\n",
        "# X_val_pre_final = blockshaped(val_array, 24, 5)\n",
        "# X_test_pre_final = blockshaped(test_array, 24, 5)"
      ],
      "metadata": {
        "id": "0_yU14VEM37m"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(edgeitems=10,linewidth=580)\n",
        "X_train_pre_final[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8KcE_XCidzo",
        "outputId": "d43b9e45-ccae-41d0-b3df-0a3d749ebb8f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   6.83  ,    6.8012,    6.81  ,    6.8279,    6.8279,    6.8842,    6.8965,    6.86  ,    6.8784,    6.8701,    6.8626,    6.8626,    6.85  ,    6.84  ,    6.8301,    6.8301,    6.8301,    6.8301,    6.84  ,    6.84  ,    6.84  ,    6.8434,    6.8434,    6.8434],\n",
              "       [   6.83  ,    6.8012,    6.8293,    6.8279,    6.8279,    6.9   ,    6.8965,    6.86  ,    6.8784,    6.8798,    6.8626,    6.8626,    6.85  ,    6.84  ,    6.8301,    6.8301,    6.8301,    6.8301,    6.84  ,    6.84  ,    6.84  ,    6.8434,    6.8434,    6.8434],\n",
              "       [   6.79  ,    6.8012,    6.81  ,    6.8279,    6.8279,    6.8842,    6.8701,    6.86  ,    6.8784,    6.87  ,    6.8626,    6.8626,    6.85  ,    6.83  ,    6.8301,    6.8301,    6.8301,    6.8301,    6.84  ,    6.84  ,    6.84  ,    6.8434,    6.8434,    6.8434],\n",
              "       [   6.8   ,    6.8012,    6.8293,    6.8279,    6.8279,    6.8861,    6.8701,    6.86  ,    6.8784,    6.8798,    6.8626,    6.8626,    6.85  ,    6.8301,    6.8301,    6.8301,    6.8301,    6.8301,    6.84  ,    6.84  ,    6.84  ,    6.8434,    6.8434,    6.8434],\n",
              "       [6405.    ,  585.    ,  300.    ,  100.    ,    0.    , 2140.    , 3741.    , 1000.    ,    0.    , 2000.    ,  540.    ,    0.    ,  400.    ,  926.    ,    0.    ,    0.    ,    0.    ,    0.    , 1174.    ,  300.    ,    0.    ,  100.    ,    0.    ,    0.    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tonp[0:24]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "29LbU_ukUK8j",
        "outputId": "0ecfc8bd-b935-46d6-8913-c3e2c0794198"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-11b18fac-1620-4cad-924e-f6492dbbee4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:30:00-05:00</th>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.7900</td>\n",
              "      <td>6.8000</td>\n",
              "      <td>6405.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:35:00-05:00</th>\n",
              "      <td>6.8012</td>\n",
              "      <td>6.8012</td>\n",
              "      <td>6.8012</td>\n",
              "      <td>6.8012</td>\n",
              "      <td>585.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:40:00-05:00</th>\n",
              "      <td>6.8100</td>\n",
              "      <td>6.8293</td>\n",
              "      <td>6.8100</td>\n",
              "      <td>6.8293</td>\n",
              "      <td>300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:45:00-05:00</th>\n",
              "      <td>6.8279</td>\n",
              "      <td>6.8279</td>\n",
              "      <td>6.8279</td>\n",
              "      <td>6.8279</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:50:00-05:00</th>\n",
              "      <td>6.8279</td>\n",
              "      <td>6.8279</td>\n",
              "      <td>6.8279</td>\n",
              "      <td>6.8279</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:55:00-05:00</th>\n",
              "      <td>6.8842</td>\n",
              "      <td>6.9000</td>\n",
              "      <td>6.8842</td>\n",
              "      <td>6.8861</td>\n",
              "      <td>2140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:00:00-05:00</th>\n",
              "      <td>6.8965</td>\n",
              "      <td>6.8965</td>\n",
              "      <td>6.8701</td>\n",
              "      <td>6.8701</td>\n",
              "      <td>3741.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:05:00-05:00</th>\n",
              "      <td>6.8600</td>\n",
              "      <td>6.8600</td>\n",
              "      <td>6.8600</td>\n",
              "      <td>6.8600</td>\n",
              "      <td>1000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:10:00-05:00</th>\n",
              "      <td>6.8784</td>\n",
              "      <td>6.8784</td>\n",
              "      <td>6.8784</td>\n",
              "      <td>6.8784</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:15:00-05:00</th>\n",
              "      <td>6.8701</td>\n",
              "      <td>6.8798</td>\n",
              "      <td>6.8700</td>\n",
              "      <td>6.8798</td>\n",
              "      <td>2000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:20:00-05:00</th>\n",
              "      <td>6.8626</td>\n",
              "      <td>6.8626</td>\n",
              "      <td>6.8626</td>\n",
              "      <td>6.8626</td>\n",
              "      <td>540.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:25:00-05:00</th>\n",
              "      <td>6.8626</td>\n",
              "      <td>6.8626</td>\n",
              "      <td>6.8626</td>\n",
              "      <td>6.8626</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:30:00-05:00</th>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:35:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>926.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:40:00-05:00</th>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:45:00-05:00</th>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:50:00-05:00</th>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:55:00-05:00</th>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:00:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>1174.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:05:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:10:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:15:00-05:00</th>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:20:00-05:00</th>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:25:00-05:00</th>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11b18fac-1620-4cad-924e-f6492dbbee4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11b18fac-1620-4cad-924e-f6492dbbee4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11b18fac-1620-4cad-924e-f6492dbbee4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             Open    High     Low   Close  Volume\n",
              "Time                                                             \n",
              "2016-12-20 09:30:00-05:00  6.8300  6.8300  6.7900  6.8000  6405.0\n",
              "2016-12-20 09:35:00-05:00  6.8012  6.8012  6.8012  6.8012   585.0\n",
              "2016-12-20 09:40:00-05:00  6.8100  6.8293  6.8100  6.8293   300.0\n",
              "2016-12-20 09:45:00-05:00  6.8279  6.8279  6.8279  6.8279   100.0\n",
              "2016-12-20 09:50:00-05:00  6.8279  6.8279  6.8279  6.8279     0.0\n",
              "2016-12-20 09:55:00-05:00  6.8842  6.9000  6.8842  6.8861  2140.0\n",
              "2016-12-20 10:00:00-05:00  6.8965  6.8965  6.8701  6.8701  3741.0\n",
              "2016-12-20 10:05:00-05:00  6.8600  6.8600  6.8600  6.8600  1000.0\n",
              "2016-12-20 10:10:00-05:00  6.8784  6.8784  6.8784  6.8784     0.0\n",
              "2016-12-20 10:15:00-05:00  6.8701  6.8798  6.8700  6.8798  2000.0\n",
              "2016-12-20 10:20:00-05:00  6.8626  6.8626  6.8626  6.8626   540.0\n",
              "2016-12-20 10:25:00-05:00  6.8626  6.8626  6.8626  6.8626     0.0\n",
              "2016-12-20 10:30:00-05:00  6.8500  6.8500  6.8500  6.8500   400.0\n",
              "2016-12-20 10:35:00-05:00  6.8400  6.8400  6.8300  6.8301   926.0\n",
              "2016-12-20 10:40:00-05:00  6.8301  6.8301  6.8301  6.8301     0.0\n",
              "2016-12-20 10:45:00-05:00  6.8301  6.8301  6.8301  6.8301     0.0\n",
              "2016-12-20 10:50:00-05:00  6.8301  6.8301  6.8301  6.8301     0.0\n",
              "2016-12-20 10:55:00-05:00  6.8301  6.8301  6.8301  6.8301     0.0\n",
              "2016-12-20 11:00:00-05:00  6.8400  6.8400  6.8400  6.8400  1174.0\n",
              "2016-12-20 11:05:00-05:00  6.8400  6.8400  6.8400  6.8400   300.0\n",
              "2016-12-20 11:10:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0\n",
              "2016-12-20 11:15:00-05:00  6.8434  6.8434  6.8434  6.8434   100.0\n",
              "2016-12-20 11:20:00-05:00  6.8434  6.8434  6.8434  6.8434     0.0\n",
              "2016-12-20 11:25:00-05:00  6.8434  6.8434  6.8434  6.8434     0.0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pre_final[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6w8fb_TU-Tx",
        "outputId": "0c1b7e0b-50ee-4748-f07e-2850381cba38"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   6.85  ,    6.84  ,    6.8301,    6.8301,    6.8301,    6.8301,    6.84  ,    6.84  ,    6.84  ,    6.8434,    6.8434,    6.8434,    6.8434,    6.8237,    6.83  ,    6.83  ,    6.8443,    6.8499,    6.8499,    6.8499,    6.83  ,    6.8201,    6.82  ,    6.84  ],\n",
              "       [   6.85  ,    6.84  ,    6.8301,    6.8301,    6.8301,    6.8301,    6.84  ,    6.84  ,    6.84  ,    6.8434,    6.8434,    6.8434,    6.8434,    6.8237,    6.83  ,    6.83  ,    6.8443,    6.8499,    6.8499,    6.8499,    6.83  ,    6.8201,    6.84  ,    6.84  ],\n",
              "       [   6.85  ,    6.83  ,    6.8301,    6.8301,    6.8301,    6.8301,    6.84  ,    6.84  ,    6.84  ,    6.8434,    6.8434,    6.8434,    6.8434,    6.8237,    6.83  ,    6.83  ,    6.8443,    6.8499,    6.8499,    6.8499,    6.83  ,    6.8201,    6.82  ,    6.84  ],\n",
              "       [   6.85  ,    6.8301,    6.8301,    6.8301,    6.8301,    6.8301,    6.84  ,    6.84  ,    6.84  ,    6.8434,    6.8434,    6.8434,    6.8434,    6.8237,    6.83  ,    6.83  ,    6.8443,    6.8499,    6.8499,    6.8499,    6.83  ,    6.8201,    6.84  ,    6.84  ],\n",
              "       [ 400.    ,  926.    ,    0.    ,    0.    ,    0.    ,    0.    , 1174.    ,  300.    ,    0.    ,  100.    ,    0.    ,    0.    ,    0.    ,  200.    ,  400.    ,    0.    ,  500.    ,  300.    ,    0.    ,    0.    , 1171.    , 5000.    , 3129.    ,    0.    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create target from OHLC and Volume Data\n",
        "###### THIS IS FOR 3 CLASS FROM PAPER ########\n",
        "# def buildTargets(obs_array,  \n",
        "#                  alph = .55, \n",
        "#                  volity_int = 10):\n",
        "\n",
        "#   \"\"\" \n",
        "#   This function will take a complete set of train, val, and test \n",
        "#   data and return the targets. Volitility will be calculated over \n",
        "#   the 24 5min incriments. The Target shift is looking at 2 hours \n",
        "#   shift from current time\n",
        "\n",
        "#   shift_2hour = The amount of time the data interval take to equal 2 hours \n",
        "#                 (i.e. 5 min data interval is equal to 24)\n",
        "#   alph = The alpha value for calculating the shift in price\n",
        "#   volity_int = the number of incriments used to calculate volitility \n",
        "#   \"\"\"\n",
        "\n",
        "#   target_close_list =[]\n",
        "\n",
        "#   for arr in obs_array:\n",
        "#     target_close_list.append(arr[3][-1])\n",
        "  \n",
        "#   target_close_df = pd.DataFrame()\n",
        "#   target_close_df[\"Close\"] = target_close_list\n",
        "\n",
        "#   target_close_df[\"Volitility\"] = target_close_df[\"Close\"].rolling(volity_int).std()\n",
        "\n",
        "#   # print(len(volatility), len(target_close_df[\"Close\"]))\n",
        "\n",
        "  \n",
        "#   targets = [0] * len(target_close_df.Close)\n",
        "\n",
        "#   targets = np.where(target_close_df.Close.shift() >= (target_close_df.Close * (1 + alph * target_close_df[\"Volitility\"])), \n",
        "#            2, targets)\n",
        "  \n",
        "#   targets = np.where(target_close_df.Close.shift() <= (target_close_df.Close * (1 - alph * target_close_df[\"Volitility\"])), \n",
        "#            1, targets)\n",
        "\n",
        "#   return targets\n",
        "\n",
        "\n",
        "#####DISREGUARD THE VOLITLITY######\n",
        "# def buildTargets(obs_array,  \n",
        "#                  alph = .55, \n",
        "#                  volity_int = 10):\n",
        "\n",
        "#   \"\"\" \n",
        "#   This function will take a complete set of train, val, and test \n",
        "#   data and return the targets. Volitility will be calculated over \n",
        "#   the 24 5min incriments. The Target shift is looking at 2 hours \n",
        "#   shift from current time\n",
        "\n",
        "#   shift_2hour = The amount of time the data interval take to equal 2 hours \n",
        "#                 (i.e. 5 min data interval is equal to 24)\n",
        "#   alph = The alpha value for calculating the shift in price\n",
        "#   volity_int = the number of incriments used to calculate volitility \n",
        "#   \"\"\"\n",
        "\n",
        "#   target_close_list =[]\n",
        "\n",
        "#   for arr in obs_array:\n",
        "#     target_close_list.append(arr[3][-1])\n",
        "  \n",
        "#   target_close_df = pd.DataFrame()\n",
        "#   target_close_df[\"Close\"] = target_close_list\n",
        "\n",
        "#   target_close_df[\"Volitility\"] = target_close_df[\"Close\"].rolling(volity_int).std()\n",
        "  \n",
        "#   targets = [0] * len(target_close_df.Close)\n",
        "\n",
        "#   targets = np.where(target_close_df.Close.shift(-1) >= (target_close_df.Close * (1 + alph)), \n",
        "#            2, targets)\n",
        "  \n",
        "#   targets = np.where(target_close_df.Close.shift(-1) <= (target_close_df.Close * (1 - alph)), \n",
        "#            1, targets)\n",
        "\n",
        "#   return targets\n",
        "\n",
        "  #####Binary Class######\n",
        "def buildTargets(obs_array,  \n",
        "                 alph = .55, \n",
        "                 volity_int = 10):\n",
        "\n",
        "  \"\"\" \n",
        "  This function will take a complete set of train, val, and test \n",
        "  data and return the targets. Volitility will be calculated over \n",
        "  the 24 5min incriments. The Target shift is looking at 2 hours \n",
        "  shift from current time\n",
        "\n",
        "  shift_2hour = The amount of time the data interval take to equal 2 hours \n",
        "                (i.e. 5 min data interval is equal to 24)\n",
        "  alph = The alpha value for calculating the shift in price\n",
        "  volity_int = the number of incriments used to calculate volitility \n",
        "  \"\"\"\n",
        "\n",
        "  target_close_list =[]\n",
        "\n",
        "  for arr in obs_array:\n",
        "    target_close_list.append(arr[3][-1])\n",
        "  \n",
        "  target_close_df = pd.DataFrame()\n",
        "  target_close_df[\"Close\"] = target_close_list\n",
        "\n",
        "  target_close_df[\"Volitility\"] = target_close_df[\"Close\"].rolling(volity_int).std()\n",
        "\n",
        "  # print(len(volatility), len(target_close_df[\"Close\"]))\n",
        "\n",
        "  \n",
        "  targets = [0] * len(target_close_df.Close)\n",
        "\n",
        "  targets = np.where(target_close_df.Close.shift() >= (target_close_df.Close * (1 + alph)), \n",
        "           1, targets)\n",
        "\n",
        "  return targets"
      ],
      "metadata": {
        "id": "Pe89LdnsLltO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "volity_val = 10\n",
        "alph = .001\n",
        "y_train_pre_final = buildTargets(X_train_pre_final, alph=alph,  volity_int = volity_val)\n",
        "y_val_pre_final = buildTargets(X_val_pre_final, alph=alph, volity_int = volity_val)\n",
        "y_test_pre_final = buildTargets(X_test_pre_final, alph=alph, volity_int = volity_val)"
      ],
      "metadata": {
        "id": "4aYPOa7INyAl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_class_distribution(obj):\n",
        "#     count_dict = {\n",
        "#         \"up\": 0,\n",
        "#         \"flat\": 0,\n",
        "#         \"down\": 0,\n",
        "#     }\n",
        "    \n",
        "#     for i in obj:\n",
        "#         if i == 2: \n",
        "#             count_dict['up'] += 1\n",
        "#         elif i == 1: \n",
        "#             count_dict['down'] += 1\n",
        "#         elif i == 0: \n",
        "#             count_dict['flat'] += 1             \n",
        "#         else:\n",
        "#             print(\"Check classes.\")\n",
        "            \n",
        "#     return count_dict\n",
        "\n",
        "##### BINARY v\n",
        "def get_class_distribution(obj):\n",
        "    count_dict = {\n",
        "        \"up\": 0,\n",
        "        \"down\": 0,\n",
        "    }\n",
        "    \n",
        "    for i in obj:\n",
        "        if i == 1: \n",
        "            count_dict['up'] += 1\n",
        "        elif i == 0: \n",
        "            count_dict['down'] += 1            \n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "            \n",
        "    return count_dict"
      ],
      "metadata": {
        "id": "vWIY2rwEYCfM"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25,7))\n",
        "# Train\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_train_pre_final)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')\n",
        "# Validation\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_val_pre_final)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
        "# Test\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_test_pre_final)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[2]).set_title('Class Distribution in Test Set')"
      ],
      "metadata": {
        "id": "-BsVCfr8YCiX",
        "outputId": "b457e087-98ec-4154-91d5-59c77a61163b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution in Test Set')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createFinalData_RemoveLateAfternoonData(arr, labels):\n",
        "\n",
        "  assert arr.shape[0] == len(labels), \"X data do not match length of y labels\"\n",
        "\n",
        "  step_count = 0\n",
        "  filtered_y_labels = []\n",
        "\n",
        "  for i in range(arr.shape[0]):\n",
        "\n",
        "    if i == 0:\n",
        "      final_arr = arr[i]\n",
        "      filtered_y_labels.append(labels[i])\n",
        "      #print(f'Appending index {i}, step_count: {step_count}')\n",
        "      step_count += 1\n",
        "\n",
        "    elif i == 1:\n",
        "\n",
        "      final_arr = np.stack((final_arr, arr[i]))\n",
        "      filtered_y_labels.append(labels[i])\n",
        "      step_count += 1\n",
        "\n",
        "    elif step_count == 0: \n",
        "      final_arr = np.vstack((final_arr, arr[i][None]))\n",
        "      filtered_y_labels.append(labels[i])\n",
        "      #print(f'Appending index {i}, step_count: {step_count}')\n",
        "      step_count += 1\n",
        "    \n",
        "    elif (step_count) % 5 == 0:\n",
        "      #print(f'skipping {i} array, step_count: {step_count}')\n",
        "      step_count += 1\n",
        "\n",
        "    elif (step_count) % 6 == 0:\n",
        "      #print(f'skipping {i} array, step_count: {step_count}')\n",
        "      step_count += 1\n",
        "\n",
        "    elif (step_count) % 7 == 0:\n",
        "      #print(f'skipping {i} array, step_count: {step_count}')\n",
        "      step_count = 0\n",
        "    \n",
        "    else:\n",
        "      final_arr = np.vstack((final_arr, arr[i][None]))\n",
        "      filtered_y_labels.append(labels[i])\n",
        "      #print(f'Appending index {i}, step_count: {step_count}')\n",
        "      step_count += 1\n",
        "  \n",
        "  return final_arr, filtered_y_labels\n",
        "\n",
        "X_train, y_train = createFinalData_RemoveLateAfternoonData(X_train_pre_final, y_train_pre_final)\n",
        "X_val, y_val = createFinalData_RemoveLateAfternoonData(X_val_pre_final, y_val_pre_final)\n",
        "X_test, y_test = createFinalData_RemoveLateAfternoonData(X_test_pre_final, y_test_pre_final)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "1XdpMcVCo2_b"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check it arrays are made correctly\n",
        "train[12:58]"
      ],
      "metadata": {
        "id": "ZyvritE4qPNR",
        "outputId": "d5fa4a76-bd4d-4f45-96a8-3144d977c644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f13a6cd8-488f-43fe-bccb-93261d8e9c2d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeWeightedAvgPrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:30:00-05:00</th>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>6.8500</td>\n",
              "      <td>400.0</td>\n",
              "      <td>6.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:35:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>926.0</td>\n",
              "      <td>6.834331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:40:00-05:00</th>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:45:00-05:00</th>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:50:00-05:00</th>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:55:00-05:00</th>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>6.8301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:00:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>1174.0</td>\n",
              "      <td>6.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:05:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>300.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:10:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:15:00-05:00</th>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.843400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:20:00-05:00</th>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:25:00-05:00</th>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:30:00-05:00</th>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>6.8434</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:35:00-05:00</th>\n",
              "      <td>6.8237</td>\n",
              "      <td>6.8237</td>\n",
              "      <td>6.8237</td>\n",
              "      <td>6.8237</td>\n",
              "      <td>200.0</td>\n",
              "      <td>6.823700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:40:00-05:00</th>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>400.0</td>\n",
              "      <td>6.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:45:00-05:00</th>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:50:00-05:00</th>\n",
              "      <td>6.8443</td>\n",
              "      <td>6.8443</td>\n",
              "      <td>6.8443</td>\n",
              "      <td>6.8443</td>\n",
              "      <td>500.0</td>\n",
              "      <td>6.844300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:55:00-05:00</th>\n",
              "      <td>6.8499</td>\n",
              "      <td>6.8499</td>\n",
              "      <td>6.8499</td>\n",
              "      <td>6.8499</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.849900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:00:00-05:00</th>\n",
              "      <td>6.8499</td>\n",
              "      <td>6.8499</td>\n",
              "      <td>6.8499</td>\n",
              "      <td>6.8499</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:05:00-05:00</th>\n",
              "      <td>6.8499</td>\n",
              "      <td>6.8499</td>\n",
              "      <td>6.8499</td>\n",
              "      <td>6.8499</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:10:00-05:00</th>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>1171.0</td>\n",
              "      <td>6.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:15:00-05:00</th>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>6.820100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:20:00-05:00</th>\n",
              "      <td>6.8200</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8200</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>3129.0</td>\n",
              "      <td>6.830320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:25:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:30:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:35:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:40:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:45:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:50:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:55:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:00:00-05:00</th>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>200.0</td>\n",
              "      <td>6.838300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:05:00-05:00</th>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:10:00-05:00</th>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:15:00-05:00</th>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:20:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>500.0</td>\n",
              "      <td>6.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:25:00-05:00</th>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>400.0</td>\n",
              "      <td>6.847400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:30:00-05:00</th>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:35:00-05:00</th>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:40:00-05:00</th>\n",
              "      <td>6.8242</td>\n",
              "      <td>6.8242</td>\n",
              "      <td>6.8200</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>800.0</td>\n",
              "      <td>6.822125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:45:00-05:00</th>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:50:00-05:00</th>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:55:00-05:00</th>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 14:00:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>6.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 14:05:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 14:10:00-05:00</th>\n",
              "      <td>6.8437</td>\n",
              "      <td>6.8437</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>400.0</td>\n",
              "      <td>6.840925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 14:15:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f13a6cd8-488f-43fe-bccb-93261d8e9c2d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f13a6cd8-488f-43fe-bccb-93261d8e9c2d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f13a6cd8-488f-43fe-bccb-93261d8e9c2d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             Open    High     Low   Close  Volume  \\\n",
              "Time                                                                \n",
              "2016-12-20 10:30:00-05:00  6.8500  6.8500  6.8500  6.8500   400.0   \n",
              "2016-12-20 10:35:00-05:00  6.8400  6.8400  6.8300  6.8301   926.0   \n",
              "2016-12-20 10:40:00-05:00  6.8301  6.8301  6.8301  6.8301     0.0   \n",
              "2016-12-20 10:45:00-05:00  6.8301  6.8301  6.8301  6.8301     0.0   \n",
              "2016-12-20 10:50:00-05:00  6.8301  6.8301  6.8301  6.8301     0.0   \n",
              "2016-12-20 10:55:00-05:00  6.8301  6.8301  6.8301  6.8301     0.0   \n",
              "2016-12-20 11:00:00-05:00  6.8400  6.8400  6.8400  6.8400  1174.0   \n",
              "2016-12-20 11:05:00-05:00  6.8400  6.8400  6.8400  6.8400   300.0   \n",
              "2016-12-20 11:10:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 11:15:00-05:00  6.8434  6.8434  6.8434  6.8434   100.0   \n",
              "2016-12-20 11:20:00-05:00  6.8434  6.8434  6.8434  6.8434     0.0   \n",
              "2016-12-20 11:25:00-05:00  6.8434  6.8434  6.8434  6.8434     0.0   \n",
              "2016-12-20 11:30:00-05:00  6.8434  6.8434  6.8434  6.8434     0.0   \n",
              "2016-12-20 11:35:00-05:00  6.8237  6.8237  6.8237  6.8237   200.0   \n",
              "2016-12-20 11:40:00-05:00  6.8300  6.8300  6.8300  6.8300   400.0   \n",
              "2016-12-20 11:45:00-05:00  6.8300  6.8300  6.8300  6.8300     0.0   \n",
              "2016-12-20 11:50:00-05:00  6.8443  6.8443  6.8443  6.8443   500.0   \n",
              "2016-12-20 11:55:00-05:00  6.8499  6.8499  6.8499  6.8499   300.0   \n",
              "2016-12-20 12:00:00-05:00  6.8499  6.8499  6.8499  6.8499     0.0   \n",
              "2016-12-20 12:05:00-05:00  6.8499  6.8499  6.8499  6.8499     0.0   \n",
              "2016-12-20 12:10:00-05:00  6.8300  6.8300  6.8300  6.8300  1171.0   \n",
              "2016-12-20 12:15:00-05:00  6.8201  6.8201  6.8201  6.8201  5000.0   \n",
              "2016-12-20 12:20:00-05:00  6.8200  6.8400  6.8200  6.8400  3129.0   \n",
              "2016-12-20 12:25:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 12:30:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 12:35:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 12:40:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 12:45:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 12:50:00-05:00  6.8400  6.8400  6.8400  6.8400   100.0   \n",
              "2016-12-20 12:55:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 13:00:00-05:00  6.8383  6.8383  6.8383  6.8383   200.0   \n",
              "2016-12-20 13:05:00-05:00  6.8383  6.8383  6.8383  6.8383     0.0   \n",
              "2016-12-20 13:10:00-05:00  6.8383  6.8383  6.8383  6.8383     0.0   \n",
              "2016-12-20 13:15:00-05:00  6.8383  6.8383  6.8383  6.8383     0.0   \n",
              "2016-12-20 13:20:00-05:00  6.8400  6.8400  6.8400  6.8400   500.0   \n",
              "2016-12-20 13:25:00-05:00  6.8474  6.8474  6.8474  6.8474   400.0   \n",
              "2016-12-20 13:30:00-05:00  6.8474  6.8474  6.8474  6.8474     0.0   \n",
              "2016-12-20 13:35:00-05:00  6.8474  6.8474  6.8474  6.8474     0.0   \n",
              "2016-12-20 13:40:00-05:00  6.8242  6.8242  6.8200  6.8201   800.0   \n",
              "2016-12-20 13:45:00-05:00  6.8201  6.8201  6.8201  6.8201     0.0   \n",
              "2016-12-20 13:50:00-05:00  6.8201  6.8201  6.8201  6.8201     0.0   \n",
              "2016-12-20 13:55:00-05:00  6.8201  6.8201  6.8201  6.8201     0.0   \n",
              "2016-12-20 14:00:00-05:00  6.8400  6.8400  6.8400  6.8400  1700.0   \n",
              "2016-12-20 14:05:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 14:10:00-05:00  6.8437  6.8437  6.8400  6.8400   400.0   \n",
              "2016-12-20 14:15:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "\n",
              "                           VolumeWeightedAvgPrice  \n",
              "Time                                               \n",
              "2016-12-20 10:30:00-05:00                6.850000  \n",
              "2016-12-20 10:35:00-05:00                6.834331  \n",
              "2016-12-20 10:40:00-05:00                0.000000  \n",
              "2016-12-20 10:45:00-05:00                0.000000  \n",
              "2016-12-20 10:50:00-05:00                0.000000  \n",
              "2016-12-20 10:55:00-05:00                0.000000  \n",
              "2016-12-20 11:00:00-05:00                6.840000  \n",
              "2016-12-20 11:05:00-05:00                0.000000  \n",
              "2016-12-20 11:10:00-05:00                0.000000  \n",
              "2016-12-20 11:15:00-05:00                6.843400  \n",
              "2016-12-20 11:20:00-05:00                0.000000  \n",
              "2016-12-20 11:25:00-05:00                0.000000  \n",
              "2016-12-20 11:30:00-05:00                0.000000  \n",
              "2016-12-20 11:35:00-05:00                6.823700  \n",
              "2016-12-20 11:40:00-05:00                6.830000  \n",
              "2016-12-20 11:45:00-05:00                0.000000  \n",
              "2016-12-20 11:50:00-05:00                6.844300  \n",
              "2016-12-20 11:55:00-05:00                6.849900  \n",
              "2016-12-20 12:00:00-05:00                0.000000  \n",
              "2016-12-20 12:05:00-05:00                0.000000  \n",
              "2016-12-20 12:10:00-05:00                6.830000  \n",
              "2016-12-20 12:15:00-05:00                6.820100  \n",
              "2016-12-20 12:20:00-05:00                6.830320  \n",
              "2016-12-20 12:25:00-05:00                0.000000  \n",
              "2016-12-20 12:30:00-05:00                0.000000  \n",
              "2016-12-20 12:35:00-05:00                0.000000  \n",
              "2016-12-20 12:40:00-05:00                0.000000  \n",
              "2016-12-20 12:45:00-05:00                0.000000  \n",
              "2016-12-20 12:50:00-05:00                6.840000  \n",
              "2016-12-20 12:55:00-05:00                0.000000  \n",
              "2016-12-20 13:00:00-05:00                6.838300  \n",
              "2016-12-20 13:05:00-05:00                0.000000  \n",
              "2016-12-20 13:10:00-05:00                0.000000  \n",
              "2016-12-20 13:15:00-05:00                0.000000  \n",
              "2016-12-20 13:20:00-05:00                6.840000  \n",
              "2016-12-20 13:25:00-05:00                6.847400  \n",
              "2016-12-20 13:30:00-05:00                0.000000  \n",
              "2016-12-20 13:35:00-05:00                0.000000  \n",
              "2016-12-20 13:40:00-05:00                6.822125  \n",
              "2016-12-20 13:45:00-05:00                0.000000  \n",
              "2016-12-20 13:50:00-05:00                0.000000  \n",
              "2016-12-20 13:55:00-05:00                0.000000  \n",
              "2016-12-20 14:00:00-05:00                6.840000  \n",
              "2016-12-20 14:05:00-05:00                0.000000  \n",
              "2016-12-20 14:10:00-05:00                6.840925  \n",
              "2016-12-20 14:15:00-05:00                0.000000  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(threshold=200)\n",
        "y_train_pre_final[50:75]"
      ],
      "metadata": {
        "id": "Bi-1VYrmn0Eb",
        "outputId": "73f540db-bbe6-428c-9951-438bee17f3c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# Code fro scaling at a later date\n",
        "######\n",
        "\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scalers = {}\n",
        "for i in range(X_train.shape[1]):\n",
        "    scalers[i] = StandardScaler()\n",
        "    X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :]) \n",
        "\n",
        "for i in range(X_val.shape[1]):\n",
        "    X_val[:, i, :] = scalers[i].transform(X_val[:, i, :]) \n",
        "\n",
        "for i in range(X_test.shape[1]):\n",
        "    X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) \n",
        "    "
      ],
      "metadata": {
        "id": "xPkrkhqV4Ef-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_class_distribution(obj):\n",
        "#     count_dict = {\n",
        "#         \"up\": 0,\n",
        "#         \"flat\": 0,\n",
        "#         \"down\": 0,\n",
        "#     }\n",
        "    \n",
        "#     for i in obj:\n",
        "#         if i == 2: \n",
        "#             count_dict['up'] += 1\n",
        "#         elif i == 1: \n",
        "#             count_dict['down'] += 1\n",
        "#         elif i == 0: \n",
        "#             count_dict['flat'] += 1             \n",
        "#         else:\n",
        "#             print(\"Check classes.\")\n",
        "            \n",
        "#     return count_dict\n",
        "\n",
        "##### BINARY v\n",
        "def get_class_distribution(obj):\n",
        "    count_dict = {\n",
        "        \"up\": 0,\n",
        "        \"down\": 0,\n",
        "    }\n",
        "    \n",
        "    for i in obj:\n",
        "        if i == 1: \n",
        "            count_dict['up'] += 1\n",
        "        elif i == 0: \n",
        "            count_dict['down'] += 1            \n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "            \n",
        "    return count_dict"
      ],
      "metadata": {
        "id": "kNH38ORXLGfn"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25,7))\n",
        "# Train\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_train)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')\n",
        "# Validation\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_val)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
        "# Test\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_test)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[2]).set_title('Class Distribution in Test Set')"
      ],
      "metadata": {
        "outputId": "10fee64d-f81e-4117-a844-584339db9448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "qqTz9-J7LGft"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution in Test Set')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras TCN"
      ],
      "metadata": {
        "id": "Y0TppU3kxLjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "X_train_1d = X_train.reshape(X_train.shape[0], \n",
        "                            X_train.shape[1], \n",
        "                            X_train.shape[2],\n",
        "                            )\n",
        "X_val_1d = X_val.reshape(X_val.shape[0],\n",
        "                          X_val.shape[1], \n",
        "                          X_val.shape[2],\n",
        "                          )\n",
        "X_test_1d = X_test.reshape(X_test.shape[0],\n",
        "                          X_test.shape[1], \n",
        "                          X_test.shape[2],\n",
        "                          )\n",
        "\n",
        "y_train = to_categorical(y_train, 2)\n",
        "y_val = to_categorical(y_val, 2)\n",
        "y_test = to_categorical(y_test, 2)\n",
        "\n",
        "print(f'X Train Length {X_train_1d.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val_1d.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test_1d.shape}, y Test Label Length {y_test.shape}')"
      ],
      "metadata": {
        "id": "sPIGmfTgaiEe",
        "outputId": "efa106ac-895e-4905-c380-3588e9f169a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4055, 5, 24), y Train Label Length (4055, 2)\n",
            "X Val Length (1430, 5, 24), y Val Label Length (1430, 2)\n",
            "X Test Length (1085, 5, 24), y Test Label Length (1085, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils import weight_norm\n",
        "import torch.nn.functional as F\n",
        "from TCN.tcn import TemporalConvNet\n",
        "\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "ucQ_XjJNxgLO"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
        "        super(TCN, self).__init__()\n",
        "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
        "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Inputs have to have dimension (N, C_in, L_in)\"\"\"\n",
        "        y1 = self.tcn(inputs)  # input should have dimension (N, C, L)\n",
        "        o = self.linear(y1[:, :, -1])\n",
        "        return F.log_softmax(o, dim=1)"
      ],
      "metadata": {
        "id": "KE03VmOzxj_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras LSTM"
      ],
      "metadata": {
        "id": "OnCA5sL2YIT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import concatenate, Input\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Flatten, Dense, Activation\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "ISv0sRnfbRa2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_2d = X_train.reshape(X_train.shape[0], \n",
        "                            X_train.shape[1], \n",
        "                            X_train.shape[2],\n",
        "                            1\n",
        "                            )\n",
        "X_val_2d = X_val.reshape(X_val.shape[0],\n",
        "                          X_val.shape[1], \n",
        "                          X_val.shape[2],\n",
        "                          1\n",
        "                          )\n",
        "X_test_2d = X_test.reshape(X_test.shape[0],\n",
        "                          X_test.shape[1], \n",
        "                          X_test.shape[2],\n",
        "                          1\n",
        "                          )\n",
        "\n",
        "y_train = to_categorical(y_train, 2)\n",
        "y_val = to_categorical(y_val, 2)\n",
        "y_test = to_categorical(y_test, 2)\n",
        "\n",
        "print(f'X Train Length {X_train_2d.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val_2d.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test_2d.shape}, y Test Label Length {y_test.shape}')"
      ],
      "metadata": {
        "id": "U44cUUWWbKDn",
        "outputId": "60fe05d7-9a61-47e3-80f7-3909aefb299d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4055, 5, 24, 1), y Train Label Length (4055, 2)\n",
            "X Val Length (1430, 5, 24, 1), y Val Label Length (1430, 2)\n",
            "X Test Length (1085, 5, 24, 1), y Test Label Length (1085, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Model\n",
        "from keras.layers import Input, Dense, Bidirectional\n",
        "from keras.layers.recurrent import LSTM\n",
        "import numpy as np\n",
        "# define model for simple BI-LSTM + DNN based binary classifier\n",
        "\n",
        "input_shape = Input(shape=(X_train_2d.shape[1],X_train_2d.shape[2],X_train_2d.shape[3]))\n",
        "\n",
        "def define_model(input_shape):\n",
        "    input1 = input_shape #use row and column size as input size\n",
        "    lstm1 = Bidirectional(LSTM(units=32))(input1)\n",
        "    dnn_hidden_layer1 = Dense(3, activation='relu')(lstm1)\n",
        "    dnn_output = Dense(2, activation='sigmoid')(dnn_hidden_layer1)\n",
        "    model = Model(inputs=[input1],outputs=[dnn_output])\n",
        "    # compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "# NO NEED TO RESHAPE THE DATA as it is already in 3D format\n",
        "# Call the model\n",
        "model = define_model(input_shape)\n",
        "# Fit the model\n",
        "model.fit([X_train_2d],[y_train],epochs=4,batch_size=2,verbose=1)\n",
        "# Take a test data to test the working of the model\n",
        "test_data = X_val_2d\n",
        "# predict the sigmoid output [0,1] for the 'test_data'\n",
        "pred = model.predict(test_data)\n",
        "print(\"predicted sigmoid output => \",pred)"
      ],
      "metadata": {
        "id": "c49-HIruYKbd",
        "outputId": "1cb7bd2f-d89c-44c5-a6fb-b920d34b42a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-c4477e0a6029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# NO NEED TO RESHAPE THE DATA as it is already in 3D format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Call the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_2d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-c4477e0a6029>\u001b[0m in \u001b[0;36mdefine_model\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;31m#use row and column size as input size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlstm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdnn_hidden_layer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_hidden_layer1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[1;32m    215\u001b[0m                          \u001b[0;34m'is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                          \u001b[0;34mf'expected ndim={spec.ndim}, found ndim={ndim}. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"bidirectional\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 5, 24, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QdxwcMTOYKgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "10KMe_sdYKjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras Model Parelle Conv2D"
      ],
      "metadata": {
        "id": "YP6SuhRkao27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import concatenate, Input\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Flatten, Dense, Activation\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "class CyclicLR(Callback):\n",
        "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
        "    The method cycles the learning rate between two boundaries with\n",
        "    some constant frequency.\n",
        "    # Arguments\n",
        "        base_lr: initial learning rate which is the\n",
        "            lower boundary in the cycle.\n",
        "        max_lr: upper boundary in the cycle. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore\n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size: number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch.\n",
        "        mode: one of {triangular, triangular2, exp_range}.\n",
        "            Default 'triangular'.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "        gamma: constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "        scale_fn: Custom scaling policy defined by a single\n",
        "            argument lambda function, where\n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored\n",
        "        scale_mode: {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on\n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle). Default is 'cycle'.\n",
        "    The amplitude of the cycle can be scaled on a per-iteration or\n",
        "    per-cycle basis.\n",
        "    This class has three built-in policies, as put forth in the paper.\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
        "        cycle iteration.\n",
        "    For more detail, please see paper.\n",
        "    # Example for CIFAR-10 w/ batch size 100:\n",
        "        ```python\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., mode='triangular')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "    Class also supports custom scaling functions:\n",
        "        ```python\n",
        "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., scale_fn=clr_fn,\n",
        "                                scale_mode='cycle')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "    # References\n",
        "      - [Cyclical Learning Rates for Training Neural Networks](\n",
        "      https://arxiv.org/abs/1506.01186)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            base_lr=0.001,\n",
        "            max_lr=0.006,\n",
        "            step_size=2000.,\n",
        "            mode='triangular',\n",
        "            gamma=1.,\n",
        "            scale_fn=None,\n",
        "            scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        if mode not in ['triangular', 'triangular2',\n",
        "                        'exp_range']:\n",
        "            raise KeyError(\"mode must be one of 'triangular', \"\n",
        "                            \"'triangular2', or 'exp_range'\")\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn is None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1 / (2.**(x - 1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma ** x\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "                new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr is not None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr is not None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size is not None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "\n",
        "    def clr(self):\n",
        "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr - self.base_lr) * \\\n",
        "                np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr - self.base_lr) * \\\n",
        "                np.maximum(0, (1 - x)) * self.scale_fn(self.clr_iterations)\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "        self.history.setdefault(\n",
        "            'lr', []).append(\n",
        "            K.get_value(\n",
        "                self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
      ],
      "metadata": {
        "id": "BFFvAg4varHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_2d = X_train.reshape(X_train.shape[0], \n",
        "                            X_train.shape[1], \n",
        "                            X_train.shape[2],\n",
        "                            1\n",
        "                            )\n",
        "X_val_2d = X_val.reshape(X_val.shape[0],\n",
        "                          X_val.shape[1], \n",
        "                          X_val.shape[2],\n",
        "                          1\n",
        "                          )\n",
        "X_test_2d = X_test.reshape(X_test.shape[0],\n",
        "                          X_test.shape[1], \n",
        "                          X_test.shape[2],\n",
        "                          1\n",
        "                          )\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_val = to_categorical(y_val, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "print(f'X Train Length {X_train_2d.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val_2d.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test_2d.shape}, y Test Label Length {y_test.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyMN3AS0a_78",
        "outputId": "8440d3cb-35ea-4566-f965-37b9de927702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4055, 5, 24, 1), y Train Label Length (4055, 3)\n",
            "X Val Length (1430, 5, 24, 1), y Val Label Length (1430, 3)\n",
            "X Test Length (1065, 5, 24, 1), y Test Label Length (1065, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create model\n",
        "\n",
        "def create_convnet(img_path='network_image.png'):\n",
        "    input_shape = Input(shape=(X_train_2d.shape[1],X_train_2d.shape[2],X_train_2d.shape[3]))\n",
        "\n",
        "    tower_1 = Convolution2D(filters=32, kernel_size=(1, 3), strides=(1, 1), padding='same', activation='relu')(input_shape)\n",
        "    tower_1 = MaxPooling2D(pool_size=(1, 3), strides=(1, 1), padding='same')(tower_1)\n",
        "    tower_1 = Dropout(0.5)(tower_1)\n",
        "\n",
        "    tower_2 = Convolution2D(filters=32, kernel_size=(1, 6), strides=(1, 1), padding='same', activation='relu')(input_shape)\n",
        "    tower_2 = MaxPooling2D(pool_size=(1, 1), strides=(1, 1), padding='same')(tower_2)\n",
        "    tower_2 = Dropout(0.5)(tower_2)\n",
        "\n",
        "    tower_3 = Convolution2D(filters=32, kernel_size=(1, 12), strides=(1, 1), padding='same', activation='relu')(input_shape)\n",
        "    tower_3 = MaxPooling2D(pool_size=(1, 1), strides=(1, 1), padding='same')(tower_3)\n",
        "    tower_3 = Dropout(0.5)(tower_3)\n",
        "\n",
        "    merged = concatenate([tower_1, tower_2, tower_3], axis=1)\n",
        "    merged = Flatten()(merged)\n",
        "\n",
        "    out = Dense(1000, activation='relu')(merged)\n",
        "    out = Dense(500, activation='relu')(out)\n",
        "    out = Dense(3, activation='softmax')(out)\n",
        "\n",
        "    model = Model(input_shape, out)\n",
        "    plot_model(model, to_file=img_path)\n",
        "    return model\n",
        "\n",
        "model = create_convnet(img_path='network_image.png')\n",
        "\n",
        "print(model.summary())\n",
        "plot_model(model, to_file=f'model_plot_{date}.png', show_shapes=True, show_layer_names=True, show_dtype=True, show_layer_activations=True)\n",
        "\n",
        "adam = Adam(learning_rate=0.001, decay=0.0001)\n",
        "nadam = Nadam(learning_rate=0.002, schedule_decay=0.004)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"]) \n",
        "\n",
        "batch_size = 12\n",
        "\n",
        "clr = CyclicLR()\n",
        "callback = EarlyStopping(monitor='loss', patience=5)\n",
        "hist = model.fit(X_train_2d, y_train, batch_size=batch_size, epochs=10, callbacks=[clr, callback], validation_data=(X_val_2d, y_val)) #, class_weight={0:1, 1:1.5, 2:1.5})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ggxSbEJbBzK",
        "outputId": "689b549a-f119-4fed-92bd-f031b8ea91c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 5, 24, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 5, 24, 32)    128         ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 5, 24, 32)    224         ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 5, 24, 32)    416         ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d_19 (MaxPooling2D  (None, 5, 24, 32)   0           ['conv2d_20[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_20 (MaxPooling2D  (None, 5, 24, 32)   0           ['conv2d_21[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_21 (MaxPooling2D  (None, 5, 24, 32)   0           ['conv2d_22[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 5, 24, 32)    0           ['max_pooling2d_19[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 5, 24, 32)    0           ['max_pooling2d_20[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 5, 24, 32)    0           ['max_pooling2d_21[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 15, 24, 32)   0           ['dropout_18[0][0]',             \n",
            "                                                                  'dropout_19[0][0]',             \n",
            "                                                                  'dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 11520)        0           ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 1000)         11521000    ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 500)          500500      ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 3)            1503        ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 12,023,771\n",
            "Trainable params: 12,023,771\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "332/338 [============================>.] - ETA: 0s - loss: 1.1306 - accuracy: 0.4566"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  \n",
        "  # model_name = f'cdt2d_model_{date}'\n",
        "  # model.save(f'models/{model_name}')\n",
        "\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(hist.history['loss'], label='train loss')\n",
        "  plt.plot(hist.history['val_loss'], label='val loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(f'plots/LossVal_loss_{date}.png')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(hist.history['accuracy'], label='train acc')\n",
        "  plt.plot(hist.history['val_accuracy'], label='val acc')\n",
        "  plt.legend()\n",
        "  plt.savefig(f'plots/AccVal_acc_{date}.png')\n",
        "  plt.show()\n",
        "  \n",
        "  y_pred = model.predict(X_test_2d)\n",
        "  \n",
        "  # Calculate the accuracy\n",
        "  test_preds = np.argmax(y_pred, axis=1)\n",
        "  y_true = np.argmax(y_test, axis=1)\n",
        "  test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "\n",
        "  # Recall for each class\n",
        "  recall_vals = []\n",
        "  for i in range(3):\n",
        "      class_idx = np.argwhere(y_true==i)\n",
        "      total = len(class_idx)\n",
        "      correct = np.sum(test_preds[class_idx]==i)\n",
        "      recall = correct / total\n",
        "      recall_vals.append(recall)\n",
        "\n",
        "  classes = [0,1,2]\n",
        "  # Calculate the test set accuracy and recall for each class\n",
        "  print('Test set accuracy is {:.3f}'.format(test_acc))\n",
        "  for i in range(3):\n",
        "      print('For class {}, recall is {:.3f}'.format(classes[i],recall_vals[i]))\n",
        "\n",
        "  print(\"Accuracy is {:.3f}\".format(test_acc))\n",
        "  # print(\"Weighted F score is {:.3f}\".format(calculate_weighted_f_score(y_true, y_pred)))\n",
        "  \n",
        "  def plot_confusion_matrix(cm,\n",
        "                            target_names,\n",
        "                            title='Confusion matrix',\n",
        "                            cmap=None,\n",
        "                            normalize=True):\n",
        "      \"\"\"\n",
        "      given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "      Arguments\n",
        "      ---------\n",
        "      cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "      target_names: given classification classes such as [0, 1, 2]\n",
        "                    the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "      title:        the text to display at the top of the matrix\n",
        "\n",
        "      cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                    see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                    plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "      normalize:    If False, plot the raw numbers\n",
        "                    If True, plot the proportions\n",
        "\n",
        "      Usage\n",
        "      -----\n",
        "      plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                                # sklearn.metrics.confusion_matrix\n",
        "                            normalize    = True,                # show proportions\n",
        "                            target_names = y_labels_vals,       # list of names of the classes\n",
        "                            title        = best_estimator_name) # title of graph\n",
        "\n",
        "      Citiation\n",
        "      ---------\n",
        "      http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "      import itertools\n",
        "\n",
        "      accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "      misclass = 1 - accuracy\n",
        "\n",
        "      if cmap is None:\n",
        "          cmap = plt.get_cmap('Blues')\n",
        "\n",
        "      plt.figure(figsize=(8, 6))\n",
        "      plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "      plt.title(title)\n",
        "      plt.colorbar()\n",
        "\n",
        "      if target_names is not None:\n",
        "          tick_marks = np.arange(len(target_names))\n",
        "          plt.xticks(tick_marks, target_names, rotation=45)\n",
        "          plt.yticks(tick_marks, target_names)\n",
        "\n",
        "      if normalize:\n",
        "          cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "      thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "      for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "          if normalize:\n",
        "              plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                        horizontalalignment=\"center\",\n",
        "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "          else:\n",
        "              plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                        horizontalalignment=\"center\",\n",
        "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.ylabel('True label')\n",
        "      plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "      plt.savefig(f'plots/Confusion_{date}.png')\n",
        "      plt.show()\n",
        "\n",
        "  def calculate_weighted_f_score(y_true, y_pred):\n",
        "      test_preds = np.argmax(y_pred, axis=-1)\n",
        "      Ntu = sum((test_preds == 2) & (y_true == 2))\n",
        "      Ntd = sum((test_preds == 1) & (y_true == 1))\n",
        "      Ntf = sum((test_preds == 0) & (y_true == 0))\n",
        "      Ewutd = sum((test_preds == 2) & (y_true == 1))\n",
        "      Ewdtu = sum((test_preds == 1) & (y_true == 2))\n",
        "      Ewutf = sum((test_preds == 2) & (y_true == 0))\n",
        "      Ewdtf = sum((test_preds == 1) & (y_true == 0))\n",
        "      Ewftu = sum((test_preds == 0) & (y_true == 2))\n",
        "      Ewftd = sum((test_preds == 0) & (y_true == 1))\n",
        "\n",
        "      beta_1 = 0.5\n",
        "      beta_2 = 0.125\n",
        "      beta_3 = 0.125\n",
        "\n",
        "      Ntp = Ntu + Ntd + beta_3**2 * Ntf\n",
        "      E1 = Ewutd + Ewdtu\n",
        "      E2 = Ewutf + Ewdtf\n",
        "      E3 = Ewftu + Ewftd\n",
        "\n",
        "      F = (1 + beta_1**2 + beta_2**2) * Ntp / ((1+beta_1**2+beta_2**2) * Ntp + E1 + beta_1**2 * E2 + beta_2**2 * E3)\n",
        "      return  F\n",
        "\n",
        " \n",
        "  print(f'Weight CDT F Score: {calculate_weighted_f_score(y_true, y_pred)}')\n",
        "  \n",
        "  nb_classes = 3\n",
        "\n",
        "  # Confusion matrix\n",
        "  conf_mat=confusion_matrix(y_true, np.argmax(y_pred, axis=-1))\n",
        "  \n",
        "  plot_confusion_matrix(conf_mat, [\"flat\",\"down\",\"up\"])\n",
        "\n",
        "  precision_score(y_true, np.argmax(y_pred, axis=-1), average='weighted')\n",
        "  \n",
        "  print(classification_report(y_true, np.argmax(y_pred, axis=-1), target_names=[\"flat\",\"down\", \"up\"], digits=4))"
      ],
      "metadata": {
        "id": "WL81xLUDa6mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V3ARLrnGarS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NCWk92ukYGgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xa7Rsrz9YGdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xsf-zToLarWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MPZ_wt4UaraU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keras Model Conv2D"
      ],
      "metadata": {
        "id": "L5x9jWH_L6nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Flatten, Dense, Activation\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n"
      ],
      "metadata": {
        "id": "26CyV_XvOgVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### ONLY EXECUTE FOR KERAS 2D CNN #####\n",
        "\n",
        "X_train_2d = X_train.reshape(X_train.shape[0], \n",
        "                          X_train.shape[1], \n",
        "                          X_train.shape[2],\n",
        "                          1\n",
        "                          )\n",
        "X_val_2d = X_val.reshape(X_val.shape[0],\n",
        "                          X_val.shape[1], \n",
        "                          X_val.shape[2],\n",
        "                          1\n",
        "                          )\n",
        "X_test_2d = X_test.reshape(X_test.shape[0],\n",
        "                          X_test.shape[1], \n",
        "                          X_test.shape[2],\n",
        "                          1\n",
        "                          )"
      ],
      "metadata": {
        "id": "Hc2wmJbsL-lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_val = to_categorical(y_val, 3)\n",
        "y_test = to_categorical(y_test, 3)"
      ],
      "metadata": {
        "id": "DCG85tZ1L-xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X Train Length {X_train_2d.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val_2d.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test_2d.shape}, y Test Label Length {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeoTjcx5L-s5",
        "outputId": "1909e0ab-736a-48a2-f4b8-9bb98827519c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4055, 5, 24, 1), y Train Label Length (4055, 3)\n",
            "X Val Length (1430, 5, 24, 1), y Val Label Length (1430, 3)\n",
            "X Test Length (1040, 5, 24, 1), y Test Label Length (1040, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_format='channels_first'\n",
        "#Create model\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(filters=32, kernel_size=(1, 4), padding='same', activation='relu', input_shape=(X_train_2d.shape[1],X_train_2d.shape[2],X_train_2d.shape[3])))\n",
        "model.add(MaxPooling2D(pool_size=(1,4), strides=(1, 4), padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Convolution2D(filters=64, kernel_size=(1,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1,3), strides=(1, 3), padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Convolution2D(filters=128, kernel_size=(1,2), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dense(500,activation=\"relu\"))\n",
        "model.add(Dense(3,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-fjU2wxL-1j",
        "outputId": "3842b9ce-98ae-481d-e835-337aa647da07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 5, 24, 32)         160       \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 5, 6, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 5, 6, 32)          0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 5, 6, 64)          6208      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 5, 2, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 5, 2, 64)          0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 5, 2, 128)         16512     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 5, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 5, 1, 128)         0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 640)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1000)              641000    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 3)                 1503      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,165,883\n",
            "Trainable params: 1,165,883\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001, decay=0.0001)\n",
        "nadam = Nadam(learning_rate=0.002, schedule_decay=0.004)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"]) "
      ],
      "metadata": {
        "id": "I7rjbRGgQqKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 12\n",
        "hist = model.fit(X_train_2d, y_train, batch_size=batch_size, epochs=350, validation_data=(X_val_2d, y_val)) #, class_weight={0:1, 1:1.5})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3d2512-b612-4080-bb81-107e458dfa5e",
        "id": "nKnSxLyGQqKm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/350\n",
            "338/338 [==============================] - 9s 21ms/step - loss: 1.1181 - accuracy: 0.3988 - val_loss: 1.0789 - val_accuracy: 0.4210\n",
            "Epoch 2/350\n",
            "338/338 [==============================] - 7s 20ms/step - loss: 1.0796 - accuracy: 0.4197 - val_loss: 1.0738 - val_accuracy: 0.4189\n",
            "Epoch 3/350\n",
            "338/338 [==============================] - 7s 20ms/step - loss: 1.0775 - accuracy: 0.4229 - val_loss: 1.0732 - val_accuracy: 0.4182\n",
            "Epoch 4/350\n",
            "338/338 [==============================] - 7s 21ms/step - loss: 1.0739 - accuracy: 0.4266 - val_loss: 1.0721 - val_accuracy: 0.4189\n",
            "Epoch 5/350\n",
            "338/338 [==============================] - 8s 25ms/step - loss: 1.0715 - accuracy: 0.4252 - val_loss: 1.0666 - val_accuracy: 0.4175\n",
            "Epoch 6/350\n",
            "338/338 [==============================] - 7s 21ms/step - loss: 1.0744 - accuracy: 0.4192 - val_loss: 1.0659 - val_accuracy: 0.4203\n",
            "Epoch 7/350\n",
            " 39/338 [==>...........................] - ETA: 5s - loss: 1.0857 - accuracy: 0.4060"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['loss'], label='train loss')\n",
        "plt.plot(hist.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')"
      ],
      "metadata": {
        "id": "HaiFRJBaRXAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'], label='train acc')\n",
        "plt.plot(hist.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "metadata": {
        "id": "2S1lgtOARXAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_2d)"
      ],
      "metadata": {
        "id": "ylr2HaMKRXAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "FkTepZ32Ui5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy\n",
        "test_preds = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "\n",
        "# Recall for each class\n",
        "recall_vals = []\n",
        "for i in range(3):\n",
        "    class_idx = np.argwhere(y_true==i)\n",
        "    total = len(class_idx)\n",
        "    correct = np.sum(test_preds[class_idx]==i)\n",
        "    recall = correct / total\n",
        "    recall_vals.append(recall)\n",
        "\n",
        "classes = [0,1,2]\n",
        "# Calculate the test set accuracy and recall for each class\n",
        "print('Test set accuracy is {:.3f}'.format(test_acc))\n",
        "for i in range(3):\n",
        "    print('For class {}, recall is {:.3f}'.format(classes[i],recall_vals[i]))\n",
        "\n",
        "print(\"Accuracy is {:.3f}\".format(test_acc))\n",
        "# print(\"Weighted F score is {:.3f}\".format(calculate_weighted_f_score(y_true, y_pred)))"
      ],
      "metadata": {
        "id": "84_JU0KURXAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "nb_classes = 3\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat=confusion_matrix(y_true, np.argmax(y_pred, axis=-1))\n",
        "plot_confusion_matrix(conf_mat, [\"flat\",\"down\",\"up\"])\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_score(y_true, np.argmax(y_pred, axis=-1), average='weighted')\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true, np.argmax(y_pred, axis=-1), target_names=[\"flat\",\"down\", \"up\"], digits=4))"
      ],
      "metadata": {
        "id": "3SjFsSeFRXAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_weighted_f_score(y_true, y_pred):\n",
        "  test_preds = np.argmax(y_pred, axis=-1)\n",
        "  Ntu = sum((test_preds == 2) & (y_true == 2))\n",
        "  Ntd = sum((test_preds == 1) & (y_true == 1))\n",
        "  Ntf = sum((test_preds == 0) & (y_true == 0))\n",
        "  Ewutd = sum((test_preds == 2) & (y_true == 1))\n",
        "  Ewdtu = sum((test_preds == 1) & (y_true == 2))\n",
        "  Ewutf = sum((test_preds == 2) & (y_true == 0))\n",
        "  Ewdtf = sum((test_preds == 1) & (y_true == 0))\n",
        "  Ewftu = sum((test_preds == 0) & (y_true == 2))\n",
        "  Ewftd = sum((test_preds == 0) & (y_true == 1))\n",
        "\n",
        "  beta_1 = 0.5\n",
        "  beta_2 = 0.125\n",
        "  beta_3 = 0.125\n",
        "\n",
        "  Ntp = Ntu + Ntd + beta_3**2 * Ntf\n",
        "  E1 = Ewutd + Ewdtu\n",
        "  E2 = Ewutf + Ewdtf\n",
        "  E3 = Ewftu + Ewftd\n",
        "\n",
        "  F = (1 + beta_1**2 + beta_2**2) * Ntp / ((1+beta_1**2+beta_2**2) * Ntp + E1 + beta_1**2 * E2 + beta_2**2 * E3)\n",
        "  return  F\n",
        "\n",
        "print(f'Weight CDT F Score: {calculate_weighted_f_score(y_true, y_pred)}')"
      ],
      "metadata": {
        "id": "AIqC-zeNRXAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Model Conv2D"
      ],
      "metadata": {
        "id": "aXbU1Pz7oKam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### ONLY EXECUTE FOR PYTORCH 2D CNN #####\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], \n",
        "                          1,\n",
        "                          X_train.shape[1], \n",
        "                          X_train.shape[2]\n",
        "                          )\n",
        "X_val = X_val.reshape(X_val.shape[0],\n",
        "                          1,\n",
        "                          X_val.shape[1], \n",
        "                          X_val.shape[2],\n",
        "                          )\n",
        "X_test = X_test.reshape(X_test.shape[0],\n",
        "                          1,\n",
        "                          X_test.shape[1], \n",
        "                          X_test.shape[2],\n",
        "                          )"
      ],
      "metadata": {
        "id": "tdeD0Rsc4rqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X Train Length {X_train.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test.shape}, y Test Label Length {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLv4oER44svp",
        "outputId": "b2341834-1a59-4136-84de-75bea8879181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4060, 1, 5, 24), y Train Label Length (4060,)\n",
            "X Val Length (1435, 1, 5, 24), y Val Label Length (1435,)\n",
            "X Test Length (1040, 1, 5, 24), y Test Label Length (1040,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = TensorDataset(torch.from_numpy(X_train).float(), \n",
        "                         torch.from_numpy(y_train).long())\n",
        "testset = TensorDataset(torch.from_numpy(X_test).float(), \n",
        "                        torch.from_numpy(y_test).long())"
      ],
      "metadata": {
        "id": "_ncbTnJ4oPhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(trainset, shuffle=False)\n",
        "i1, l1 = next(iter(train_loader))\n",
        "print(i1.shape)\n",
        "\n",
        "# val_data = []\n",
        "# for i in range(len(X_val)):\n",
        "#    val_data.append([X_val[i].astype('float'), y_val[i]])\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(testset, shuffle=False)\n",
        "i1, l1 = next(iter(val_loader))\n",
        "print(i1.shape)"
      ],
      "metadata": {
        "id": "TQl5pGL7opIj",
        "outputId": "7c2b101d-c683-4272-8316-08861205e201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 5, 24])\n",
            "torch.Size([1, 1, 5, 24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get next batch of training images\n",
        "windows, labels = iter(train_loader).next()\n",
        "print(windows.shape)\n",
        "windows = windows.numpy()\n",
        "batch_size = 12\n",
        "# plot the windows in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "for idx in range(batch_size):\n",
        "    print(labels)"
      ],
      "metadata": {
        "id": "WOiXPp7popOT",
        "outputId": "a3310111-1bb1-4154-c9f4-105f116ef214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 5, 24])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up dict for dataloaders\n",
        "dataloaders = {'train':train_loader,'val':val_loader}\n",
        "# Store size of training and validation sets\n",
        "dataset_sizes = {'train':len(train_loader),'val':len(val_loader)}\n",
        "# Get class names associated with labels\n",
        "classes = [0,1,2]"
      ],
      "metadata": {
        "id": "96KWdOCcKgtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockShiftClassification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(StockShiftClassification, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool1 = nn.MaxPool2d((1,4),4)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool2 = nn.MaxPool2d((1,3),3)  \n",
        "\n",
        "    self.conv3 = nn.Conv2d(64, 128, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool3 = nn.MaxPool2d((1,2),2)\n",
        "\n",
        "    self.fc1 = nn.Linear(256,1000) #calculate this\n",
        "    self.fc2 = nn.Linear(1000,500)\n",
        "    self.fc3 = nn.Linear(500,3)\n",
        "\n",
        "    self.drop = nn.Dropout(p=0.7)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    x = self.drop(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool2(x)\n",
        "    x = self.drop(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.pool3(x)\n",
        "    x = self.drop(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    # Linear layer\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    output = x #F.log_softmax(x, dim=1)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "1hHxQyq1opQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "net = StockShiftClassification().float()\n",
        "\n",
        "# Display a summary of the layers of the model and output shape after each layer\n",
        "summary(net,(windows.shape[1:]),batch_size=batch_size,device=\"cpu\")"
      ],
      "metadata": {
        "id": "_QVWUvZ2opU6",
        "outputId": "b4c6acd2-1011-41f0-9ae0-9a001fd9a66c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [12, 32, 7, 24]             128\n",
            "         MaxPool2d-2             [12, 32, 2, 6]               0\n",
            "           Dropout-3             [12, 32, 2, 6]               0\n",
            "            Conv2d-4             [12, 64, 4, 6]           6,208\n",
            "         MaxPool2d-5             [12, 64, 2, 2]               0\n",
            "           Dropout-6             [12, 64, 2, 2]               0\n",
            "            Conv2d-7            [12, 128, 4, 2]          24,704\n",
            "         MaxPool2d-8            [12, 128, 2, 1]               0\n",
            "           Dropout-9            [12, 128, 2, 1]               0\n",
            "           Linear-10                 [12, 1000]         257,000\n",
            "           Linear-11                  [12, 500]         500,500\n",
            "           Linear-12                    [12, 3]           1,503\n",
            "================================================================\n",
            "Total params: 790,043\n",
            "Trainable params: 790,043\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.03\n",
            "Params size (MB): 3.01\n",
            "Estimated Total Size (MB): 4.05\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = torch.from_numpy(X_train).float()\n",
        "train_y = torch.from_numpy(y_train).long()\n",
        "val_x = torch.from_numpy(X_val).float()\n",
        "val_y = torch.from_numpy(y_val).long()"
      ],
      "metadata": {
        "id": "Mg6bEz7orEsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, train_loaders, device, num_epochs=50, scheduler):\n",
        "\n",
        "    model = model.to(device) # Send model to GPU if available\n",
        "\n",
        "    writer = SummaryWriter() # Instantiate TensorBoard\n",
        "\n",
        "    iter_num = {'train':0,'val':0} # Track total number of iterations\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Get the input images and labels, and send to GPU if available\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the weight gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass to get outputs and calculate loss\n",
        "                # Track gradient only for training data\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    # print(outputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backpropagation to get the gradients with respect to each weight\n",
        "                    # Only if in train\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        # Update the weights\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Convert loss into a scalar and add it to running_loss\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                # Track number of correct predictions\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                # Iterate count of iterations\n",
        "                iter_num[phase] += 1\n",
        "\n",
        "                # Write loss for batch to TensorBoard\n",
        "                writer.add_scalar(\"{} / batch loss\".format(phase), loss.item(), iter_num[phase])\n",
        "\n",
        "                # scheduler.step()\n",
        "\n",
        "            # Calculate and display average loss and accuracy for the epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # Write loss and accuracy for epoch to TensorBoard\n",
        "            writer.add_scalar(\"{} / epoch loss\".format(phase), epoch_loss, epoch)\n",
        "            writer.add_scalar(\"{} / epoch accuracy\".format(phase), epoch_acc, epoch)\n",
        "\n",
        "    writer.close()\n",
        "    \n",
        "    return"
      ],
      "metadata": {
        "id": "7-A3kueTqlai",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "2116a4d3-c02a-40f9-86f4-3cacf96241e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-6a0f5bcddbc5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def train_model(model, criterion, optimizer, train_loaders, device, num_epochs=50, scheduler):\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Cross entropy loss combines softmax and nn.NLLLoss() in one single class.\n",
        "weights = torch.tensor([1.5, 2.25, 1.]).to(device)\n",
        "criterion_weighted = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.00001)\n",
        "\n",
        "\n",
        "n_epochs= 500 # For demo purposes.  Use epochs>100 for actual training\n",
        "\n",
        "onecycle_scheduler = optim.lr_scheduler.OneCycleLR(optimizer,\n",
        "                                        max_lr=0.01,\n",
        "                                        base_momentum = 0.8,\n",
        "                                        steps_per_epoch=len(train_loader),\n",
        "                                        epochs=n_epochs)\n",
        "\n",
        "\n",
        "train_model(net, criterion, optimizer, dataloaders, device, num_epochs=n_epochs, scheduler=onecycle_scheduler)"
      ],
      "metadata": {
        "id": "cnrwBuUoqljR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "ff304399-4c0b-4c5f-b30f-9f2f1eddbec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-262565c34f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monecycle_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train_model() got an unexpected keyword argument 'scheduler'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KERAS 1D Model"
      ],
      "metadata": {
        "id": "qtbdKWSK7l7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_val = to_categorical(y_val, 3)\n",
        "y_test = to_categorical(y_test, 3)\n"
      ],
      "metadata": {
        "id": "lNIh0H7JVnF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X Train Length {X_train.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test.shape}, y Test Label Length {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2cc2486-914a-4084-d04e-80ea556ea146",
        "id": "xUtWCihJoI1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4060, 5, 24), y Train Label Length (4060, 3)\n",
            "X Val Length (1435, 5, 24), y Val Label Length (1435, 3)\n",
            "X Test Length (1040, 5, 24), y Test Label Length (1040, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam, Nadam"
      ],
      "metadata": {
        "id": "MUE5rS-l7z9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=4, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dense(500,activation=\"relu\"))\n",
        "model.add(Dense(3,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYwZW6eJ2HBu",
        "outputId": "0aae7496-e12d-4f1a-f760-59840802643d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (None, 5, 32)             2336      \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 2, 32)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 2, 32)             0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 2, 64)             6208      \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 1, 64)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 1, 64)             0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 1, 128)            24704     \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 1, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 1, 128)            0         \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1000)              129000    \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 3)                 1503      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664,251\n",
            "Trainable params: 664,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001, decay=0.0001)\n",
        "nadam = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
        "\n",
        "def custom_loss_function(y_true, y_pred):\n",
        "   squared_difference = tf.square(y_true - y_pred)\n",
        "   return tf.reduce_mean(squared_difference, axis=-1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"]) "
      ],
      "metadata": {
        "id": "SOmAeEzs2HGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 12\n",
        "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=350, validation_data=(X_val, y_val)) #, class_weight={0:1, 1:1.5})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ux9JsTrE2HJz",
        "outputId": "f5f69606-1105-44bd-de38-d792e7710063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/350\n",
            "335/339 [============================>.] - ETA: 0s - loss: 0.9849 - accuracy: 0.5032"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-da5fffad1253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, class_weight={0:1, 1:1.5})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['loss'], label='train loss')\n",
        "plt.plot(hist.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')"
      ],
      "metadata": {
        "id": "CMsqd9n02HMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'], label='train acc')\n",
        "plt.plot(hist.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "metadata": {
        "id": "M_S_jaA_2ubl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Gct8IuVa25GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy\n",
        "test_preds = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "\n",
        "# Recall for each class\n",
        "recall_vals = []\n",
        "for i in range(3):\n",
        "    class_idx = np.argwhere(y_true==i)\n",
        "    total = len(class_idx)\n",
        "    correct = np.sum(test_preds[class_idx]==i)\n",
        "    recall = correct / total\n",
        "    recall_vals.append(recall)\n",
        "\n",
        "classes = [0,1,2]\n",
        "# Calculate the test set accuracy and recall for each class\n",
        "print('Test set accuracy is {:.3f}'.format(test_acc))\n",
        "for i in range(3):\n",
        "    print('For class {}, recall is {:.3f}'.format(classes[i],recall_vals[i]))\n",
        "\n",
        "print(\"Accuracy is {:.3f}\".format(test_acc))\n",
        "# print(\"Weighted F score is {:.3f}\".format(calculate_weighted_f_score(y_true, y_pred)))"
      ],
      "metadata": {
        "id": "rk2qkycw25Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "nb_classes = 2\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat=confusion_matrix(y_true, np.argmax(y_pred, axis=-1))\n",
        "plot_confusion_matrix(conf_mat, [0,1,2])\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_score(y_true, np.argmax(y_pred, axis=-1), average='weighted')\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true, np.argmax(y_pred, axis=-1), target_names=[\"flat\",\"down\", \"up\"], digits=4))"
      ],
      "metadata": {
        "id": "coQSJfRo2uoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_weighted_f_score(y_true, y_pred):\n",
        "  test_preds = np.argmax(y_pred, axis=-1)\n",
        "  Ntu = sum((test_preds == 2) & (y_true == 2))\n",
        "  Ntd = sum((test_preds == 1) & (y_true == 1))\n",
        "  Ntf = sum((test_preds == 0) & (y_true == 0))\n",
        "  Ewutd = sum((test_preds == 2) & (y_true == 1))\n",
        "  Ewdtu = sum((test_preds == 1) & (y_true == 2))\n",
        "  Ewutf = sum((test_preds == 2) & (y_true == 0))\n",
        "  Ewdtf = sum((test_preds == 1) & (y_true == 0))\n",
        "  Ewftu = sum((test_preds == 0) & (y_true == 2))\n",
        "  Ewftd = sum((test_preds == 0) & (y_true == 1))\n",
        "\n",
        "  beta_1 = 0.5\n",
        "  beta_2 = 0.125\n",
        "  beta_3 = 0.125\n",
        "\n",
        "  Ntp = Ntu + Ntd + beta_3**2 * Ntf\n",
        "  E1 = Ewutd + Ewdtu\n",
        "  E2 = Ewutf + Ewdtf\n",
        "  E3 = Ewftu + Ewftd\n",
        "\n",
        "  F = (1 + beta_1**2 + beta_2**2) * Ntp / ((1+beta_1**2+beta_2**2) * Ntp + E1 + beta_1**2 * E2 + beta_2**2 * E3)\n",
        "  return  F\n",
        "\n",
        "print(f'Weight CDT F Score: {calculate_weighted_f_score(y_true, y_pred)}')"
      ],
      "metadata": {
        "id": "F7n6lPZp2uvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7v0QHbxx2uyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_weighted_f_score(y_true, y_pred):\n",
        "  test_preds = np.argmax(y_pred, axis=1)\n",
        "  Ntu = sum((test_preds == 1) & (y_true == 1))\n",
        "  Ntd = sum((test_preds == 0) & (y_true == 0))\n",
        "  Ntf = sum((test_preds == 2) & (y_true == 2))\n",
        "  Ewutd = sum((test_preds == 1) & (y_true == 0))\n",
        "  Ewdtu = sum((test_preds == 0) & (y_true == 1))\n",
        "  Ewutf = sum((test_preds == 1) & (y_true == 2))\n",
        "  Ewdtf = sum((test_preds == 0) & (y_true == 2))\n",
        "  Ewftu = sum((test_preds == 2) & (y_true == 1))\n",
        "  Ewftd = sum((test_preds == 2) & (y_true == 0))\n",
        "\n",
        "  beta_1 = 0.5\n",
        "  beta_2 = 0.125\n",
        "  beta_3 = 0.125\n",
        "\n",
        "  Ntp = Ntu + Ntd + beta_3**2 * Ntf\n",
        "  E1 = Ewutd + Ewdtu\n",
        "  E2 = Ewutf + Ewdtf\n",
        "  E3 = Ewftu + Ewftd\n",
        "\n",
        "  F = (1 + beta_1**2 + beta_2**2) * Ntp / ((1+beta_1**2+beta_2**2) * Ntp + E1 + beta_1**2 * E2 + beta_2**2 * E3)\n",
        "  return F"
      ],
      "metadata": {
        "id": "Z9EfhZEA70xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape[1],X_train.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ytUuvub8xcJ",
        "outputId": "d7408444-1252-4153-95d4-1d7e14e813f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=4, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dense(500,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q50kVGG076-F",
        "outputId": "99b837fa-103d-4eee-dc58-98a42a0fdee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_18 (Conv1D)          (None, 5, 32)             2336      \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 2, 32)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 2, 32)             0         \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 2, 64)             6208      \n",
            "                                                                 \n",
            " max_pooling1d_19 (MaxPoolin  (None, 1, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 1, 64)             0         \n",
            "                                                                 \n",
            " conv1d_20 (Conv1D)          (None, 1, 128)            24704     \n",
            "                                                                 \n",
            " max_pooling1d_20 (MaxPoolin  (None, 1, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 1, 128)            0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1000)              129000    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 2)                 1002      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 663,750\n",
            "Trainable params: 663,750\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001, decay=0.0001)\n",
        "nadam = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
        "\n",
        "def custom_loss_function(y_true, y_pred):\n",
        "   squared_difference = tf.square(y_true - y_pred)\n",
        "   return tf.reduce_mean(squared_difference, axis=-1)\n",
        "\n",
        "def calculate_weighted_f_score(y_true, y_pred):\n",
        "  test_preds = np.argmax(y_pred, axis=-1)\n",
        "  print(test_preds)\n",
        "  Ntu = sum((test_preds == 1) & (y_true == 1))\n",
        "  Ntd = sum((test_preds == 0) & (y_true == 0))\n",
        "  Ntf = sum((test_preds == 2) & (y_true == 2))\n",
        "  Ewutd = sum((test_preds == 1) & (y_true == 0))\n",
        "  Ewdtu = sum((test_preds == 0) & (y_true == 1))\n",
        "  Ewutf = sum((test_preds == 1) & (y_true == 2))\n",
        "  Ewdtf = sum((test_preds == 0) & (y_true == 2))\n",
        "  Ewftu = sum((test_preds == 2) & (y_true == 1))\n",
        "  Ewftd = sum((test_preds == 2) & (y_true == 0))\n",
        "\n",
        "  beta_1 = 0.5\n",
        "  beta_2 = 0.125\n",
        "  beta_3 = 0.125\n",
        "\n",
        "  Ntp = Ntu + Ntd + beta_3**2 * Ntf\n",
        "  E1 = Ewutd + Ewdtu\n",
        "  E2 = Ewutf + Ewdtf\n",
        "  E3 = Ewftu + Ewftd\n",
        "\n",
        "  F = (1 + beta_1**2 + beta_2**2) * Ntp / ((1+beta_1**2+beta_2**2) * Ntp + E1 + beta_1**2 * E2 + beta_2**2 * E3)\n",
        "  return  F\n",
        "\n",
        "prec = tf.keras.metrics.Precision()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[prec]) "
      ],
      "metadata": {
        "id": "vKDmE-h59Lv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 12\n",
        "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, validation_data=(X_val, y_val)) #, class_weight={0:2, 1:3, 2:1})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK4V5UIa9ORe",
        "outputId": "8b6e9317-44ba-438e-aab9-e9ed3113f482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 3s 6ms/step - loss: 0.6739 - precision_7: 0.6014 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6746 - precision_7: 0.6019 - val_loss: 0.6747 - val_precision_7: 0.6007\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6734 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6727 - precision_7: 0.6019 - val_loss: 0.6751 - val_precision_7: 0.6007\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6733 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6730 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 7/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6728 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6737 - val_precision_7: 0.6007\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6728 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6729 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 11/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6732 - precision_7: 0.6019 - val_loss: 0.6734 - val_precision_7: 0.6007\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6730 - val_precision_7: 0.6007\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6730 - val_precision_7: 0.6007\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6728 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 19/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6017 - val_loss: 0.6731 - val_precision_7: 0.6007\n",
            "Epoch 20/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6730 - val_precision_7: 0.6007\n",
            "Epoch 21/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6727 - precision_7: 0.6019 - val_loss: 0.6730 - val_precision_7: 0.6007\n",
            "Epoch 22/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6727 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 23/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 24/50\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 25/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6730 - val_precision_7: 0.6007\n",
            "Epoch 26/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 27/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 28/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 29/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 30/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 31/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 32/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6723 - precision_7: 0.6019 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 33/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6026 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 34/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6017 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 35/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6019 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 36/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 37/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6727 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 38/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 39/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 40/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 41/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 42/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 43/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 44/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 45/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6727 - precision_7: 0.6014 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 46/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6722 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 47/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6017 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 48/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 49/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6017 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 50/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6009 - val_loss: 0.6738 - val_precision_7: 0.6007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj9-LfyGhwZz",
        "outputId": "b3e8eb0b-0d48-4d9b-91af-3f1dc7360708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.6739199161529541,\n",
              "  0.6745873689651489,\n",
              "  0.673353374004364,\n",
              "  0.6727477312088013,\n",
              "  0.6732865571975708,\n",
              "  0.6729598045349121,\n",
              "  0.6728412508964539,\n",
              "  0.6726021766662598,\n",
              "  0.6728477478027344,\n",
              "  0.6728655695915222,\n",
              "  0.6732037663459778,\n",
              "  0.6726383566856384,\n",
              "  0.6725048422813416,\n",
              "  0.6726340055465698,\n",
              "  0.6724653244018555,\n",
              "  0.6726179718971252,\n",
              "  0.6727598905563354,\n",
              "  0.6725648641586304,\n",
              "  0.6725471615791321,\n",
              "  0.6725770235061646,\n",
              "  0.6726747155189514,\n",
              "  0.6726670861244202,\n",
              "  0.6725931167602539,\n",
              "  0.6725555658340454,\n",
              "  0.6725409030914307,\n",
              "  0.6725565195083618,\n",
              "  0.6725572943687439,\n",
              "  0.6725035905838013,\n",
              "  0.6724714040756226,\n",
              "  0.6725125908851624,\n",
              "  0.672520101070404,\n",
              "  0.6723334193229675,\n",
              "  0.6723588705062866,\n",
              "  0.6725103259086609,\n",
              "  0.6724315285682678,\n",
              "  0.6723941564559937,\n",
              "  0.672657310962677,\n",
              "  0.6724977493286133,\n",
              "  0.6724774241447449,\n",
              "  0.6724062561988831,\n",
              "  0.6724578142166138,\n",
              "  0.6725069880485535,\n",
              "  0.6724458336830139,\n",
              "  0.672408938407898,\n",
              "  0.672699511051178,\n",
              "  0.6722479462623596,\n",
              "  0.6723613739013672,\n",
              "  0.6724828481674194,\n",
              "  0.6723563075065613,\n",
              "  0.672439694404602],\n",
              " 'precision_7': [0.6014217734336853,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6016587615013123,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6026066541671753,\n",
              "  0.6016587615013123,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6014217734336853,\n",
              "  0.6018957495689392,\n",
              "  0.6016587615013123,\n",
              "  0.6018957495689392,\n",
              "  0.6016587615013123,\n",
              "  0.6009478569030762],\n",
              " 'val_loss': [0.6729004979133606,\n",
              "  0.6747092604637146,\n",
              "  0.6727417707443237,\n",
              "  0.6751312613487244,\n",
              "  0.6727463006973267,\n",
              "  0.672755241394043,\n",
              "  0.6727584600448608,\n",
              "  0.6737393736839294,\n",
              "  0.6728079319000244,\n",
              "  0.6728230714797974,\n",
              "  0.6733888387680054,\n",
              "  0.6727582812309265,\n",
              "  0.6729012131690979,\n",
              "  0.672968327999115,\n",
              "  0.6730093359947205,\n",
              "  0.6727268695831299,\n",
              "  0.6727235913276672,\n",
              "  0.672727644443512,\n",
              "  0.6730960011482239,\n",
              "  0.6729731559753418,\n",
              "  0.6729639172554016,\n",
              "  0.6727637052536011,\n",
              "  0.6727550029754639,\n",
              "  0.6728544235229492,\n",
              "  0.6729679107666016,\n",
              "  0.6727513670921326,\n",
              "  0.6728929877281189,\n",
              "  0.6727278828620911,\n",
              "  0.672716498374939,\n",
              "  0.672760546207428,\n",
              "  0.6728389263153076,\n",
              "  0.6729355454444885,\n",
              "  0.6727286577224731,\n",
              "  0.6727634072303772,\n",
              "  0.6728515028953552,\n",
              "  0.67275470495224,\n",
              "  0.6727381944656372,\n",
              "  0.6727297306060791,\n",
              "  0.6727380156517029,\n",
              "  0.672787606716156,\n",
              "  0.6727962493896484,\n",
              "  0.6727461218833923,\n",
              "  0.6727689504623413,\n",
              "  0.6727339029312134,\n",
              "  0.6727678775787354,\n",
              "  0.6728211045265198,\n",
              "  0.6727349162101746,\n",
              "  0.6727569699287415,\n",
              "  0.6727298498153687,\n",
              "  0.6737827062606812],\n",
              " 'val_precision_7': [0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628]}"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['loss'], label='train loss')\n",
        "plt.plot(hist.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "PP75W71D9ij8",
        "outputId": "93ecd498-1356-42bf-bd10-6db42c5d3c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxU1d3/32eSyTphycYWIOwgq4CIouBSUSvigqLWvVXbPlqf1v7c2qe2ttra1tZWq7Xu+1bqggoFFxRFkU2UfQ8QluwJyUyS2c7vj3MnmSQzmUkyCQx8369XXjNz77lbMrmf+12P0lojCIIgCMHYDvcJCIIgCEceIg6CIAhCC0QcBEEQhBaIOAiCIAgtEHEQBEEQWpB4uE8gFmRnZ+v8/PzDfRqCIAhxxerVq0u11jmh1h0V4pCfn8+qVasO92kIgiDEFUqp3eHWiVtJEARBaIGIgyAIgtACEQdBEAShBUdFzEEQhKMXj8dDYWEhdXV1h/tU4paUlBTy8vKw2+1RbyPiIAjCEU1hYSEZGRnk5+ejlDrcpxN3aK0pKyujsLCQQYMGRb2duJUEQTiiqaurIysrS4ShnSilyMrKarPlJeIgCMIRjwhDx2jP70/EIVYcXAd7vjrcZyEIghATRBxixcf3w8LbD/dZCIIQYyorK3nsscfate13v/tdKisrox7/m9/8hgcffLBdx4o1Ig6xwl0DbufhPgtBEGJMa+Lg9Xpb3XbBggX06NGjM06r0xFxiBUeF3hqD/dZCIIQY+666y527NjBhAkTuP322/nkk0849dRTmT17NscddxwAF154IZMmTWL06NE88cQTDdvm5+dTWlpKQUEBo0aN4sYbb2T06NHMnDmT2trW7xdr165l6tSpjBs3josuuoiKigoAHn74YY477jjGjRvH5ZdfDsCnn37KhAkTmDBhAscffzzV1dUdvm5JZY0VnlojEIIgdBr3vruBjfsPxXSfx/Xtxq/PHx12/QMPPMD69etZu3YtAJ988glr1qxh/fr1DamhzzzzDJmZmdTW1nLCCScwZ84csrKymuxn27ZtvPrqqzz55JPMnTuX//znP1x11VVhj3vNNdfwyCOPMGPGDO655x7uvfde/va3v/HAAw+wa9cukpOTG1xWDz74II8++ijTpk2jpqaGlJSUjv5axHKIGZ5a8EiRjiAcC0yZMqVJzcDDDz/M+PHjmTp1Knv37mXbtm0tthk0aBATJkwAYNKkSRQUFITdf1VVFZWVlcyYMQOAa6+9lqVLlwIwbtw4rrzySl566SUSE83z/bRp07jtttt4+OGHqaysbFjeEcRyiBWeWvDWgt8PNtFcQegMWnvC70rS09Mb3n/yySd8+OGHfPnll6SlpXHaaaeFrClITk5ueJ+QkBDRrRSO999/n6VLl/Luu+9y//33s27dOu666y7OO+88FixYwLRp01i0aBEjR45s1/4DRHUXU0qdo5TaopTarpS6K8yYuUqpjUqpDUqpV6xlpyul1gb91CmlLrTWPaeU2hW0boK1XCmlHraO9a1SamKHrrCrCMQbvGI9CMLRREZGRqs+/KqqKnr27ElaWhqbN29m+fLlHT5m9+7d6dmzJ5999hkAL774IjNmzMDv97N3715OP/10/vjHP1JVVUVNTQ07duxg7Nix3HnnnZxwwgls3ry5w+cQ0XJQSiUAjwJnAYXASqXUfK31xqAxw4C7gWla6wqlVC6A1noJELjpZwLbgcVBu79daz2v2SHPBYZZPycC/7Rej2y8ljh4aiEp7fCeiyAIMSMrK4tp06YxZswYzj33XM4777wm68855xwef/xxRo0axYgRI5g6dWpMjvv888/zox/9CJfLxeDBg3n22Wfx+XxcddVVVFVVobXm1ltvpUePHvzqV79iyZIl2Gw2Ro8ezbnnntvh4yutdesDlDoJ+I3W+mzr890AWus/BI35E7BVa/1UK/u5CZihtb7S+vwc8F5zcVBK/Qv4RGv9qvV5C3Ca1vpAuH1PnjxZH9bJfnxe+J0VfPrZBuied/jORRCOMjZt2sSoUaMO92nEPaF+j0qp1VrryaHGR+NW6gfsDfpcaC0LZjgwXCm1TCm1XCl1Toj9XA682mzZ/Zbr6CGlVMAhF83xUErdpJRapZRaVVJSEsVldCLeIN+hpLMKgnAUEKvIaSLGDXQacAXwpFKqofJDKdUHGAssCtrmbmAkcAKQCdzZlgNqrZ/QWk/WWk/OyQk5BWrXEZylJOmsgiAcBUQjDvuA/kGf86xlwRQC87XWHq31LmArRiwCzAXe0lp7Agu01ge0oR54FpjShuMdWQQLgqSzCoJwFBCNOKwEhimlBimlkjDuofnNxryNsRpQSmVj3Ew7g9ZfQTOXkmVNoEy7wAuB9daq+cA1VtbSVKCqtXjDEUGwK0ksB0EQjgIiZitprb1KqVswLqEE4Bmt9Qal1G+BVVrr+da6mUqpjYAPk4VUBqCUysdYAp822/XLSqkcQAFrgR9ZyxcA38VkNrmA6zt0hV1BE8tBYg6CIMQ/URXBaa0XYG7awcvuCXqvgdusn+bbFhAioKy1PiPMsTRwczTndcTglZiDIAhHF1LKGwuCBUGK4AThmMfhcLRp+ZGIiEMs8EgqqyAIRxciDrFAUlkF4ajlrrvu4tFHH234HJiQp6amhjPPPJOJEycyduxY3nnnnaj3qbXm9ttvZ8yYMYwdO5bXX38dgAMHDjB9+nQmTJjAmDFj+Oyzz/D5fFx33XUNYx966KGYX2MopPFeLJCAtCB0DQvvMlPyxpLeY+HcB8Kuvuyyy/jpT3/KzTebUOgbb7zBokWLSElJ4a233qJbt26UlpYydepUZs+eHdV8zW+++SZr167lm2++obS0lBNOOIHp06fzyiuvcPbZZ/PLX/4Sn8+Hy+Vi7dq17Nu3j/XrTUJnW2aW6wgiDrFA3EqCcNRy/PHHU1xczP79+ykpKaFnz570798fj8fDL37xC5YuXYrNZmPfvn0UFRXRu3fviPv8/PPPueKKK0hISKBXr17MmDGDlStXcsIJJ/D9738fj8fDhRdeyIQJExg8eDA7d+7kJz/5Ceeddx4zZ87sgqsWcYgNAcshMUXEQRA6k1ae8DuTSy+9lHnz5nHw4EEuu+wyAF5++WVKSkpYvXo1drud/Pz8kK2628L06dNZunQp77//Ptdddx233XYb11xzDd988w2LFi3i8ccf54033uCZZ56JxWW1isQcYkEgQym1p8QcBOEo5LLLLuO1115j3rx5XHrppYBp1Z2bm4vdbmfJkiXs3r076v2deuqpvP766/h8PkpKSli6dClTpkxh9+7d9OrVixtvvJEbbriBNWvWUFpait/vZ86cOdx3332sWbOmsy6zCWI5xAKPCxJTwZ4qqayCcBQyevRoqqur6devH3369AHgyiuv5Pzzz2fs2LFMnjy5TZPrXHTRRXz55ZeMHz8epRR/+tOf6N27N88//zx//vOfsdvtOBwOXnjhBfbt28f111+P3+8H4A9/+EOEvceGiC2744HD3rL7/Z/D+jehW1/omQ+Xv3z4zkUQjjKkZXds6IyW3UIkPHVgTzOWg7iVBEE4ChBxiAUelxEGe6oEpAVBOCoQcYgFnlqwp5i4g4iDIMSco8H9fThpz+9PxCEWeFxBbiURB0GIJSkpKZSVlYlAtBOtNWVlZaSkpLRpO8lWCoXWsOIJGHsppGVGHu+ts9xKaSIOghBj8vLyKCws5LBPBxzHpKSkkJfXtrntRRxCUbELFt5hitomXRt5vMcFqZkSkBaETsButzNo0KDDfRrHHOJWCkV9tXl110Q33lPbGJCWOgdBEI4CRBxCUW+JgjtKK6B5Kqv4RgVBiHNEHEIRsBiithyCUlm1H3zuzjs3QRCELkDEIRQNbiVndOODU1kDnwVBEOIYEYdQNFgOUYiD1uCtbXQrgYiDIAhxj4hDKAKiEI1bKRCADqSygmQsCYIQ94g4hMIKSOtoAtIBKyHQlTV4mSAIQpwi4hACZ7WZhq+isiLy4ICVYA8SB0lnFQQhzhFxCEH1ISMK/voo3EqegFspOOYgbiVBEOIbEYcQ1NVUAWDzRhGQDmU5iFtJEIQ4JypxUEqdo5TaopTarpS6K8yYuUqpjUqpDUqpV6xlpyul1gb91CmlLmy23cNKqZqgz9cppUqCtrmhIxfYHjy1hwBI9LYh5mBPkYC0IAhHDRF7KymlEoBHgbOAQmClUmq+1npj0JhhwN3ANK11hVIqF0BrvQSYYI3JBLYDi4O2mwz0DHHY17XWt7T7qjpIwJ1k90URO/AGxCHN9GKCRleTIAhCnBKN5TAF2K613qm1dgOvARc0G3Mj8KjWugJAa10cYj+XAAu11i5oEJ0/A3e09+Q7C2Wlsibr2sitMBosB0llFQTh6CEacegH7A36XGgtC2Y4MFwptUwptVwpdU6I/VwOvBr0+RZgvtb6QIixc5RS3yql5iml+kdxjjFDa43dijXY0JHjBwEhkFRWQRCOImIVkE4EhgGnAVcATyqlegRWKqX6AGOBRdbnvsClwCMh9vUukK+1Hgd8ADwf6oBKqZuUUquUUqti2ee9wuUhlaCbe6Qq6SaWQyCVVcRBEIT4Jhpx2AcEP73nWcuCKcRYAR6t9S5gK0YsAswF3tJae6zPxwNDge1KqQIgTSm1HUBrXaa1rrfGPQVMCnVSWusntNaTtdaTc3JyoriM6NhT7iKdOqpJN8eJVCXtCYo5JNjBliiWgyAIcU804rASGKaUGqSUSsK4h+Y3G/M2xmpAKZWNcTPtDFp/BUEuJa31+1rr3lrrfK11PuDSWg+1tu8TtN1sYFObrqiD7C6tIZ06nEnZANS7ohUHKxgts8EJgnAUEDFbSWvtVUrdgnEJJQDPaK03KKV+C6zSWs+31s1USm0EfMDtWusyAKVUPsby+DTKc7pVKTUb8ALlwHVtuqIOsr+kHJvS6PRccO+m+lAlrc68Gtw+A2Q2OEEQjgqimiZUa70AWNBs2T1B7zVwm/XTfNsCWgawm49xBL2/G5MWe1goLi015+HoBRXgrKmkVaeVtxYSkiDB+lUmpkgqqyAIcY9USDejrKLcvHH0AqC25lDrGwSmCA1gTxPLQRCEuEfEoRlVljgkdu8NQJ2ruvUNPK5GlxJYbiWJOQiCEN+IOARR5/FR5zSWQnLPvgC4I4pDKMtBxEEQhPhGxCGIveUu0pSJF6RmGnHw1kYjDmmNn+0pUucgCELcI+IQxJ5yFw6rAC6pu8mo9dZFkcpqD8pnEreSIAhHASIOQewuc5FuWQ4kd6OW5MhzOrSwHCQgLQhC/CPiEMSecheZiW7zISmdOpUKngjtM7zNYg6SyioIwlGAiEMQu8uc9E31mg9JDjy2lIYOrWGRgLQgCEchIg5B7Cl3kZvsNampCYl4EtIiT/gTMpVV3EqCIMQ3Ig4Wfr9mb0Ut2UkeSDYF277ENBJ9kcShrqXl4PeAz9uJZysIgtC5iDhYHDxUh9vrp2diPSQZcfDb00ny1+L3tzLhT6hUVpB0VkEQ4hoRB4vdZcZC6GZrFAeS0kmlnuq6MFaA1saF1DyVFSTuIAhCXCPiYLG33IhDOrUNbiWVlE46dVS43KE38nlA+1q6lUDiDoIgxDUiDha7y50k2hTJfleD5ZCQ6iBN1YcXB2/QRD8BEi0rQiwHQRDiGBEHi91lLvr1TDWpq5blYE/JIJ06Kl2e0BsFTxEaoMFyEHEQBCF+EXGw2FPuYkBmGrhrGiwHe2oGqcpNhTPMjT7gOmqeygoiDoIgxDUiDhYN4lBfA8kZAKSkdwOgpjpM871AJbRYDoIgHGWIOABVtR4qXR4GZqZalkM6AClpRiRqa6pCb+gJEXMIZC5JQFoQhDhGxAHYY6WxDuquAN3gVrJZsQeXM8xscAEBaJLKagmFV/orCYIQv4g4YDKVAAZmWMVuyY11DgD1YcUhlOUQiDmI5SAIQvwi4oCJNwDkpfnMgqQM69WIg7s2TNtub6hsJQlIC4IQ/4g4YNxK2Y4k0rR1Q2+wHMyrty5cQDqEOCSKOAiCEP+IOGBqHBrSWCGofYZxF/nCzQYXKpU1MRlQIg6CIMQ1Ig4Yt9LArHSTxgpNeisBjcubEyqVVSmZDU4QhLjnmBcHt9fP/qrappZDM7dSgs+F2+tvuXFDtlJa0+X2FLEcBEGIa455cSiscKE1YdxKxnJIo57KUP2VPLWgbJBgb7rcniaprIIgxDVRiYNS6hyl1Bal1Hal1F1hxsxVSm1USm1QSr1iLTtdKbU26KdOKXVhs+0eVkrVBH1OVkq9bh3rK6VUfvsvLzK7rUylgVlpje6jgOWQmILGRpqqo7I2RH+lwFwOSjVdLrPBCYIQ5yRGGqCUSgAeBc4CCoGVSqn5WuuNQWOGAXcD07TWFUqpXACt9RJggjUmE9gOLA7abjLQs9khfwBUaK2HKqUuB/4IXNb+S2ydQAHcgKw0KGhmOSiFLzGNdG89Fc4QloO32fzRAeyp4lYSBCGuicZymAJs11rv1Fq7gdeAC5qNuRF4VGtdAaC1Lg6xn0uAhVprFzSIzp+BO5qNuwB43no/DzhTqeaP5rFjT7mLVHsCOY5kqK82mUe2hIb1OimNNOqoCNWZ1RNGHBLFchAEIb6JRhz6AXuDPhday4IZDgxXSi1TSi1XSp0TYj+XA68Gfb4FmK+1PhDueFprL1AFZDXfmVLqJqXUKqXUqpKSkiguIzSBNFallIk5BFxKAZIcpKu6MDEHV9M01gD21MZMJkEQhDgkVgHpRGAYcBpwBfCkUqpHYKVSqg8wFlhkfe4LXAo80t4Daq2f0FpP1lpPzsnJafeJ7yl3GpcSgNvZ6FKysCU7SKU+TMyhLoxbKU3cSoIgxDXRiMM+oH/Q5zxrWTCFGCvAo7XeBWzFiEWAucBbWuvAHfZ4YCiwXSlVAKQppbY3P55SKhHoDpRFfUVtQGttahwyLXGob2k52JLTcYSbDc7japnGChKQFgQh7olGHFYCw5RSg5RSSRj30PxmY97GWA0opbIxbqadQeuvIMilpLV+X2vdW2udr7XOB1xa66HW6vnAtdb7S4CPtda6TVcVJSXV9dR5/CZTCax23RlNxqikdLol1FPpDBdzSGm53J4iqayCIMQ1EbOVtNZepdQtGJdQAvCM1nqDUuq3wCqt9Xxr3Uyl1EbAB9yutS4DsFJR+wOfRnlOTwMvWpZEOUaMOoVAGmv/BsuhGhy5TQcltWI5eOvA3rvlcqmQFgQhzokoDgBa6wXAgmbL7gl6r4HbrJ/m2xbQMoDdfIwj6H0dJh7R6eyvNHGBgVlWmwx3DSQNajooyRF+HmmPS1JZBUE4KolKHI5WLpjQj9NH5pKeZP0a6mtaBKRJSieFOiprw1RIJ4ZwKyWmGqvC7wfbMV+ELghCHHLM37m6pdhJsFllFG5nw/zRDdjTSNHh6hxaCUiDxB0EQYhbjnlxaEBry63Uss4hUXtwuly0iIu3lsoK4loSBCFuEXEI4HYCOkQRnIlHJPpqcbp9jcv9PvDVt245SFBaEIQ4RcQhQPOOrAEscUinWX+lhlngQqWyymxwgiDENyIOAZpP9BMg0LZb1VEVXCUdiCe0GnMQcRAEIT4RcQjQfKKfAEFzOjSpdWiY6CdMKiuI5SAIQtwi4hAgkltJNctYCtz4w6WygsQcBEHoXFzlJv7ZCYg4BGg+0U+ABsuhWWfWcFOEQpDlIKmsgiB0Ig+Nhg/uiTyuHYg4BGiwHJrVOViWRBr1VAT3Vwrc+FtNZRXLQRCETsLtNPeY9OxO2b2IQ4D6avNqWQoNWJ8z7Z6mVdJRWQ4ScxAEoZNwWvPYpLd/yoLWEHEIEC4gbd38s5LcTfsrHY5U1udnd5oJKQhCnOEsNa+dJA7HdG+lJrid5jVEhTRAZqKHr4NjDocjlfXA2tjuTxCE+KXBchC3UudSX21u9EHzRwOQmAQ2Oz0S3c2ylVpJZU3sBMvBUwd1VVATanpuQRCOOcSt1EWE6qsUICmdjAQPVa4QFdKh5pC22UyKaywD0oEvQs3B2O1TEIT4JXBPSBPLoXMJMUVoA0kOutnqQ9c5hLIcwBKHGFoOAYuhtgK89bHbryAI8Ymz1DzQJoVwbccAEYcA7pqWmUoBktJIV/UcqvPg81udWVsrggNrNrhYikNR6PeCIBybOEs6Ld4AIg6NuJ0taxwCJKWTTi1a09hfyeMyLqVwk/nEejY4Z1CsoVrEQRCOeZwlnRZvABGHRuqrW3UrpWCykxr6K3lqQ6exBoi1OAQHoiXuIAiCsxTScyOPayciDgEiBKST/UYcGmodvLWh01gD2FNjm8paUwTK+nNVizgIwjGPuJW6iFYD0unY/eZGX9nEcggTjIbOsRwyBxuBkJiDIBzb+P2W5SBupc7HXRM+5mBPI9Fr0lIbMpY8taHTWIO2iWkqa00xZPQxXwaxHATh2KauErRPxKHT8futgHS4bCUHCR5TQR215RDzVNYicPQyP1IIJwjHNp1cHQ3SPsPgcRFy/ugASengcZJgax6QjmQ5xLBlt7MEHLlQf0gC0oJwrNPJ1dEgloMh3EQ/AZLSUdpPTkpQQNrjihyQjpVbye005+jINZaDpLIKwrHNkSIOSqlzlFJblFLblVJ3hRkzVym1USm1QSn1irXsdKXU2qCfOqXUhda6p5VS3yilvlVKzVNKOazl1ymlSoK2uSFWFxuWhol+wtU5GNHoneoLEocuTGUNuJEcvSCjt6l56KTZnwRBiAM6uSMrROFWUkolAI8CZwGFwEql1Hyt9cagMcOAu4FpWusKpVQugNZ6CTDBGpMJbAcWW5v9TGt9yFr3V+AW4AFr3eta61ticH3R4Q7M5RDOcjAWQu9UX6NbyVsXneWgNSjVsfMLiEN6rrEitJWpkNGrY/sVBCE+cZYACtIyO+0Q0VgOU4DtWuudWms38BpwQbMxNwKPaq0rALTWoSKmlwALtdYua0xAGBSQCuj2XUIMCDdFaAArUJ2b7AnKVnJFTmVFg88dfky0BFJXA24lkLiDIBzL1BRDWlbLLtIxJBpx6AfsDfpcaC0LZjgwXCm1TCm1XCl1Toj9XA68GrxAKfUscBAYCTwStGpOkLupf6iTUkrdpJRapZRaVVJSEsVltELDXA7hs5UAspN8TbOVwvVVgthOFRponeHINW4lkLiDIBzLdHLrDIhdQDoRGAacBlwBPKmU6hFYqZTqA4wFFgVvpLW+HugLbAIusxa/C+RrrccBHwDPhzqg1voJrfVkrfXknJwO/pLCzR8doGGqUGs2OK2tmEMrbqWAcMQi7lBTjDEhs8VyEATBKoDrvDRWiE4c9gHBT+951rJgCoH5WmuP1noXsBUjFgHmAm9prT3NtkNr7cO4quZYn8u01oGe1E8Bk6K5kA4RmD86nFvJEoFMu4daj4+6Oiv1NVIqK8RIHIrMFyEhsVEcxHIQhGOXI8RyWAkMU0oNUkolYdxD85uNeRtjNaCUysa4mXYGrb+CIJeSMgwNvAdmA5utz32CtpuNsSo6l4iprGZ59wTjUqo6dMgsjxSQhhiJQ0ljgy17CqT0EMtBEI5lOrl1BkSRraS19iqlbsG4hBKAZ7TWG5RSvwVWaa3nW+tmKqU2Aj7gdq11GYBSKh9jeXwatFsFPK+U6ma9/wb4sbXuVqXUbMALlAPXdfQiIxIISIeNOZjl3RKMQXPo0CF6QYRU1hhbDo6g7osZvaW/kiAcq3jrob7q8IsDgNZ6AbCg2bJ7gt5r4Dbrp/m2BTQLYGut/cC0MMe6G5MW23W4a0LPHx3AEgeHMpZDTY3lhmrVcgjEHGIQkK4phqyhjZ+lEE4Qjl0aahwOf8zh6Ke1dt3QIA7pylgOzgZxiJTKiqmH6Aham2wlR9BTQkZvcSsJwrFKF1RHg4iDobV23WAsisQU0jAuIpfTEodIXVmh45ZD/SEjMI6ggreA5aDbWRpSvgseGAAH13fs3ARB6Hq6oDoaRBwMkSwHgKR0UrSxAlwuK0YRjeXQ0ZhDcOuMABm9wVdv2va2h70roK4K9n7VsXMTBKHr6YKOrCDiYKivCd9XKUBSOoleFyl2G/W1UYhDwKroqOXQ0Doj6Cmho+mspVvMa/nO1scJgnDkIW6lLsRdHYXl4ACPk9yMlKCAdDSWQwdjDg2tM5q5laD9cYcSSxzKdrT/vARBODw4SyAhOfIDbQcRcYDWJ/oJkJQObieDstOpOtQWcegktxJ0wHLYal7LRRwEIe4I1Dh0tKFnBEQcIHJAGkyA2RKHmuooiuAS7GBL7LhbyVkMKgFSezYu64jl4PMYd5KyQUWBtP4WhHjDWdLp8QYQcTC0Nn90gCQHuJ0MzknH5rNcRa1ZDmDNBtdRy8EqgLMF/amSM8y+22M5lO8EvxcGnGQ6xlYVduz8BEHoWrqgdQaIOFjzR0dhOSSlg7uGwdkOUrFaP7WWygpgT2XngVKm/2kJ9d52PqHXFDetjgZjTjp6ta9KOhBvGG41zhXXkiDEF13QOgNEHMATaNcdjTi4GJSTTopy41OJphFea9hTKa+sZE+5i1UFFe07v5rixr5KwbS3hUZpM3GQoLQgxA9ai1upywjM5RCV5eCkT7cUHDYPHlsrfZUCJKZSX2f2v3RrO+ecqCluGowO4OgF1e2IOZRshW55ph1HYqopiBMEIT6orzY1TmI5dAH1ETqyBkhKB48TG5qcFD91JEXctban4q03AelP2yMOfr95SnCE+CJ0xHLIGW5iGJmDxa0kCPFEF9U4gIhD5PmjAwRSXT0uspJ9OP2RxaFeJZOs6xmcnc7mg9UUH2pjzUNdJfg94S2H+kPgbkM2lN8Ppdsge4T5nDVY3EqCEE8EWmeEemCMMSIOkeaPDhAQB7eTnnYvNT47Hp+/1U1qfImkUM/3TxkEwNJtpW07t+C5o5vTnnTWQ4XgcaGzh/PljjJ0zyEmndXnbdt5CYJweBDLoQuJNNFPgMB6j5NuCV5qSWJveetP7VVeO6m4OX98X7IdyW2POzS0zggVkG5HCw2r+G1dfW+ueHI5Wzw5xjKp2hthQ0EQjghEHLqQBsshcm8lAAFh67sAACAASURBVNxO0hPc1JHEzhJnq5uUuxNIt3nonmpn+rBsPt9eit/fhk6qoaqjAzisKum2WA4lRhw+LjPTe2/2WF8w6bEkCPFBwK2UJtlKnY87wixwAQLV0G4nqXio1UnsKm1dHErqEnDYzLTZ04fnUO50s35/VfTn1ppbqT0tNEq3QGomiwpMzcVaZ5ZZLuIgCPGBswRSukNi5JhnRxFxaKtbyV1Doq8OX0IKO1sRB59fU1ynSLEmCDplmFH6NrmWnMWQkGS+DM1JzTTtOdpoOXgyh7HpgGn/8XV5MtjTJSgtCPFCF1VHg4hD21JZwWQHeVzYU9LZVVoTdvjuMidOv50kvxGHbEcyo/t2Y+nWNgSlAzUOoRps2WxWlXRx9Psr3cK+xAEAHD+gB9tLnOjMQZLOKgjxgohDF+KuMU/Ptgi/iqCYA946klLTW405bC2qoVYnY9Ne0+wO41pas6eC6jpPdOcW6KsUjrYUwjnLwFXGt3W96J5q58IJ/XC6fdRlDBS3kiDEC87SLqmOBhEHU3EYKY0VmriV8NSSmpZBcXU9NfWh00C3FVVTGyiUs5rvTR+Wg9ev+WJHWXTnVlMSOlMpQFsK4ay2GUvKe3DykCyG9zIB+JKkPElnFYR4QSyHLsTtjOxSAkhqDEjjcZGRYW6uBWHiDluLa0hJDaS/GnGYNLAn6UkJ0ccdYmk5WA33VlTncMqwbIbmmnPbrfuYLq1Ve6Lbz5HEmhfhn6eAq/xwn4kgdD5+H7jKRBy6DHdN5EwlsDqwKjP3st9Lt4xuAOwoCR132FZUTc/uZgxeIw5JiTZOGpLF0m0laB0hpdXvA1dp6DTWABm9zRhfFG6q0q14ElLYTxanDM0m25FE91Q7m9zWF60sDl1L6+dB0Tp452bTkEwQjmZc5YAWcegyopk/GkxMIind3IyBHt27oRQh01m9Pj87S5xk9TT1BMFzOkwfnsPe8loKyiK0vXCVgfZHsBysddEEpUu2sD+hP3mZ6QzMSkcpxdBcByurrUmE4i0o7fPA3hWmieCWBbDiicN9RoLQuTQUwEnMoWuIZv7oAEnpDUUo9uR0+vVIDSkOBWUu3D4/uZkBcWgUgunDjOpHdC21VuMQoA2FcLp0C+vqe3HK0MYv1tAcB2tK7eb64y0ovf9r83s9+z7Tfnzx/8H+tYf7rASh8+jC6miIUhyUUucopbYopbYrpe4KM2auUmqjUmqDUuoVa9npSqm1QT91SqkLrXVPK6W+UUp9q5Sap5RyWMuTlVKvW8f6SimVH5tLDUM0U4QGSEpv/APZUxmUHTpjaVuRaebXO9t6Kg+yHPKz0xmQmdYGcWjNrRRlC436GlRVIZu8fTllaOMXa2iugzKXB2+P/PirdSj43LwOPAUueMxUjM673iQYCMLRyJEmDkqpBOBR4FzgOOAKpdRxzcYMA+4GpmmtRwM/BdBaL9FaT9BaTwDOAFzAYmuzn2mtx2utxwF7gFus5T8AKrTWQ4GHgD928Bpbx10TveVgb7QcsKcyODudXaXOFvGDrUUmDtEvJ9Ms8DTtxjp9eDZf7izD7W2lcV9NFF+EaC2Hsm0A7KAvJw/JalgcCEofShsQf26l3ctMd1lHDqRnwSVPm6yr926T+INwdBK49xwp4gBMAbZrrXdqrd3Aa8AFzcbcCDyqta4A0FqHcoJfAizUWrusMYcAlFIKSAUC/9EXAM9b7+cBZ1pjOge3M7qYAzRxK2FPY3COg5p6LyU19U2GbS2upn9mKimp1n49TeML04fl4HL7WLW7lSybaCwHRy6gIsccrJ5KKnsEPdMby+4D4nAgoR9U7I4usB0JrWHnp/DSJfCnIe2bkCgSPi/sWQ750xqXDTwZTrsb1r0Ba1+O/TEF4XDjLAGVACk9uuRw0YhDPyC4bWehtSyY4cBwpdQypdRypdQ5IfZzOfBq8AKl1LPAQWAk8Ejz42mtvUAVkEUzlFI3KaVWKaVWlZS0c5a1wPzR0WQrgTUbnOW2sNxKQAvX0raiaobnZoDdmmM6yK0EcNKQLBJtqvVq6ZpiY6m05vJKsENaVsQbsLtoEx6dwOAR45os79cjlRS7je2+XqB9UNmBdFafB759A/41HV6YDftWm+D9pnfbv89wHPzG/N0GTmu6/NSfQ/6psOD2xrmyBeFoITA9aKSC3RgRq6MkAsOA04ArgCeVUg3yppTqA4wFFgVvpLW+HugLbAIua8sBtdZPaK0na60n5+S008yKdv7oAMEiktgoDsFBaY/Pz65SJ8N6BYtDU8shI8XOxIE9W487OIujm9AjikK4yj3r2a17cfLw3k2W22yKwdkO1rk60ICvvga+eAT+Ph7evBG8dTD7EbhtE2QPh03z277PSBQsM6/5pzRdbkuAi580TRJfv8qc17p5Jj5RtqNxStjOprad84ULQms4S7vMpQTRicM+oH/Q5zxrWTCFwHyttUdrvQvYihGLAHOBt7TWLfwWWmsfxlU1p/nxlFKJQHcgypLiNhLtRD8BgsXBnkq/HqkkJdqaiENBqROPTzO8l6NRHLwtZ4CbMTyHjQcOcbAqzOxwNUWtu5QCRFEIp0q3spN+TBrYs8W6obkOlldZOt7WoPT+r+HxU0ymUOZg+N4b8D9fwcRrwJ4Co843N3JnjP98u5dB5pDGzrTBdOsDFz9hLK/F/wf/+QE8dx48MhF+39e4unZ9FtvzCWbFk/CnwbBjSecdQzg2CVgOXUQ04rASGKaUGqSUSsK4h5o/Dr6NsRpQSmVj3EzBj6FXEORSUoahgffAbGCztXo+cK31/hLgYx2xYqydNHRkbUPMIYA9FZtNMSgrnZ1BhXCBYPTwXhmNbb49LWsazh3Tm6QEG3e9+W3oOR5qiqN7SohkOfg89KwrpLb7UFLsCS1WD811sL4qCZ3kiD4orTUsfxyeOgt8brj2PbjuPRh+dlOTd9Rs467aujC6/UaD3we7v2wab2jO0DPhzgK4aw/cvAKufhsufBzO/DUkJsNHv43d+QRTsAz+e5epT1n+z845hnDs0oWtMyAKcbD8/rdgXEKbgDe01huUUr9VSs22hi0CypRSG4ElwO1a6zIAKxW1P/Bp0G4V8LxSah2wDugDBP5jnwaylFLbgduAkKmzMcHdMcsBMOmsQZbD1qJqlIIhOQ7TbhvVIuYAMDjHwa9mjeKTLSX889MQN+VAR9ZIOHoZcfCHznwq3bOJRHxk5B0Xcr0JSivquuVHZzm4yuG1K+G/d8LQ78CPPodBp4Ye22c8dB8Q27hD0XqorzIprK2hlGl1njMChpwOE66AU2+DaT+FwhWw56vYnRNAVSG8cQ30HAQn/gi2LTbZU0cybhe8chksuONwn4kQDV3sVkqMZpDWegGwoNmye4Lea8yN/LYQ2xbQLICttfYDIR/9tNZ1wKXRnFeHaWjXHW1AOkhEAuKQk86Hm4rw+vwkJtjYVlzNgMw0UpOsp3R7WkhxALhq6kBWFlTwl8VbOL5/D04OFKj5PFBbHr04+L1mfAiTc9uG1WQDA0ceH3LzQMZSWXJ/8so3hxzTwJ6vYN73jRid/QeY+uPQ7cQDKGVcSyuftBocRmmhtUZDvKEVy6E1jr8SltwPXz4CA07s+PmASVV+/Wrw1sPlr5jv04onYeXTMPN3sTlGrPG6TVxmx0egbHDyLdBjwOE+KyEcnlqTDHOEuZWOXqKd6CdAE8vBuIwGZ6fj9Wv2VhgB2FpUw7DcoJugPTWsOCil+MPFYxmc4+DW176m6JAVfwgUu0QVkA4UwoWOO1TsXg/AoBGhxSE/K50Em2IvvU22Urh01hVPwrPnQkIi/GAxnPQ/rQtDgFHnG9fTtsWRx0bD7mXQYyB0z2vf9knpcMINsOm92BT+aQ3v/xz2r4GLHoec4dC9H4z8Lnz9Yti/fRP8/q6tzfD74M0bjDCc/ktASfuRI50uLoCDY10c/D7jekjuFt34QAxB2SyXEQzOCWQs1eD2+ikodTKidzMLo5UbRHpyIv+8ciLOeh8/eeVrvD5/dDUOAVophNNao0q3Up7YC1tKaAFMSrQxMDONLe5cEx+o2N1y0IFvYaHlRvrhUug3MfJ5Beg/xbQdj4Vrye834tA8S6mtTLnJpAEvf6zj57TyKVj7Eky/A0bNanqM2gpY/2br23vd8MxMePfWjp9LNGgN7/4vbHwHZt4PM+6A4y6A1S80WtLCkYeIQxczapYJWmYPjW58wMJITG14ah6UbZbtLHGyq9SJ168b5koALHFovcnesF4Z/OHisawoKOfPi7c0FrVFIw6ttNDYfLCaPN8e6nu2fn1Dch2scVrV3M2D0n6fuXGlZcHF/wo9ZWlr2BJg5HmwdXF0T9GtUbLJ3HCb1ze0lYxeMG4ufP1yxzKpdn9pAtDDzzEFeMHknwo5I41LrTU+fwgKV8KaF2DvyvafSzRobTK4vn7RiNnJVlOCk242cZy1r3Tu8YX208XV0XCsi0NbCbiVAimqQGZ6Ej3S7OwqdbLV6qnUwq0UIpW1ORce348rTxzAvz7dyYat283CaL4IluVQV3mA5TvLeOqznfzs9bWc9ddPmfXwpwxRB8jIG93qLobmOlheaaWzNq91+OpfJmX13AcgtWUqbFSMOt/UlHQ0vXP3F+a1vfGGYE66xbRSX/V0+7av2mcC0D0GwkX/almYpJRxX+3/GgpXh95H8WZY+mcYOctYVx/8qnPdS0sfhC//AVN+CKf/onF53mTIOwG++mfYxIaoOLRfWpd0Fl3ckRVEHNpGgzikNVkcaMC3ragam2p0NTWMjWA5BPjVrOMY068bH6361ixorSNrwzmlUZ+QzqsfreDyJ5Zz3/ub+HJHGQOz0vjFtG6kqXoc/UJnKgUYmuOg2O/Al9StqR++cg98fB8MmwmjL47qGkKSf6qxODrqWir43LTo7jGwY/sByB1lrmvFEy16X0WkthJevtT8XS9/BVLDtDMYd5mxNkNZD36/sciSHTDrb3D63bDnS9j8ftuvJRqWPw5L7oPxV8A5D7SMF039sXkwaG9s6MvH4K+j4L2fikB0BuJWOsIJuJXsKU0WD7Ia8G0tqiE/K71pPUFiStTulBR7Av+8chI9/JXU2hxNLJRw1Ht97Pd1Z6TDxbPXn8DKX36H5b84k6eunsgPBljuqZwRre4jkM5ak96/0a2kNbz//wAN5/0luuBzOBKTYPi5Zt6F9vZv0tqKN0zr2LkEc/JPzD/dt69Hv42nFl69HEq3wmUvQe7I8GNTusH4y03cobn7avUzsPcrOPv3JvHg+GtMRfmHv45Nj6sAWsOS35vU45GzYPY/QrdfGDUbuvVrXxzm84dg0d2mMHH1c+YaBPNdidXf0llq2ulEm1kZA0Qc2kJgqtBmN+0hOQ4OHqrjm8JKhvVqFvhtJZU1FP0z0xjTvZ4ifwZ1Hl/E8Us2F3PQ14NxSfs5vfhFchbfAo+faqqB37zBNOrKaeUGhok5ABQl5jVaDhvegm2L4Iz/i02K46jzoa6ysdV2WyndZm7kHY03BJN/qqnF+PIf0blTfF749/Wm6d/FT5j6iUiccCP46uHrFxqXVe2DD34Dg08zT/JgssC+cy+UbYc1z4fYUTvw1sNbP4JP/wgTroJLnjXHCUWCHabcCLs+haIN0R/j0z/Bh7+BMXPg5q+MK23Z3+Gzv8bkEuISv88kKvx1FDx5emOH5Y7QxdXRIOLQNlpxKwEcqKprGoyGiNlKoRiS6qTI353FGyPM0wDMW72PksTepB/aYSp/dy8zpucJN5inxB8vg7TMVvfhSE6kT/cUduleULXXBMQX3gl9jzcFXbFgyBnm99Ze19JuS1Q6mqkUjFJw0k+MFRDJnaI1vPe/ptr7u3+GMVG62XJHGhFa+Yy5aQRSX/1e404KtoJGnGvE75MHOj4vRW0FvHgxfPuaEfgL/mEsuNaYeK1Jtoimultr+Oh3pmZk/BWmp1WCHc79M4ydCx/da26QXY3PY8R33xrYshBWP2+y7bqK3V/Av2aYv3H2cCjdDs9918RjOkIXV0dDlEVwgkVDtlJLt1KAYS3EIXq3UoBuvnJqEnvx71V7mT2+b9hxZTX1fLKlmFFT74aJ/2eyrtqaTWQxNNfBhoocztZ+U+jmKoOr5plso1iQlGZSYTe/B999sO2dJQuWmeB75uDYnE+A0ReaJ98vHoERoZoJW3x0L3z9Esy40zxht4UpN5rg9dZFxorYuhDO+h1kDmo6Timz/KkzYNnDcMYv23w5AJTvMjGRyt1w8VMwLsqa0rRMU0n+9cum1Ui4OhutTfD8i0dMH61Zf2/8e9pscOFjRtze/38mTXzc3PZdRzRoDVv/ayyV8h3mexuKcZfBGb+CHv1Dr+8oh/bD4l+Zec275cGlz8FxF5o40stz4Zlz4Nr50DO/fft3lpj9diFiObSFCJYDYBruBdOGgHQAVVNCZq88Pt9eyv7K8MIy/5v9eP2aWVNGQd6kdgsDGNfYikNWYLXgM5Pe2Gd8u/cXkuMuMDUchW1M2eyMeEOABLsJxu7+HLZ/GLpz65ePGr/6pOtbpqxGw4jzIKOvcbcsuMP8Xqf+T+ixeZNM8P/Lf8ChA20/VuEqeOo75mZy9dvRC0OAE39sBGz1s6HX+/3GqvziEWOdBgtDgAS7uTnmn2LcWlti2FsrmMLV8NwsEwNylZm4yWl3w6yH4PJX4YaP4Sdr4JTbTF3HI5PMg0BdVej9Vew2DwBLHzRP/NFQXWRca49MNlbx9DvglhUw+iLzXR14Mlz7DtQfgmfObZhbpc04S7vcrSSWQ1tISAJbYouYQ4o9gX49Ujl4qK6JUACNbqWKAvNFqjloXqsPmH9gj8tky3hrG1/rqxiUn4/eBW+uKeSWM4YRijfX7GN0326M6N3xthRDcx28486BFEw2UHtugpEYNtP8DjfNb9G6os7j48YXVnH++L7Mndzs6a58p/l9xTLeEMzEa2Dpn+AlqzFwUobJFMvobSZW2fK+ufG0NzCfkAiTrzcuGJVgLLJwvn+AM+8xN5pPfm/an0dD9UFjbax8ynSmvXIeZIf+3rRKznAYepbZz7T/NY0Kwdw4175iJlKq2gtTb4az7w//+7CnwBWvwvOz4Y1rYfrt0HcC9Bpjfq8dEfnyncalteFN42o57y/GJZZgDz3+O7+Gyd83mXefP2RqSmbcBcPOMvGjgs9Mp96qoPlMPv4dDDgZJl5tHmqCA8HeemOtrH0Ftn1gikdHnGd+H82tQYB+k+C69+GFC02Xgavfgj5Bc6u4ys157F5mrL38U03tTE8rK09rcSsd8ShlMgZCZBENzXWQnpxAcmIzN0ySwzyJ/b3ZU7gt0cx7nGTtLzHFvKZlw+iL6DHxEqbuLmPe6kJuPn0ozSfD21pUzbp9Vdwzq/U01WgZmuugggx2j7mFgVMvbgy+x5KUbiYIu2k+zLyvyQ3i4Y+28dm2UjYdOMTs8X2bZnztDjN/QyzP66ZPjQug+qCxbmqKjIiXbDJPgRc+3jEX28Rr4fO/wYk/jGyRZQ4yrqivHjcWRu6o8GMr98Kyv8GaF00cY+yl5ibVkafMqT+Gly42N7/kDHMz3fUpoEwQfuZ95oYZ6QafnAFX/QdemWvSaAOkZkLvMdBrLGQNMcWejl5GkB25jf9ffr+JnTiLTRysptg0TVz1rBGCGXeajLNoenb16G+KOKf+2BQCLrwdAgZNaqaxSk++xdyYU3uaWM2aF+HtHxtrb+wcc8Pe8TGs+7c5r4w+MO1WGP89I6qt0Ws0XL8QXrgAnp9lHgBKtpgYRdEGQJsHJ0cv82Cw8A7IGWVcnQOnmb9tF4uD6qxu2F3J5MmT9apVq7rmYB/8GvqfaHrnBLG33EWdx9cy5nBov/kypWaaL1NGL+M7T8uK6Hf/z+pCfv7vb3jjhycxZVDToPIfFm7i6c92sfwXZ5LtSO7wZZXW1DP5vg/51azj+MEpIZ5+YsWaF2D+T8zNJaUH2FMprU/gxVVF9OzejeLKGs4d0Y2xOYmm95XbZQrJ6qvh9u2xdyt1JbUV5pqjuQZXOfx9gvm+DD7NWHM9BjT+1FUaP/s3rwLKxApO+VlsYjJaw6MnQqk1m16PAXD81Sbw3F6ffW0FFG00XXUPrjM3xOJNxlJuTnJ3IxCuUnNTDEbZzLmc/ovQ83lEg9amr1T5LhhwEuQeF/p/UWtz8/76RdjwtjnXhGTTWWHC92Dw6W1/YKjcY6ypil3mQbP/FHPzH3iysTDsKSZjcMtCY53s/sJYJmCC/jGO3yilVmutJ4dcJ+Jw5OJye5ly/0ecM6Y3D17a+LTp82tOfuAjxvbrzlPXnhCTY2mtOf53H3DumD784eKxMdlnSGorTJvo6oPgrUN7avHWu7DTeBPwYiMh2YFKchgLJikdxlxintKOJTa8ZfzfFbsbp6cNJiEZJl0LJ98a+0DrjiXm+GPmmKfpzpia0u+zLIKioNci40JxO82TcsCaSLdeM/oYS6+rqasy7U3yJocveoyW+mojTLmjwrvCAtRWGiHbt8ZMgxsh87CttCYO4lY6gklLSuS8sX1499v93Dt7NOnJ5s+1bHspRYfq+fX5scteUEoxNMfBjuJObr6W2tN0dbV45vNd/O69jTxy+TjOH9WTRZvL+eGr3/KPiycya1z4TK1jgtEXmR+tjaVQucf8VOw2rsoJV7b/6TkSQ06Pro6jI9gSTHykW5/OPU4sSOkOw77TYrHPr7lj3rdcMaU/k/OjvHEnZzSNObRGag8j0GPmRB4bYyRb6Qjn0sl5uNw+3l/XmLny5ppCuqUkcuaoKNprtIGhuQ62l3RdZ8695S4eXLSFM0bmMmt8HiQ7OGtsfwZnO3j80x10hlVb5/FR741cXHhEoZQR1T7jTTHhybeYp8jOEgYhatbsqeA/awr5z5rmMyfHP2I5HOFMGtiTwdnpzFtVyNzJ/amu8/DfDQeZMzGvZfC7gwzNdfDayr2UO91kpkcomOogWmt++fZ6bAp+d+GYhoC7zaa4afpg7npzHcu2l3HKsNil7y3bXsqNL6zC5faRkZxIliOJzPQkshzJZDuSOH98X04e0rXpgkJ8s3iDaZW/fl+Y9Ng4RiyHIxylFHMm5bGioJyCUicL1x+kzuNnzqTYF8QE2mhs72zXEvDO2v0s3VrC7WePoF+PptlfF03sR25GMo+Hmj61nazdW8mNL6wir2cqPz9rOHMm5TE2rwepSQnsLXfx/rcHuOqpr3hy6c5OsViElvx18RZ+8da6w30a7UZr3dDFYPPBQ/FnkUZALIc4YM7EPP6yeAvzVheyanc5g7LTOb5/B4NiIRiaY8RhW3F1i+yocLjcXspq3PTPjD71tdzp5rfvbWRC/x5cfVJ+i/XJiQl8/5RBPLBwM+sKqxib1/7iPoBtRdVc9+wKshxJvPSDE8ntltJijMvt5edvfMP9Czax6cAhfn/x2KbptEJMqXX7ePrzXTjdPs4b24dpQ+PPYttWXMPuMhfThmaxbHsZWw/WdPi7eiQhlkMc0Lt7CqcOy+GVFXtYvrOci4/v16LuIRb065FK/8xUnvpsF7XuyE9BXp+fq576irP/tpTi6ujbXt/33kYO1Xr445xxJNhCX8f3ThxARnIijy/tmPWwt9zF1U+vwJ5gCysMYIL/j35vIredNZw3v97HZU8sb5y2VYg5H28uxun2kZaUwO/e24jPH3/WWsCl9LPvmBqHb/dVHs7TiTkiDnHCpZPzKHe6AeN26QxsNsUf54xjV6mTPy3aHHH8Y5/sYM2eSmo9Ph75KLp2A19sL+XNr/fx49OGtFrZ3S3FzpVTB7Jw3QF2l4VoaREFJdX1XP30V7jcXl78wRQGZrXe7thmU9x65jD+dfUkthdVc/4jn/P1nop2HVtonXe/2U9ORjIPzBnH5oPVvL5y7+E+pTazeGMRE/r3YNLAnnRPtR91cQcRhzjhrON60SPNzkmDs8jr2QnVyxYnD8nmupPzeXZZAV/sKA07bu3eSv7+0TYumNCXK08cwKsr9lBQ2vpN3OPz8+v5G+ifmcrNp0eemvX70/JJtNl4YunOiGObU1Xr4dpnVnDwUB3PXn8CI3tHnxt/9ujevPk/00i227jsX8t5bll0lpQQHdV1Hj7eUsx5Y/tw/rg+nJDfk79+sIXquhjOY9HJ7K+s5dvCKmaO7oVSirH9urNOxEE4HCQnJvDqjVP5y9wYN8MLwZ3njGRQdjp3zPuWmnpvi/Uut5efvb6WXhnJ/PaCMdx65jDsCTYeXLyl1f0+/0UB24pruGfW6Kj8+bndUpgzqR//Xl1ISXV91Oe/p8zFDc+vZFtxNf+6ejKTBra9cGhE7wzm33wKUwZl8pt3N3Li7z/kd+9tZGcXpvoerXywsQi318/54/uilOJXs46jtMbNo0til4DQ2Xy4yQSiZx5n0onH9OvOloPVR1VQWsQhjhjVpxt9e7Ts6xRrUpMSePDSceyvrOX+9ze1WH/f+5soKHPyl7kT6J5qJzcjhRtOHcR73x5gXWHop6fi6jr+9uE2ThuRw3faUJ9x46mDLYtjPUu2FIcViYJSJ499sp1Zj3zG9D8vYc2eSv46dwIzhre/H03P9CRe/MEUXr9pKtOH5/D8FwWc8ZdPufrpr1i84SBeX/vmW/b7NV6fH7fXT53HR63bd0xlSL37zX769Uhl4gCTVDEurwcXT+zHM5/vYk9Z2zoYHy4+2FjE4Jx0axZFGNuvOx6fZsvBDs7DcQQh2UpCSCYNzOTG6YP516c7OXt0L04bYW7oH20q4pWv9vDD6YM5aUhWw/ibpg/mpeW7+eN/N/PSDSe22N8DCzfj9vr59fmj2xRMH5zj4NqT8nnuiwIWrDMBwF7dkhnTtzuj+3Un0aZYuP4gmw4cAmBC/x788rujOGdM7zZlUIVDKcWJg7M4cXAWxdV1vL5iL6+s2MNN43P3CwAAEvhJREFUL64mMz2Jkb0zGJrrYFiugyG5DobmOshxJFN0qJ4tRdVsPVhtXouq2VZUQ22Y2f1G9+3GvbNHR19lG6dUON18tq2UH5w6qMn34I6zR7Jw3UEe+O8mHrty0mE8w8hU1Xr4ckcZPzi1sQfZOCtLad2+KsblxT6T8HAQlTgopc4B/g4kAE9prR8IMWYu8BtAA99orb+nlDodeCho2Ejgcq3120qpl4HJgAdYAfxQa+1RSp0GvAPssrZ5U2v92/ZcnNAxfvad4SzZXMyd//mWxT+dgdvn54553zKqTzdum9m0C2VGip1bzhjG797byGfbSjh1WOMT+6qCct5cs4//OW1Iy5bmUfCb2aP5+czhbNx/iPX7D7FhXxXr91exZEsxfm0KBX816zjOGdO7Rc1ELMnNSOEnZw7jx6cN4cNNxXy4qYjtxTW8uWZfE/dbUoINd5BVkZORzIheGVx2Qn+6pdqxKbApRYJNoRR4fZpXV+zhkse/5OLj+3HXuSPDZlXFO//dcBCvX3N+s9Yovbun8KMZQ3jow62s2FUedSr14eCTLcV4/brBpQSQ1zOV7ql2Yzm3fDaKSyI23lNKJQBbgbOAQmAlcIXWemPQmGHAG8AZWusKpVSu1rq42X4yge1AntbapZT6Lo1Nc18Blmqt/2mJw//TWs+K9iKO1sZ7RwLrCqu46LFlzBrXh+o6L59tL+W9n5zScjpUoN7r44wHP6Vnup35N5+Czabw+TXnP/I5FS43H/18BmlJsTNWa90+aj2+Tq/mjoTWmqJD9WwrrmZ7cQ37KmoZkJXG8F4ZDO+VEdX5udxeHl2ynSeX7iIp0cb/njmM66blY09om+dXa011vak9KXfWW69uKms9nDe2T0ysqY5whZUi/NHPZ7SwIGvdPs74yydkO5J55+Zp2MKkOR9ubn55DV/tKmfFL85sco5XP/0V5U4379966mE8u7bR0cZ7U4DtWuud1s5eAy4ANgaNuRF4VGtdAdBcGCwuARZqrV3WmAVBJ7gC6No58ISoGJvXnZtPH8rfP9oGwD2zjgspDGCC5j+fOZzb3viG99cd4PzxfXllxR42HjjEP753fEyFAUxsJDXp8BeqKaXo3T2loR6lPaQlJXL72SO5dFJ/7n13A/cv2MRrK/dw97mjOG1EDokRRGJPmYunP9/JvNWFOMNkVi3fWcZz109p1/kFWFdYxV8+2MLd545q8yRTxYfqWL6rjJ+cMSykazE1KYE7zxnJT19fy5tf7+OSTugCAKZZ3ltf76OmzsNVUwdG/N0GU+/18cmWYmZP6NdCvMb0685Tn+2kzuM7Kgooo/lv7QcEJyEX0tJwGg6glFqGcT39Rmv932ZjLgf+2nznSik7cDXwv0GLT1JKfQPsx1gRG6I4T6GTuOWMoXy5o4zuaXauOzm/1bEXTOjHE0t38uDiLZw4KJMHF23h5CFZnDc2DjpvHgHkZ6fz7PVT+GhTEfe+u5EbXlhFtiOZWeP6cOHx/Rif173JjXXt3kqeWLqD/64/SIJNcf64vhzXt1tDz6isdNM/at7qQv76wVa+Laxst0/c6/Nz53++ZeOBQ6wuqODxqye1qbL5/XUH0Bpmjw//XZg9vi/PflHAPe+sZ+G6A0wc2JOJA3oyvn/3Dj9caK35eHMxf/zvZrYWmayzt9bu5y+Xjm8ILEfiix1lON0+Zo7u1WJdcFB6fCd0MOhqYvUolwgMA07DWABLlVJjtdaVAEqpPsBYYFGIbR/DuJQ+sz6vAQZqrWss19Pb1r6boJS6CbgJYMCAATG6DCEU9gQbr900FaWIGExOsCnuPGck1z+3kjmPf4Gz3su9s9sWhBbgzFG9OGVYNks2l/DO2n28smIPz31RwKDsdGaP78vQXAcvfrmbFQXlZKQk8sMZQ7ju5Hx6hYlVXD8tn6c+28k/Pt7OE9eE9CJE5OWvjBX4f+eN4t+rCrn2mRU8MGdc1E/4736zn1F9ujE0N7zFYbMpHr58Av/4eDtr9lTw0WbjhEiwKUb1yWBKfha3nDG0za7Er/dU8IeFm1mxq5z8rDQe/d5EfFpzzzvr+e7Dn3H7zBF8/5RBYSv2AyzeUER6UgInByVjBBjbrzEo3R5xWLjuAI9+sp3Hr5rUqbVM0RKNOOwDgmcSybOWBVMIfKW19gC7lFJbMTf0wEzyc4G3rPUNKKV+DeQAPwws01ofCnq/QCn1mFIqW2vdpCJLa/0E8ASYmEMU1yF0gLb4f08bkcP/b+/Ow6uqzwSOf9+ELSxmY89GMICyBjKEWCib6ERlRGcodaG1FYd2qg7ugC12tOo8Vh4K+vionY6VMiJLQYayyKIIg5U1BBICkqAQglkIa9hCkvvOH/cQAzeXEJJwyb3v53ny5J6Tc3N+L5zc95zfOig+gs3fHuOxIfGeq+OZq9K8STCpvTuS2rsjJ8+VsSqzgE92HOatz7NRdU93Mm10T348MIbWza/8p9ymRVN+PjieWZ9ls7fgVK0GBYJ7pcDpq79mcEIkE4bEM25gDL/6nzSeW7iTQ8fO8tSo6quKLjp07CxpuSd4IbVHjeeKi2zFm87iVifOXmBH7gm2HzxOWu5x5mw6wKrdBbw3Pumq5jH6tvgMb67ay4qMAtq2bsbvxvTigeTYyraclK4RvLg4k9dW7GHV7gKm/6gfXbx0mnC5lDVZhQzv0b7aGZGjw0MIa9nUa3fuK/nmyGmeW7iTMxcqeHp+Oh//a0qtqrsahKpe8Qt3AvkGiAeaATuBXpcdkwrMdl63xV0NFVnl55uAEZe95zHg70DIZfs78n1DeTKQe3Hb21dSUpKaG8u+glP6wsKdevLcBV8Xxe/knzinG7OP6IXyilq97/iZUu05baU+MTet1ud8bkG6Jry4XLMLSyr3lZZV6LML0jVu8jJ9Zn66lpZ5L8+7X+Ro3ORlmnv0TK3PXVV67nG97fW12u3XK3T+llyvx504c0Ff+dtuvXnqcr112kqdsfprLTlfVu2xLpdL/7rtkPb+7afa4zcr9L827NezpeUex207cEzjJi/TJTvyvJ53/J826V0zN9QqpnMXyjV15gbt9/Kqyn+nWWv3XdV7i0vOa0WFq1bnqwrYpl4+V2tMTapaDjyBu0poD7BAVXeLyCsicq9z2CrgqIhkAeuA51X1KICIdMH95LH+sl/9HtAB+EpE0kXkJWf/WCDTaXN4C3fXV3syaGS6dWjDG2P7clOLGpZBNLXWMbQFgxPa1ronU1jLZvz0B11Ytus79tdipPf2g8dZuD2PR4fEX1I336xJEG+O7cszd3RnUVoeP/vzFg4dq34Q29L070iMCatzb6l+MWH87ckhDOwSzguLdjF1ccYlo5LLK1zM+eoAw6ev44Mvv2VsUjRfPD+cp+/o7vXp6uK0+GueHsag+EheXb6H5NfX8h9Ld5Nd+P2gttVZBTQJksoxP9XpExXKvsISznsZz1KdV5dnsSf/FDPG9eOXw27mvsTOzPosm+0HrzyvV07Raf7p7Y3MWLPvqs9VG7aGtDEBpPh0KUPe+Jx7+nS+qqlYKlzKmHc2Ulzi7orcyssH7OK0PKYsyqDM5WJEj/aMT4llWPf2BAcJOUWnGTVjPdNG92TCkPhq319b5RUupq/ex3vr99MvJox3Hx5AdtFpXl2WRXbRaVK6RjBtdE96da7dFNqqytYDx/lo80FWZhRwocJFcnwEDw+KZebabKLDQ5gzwftAhpUZ+fzbR2kseXwwiVfR7rB8Vz6Pz01j4tCuvHj3rQCcOl/G3bPcTbArJv2w2husnYdO8LM/byE4SJj9aHKt47zI1pA2xgDQtnVzHkqOY/ZXB3hqVLca7+Tnbskl8/Ap3n6wv9fEAPDPA6JJ6RrJvC25fLz1EI9+6F5Y6aFBsRwpKUWEeu2x1iQ4iCl33UJiTCjPLtjJiOlfUFruIi6yJe//JIk7e3a4pk4QIkJyfATJ8RG8NLqUhdvzmLs5l0nz0gF3w/6V9K7SKF1Tcjh49AxTFu2if2wYz//j920xN7VoyqwHEhn3/iZeWpLJzAf6X/K+L3OKmfiXbYS3cq9P4q2NpK4sORgTYH4xzD3Vybvr9/P6/X28HnfszIXKrsij+9b8wd45LIRn7uzBk7d3Y/XuQuZsOsDvP3VPxjgoPoKOofU/6ju1dycS2rfhd8uyGJwQySM/6FJvy+dGtm7OL4fdzMQfdmVjTjEbc4q5r/+Vp8uPDg8hvGVTMmtolC4tr+CJuTsIChLefrC/RxVhUlwET45McOYja1953pUZ+Uyal05821b8ZUKy195p9cGSgzEBpsNNLRg3MJoFW/N4cmQCnUKrn3Lk95/u5UxpOa+MqV1X5KbBQdzTtxP39O1EdmEJi3ccZtStnuMC6ktC+9bMfrRug/uuJChIGNq9HUOvYhJHEaF3VCi7api++z9X7CXj8En++BPv3VafGJHAxuxifrMkkwGx4Xy5v5hff5JB/9hwPnhkIKEtG7Y9z2ZlNSYA/WLozbhUeX+951oZ58sqWLrzO+ZtPeQ0Ql97V+RuHdowOfUWkuLC61LcRqVPVCjZV2iU/jSzgA//foCfD+7Cnb06VnsMuKvO/vDjRAQY9/5XTF2cwdDu7ZgzIbnBEwPYk4MxASkmoiX394/i4y25PD4igZPnytiw7wjr9x1h0zdHKS13ERvRkn+/3WP8qalB3+hQyl3K3oISj3aHnCL3eIZ+0aFMvevWGn9XTERLXr2/N5PmpTMmsTPTf9Sv1r3UrpUlB2MC1K9GJLAoLY/hb66rnI+pa7tWPDQolqHd25ESH3lDzF3V2FQ2SueduCQ5nDpfxsQ522jRNIh3xyfRrMnVfciPSYxiQGw4UWEh13UyQksOxgSo+LatmHR7d7LyT7rr1Lu18/msrf4gKiyEiFbNLlk21OVSnpmfTu7Rs3z02KBaL9rli/8XSw7GBLBJo6zaqL5VNkpX6bH01ufZrN1TxMv39mJQV895mW5E1iBtjDH1rE/UTWQXneZ8WQVrsgqZuTabfxkQzU9vi/N10a6aJQdjjKlnfaLCqHApy3bl8/T8dPpGh/La/b0b1ezElhyMMaaeXZwxdvKiXTRvEsR745Ma3QJAlhyMMaaedQ5tUbnmxDsPD6h1A/SNwBqkjTGmnokIU1JvIaRZMCmNpAH6cpYcjDGmAYwbGFPzQTcwq1YyxhjjwZKDMcYYD5YcjDHGeLDkYIwxxoMlB2OMMR4sORhjjPFgycEYY4wHSw7GGGM8iKr6ugx1JiJHgIPX+Pa2QHE9FqcxCdTYLe7AYnF7F6eq1S6O7RfJoS5EZJuq/oOvy+ELgRq7xR1YLO5rY9VKxhhjPFhyMMYY48GSA/zR1wXwoUCN3eIOLBb3NQj4NgdjjDGe7MnBGGOMB0sOxhhjPAR0chCRVBH5WkRyRGSKr8vTUETkAxEpEpHMKvsiRGSNiGQ738N9WcaGICIxIrJORLJEZLeITHL2+3XsItJCRLaIyE4n7ped/fEistm53ueLSDNfl7UhiEiwiOwQkWXOtt/HLSIHRCRDRNJFZJuzr07XecAmBxEJBt4B7gJ6Ag+KSE/flqrBfAikXrZvCvCZqnYDPnO2/U058Kyq9gRSgMed/2N/j70UGKmq/YBEIFVEUoA3gD+oagJwHJjgwzI2pEnAnirbgRL3CFVNrDK2oU7XecAmByAZyFHVb1T1AjAPGOPjMjUIVd0AHLts9xhgtvN6NnDfdS3UdaCq+aqa5rwuwf2BEYWfx65up53Nps6XAiOBvzr7/S5uABGJBu4B/uRsCwEQtxd1us4DOTlEAYeqbOc5+wJFB1XNd14XAB18WZiGJiJdgP7AZgIgdqdqJR0oAtYA+4ETqlruHOKv1/tM4AXA5WxHEhhxK7BaRLaLyERnX52u8yb1WTrTOKmqiojf9mkWkdbAIuApVT3lvpl089fYVbUCSBSRMOAT4BYfF6nBichooEhVt4vIcF+X5zoboqqHRaQ9sEZE9lb94bVc54H85HAYiKmyHe3sCxSFItIJwPle5OPyNAgRaYo7MXykqoud3QERO4CqngDWAbcBYSJy8YbQH6/3wcC9InIAdzXxSGAW/h83qnrY+V6E+2YgmTpe54GcHLYC3ZyeDM2AB4ClPi7T9bQUeMR5/Qjwvz4sS4Nw6pv/G9ijqjOq/MivYxeRds4TAyISAtyBu71lHTDWOczv4lbVqaoarapdcP89f66qD+PncYtIKxFpc/E1cCeQSR2v84AeIS0id+OuowwGPlDV13xcpAYhIh8Dw3FP4VsI/BZYAiwAYnFPdz5OVS9vtG7URGQI8H9ABt/XQb+Iu93Bb2MXkb64GyCDcd8ALlDVV0SkK+476ghgBzBeVUt9V9KG41QrPaeqo/09bie+T5zNJsBcVX1NRCKpw3Ue0MnBGGNM9QK5WskYY4wXlhyMMcZ4sORgjDHGgyUHY4wxHiw5GGOM8WDJwRhjjAdLDsYYYzz8P89YtUaMpW5AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['precision_7'], label='train acc')\n",
        "plt.plot(hist.history['val_precision_7'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "esQzOZTb9p48",
        "outputId": "8ac28837-c403-4d2a-ed6b-58803bd453b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "MNh51nKK9u15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy\n",
        "test_preds = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "\n",
        "# Recall for each class\n",
        "recall_vals = []\n",
        "for i in range(3):\n",
        "    class_idx = np.argwhere(y_true==i)\n",
        "    total = len(class_idx)\n",
        "    correct = np.sum(test_preds[class_idx]==i)\n",
        "    recall = correct / total\n",
        "    recall_vals.append(recall)\n",
        "\n",
        "classes = [0,1]\n",
        "# Calculate the test set accuracy and recall for each class\n",
        "print('Test set accuracy is {:.3f}'.format(test_acc))\n",
        "for i in range(2):\n",
        "    print('For class {}, recall is {:.3f}'.format(classes[i],recall_vals[i]))\n",
        "\n",
        "print(\"Weighted F score is {:.3f}\".format(test_acc))\n",
        "# print(\"Weighted F score is {:.3f}\".format(calculate_weighted_f_score(y_true, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuLzuden9xuZ",
        "outputId": "440cf5f8-14b0-4d88-ecc1-12a09fae9cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy is 0.608\n",
            "For class 0, recall is 1.000\n",
            "For class 1, recall is 0.000\n",
            "Weighted F score is 0.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Completely New Model Build"
      ],
      "metadata": {
        "id": "KHDKw2Fj3Q9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D"
      ],
      "metadata": {
        "id": "uBUl4s7dF9ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (1, 3), activation='relu', padding='same', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n",
        "model.add(MaxPooling2D((1, 4), strides=4))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv2D(64, (1, 3), activation='relu', padding='same',))\n",
        "model.add(MaxPooling2D((1, 3), strides=3))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv2D(128, (1, 3), activation='relu', padding='same',))\n",
        "model.add(MaxPooling2D((1, 2), strides=2))\n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dense(500,activation=\"relu\"))\n",
        "model.add(Dense(3,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "hFN0cl_cSjwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KKO5LSUTB1v",
        "outputId": "f16f4296-8e3b-4f7b-b141-9a6623e31a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22 (Conv2D)          (None, 5, 24, 32)         128       \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 2, 6, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 2, 6, 32)          0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 2, 6, 64)          6208      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 1, 2, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 1, 2, 64)          0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 1, 2, 128)         24704     \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 1, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 1, 1, 128)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1000)              129000    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 3)                 1503      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 662,043\n",
            "Trainable params: 662,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy']) "
      ],
      "metadata": {
        "id": "NRIZjV2-THkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 12\n",
        "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, validation_data=(X_val, y_val))\n",
        "\n",
        "##### LABLES NEED TO BY 1x3 ARRAY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EDJJqlJUMHb",
        "outputId": "a214b6fc-c9d2-435d-9a02-b8a3db3829cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 10s 5ms/step - loss: 1.1026 - accuracy: 0.3635 - val_loss: 1.0981 - val_accuracy: 0.3671\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0940 - accuracy: 0.3780 - val_loss: 1.0986 - val_accuracy: 0.3671\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0958 - accuracy: 0.3765 - val_loss: 1.0988 - val_accuracy: 0.3671\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0938 - accuracy: 0.3770 - val_loss: 1.0990 - val_accuracy: 0.3671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5S0IDmg7URVU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}