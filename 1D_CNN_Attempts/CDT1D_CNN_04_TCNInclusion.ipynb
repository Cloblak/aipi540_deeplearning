{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "background_execution": "on",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cloblak/aipi540_deeplearning/blob/main/1D_CNN_Attempts/CDT1D_CNN_04_TCNInclusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alpaca_trade_api"
      ],
      "metadata": {
        "id": "Xj0pR3efRVrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e4a699-f21c-4c9b-d841-1616640f0a3c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alpaca_trade_api\n",
            "  Downloading alpaca_trade_api-1.5.1-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.21.5)\n",
            "Collecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 24.1 MB/s \n",
            "\u001b[?25hCollecting msgpack==1.0.2\n",
            "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
            "\u001b[K     |████████████████████████████████| 273 kB 69.7 MB/s \n",
            "\u001b[?25hCollecting websockets<11,>=8.0\n",
            "  Downloading websockets-10.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 83.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.24.3)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.3.5)\n",
            "Collecting websocket-client<2,>=0.56.0\n",
            "  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>2 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (2.23.0)\n",
            "Collecting aiohttp==3.7.4\n",
            "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 48.0 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (3.10.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (21.4.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 975 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation==2.1.0->alpaca_trade_api) (21.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.1->alpaca_trade_api) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->alpaca_trade_api) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->alpaca_trade_api) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation==2.1.0->alpaca_trade_api) (3.0.7)\n",
            "Installing collected packages: multidict, yarl, async-timeout, websockets, websocket-client, PyYAML, msgpack, deprecation, aiohttp, alpaca-trade-api\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.3\n",
            "    Uninstalling msgpack-1.0.3:\n",
            "      Successfully uninstalled msgpack-1.0.3\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.7.4 alpaca-trade-api-1.5.1 async-timeout-3.0.1 deprecation-2.1.0 msgpack-1.0.2 multidict-6.0.2 websocket-client-1.3.1 websockets-10.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features To Consider\n",
        " - Targets are only predicting sell within market hours, i.e. at 1530, target is prediciting price for 1100 the next day.  Data from pre and post market is taken into consideration, and a sell or buy will be indicated if the price will flucuate after close."
      ],
      "metadata": {
        "id": "hdKRKIogGAu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "import alpaca_trade_api as tradeapi\n",
        "from datetime import datetime, timedelta, tzinfo, timezone, time\n",
        "import os.path\n",
        "import ast\n",
        "import threading\n",
        "import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import warnings"
      ],
      "metadata": {
        "id": "J1fWNRnTQZX-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 182\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrI_WR501Iis",
        "outputId": "d81ed128-0696-4a11-ba6c-4e760cde77c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa8e890e290>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAPER_API_KEY = \"PKE39LILN9SL1FMJMFV7\"\n",
        "PAPER_SECRET_KEY = \"TkU7fXH6WhP15MewgWlSnQG5RUoHGOPQ7yqlD6xq\"\n",
        "PAPER_BASE_URL = 'https://paper-api.alpaca.markets'"
      ],
      "metadata": {
        "id": "IXnO8ykgRIuv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api = tradeapi.REST(PAPER_API_KEY, PAPER_SECRET_KEY, PAPER_BASE_URL, api_version='v2')"
      ],
      "metadata": {
        "id": "_3XShkLcRQMs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepost_train_test_validate_offset_data(api, ticker, interval, train_days=180, test_days=60, validate_days=30, offset_days = 0):\n",
        "    ticker_data_dict = None\n",
        "    ticker_data_dict = {}\n",
        "    monthly_data_dict = None\n",
        "    monthly_data_dict = {}\n",
        "    interval_loop_data = None\n",
        "    interval_loop_data = pd.DataFrame()\n",
        "    stock_data = None\n",
        "    \n",
        "    days_to_collect = train_days + test_days + validate_days + offset_days\n",
        "\n",
        "    TZ = 'US/Eastern'\n",
        "\n",
        "    start = pd.to_datetime((datetime.now() - timedelta(days=days_to_collect)).strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "    end = pd.to_datetime(datetime.now().strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "\n",
        "    stock_data = api.get_bars(ticker, interval, start = start.isoformat(), end=end.isoformat(), adjustment=\"raw\").df\n",
        "    \n",
        "    interval_loop_data = interval_loop_data.append(stock_data)\n",
        "    df_start_ref = interval_loop_data.index[0]\n",
        "    start_str_ref = pd.to_datetime(start, utc=True)\n",
        "\n",
        "    while start_str_ref.value < ( pd.to_datetime(df_start_ref, utc=True) - pd.Timedelta(days=2.5)).value:\n",
        "        end_new = pd.to_datetime(interval_loop_data.index[0].strftime(\"%Y-%m-%d %H:%M\"), utc=True).isoformat()\n",
        "        stock_data_new = None\n",
        "        stock_data_new = api.get_bars(ticker, interval, start=start, end=end_new, adjustment=\"raw\").df\n",
        "        #stock_data_new = stock_data_new.reset_index()\n",
        "        interval_loop_data = interval_loop_data.append(stock_data_new).sort_values(by=['index'], ascending=True)\n",
        "        df_start_ref = interval_loop_data.index[0]\n",
        "        \n",
        "    stock_yr_min_df = interval_loop_data.copy()\n",
        "    stock_yr_min_df[\"Open\"] = stock_yr_min_df['open']\n",
        "    stock_yr_min_df[\"High\"]= stock_yr_min_df[\"high\"]\n",
        "    stock_yr_min_df[\"Low\"] = stock_yr_min_df[\"low\"]\n",
        "    stock_yr_min_df[\"Close\"] = stock_yr_min_df[\"close\"]\n",
        "    stock_yr_min_df[\"Volume\"] = stock_yr_min_df[\"volume\"]\n",
        "    stock_yr_min_df[\"VolumeWeightedAvgPrice\"] = stock_yr_min_df[\"vwap\"]\n",
        "    stock_yr_min_df[\"Time\"] = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    stock_yr_min_df.index = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    final_df = stock_yr_min_df.filter([\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"VolumeWeightedAvgPrice\"], axis = 1)\n",
        "    \n",
        "    first_day = final_df.index[0]\n",
        "    traintest_day = final_df.index[-1] - pd.Timedelta(days= test_days+validate_days+offset_days)\n",
        "    valtest_day = final_df.index[-1] - pd.Timedelta(days= test_days+offset_days)\n",
        "    last_day = final_df.index[-1] - pd.Timedelta(days= offset_days)\n",
        "    training_df =  final_df.loc[first_day:traintest_day] #(data_split - pd.Timedelta(days=1))]\n",
        "    validate_df = final_df.loc[traintest_day:valtest_day]\n",
        "    testing_df =  final_df.loc[valtest_day:last_day]\n",
        "    full_train = final_df.loc[first_day:last_day]\n",
        "    offset_df =  final_df.loc[last_day:]\n",
        "\n",
        "    return training_df, validate_df, testing_df, full_train, offset_df, final_df, traintest_day, valtest_day\n",
        "\n",
        "from datetime import date\n",
        "\n",
        "train_start = date(2017, 2, 18)\n",
        "train_end = date(2020, 3, 29)\n",
        "train_delta = train_end - train_start\n",
        "print(f'Number of days of Training Data {train_delta.days}')\n",
        "\n",
        "val_day_num = 400\n",
        "print(f'Number of days of Validation Data {val_day_num}')\n",
        "\n",
        "test_start = train_end + timedelta(val_day_num)\n",
        "test_end = date.today()\n",
        "test_delta = (test_end - test_start)\n",
        "print(f'Number of days of Holdout Test Data {test_delta.days}')\n",
        "\n",
        "ticker = \"WEAT\" # Ticker Symbol to Test\n",
        "interval = \"5Min\" # Interval of bars\n",
        "train_day_int = train_delta.days # Size of training set (Jan 2010 - Oct 2017)\n",
        "val_day_int = val_day_num # Size of validation set\n",
        "test_day_int = test_delta.days # Size of test set\n",
        "offset_day_int = 60 # Number of days to off set the training data\n",
        "train_raw, val_raw, test_raw, full_raw, offset_raw, complete_raw, traintest_day, testval_day = prepost_train_test_validate_offset_data(api, ticker, \n",
        "                                                                                     interval, \n",
        "                                                                                     train_days=train_day_int, \n",
        "                                                                                     test_days=test_day_int, \n",
        "                                                                                     validate_days=val_day_int,\n",
        "                                                                                     offset_days = offset_day_int)\n",
        "\n",
        "def timeFilterAndBackfill(df):\n",
        "  \"\"\" \n",
        "  Prep df to be filled out for each trading day:\n",
        "    Time Frame: 0930-1930\n",
        "    Backfilling NaNs\n",
        "    Adjusting Volume to Zero if no Trading data is present\n",
        "      - Assumption is that there were no trades duing that time \n",
        "\n",
        "  We will build over lapping arrays by 30 min to give ourselfs more\n",
        "  oppurtunities to predict during a given trading day \n",
        "  \"\"\"\n",
        "  \n",
        "  df = df.between_time('07:29','17:29') # intial sorting of data\n",
        "\n",
        "  TZ = 'US/Eastern' # define the correct timezone\n",
        "\n",
        "  start_dateTime = pd.Timestamp(year = df.index[0].year, \n",
        "                                month = df.index[0].month, \n",
        "                                day = df.index[0].day, \n",
        "                                hour = 7, minute = 25, tz = TZ)\n",
        "\n",
        "  end_dateTime = pd.Timestamp(year = df.index[-1].year, \n",
        "                              month = df.index[-1].month, \n",
        "                              day = df.index[-1].day, \n",
        "                              hour = 17, minute = 35, tz = TZ)\n",
        "\n",
        "  # build blank index that has ever 5 min interval represented\n",
        "  dateTime_index = pd.date_range(start_dateTime,\n",
        "                                end_dateTime, \n",
        "                                freq='5min').tolist()\n",
        "\n",
        "  dateTime_index_df = pd.DataFrame()\n",
        "  dateTime_index_df[\"Time\"] = dateTime_index \n",
        "  filtered_df = pd.merge_asof(dateTime_index_df, df,  \n",
        "                              on='Time').set_index(\"Time\").between_time('09:29','17:29')\n",
        "\n",
        "  # create the close array by back filling NA, to represent no change in close\n",
        "  closeset_list = []\n",
        "  prev_c = None\n",
        "\n",
        "  for c in filtered_df[\"Close\"]:\n",
        "\n",
        "    if prev_c == None:\n",
        "      if math.isnan(c):\n",
        "        prev_c = 0\n",
        "        closeset_list.append(0)\n",
        "      else:\n",
        "        prev_c = c\n",
        "        closeset_list.append(c)\n",
        "    \n",
        "    elif prev_c != None:\n",
        "      if c == prev_c:\n",
        "        closeset_list.append(c)\n",
        "      elif math.isnan(c):\n",
        "        closeset_list.append(prev_c)\n",
        "      else:\n",
        "        closeset_list.append(c)\n",
        "        prev_c = c\n",
        "    \n",
        "  filtered_df[\"Close\"] = closeset_list\n",
        "\n",
        "  # create the volume\n",
        "  volumeset_list = []\n",
        "  prev_v = None\n",
        "\n",
        "  for v in filtered_df[\"Volume\"]:\n",
        "    \n",
        "    if prev_v == None:\n",
        "      if math.isnan(v):\n",
        "        prev_v = 0\n",
        "        volumeset_list.append(0)\n",
        "      else:\n",
        "        prev_v = v\n",
        "        volumeset_list.append(v)\n",
        "\n",
        "    elif prev_v != None:\n",
        "      if v == prev_v:\n",
        "        volumeset_list.append(0)\n",
        "        prev_v = v\n",
        "      elif math.isnan(v):\n",
        "        volumeset_list.append(0)\n",
        "        prev_v = 0\n",
        "      else:\n",
        "        volumeset_list.append(v)\n",
        "        prev_v = v\n",
        "\n",
        "  filtered_df[\"Volume\"] = volumeset_list\n",
        "  \n",
        "  adjvolumeset_list = []\n",
        "  prev_v = None\n",
        "\n",
        "  for v in filtered_df[\"VolumeWeightedAvgPrice\"]:\n",
        "    if prev_v == None:\n",
        "      if math.isnan(v):\n",
        "        prev_v = 0\n",
        "        adjvolumeset_list.append(0)\n",
        "      else:\n",
        "        prev_v = v\n",
        "        adjvolumeset_list.append(v)\n",
        "    elif prev_v != None:\n",
        "      if v == prev_v:\n",
        "        adjvolumeset_list.append(0)\n",
        "        prev_v = v\n",
        "      elif math.isnan(v):\n",
        "        adjvolumeset_list.append(0)\n",
        "        prev_v = 0\n",
        "      else:\n",
        "        adjvolumeset_list.append(v)\n",
        "        prev_v = v\n",
        "\n",
        "  filtered_df[\"VolumeWeightedAvgPrice\"] = adjvolumeset_list\n",
        "\n",
        "  preped_df = filtered_df.backfill()\n",
        "\n",
        "  return preped_df  "
      ],
      "metadata": {
        "id": "tINNlljbRaDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1bd7c82-287b-489d-bd37-881e349dfbbe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of days of Training Data 1135\n",
            "Number of days of Validation Data 400\n",
            "Number of days of Holdout Test Data 305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw[0:300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "J6Cw_PVrh2lJ",
        "outputId": "445bf5b8-884e-4110-8274-0c546b1e4c02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-63c9a56a-51c9-4ea4-9748-ff45ffbc6bd4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeWeightedAvgPrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:10:00-05:00</th>\n",
              "      <td>2016-12-20 12:10:00-05:00</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>1171</td>\n",
              "      <td>6.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:15:00-05:00</th>\n",
              "      <td>2016-12-20 12:15:00-05:00</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>5000</td>\n",
              "      <td>6.820100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:20:00-05:00</th>\n",
              "      <td>2016-12-20 12:20:00-05:00</td>\n",
              "      <td>6.8200</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8200</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>3129</td>\n",
              "      <td>6.830320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:50:00-05:00</th>\n",
              "      <td>2016-12-20 12:50:00-05:00</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>100</td>\n",
              "      <td>6.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:00:00-05:00</th>\n",
              "      <td>2016-12-20 13:00:00-05:00</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>200</td>\n",
              "      <td>6.838300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-30 10:00:00-05:00</th>\n",
              "      <td>2016-12-30 10:00:00-05:00</td>\n",
              "      <td>6.8926</td>\n",
              "      <td>6.8999</td>\n",
              "      <td>6.8926</td>\n",
              "      <td>6.8999</td>\n",
              "      <td>5423</td>\n",
              "      <td>6.893169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-30 10:05:00-05:00</th>\n",
              "      <td>2016-12-30 10:05:00-05:00</td>\n",
              "      <td>6.8947</td>\n",
              "      <td>6.8947</td>\n",
              "      <td>6.8947</td>\n",
              "      <td>6.8947</td>\n",
              "      <td>150</td>\n",
              "      <td>6.894700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-30 10:10:00-05:00</th>\n",
              "      <td>2016-12-30 10:10:00-05:00</td>\n",
              "      <td>6.8937</td>\n",
              "      <td>6.8937</td>\n",
              "      <td>6.8937</td>\n",
              "      <td>6.8937</td>\n",
              "      <td>2000</td>\n",
              "      <td>6.893700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-30 10:15:00-05:00</th>\n",
              "      <td>2016-12-30 10:15:00-05:00</td>\n",
              "      <td>6.8907</td>\n",
              "      <td>6.8941</td>\n",
              "      <td>6.8900</td>\n",
              "      <td>6.8900</td>\n",
              "      <td>4000</td>\n",
              "      <td>6.893743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-30 10:20:00-05:00</th>\n",
              "      <td>2016-12-30 10:20:00-05:00</td>\n",
              "      <td>6.8993</td>\n",
              "      <td>6.8993</td>\n",
              "      <td>6.8993</td>\n",
              "      <td>6.8993</td>\n",
              "      <td>800</td>\n",
              "      <td>6.899300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63c9a56a-51c9-4ea4-9748-ff45ffbc6bd4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63c9a56a-51c9-4ea4-9748-ff45ffbc6bd4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63c9a56a-51c9-4ea4-9748-ff45ffbc6bd4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               Time    Open    High     Low  \\\n",
              "timestamp                                                                     \n",
              "2016-12-20 12:10:00-05:00 2016-12-20 12:10:00-05:00  6.8300  6.8300  6.8300   \n",
              "2016-12-20 12:15:00-05:00 2016-12-20 12:15:00-05:00  6.8201  6.8201  6.8201   \n",
              "2016-12-20 12:20:00-05:00 2016-12-20 12:20:00-05:00  6.8200  6.8400  6.8200   \n",
              "2016-12-20 12:50:00-05:00 2016-12-20 12:50:00-05:00  6.8400  6.8400  6.8400   \n",
              "2016-12-20 13:00:00-05:00 2016-12-20 13:00:00-05:00  6.8383  6.8383  6.8383   \n",
              "...                                             ...     ...     ...     ...   \n",
              "2016-12-30 10:00:00-05:00 2016-12-30 10:00:00-05:00  6.8926  6.8999  6.8926   \n",
              "2016-12-30 10:05:00-05:00 2016-12-30 10:05:00-05:00  6.8947  6.8947  6.8947   \n",
              "2016-12-30 10:10:00-05:00 2016-12-30 10:10:00-05:00  6.8937  6.8937  6.8937   \n",
              "2016-12-30 10:15:00-05:00 2016-12-30 10:15:00-05:00  6.8907  6.8941  6.8900   \n",
              "2016-12-30 10:20:00-05:00 2016-12-30 10:20:00-05:00  6.8993  6.8993  6.8993   \n",
              "\n",
              "                            Close  Volume  VolumeWeightedAvgPrice  \n",
              "timestamp                                                          \n",
              "2016-12-20 12:10:00-05:00  6.8300    1171                6.830000  \n",
              "2016-12-20 12:15:00-05:00  6.8201    5000                6.820100  \n",
              "2016-12-20 12:20:00-05:00  6.8400    3129                6.830320  \n",
              "2016-12-20 12:50:00-05:00  6.8400     100                6.840000  \n",
              "2016-12-20 13:00:00-05:00  6.8383     200                6.838300  \n",
              "...                           ...     ...                     ...  \n",
              "2016-12-30 10:00:00-05:00  6.8999    5423                6.893169  \n",
              "2016-12-30 10:05:00-05:00  6.8947     150                6.894700  \n",
              "2016-12-30 10:10:00-05:00  6.8937    2000                6.893700  \n",
              "2016-12-30 10:15:00-05:00  6.8900    4000                6.893743  \n",
              "2016-12-30 10:20:00-05:00  6.8993     800                6.899300  \n",
              "\n",
              "[300 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildTargets_VolOnly(full_df = full_raw, train_observations = train_raw.shape[0], \n",
        "                         val_observations = val_raw.shape[0], \n",
        "                         test_observations = test_raw.shape[0], \n",
        "                         alph = .55, volity_int = 10):\n",
        "\n",
        "  \"\"\" \n",
        "  This function will take a complete set of train, val, and test data and return the targets.\n",
        "  Volitility will be calculated over the 252 5min incriments \n",
        "  The Target shift is looking at 2 hours shift from current time\n",
        "  \"\"\"\n",
        "\n",
        "  returns = np.log(full_df['Close']/(full_df['Close'].shift()))\n",
        "  returns.fillna(0, inplace=True)\n",
        "  volatility = returns.rolling(window=(volity_int)).std()*np.sqrt(volity_int)\n",
        "\n",
        "\n",
        "\n",
        "  return volatility\n",
        "  #return train_targets, val_targets, test_targets, full_targets\n",
        "\n",
        "volatility = buildTargets_VolOnly()\n",
        "\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "ax1 = fig.add_subplot(1, 1, 1)\n",
        "volatility.plot(ax=ax1, color = \"red\")\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Volatility', color = \"red\")\n",
        "ax1.set_title(f'Annualized volatility for {ticker}')\n",
        "ax2 = ax1.twinx()\n",
        "full_raw.Close.plot(ax=ax2, color = \"blue\")\n",
        "ax2.set_ylabel('Close', color = \"blue\")\n",
        "ax2.axvline(x=full_raw.index[train_raw.shape[0]])\n",
        "ax2.axvline(x=full_raw.index[val_raw.shape[0]+train_raw.shape[0]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fWqLBPQPbjYZ",
        "outputId": "cd156015-2a22-4a6d-f5b6-0a1342cf4da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = timeFilterAndBackfill(train_raw)\n",
        "val = timeFilterAndBackfill(val_raw)\n",
        "test = timeFilterAndBackfill(test_raw)\n",
        "\n",
        "train = train[train.index.dayofweek <= 4].copy()\n",
        "val = val[val.index.dayofweek <= 4].copy()\n",
        "test = test[test.index.dayofweek <= 4].copy()\n",
        "\n",
        "train[\"Open\"] = np.where((train[\"Volume\"] == 0), train[\"Close\"], train[\"Open\"])\n",
        "train[\"High\"] = np.where((train[\"Volume\"] == 0), train[\"Close\"], train[\"High\"])\n",
        "train[\"Low\"] = np.where((train[\"Volume\"] == 0), train[\"Close\"], train[\"Low\"])\n",
        "\n",
        "val[\"Open\"] = np.where((val[\"Volume\"] == 0), val[\"Close\"], val[\"Open\"])\n",
        "val[\"High\"] = np.where((val[\"Volume\"] == 0), val[\"Close\"], val[\"High\"])\n",
        "val[\"Low\"] = np.where((val[\"Volume\"] == 0), val[\"Close\"], val[\"Low\"])\n",
        "\n",
        "test[\"Open\"] = np.where((test[\"Volume\"] == 0), test[\"Close\"], test[\"Open\"])\n",
        "test[\"High\"] = np.where((test[\"Volume\"] == 0), test[\"Close\"], test[\"High\"])\n",
        "test[\"Low\"] = np.where((test[\"Volume\"] == 0), test[\"Close\"], test[\"Low\"])\n",
        "\n",
        "def strided_axis0(a, L, overlap=1):\n",
        "    if L==overlap:\n",
        "        raise Exception(\"Overlap arg must be smaller than length of windows\")\n",
        "    S = L - overlap\n",
        "    nd0 = ((len(a)-L)//S)+1\n",
        "    if nd0*S-S!=len(a)-L:\n",
        "        warnings.warn(\"Not all elements were covered\")\n",
        "    m,n = a.shape\n",
        "    s0,s1 = a.strides\n",
        "    return np.lib.stride_tricks.as_strided(a, shape=(nd0,L,n), strides=(S*s0,s0,s1))\n",
        "\n",
        "# OLDER CODE WITHOUT OVERLAP OF LABELING\n",
        "# def blockshaped(arr, nrows, ncols):\n",
        "#     \"\"\"\n",
        "#     Return an array of shape (n, nrows, ncols) where\n",
        "#     n * nrows * ncols = arr.size\n",
        "\n",
        "#     If arr is a 2D array, the returned array should look like n subblocks with\n",
        "#     each subblock preserving the \"physical\" layout of arr.\n",
        "#     \"\"\"\n",
        "#     h, w = arr.shape\n",
        "#     assert h % nrows == 0, f\"{h} rows is not evenly divisible by {nrows}\"\n",
        "#     assert w % ncols == 0, f\"{w} cols is not evenly divisible by {ncols}\"\n",
        "#     return np.flip(np.rot90((arr.reshape(h//nrows, nrows, -1, ncols)\n",
        "#                .swapaxes(1,2)\n",
        "#                .reshape(-1, nrows, ncols)), axes = (1, 2)), axis = 1)\n",
        "\n",
        "\n",
        "def blockshaped(arr, nrows, ncols, overlapping_5min_intervals = 12):\n",
        "    \"\"\"\n",
        "    Return an array of shape (n, nrows, ncols) where\n",
        "    n * nrows * ncols = arr.size\n",
        "\n",
        "    If arr is a 2D array, the returned array should look like n subblocks with\n",
        "    each subblock preserving the \"physical\" layout of arr.\n",
        "    \"\"\"\n",
        "\n",
        "    h, w = arr.shape\n",
        "    assert h % nrows == 0, f\"{h} rows is not evenly divisible by {nrows}\"\n",
        "    assert w % ncols == 0, f\"{w} cols is not evenly divisible by {ncols}\"\n",
        "\n",
        "    return np.flip(np.rot90((strided_axis0(arr, 24, overlap=overlapping_5min_intervals).reshape(-1, nrows, ncols)), axes = (1, 2)), axis = 1)\n",
        "\n",
        "train_tonp = train[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "val_tonp = val[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "test_tonp = test[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "train_array = train_tonp.to_numpy()\n",
        "val_array = val_tonp.to_numpy()\n",
        "test_array = test_tonp.to_numpy()\n",
        "\n",
        "X_train_pre_final = blockshaped(train_array, 24, 5, overlapping_5min_intervals = 12)\n",
        "X_val_pre_final = blockshaped(val_array, 24, 5, overlapping_5min_intervals = 12)\n",
        "X_test_pre_final = blockshaped(test_array, 24, 5, overlapping_5min_intervals = 12)\n",
        "\n",
        "# X_train_pre_final = blockshaped(train_array, 24, 5)\n",
        "# X_val_pre_final = blockshaped(val_array, 24, 5)\n",
        "# X_test_pre_final = blockshaped(test_array, 24, 5)"
      ],
      "metadata": {
        "id": "0_yU14VEM37m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(edgeitems=10,linewidth=580)\n",
        "X_train_pre_final[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8KcE_XCidzo",
        "outputId": "165dc69a-19bc-44af-e8da-232e8d81a744"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tonp[0:24]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "29LbU_ukUK8j",
        "outputId": "67789472-aabd-469d-946d-a41d9f2255c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-71723ea3-7d80-47db-98d9-3deb094d9c74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:30:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:35:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:40:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:45:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:50:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 09:55:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:00:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:05:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:10:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:15:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:20:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:25:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:30:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:35:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:40:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:45:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:50:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:55:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:00:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:05:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:10:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:15:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:20:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:25:00-05:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71723ea3-7d80-47db-98d9-3deb094d9c74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71723ea3-7d80-47db-98d9-3deb094d9c74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71723ea3-7d80-47db-98d9-3deb094d9c74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           Open  High  Low  Close  Volume\n",
              "Time                                                     \n",
              "2016-12-20 09:30:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 09:35:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 09:40:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 09:45:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 09:50:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 09:55:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:00:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:05:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:10:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:15:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:20:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:25:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:30:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:35:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:40:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:45:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:50:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 10:55:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 11:00:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 11:05:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 11:10:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 11:15:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 11:20:00-05:00   0.0   0.0  0.0    0.0     0.0\n",
              "2016-12-20 11:25:00-05:00   0.0   0.0  0.0    0.0     0.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pre_final[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6w8fb_TU-Tx",
        "outputId": "6471b8a2-a84c-45c0-c2da-d7c7b60a5099"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    6.83  ,    6.8201,    6.82  ,    6.84  ],\n",
              "       [   0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    6.83  ,    6.8201,    6.84  ,    6.84  ],\n",
              "       [   0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    6.83  ,    6.8201,    6.82  ,    6.84  ],\n",
              "       [   0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    6.83  ,    6.8201,    6.84  ,    6.84  ],\n",
              "       [   0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    ,    0.    , 1171.    , 5000.    , 3129.    ,    0.    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create target from OHLC and Volume Data\n",
        "###### THIS IS FOR 3 CLASS FROM PAPER ########\n",
        "# def buildTargets(obs_array,  \n",
        "#                  alph = .55, \n",
        "#                  volity_int = 10):\n",
        "\n",
        "#   \"\"\" \n",
        "#   This function will take a complete set of train, val, and test \n",
        "#   data and return the targets. Volitility will be calculated over \n",
        "#   the 24 5min incriments. The Target shift is looking at 2 hours \n",
        "#   shift from current time\n",
        "\n",
        "#   shift_2hour = The amount of time the data interval take to equal 2 hours \n",
        "#                 (i.e. 5 min data interval is equal to 24)\n",
        "#   alph = The alpha value for calculating the shift in price\n",
        "#   volity_int = the number of incriments used to calculate volitility \n",
        "#   \"\"\"\n",
        "\n",
        "#   target_close_list =[]\n",
        "\n",
        "#   for arr in obs_array:\n",
        "#     target_close_list.append(arr[3][-1])\n",
        "  \n",
        "#   target_close_df = pd.DataFrame()\n",
        "#   target_close_df[\"Close\"] = target_close_list\n",
        "\n",
        "#   target_close_df[\"Volitility\"] = target_close_df[\"Close\"].rolling(volity_int).std()\n",
        "\n",
        "#   # print(len(volatility), len(target_close_df[\"Close\"]))\n",
        "\n",
        "  \n",
        "#   targets = [0] * len(target_close_df.Close)\n",
        "\n",
        "#   targets = np.where(target_close_df.Close.shift() >= (target_close_df.Close * (1 + alph * target_close_df[\"Volitility\"])), \n",
        "#            2, targets)\n",
        "  \n",
        "#   targets = np.where(target_close_df.Close.shift() <= (target_close_df.Close * (1 - alph * target_close_df[\"Volitility\"])), \n",
        "#            1, targets)\n",
        "\n",
        "#   return targets\n",
        "\n",
        "\n",
        "#####DISREGUARD THE VOLITLITY######\n",
        "# def buildTargets(obs_array,  \n",
        "#                  alph = .55, \n",
        "#                  volity_int = 10):\n",
        "\n",
        "#   \"\"\" \n",
        "#   This function will take a complete set of train, val, and test \n",
        "#   data and return the targets. Volitility will be calculated over \n",
        "#   the 24 5min incriments. The Target shift is looking at 2 hours \n",
        "#   shift from current time\n",
        "\n",
        "#   shift_2hour = The amount of time the data interval take to equal 2 hours \n",
        "#                 (i.e. 5 min data interval is equal to 24)\n",
        "#   alph = The alpha value for calculating the shift in price\n",
        "#   volity_int = the number of incriments used to calculate volitility \n",
        "#   \"\"\"\n",
        "\n",
        "#   target_close_list =[]\n",
        "\n",
        "#   for arr in obs_array:\n",
        "#     target_close_list.append(arr[3][-1])\n",
        "  \n",
        "#   target_close_df = pd.DataFrame()\n",
        "#   target_close_df[\"Close\"] = target_close_list\n",
        "\n",
        "#   target_close_df[\"Volitility\"] = target_close_df[\"Close\"].rolling(volity_int).std()\n",
        "  \n",
        "#   targets = [0] * len(target_close_df.Close)\n",
        "\n",
        "#   targets = np.where(target_close_df.Close.shift(-1) >= (target_close_df.Close * (1 + alph)), \n",
        "#            2, targets)\n",
        "  \n",
        "#   targets = np.where(target_close_df.Close.shift(-1) <= (target_close_df.Close * (1 - alph)), \n",
        "#            1, targets)\n",
        "\n",
        "#   return targets\n",
        "\n",
        "  #####Binary Class######\n",
        "def buildTargets(obs_array,  \n",
        "                 alph = .55, \n",
        "                 volity_int = 10):\n",
        "\n",
        "  \"\"\" \n",
        "  This function will take a complete set of train, val, and test \n",
        "  data and return the targets. Volitility will be calculated over \n",
        "  the 24 5min incriments. The Target shift is looking at 2 hours \n",
        "  shift from current time\n",
        "\n",
        "  shift_2hour = The amount of time the data interval take to equal 2 hours \n",
        "                (i.e. 5 min data interval is equal to 24)\n",
        "  alph = The alpha value for calculating the shift in price\n",
        "  volity_int = the number of incriments used to calculate volitility \n",
        "  \"\"\"\n",
        "\n",
        "  target_close_list =[]\n",
        "\n",
        "  for arr in obs_array:\n",
        "    target_close_list.append(arr[3][-1])\n",
        "  \n",
        "  target_close_df = pd.DataFrame()\n",
        "  target_close_df[\"Close\"] = target_close_list\n",
        "\n",
        "  target_close_df[\"Volitility\"] = target_close_df[\"Close\"].rolling(volity_int).std()\n",
        "\n",
        "  # print(len(volatility), len(target_close_df[\"Close\"]))\n",
        "\n",
        "  \n",
        "  targets = [0] * len(target_close_df.Close)\n",
        "\n",
        "  targets = np.where(target_close_df.Close.shift() >= (target_close_df.Close * (1 + alph)), \n",
        "           1, targets)\n",
        "\n",
        "  return targets"
      ],
      "metadata": {
        "id": "Pe89LdnsLltO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "volity_val = 10\n",
        "alph = .001\n",
        "y_train_pre_final = buildTargets(X_train_pre_final, alph=alph,  volity_int = volity_val)\n",
        "y_val_pre_final = buildTargets(X_val_pre_final, alph=alph, volity_int = volity_val)\n",
        "y_test_pre_final = buildTargets(X_test_pre_final, alph=alph, volity_int = volity_val)"
      ],
      "metadata": {
        "id": "4aYPOa7INyAl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_distribution(obj):\n",
        "    count_dict = {\n",
        "        \"up\": 0,\n",
        "        \"down/flat\": 0,\n",
        "    }\n",
        "    \n",
        "    for i in obj:\n",
        "        if i == 1: \n",
        "            count_dict['up'] += 1\n",
        "        elif i == 0: \n",
        "            count_dict['down/flat'] += 1\n",
        "        # elif i == 0: \n",
        "        #     count_dict['flat'] += 1             \n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "            \n",
        "    return count_dict"
      ],
      "metadata": {
        "id": "vWIY2rwEYCfM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25,7))\n",
        "# Train\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_train_pre_final)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')\n",
        "# Validation\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_val_pre_final)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
        "# Test\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_test_pre_final)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[2]).set_title('Class Distribution in Test Set')"
      ],
      "metadata": {
        "id": "-BsVCfr8YCiX",
        "outputId": "059bcec4-2f34-4556-9e76-55405c005f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution in Test Set')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABa8AAAG5CAYAAACJPcgFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdfZwdZXnw8d8VEoi8FAIkiAmQqBEkYCCsiMpbS5WAlmArAqIEwaY8orSI1aAtLwqtFPug1JcWSyRBJOTJUzTyRDAiCMprQgOCgKQQyEYgayABgWAC1/PHzMaTdTfZzZ6zO3v29/18zicz99xzzzXnBK6c68zcE5mJJEmSJEmSJElVMqS/A5AkSZIkSZIkqSOL15IkSZIkSZKkyrF4LUmSJEmSJEmqHIvXkiRJkiRJkqTKsXgtSZIkSZIkSaoci9eSJEmSJEmSpMqxeK2mERHnR8R3+zuOWhHxo4iYWqexDomIR2rWl0bEn9dj7HK8ByPi8HqNVzNu3d6DgRyDJKlr5vBej99UOTwiMiLe3NfHlSR1zjzd6/GbKk9Lfc3itQaUiPhwRCyMiN9FxFPl/6wP7qdYMiJeLGNZGRE3RcTxtX0y86jMnNnNsTb6JS0zb8vMPXsbd3m8KyPiwg7jT8jMW+oxfodxu/UedFS+r+2v1yLi5Zr1k/oihjKOgyPi9ohYHRHPRsQvIuLt3dzXL9+SVDKHD6ocfkNEfLGT9ikR8XREDN3cmCJiQkT8uMzJqyJiUUQc3c1961qMkKRmYp4eVHm6bt+1y/FuiYiPb6LPaRHxcES8EBHPRMT8iNiuG2MfHhGtPY1JzcXitQaMiPg08FXgn4BdgN2BbwJT+jGsiZm5LbAncCXw9Yg4r94H6c2XvIEqM7dtfwFPAn9R03Z1e79GvjcR8SfA9cC/ATsCo4ELgFcadUxJakbm8EFnJvCRiIgO7R8Frs7Mdb0Y+4fAAuD1wCjgTOD5XownSYOeeXpw6e537XqJiMMo/m6dmJnbAW8Frq33cdTEMtOXr8q/gO2B3wHHbaTP+cB3a9b/D/A0sBq4FZhQs+1o4FfAC8By4DNl+84UxcpVwLPAbcCQLo6XwJs7tH0QWAPsVK7fAny8XH4z8LMynt8C15btt5ZjvVie4/HA4UAr8LnyHK5qb6s51lLgnPI8ngO+Awwvt50C/LyzeIFpwFrg9+Xxflgz3p+Xy1tR/OPlN+Xrq8BW5bb22M4GVgBPAR/byOdS+x6cAvwc+EoZ8+PAUd34/Gtj6+y9GVF+bm3luNcDY3obA9ACrNpEbKcCD5Vj3Qjs0dXn2t//Hfny5ctXf7wwhw+6HA68rnyvDq1pG1G+vxOBA4E7ys/qKeDrwJYb+3xqPuMEdthIzO8HFpdj3w68rWy/CngNeLl87z7b3/9t+PLly1cVXpinB12e7jBGbWxDgOnA/wArgTnAjuW24cB3y/ZVwD0UP3RcBLxafja/A77eyTE+A3x/IzFsVcb9JPAM8O8U/5bYhiJvv1aO/TvgDf3934yvvn955bUGindS/M/yuh7s8yNgPMVVOfcCtb8gXgH8TRa/+u0D/LRsP5siWYyk+B/x5ykSUXf9ABhK8aWsoy8BP6b48jaG4mpeMvPQcvvELH7pbP8F8vUUV/vuQZEEO3MScCTwJuAtwD9sKsDMvJzivfiX8nh/0Um3LwAHAfvxhy+ZtWO/nuIfOaOB04BvRMSITR279A7gEYp/vPwLcEUnV2ZtSsf3ZgjFPyj2oLhK4GWKL8K9jeHXwKsRMTMijup4jhExheLvyF9S/J25DbgGNvq5StJgYw7vXNPm8Mx8meIL78k1zR8CHs7M+yi+5J5VjvNO4AjgE904/kpgCfDdiDg2Inap3RgR+wMzgL8BdgL+A5gXEVtl5kfZ8Oqyf+nmOUtSszNPd65p8/RGfAo4FjgMeANFEfwb5bapZVy7UeTY04GXM/MLFN+DP1me8yc7Gfcu4MiIuCAi3h0RW3XY/mWK93g/ih8BRgPnZuaLwFHAb/IPV4b/pgfnoyZh8VoDxU7Ab7MHt5lm5ozMfCEzX6H4pXhiRGxfbl4L7B0Rf5KZz2XmvTXtu1JcPbs2i7mvup1QM3MtxS+9O3ayeS1FcnxDZq7JzJ9vYrjXgPMy85XyS2Bnvp6ZyzLzWYpfPE/sbqybcBLwxcxckZltFFNlfLRm+9py+9rMnE/xC2h35wh7IjO/nZmvUtxWvCvFP156YoP3JjNXZub/zcyXMvMFivfisN7GkJnPAwdT/KPq20BbRMyr+bJ8OvDPmflQ+Xfzn4D9ImKPHp6PJDUzc3jnmj2HzwQ+GBHDy/WTyzYyc1Fm3pmZ6zJzKUWReWN5m3K/BP6U4iqxfwWeiohbI2J82WUa8B+ZeVdmvprFPKCvUBQJJEmdM093rtnzdGdOB76Qma01n+0Hy6lV1lL8XXlzmWMXld+XNykzb6O44GsS8P+AlRHxvyNii7K4Pg04KzOfLb/P/xNwQg/iVpOzeK2BYiWwc3fnoyr/J/jliPifiHie4ksOFL9AAvwVxe1MT0TEzyLinWX7JRRX9Pw4Ih6LiOk9CTIihlH8kvxsJ5s/CwRwdxRPGz51E8O1ZeaaTfRZVrP8BMWvo/XwhnK8rsZe2eEfNy8B23Zz7KfbFzLzpXKxu/u22+C9iYitI+I/IuKJ8vO+FdghIrbobQxlYfqUzBxDceXAGyhu7YLiH0hfKx8Y1X77W1D8UixJKpjDO9fUObwsHPwWODYi3kRxZdn3ACLiLRFxfRQPb3ye4kvqzp2N08m4rZn5ycx8E0UefhGYVW7eAzi7PS+XuXk36vfeSlIzMk93rqnzdBf2AK6ryaEPUdwttQvF9Co3ArMj4jcR8S/lZ9ItmfmjLK5E35FiLvVTgI9TfKZbA4tqjntD2S4BFq81cNxBceXMsd3s/2GK/yH+OcWtLWPL9gDIzHsycwrFbU7fp7i1lfLX47Mz843AMcCnI+KIHsQ5BVgH3N1xQ2Y+nZl/nZlvoLid9Zux8aced+dX6N1qlnenmDMLii9yW7dviIjX93Ds31Akrs7GroKO8Z9N8Wv0OzLzT4D228N6Oh3Jxg+a+TDFw0L2KZuWUdwSt0PN63WZeXs9jytJA5w5vHODIYfPorji+iPAjZn5TNn+LeBhYHyZtz/PZuTszFxGcTtzbV6+qENe3jozr2nfpRfnIknNyjzducGQpztaRjFPdm0eHZ6Zy8srwS/IzL2Bd1E8Y6J9erCeXEH/WmbeRDGdzD4UP3S/TDFvevsxt8/iYZI9GlvNy+K1BoTMXA2cSzHf07HllbbDynmIO5uzcDuKBLySIrH8U/uGiNgyIk6KiO3LW4+ep7htiIh4f0S8ubx1ZTXFr4yvbSq+iNgxIk6i+AJ1cWau7KTPcRExplx9juJ/wu1jPwO8sRtvRUdnRMSYiNiRYu6s9jm87gMmRMR+5e2653fYb1PHuwb4h4gYGRE7U7z3392M+PrKdhQJb1X5XpxXj0EjYq+IOLv9c4uI3ShuF7uz7PLvwDkRMaHcvn1EHFczxOZ+rpLUNMzhXRoMOXwWRXHjrymnDCltR/HZ/S4i9gL+V3cGi4gRUcyX+eaIGFKe36n8IS9/Gzg9It4RhW0i4n0RsV253bwsSR2Yp7s0GPJ0R/8OXBTlNJhljFPK5T+NiH2juLv5eYppRLr1HkfElIg4oczjEREHUkwXdmdmvkaRvy+NiFFl/9ERcWTN2DvFH6al0SBk8VoDRmb+K/BpiocZtFH8KvhJil9zO5pFcfvNcoonBN/ZYftHgaVR3OZ0OsW8U1A8dOInFPNK3QF8MzNv3khY90XE7yhuf/o4xTxN53bR9+3AXWX/ecDfZuZj5bbzgZnlbTIf2sjxOvoexYMpHqN4IvCFAJn5a+CL5bk8SvHU4VpXUMxDtioiOnv/LgQWAvcDv6R4CMeFPYirr32V4mnEv6X4rG+o07gvUDz04q6IeLEc+wGKK73JzOuAiylunXq+3HZUzf7ns3mfqyQ1FXN4p5o+h2cxn/XtwDYU71u7z1BcufcCxRfW7j7U+PcUV/j9hOKL8wMUBZRTyuMtpCiUf52ieLGkfVvpnykKBqsi4jM9PyNJak7m6U41fZ7uxNco3r8fR8QLFJ/tO8ptrwfmUuTfh4CfUUwl0r7fByPiuYi4rJNxn6PIz4+W+38XuCQz2x/0+TmKz/nO8u/NTyjn+S7vfr4GeKx8T50KbBCKHsyPL0mSJEmSJElSn/DKa0mSJEmSJElS5Vi8liRJkiRJkiRVjsVrSZIkSZIkSVLlWLyWJEmSJEmSJFXO0P4OoBF23nnnHDt2bH+HIUlqYosWLfptZo7s7zgGOnO2JKmRzNf1Yb6WJDXSxvJ1Uxavx44dy8KFC/s7DElSE4uIJ/o7hmZgzpYkNZL5uj7M15KkRtpYvnbaEEmSJEmSJElS5Vi8liRJkiRJkiRVjsVrSZIkSZIkSVLlNOWc151Zu3Ytra2trFmzpr9DGdCGDx/OmDFjGDZsWH+HIklqUubs3jNfS5IazXxdH+ZsSdq4QVO8bm1tZbvttmPs2LFERH+HMyBlJitXrqS1tZVx48b1dziSpCZlzu4d87UkqS+Yr3vPnC1JmzZopg1Zs2YNO+20k0m1FyKCnXbayV/WJUkNZc7uHfO1JKkvmK97z5wtSZs2aIrXgEm1DnwPJUl9wXzTO75/kqS+YL7pPd9DSdq4QVW8liRJkiRJkiQNDBav+9nRRx/NqlWrNtpn22237bT9lFNOYe7cuY0IS5Ik1TBfS5I0MJizJam5DJoHNlZNZpKZzJ8/v79DkSRJXTBfS5I0MJizJak5eeV1L02fPp1vfOMb69fPP/98LrzwQo444ggmTZrEvvvuyw9+8AMAli5dyp577snJJ5/MPvvsw7Jlyxg7diy//e1vATj22GM54IADmDBhApdffvkGxznrrLOYMGECRxxxBG1tbX8Ux6JFizjssMM44IADOPLII3nqqacaeNaSJA0s5mtJkgYGc7YkqZbF6146/vjjmTNnzvr1OXPmMHXqVK677jruvfdebr75Zs4++2wyE4BHH32UT3ziEzz44IPsscceG4w1Y8YMFi1axMKFC7nssstYuXIlAC+++CItLS08+OCDHHbYYVxwwQUb7Ld27Vo+9alPMXfuXBYtWsSpp57KF77whQafuSRJA4f5WpI00EXEjIhYEREP1LRdEhEPR8T9EXFdROxQs+2ciFgSEY9ExJE17ZPLtiURMb2vz2NTzNmSpFpOG9JL+++/PytWrOA3v/kNbW1tjBgxgte//vWcddZZ3HrrrQwZMoTly5fzzDPPALDHHntw0EEHdTrWZZddxnXXXQfAsmXLePTRR9lpp50YMmQIxx9/PAAf+chH+Mu//MsN9nvkkUd44IEHeM973gPAq6++yq677tqoU5YkacAxX0uSmsCVwNeBWTVtC4BzMnNdRFwMnAN8LiL2Bk4AJgBvAH4SEW8p9/kG8B6gFbgnIuZl5q/66Bw2yZwtSapl8boOjjvuOObOncvTTz/N8ccfz9VXX01bWxuLFi1i2LBhjB07ljVr1gCwzTbbdDrGLbfcwk9+8hPuuOMOtt56aw4//PD1+3QUERusZyYTJkzgjjvuqO+JSZLURMzXkqSBLDNvjYixHdp+XLN6J/DBcnkKMDszXwEej4glwIHltiWZ+RhARMwu+1ameA3mbEnSHzhtSB0cf/zxzJ49m7lz53LcccexevVqRo0axbBhw7j55pt54oknNjnG6tWrGTFiBFtvvTUPP/wwd9555/ptr7322vonHn/ve9/j4IMP3mDfPffck7a2tvWJde3atTz44IN1PENJkgY+87UkqcmdCvyoXB4NLKvZ1lq2ddVeKeZsSVI7i9d1MGHCBF544QVGjx7NrrvuykknncTChQvZd999mTVrFnvttdcmx5g8eTLr1q3jrW99K9OnT9/gtqdtttmGu+++m3322Yef/vSnnHvuuRvsu+WWWzJ37lw+97nPMXHiRPbbbz9uv/32up+nJEkDmflaktSsIuILwDrg6jqOOS0iFkbEws4eaNhI5mxJUrtof8hBM2lpacmFCxdu0PbQQw/x1re+tZ8iai6+l1LfefKL+/Z3CE1h93N/WfcxI2JRZrbUfeBBxpzdOL6PUt8xX9eH+XrTymlDrs/MfWraTgH+BjgiM18q284ByMx/LtdvBM4vdzk/M4/srF9XzNeN5Xsp9R1zdn3UO2dvLF975bUkSZIkSQNQREwGPgsc0164Ls0DToiIrSJiHDAeuBu4BxgfEeMiYkuKhzrO6+u4JUnqLovXkiQNchExIyJWRMQDHdo/FREPR8SDEfEvNe3nRMSSiHgkIo6saZ9cti2JiOl9eQ6SJDW7iLgGuAPYMyJaI+I04OvAdsCCiFgcEf8OkJkPAnMoHsR4A3BGZr6ameuATwI3Ag8Bc8q+kiRV0tD+DkCSJPW7Kym+/M5qb4iIPwWmABMz85WIGFW2701xldYE4A3ATyLiLeVu3wDeQ/Hwp3siYl5m/qrPzkKSpCaWmSd20nzFRvpfBFzUSft8YH4dQ5MkqWEsXkuSNMhl5q3lHJq1/hfw5cx8peyzomyfAswu2x+PiCXAgeW2JZn5GEBEzC77WryWJEmSJG0Wpw2RJEmdeQtwSETcFRE/i4i3l+2jgWU1/VrLtq7aJUmSJEnaLF55LUmSOjMU2BE4CHg7MCci3liPgSNiGjANYPfdd6/HkJIkSZKkJjRoi9cH/P2sTXfqgUWXnFzX8SRJ6metwH9lZgJ3R8RrwM7AcmC3mn5jyjY20r6BzLwcuBygpaUlNxWIOVuSpOozX0uSGsFpQyRJUme+D/wpQPlAxi2B3wLzgBMiYquIGAeMB+4G7gHGR8S4iNiS4qGO8/olckmSJElSUxi0V173h6VLl/L+97+fBx54AICvfOUr/O53v+OWW25h4sSJ/OxnP2PdunXMmDGDAw88cBOjSZJUHxFxDXA4sHNEtALnATOAGRHxAPB7YGp5FfaDETGH4kGM64AzMvPVcpxPAjcCWwAzMvPBPj+ZOjFnS5JUfeZrSWp+Fq8r4qWXXmLx4sXceuutnHrqqeuTryRJjZaZJ3ax6SNd9L8IuKiT9vnA/DqGVknmbEmSqs98LUnNwWlDKuLEE4u6waGHHsrzzz/PqlWr+jkiSZLUGXO2JEnVZ76WpOZg8boPDR06lNdee239+po1a9YvR8QGfTuuS5KkvmPOliSp+szXktT8LF73oV122YUVK1awcuVKXnnlFa6//vr126699loAfv7zn7P99tuz/fbb91eYkiQNeuZsSZKqz3wtSc1v0M55veiSk/v8mMOGDePcc8/lwAMPZPTo0ey1117rtw0fPpz999+ftWvXMmPGjD6PTZKkqjJnS5JUfeZrSVIjDNridX8588wzOfPMMzdoO/zww/nIRz7CV7/61X6KSpIkdWTOliSp+szXktTcnDZEkiRJkiRJklQ5XnldAbfcckt/hyBJkrrBnC1JUvWZryWpeXjltSRJkiRJkiSpcixeS5IkSZIkSZIqx+K1JEmSJEmSJKlyLF5LkiRJkiRJkipn0D6w8ckv7lvX8XY/95c93uf8889n22235TOf+UxdY2l31FFH8e1vf5vHH3+c008/nWHDhnHNNddw3HHH8cADD3S539KlS7n99tv58Ic/3JC4JEnqif7O2eZrSZI2rb/zNZizJakZeeV1k3r55ZdZuXIlY8aM4eqrr+acc85h8eLFvO51r9vkvkuXLuV73/teH0QpSdLgZr6WJGlgMGdLUv+weN3HLrroIt7ylrdw8MEH88gjjwCwePFiDjroIN72trfxgQ98gOeee44VK1ZwwAEHAHDfffcRETz55JMAvOlNb+Kll17ilFNO4cwzz+Rd73oXb3zjG5k7d+7649xyyy0cfvjh/Od//idz5szhH//xHznppJM2iGXp0qUccsghTJo0iUmTJnH77bcDMH36dG677Tb2228/Lr300r54WyRJqhTztSRJA4M5W5Kam8XrPrRo0SJmz57N4sWLmT9/Pvfccw8AJ598MhdffDH3338/++67LxdccAGjRo1izZo1PP/889x22220tLRw22238cQTTzBq1Ci23nprAJ566il+/vOfc/311zN9+vT1x/rRj37E5MmT+fjHP84xxxzDJZdcwtVXX71BPKNGjWLBggXce++9XHvttZx55pkAfPnLX+aQQw5h8eLFnHXWWX307kiSVA3ma0mSBgZztiQ1v0E753V/uO222/jABz6wPikec8wxvPjii6xatYrDDjsMgKlTp3LccccB8K53vYtf/OIX3HrrrXz+85/nhhtuIDM55JBD1o957LHHMmTIEPbee2+eeeaZ9e2/+MUv+MpXvrLReNauXcsnP/lJFi9ezBZbbMGvf/3rep+yJEkDjvlakqSBwZwtSc3P4nWFHXrooet/CZ4yZQoXX3wxEcH73ve+9X222mqr9cuZCcBjjz3GbrvtxpZbbrnR8S+99FJ22WUX7rvvPl577TWGDx/emBORJKmJma8lSRoYzNmSNPA4bUgfOvTQQ/n+97/Pyy+/zAsvvMAPf/hDttlmG0aMGMFtt90GwFVXXbX+F+JDDjmE7373u4wfP54hQ4aw4447Mn/+fA4++OCNHqf9dqZNWb16NbvuuitDhgzhqquu4tVXXwVgu+2244UXXujl2UqSNDCZryVJGhjM2ZLU/Abtlde7n/vLPj/mpEmTOP7445k4cSKjRo3i7W9/OwAzZ87k9NNP56WXXuKNb3wj3/nOdwAYO3Ysmcmhhx4KwMEHH0xraysjRozY6HFuuOEG/u3f/m2T8XziE5/gr/7qr5g1axaTJ09mm222AeBtb3sbW2yxBRMnTuSUU05xTi5JUr/q65xtvpYkqef8jm3OlqRGiPbbYJpJS0tLLly4cIO2hx56iLe+9a39FFHfeeWVV3j3u99Nx/Ovp8HyXkpV8OQX9+3vEJpCI75MRcSizGyp+8CDzGDN2eZrqbmYr+vDfF1dgzVfgzlbajbm7Pqod87eWL522pAms9VWWzU0qUqSpN4zX0uSNDCYsyWpf1m8liRJkiRJkiRVTsOL1xGxRUT8d0RcX66Pi4i7ImJJRFwbEVuW7VuV60vK7WNrxjinbH8kIo7c3FiacYqUvuZ7KEnqC+ab3vH9kyT1BfNN7/keStLG9cWV138LPFSzfjFwaWa+GXgOOK1sPw14rmy/tOxHROwNnABMACYD34yILXoaxPDhw1m5cqWJoRcyk5UrVzJ8+PD+DkWS1MTM2b1jvpYk9QXzde+ZsyVp04Y2cvCIGAO8D7gI+HREBPBnwIfLLjOB84FvAVPKZYC5wNfL/lOA2Zn5CvB4RCwBDgTu6EksY8aMobW1lba2tl6d02A3fPhwxowZ099hSJKamDm798zXkqRGM1/XhzlbkjauocVr4KvAZ4HtyvWdgFWZua5cbwVGl8ujgWUAmbkuIlaX/UcDd9aMWbvPehExDZgGsPvuu/9RIMOGDWPcuHG9PB1JktRo5mxJkqrPfC1J6gsNmzYkIt4PrMjMRY06Rq3MvDwzWzKzZeTIkX1xSEmSJEmSJElSgzTyyut3A8dExNHAcOBPgK8BO0TE0PLq6zHA8rL/cmA3oDUihgLbAytr2tvV7iNJkiRJkiRJakINu/I6M8/JzDGZOZbigYs/zcyTgJuBD5bdpgI/KJfnleuU23+axZMf5gEnRMRWETEOGA/c3ai4JUmSJEmSJEn9r9FzXnfmc8DsiLgQ+G/girL9CuCq8oGMz1IUvMnMByNiDvArYB1wRma+2vdhS5IkSZIkSZL6Sp8UrzPzFuCWcvkx4MBO+qwBjuti/4uAixoXoSRJkiRJkiSpSho2bYgkSZIkSZIkSZvL4rUkSZIkSZIkqXIsXkuSJEmSJEmSKsfitSRJkiRJkiSpcixeS5IkSZIkSZIqx+K1JEmDXETMiIgVEfFAJ9vOjoiMiJ3L9YiIyyJiSUTcHxGTavpOjYhHy9fUvjwHSZIkSVLzsXgtSZKuBCZ3bIyI3YD3Ak/WNB8FjC9f04BvlX13BM4D3gEcCJwXESMaGrUkSZIkqalZvJYkaZDLzFuBZzvZdCnwWSBr2qYAs7JwJ7BDROwKHAksyMxnM/M5YAGdFMQlSZIkSeoui9eSJOmPRMQUYHlm3tdh02hgWc16a9nWVXtnY0+LiIURsbCtra2OUUuSJEmSmonFa0mStIGI2Br4PHBuI8bPzMszsyUzW0aOHNmIQ0iSJEmSmoDFa0mS1NGbgHHAfRGxFBgD3BsRrweWA7vV9B1TtnXVLkmSJEnSZrF4LUmSNpCZv8zMUZk5NjPHUkwBMikznwbmASdH4SBgdWY+BdwIvDciRpQPanxv2SZJkiRJ0maxeC1J0iAXEdcAdwB7RkRrRJy2ke7zgceAJcC3gU8AZOazwJeAe8rXF8s2SZIkSZI2y9D+DkCSJPWvzDxxE9vH1iwncEYX/WYAM+oanCRJkiRp0PLKa0mSJEmSKi4iZkTEioh4oKZtx4hYEBGPln+OKNsjIi6LiCURcX9ETKrZZ2rZ/9GImNof5yJJUndZvJYkSZIkqfquBCZ3aJsO3JSZ44GbynWAo4Dx5Wsa8C0oit3AecA7gAOB89oL3pIkVZHFa0mSJEmSKi4zbwU6Pk9iCjCzXJ4JHFvTPisLdwI7RMSuwJHAgsx8NjOfAxbwxwVxSZIqw+K1JEmSJEkD0y6Z+VS5/DSwS7k8GlhW06+1bOuq/Y9ExLSIWBgRC9va2uobtSRJ3WTxWpIkSZKkAa58qHLWcbzLM7MlM1tGjhxZr2ElSeoRi9eSJEmSJA1Mz5TTgVD+uaJsXw7sVtNvTNnWVbskSZVk8VqSJEmSpIFpHjC1XJ4K/KCm/eQoHASsLqcXuRF4b0SMKB/U+N6yTZKkShra3wFIkiRJkqSNi4hrgMOBnSOiFTgP+DIwJyJOA54APlR2nw8cDSwBXgI+BpCZz0bEl4B7yn5fzMyOD4GUJKkyLF5LkiRJklRxmXliF5uO6KRvAmd0Mc4MYEYdQ5MkqWGcNl8QylkAACAASURBVESSJEmSJEmSVDkWryVJkiRJkiRJlWPxWpIkSZIkSZJUORavJUmSJEmSJEmVY/FakiRJkiRJklQ5Fq8lSZIkSZIkSZVj8VqSJEmSJEmSVDkWryVJkiRJkiRJlWPxWpIkSZIkSZJUORavJUmSJEmSJEmVY/FakiRJkiRJklQ5Fq8lSZIkSZIkSZVj8VqSJEmSJEmSVDkWryVJkiRJkiRJlWPxWpIkSZIkSZJUORavJUmSJEmSJEmVY/FakiRJkiRJklQ5Fq8lSZIkSZIkSZVj8VqSJEmSJEmSVDkWryVJkiRJkiRJlWPxWpIkSZIkSZJUORavJUmSJEmSJEmVY/FakiRJkiRJklQ5Fq8lSZIkSZIkSZVj8VqSJEmSJEmSVDkWryVJkiRJkiRJlWPxWpIkSZIkSZJUORavJUka5CJiRkSsiIgHatouiYiHI+L+iLguInao2XZORCyJiEci4sia9sll25KImN7X5yFJkiRJai4WryVJ0pXA5A5tC4B9MvNtwK+BcwAiYm/gBGBCuc83I2KLiNgC+AZwFLA3cGLZV5IkSZKkzWLxWpKkQS4zbwWe7dD248xcV67eCYwpl6cAszPzlcx8HFgCHFi+lmTmY5n5e2B22VeSJEmSpM1i8VqSJG3KqcCPyuXRwLKaba1lW1ftfyQipkXEwohY2NbW1oBwJUmSJEnNwOK1JEnqUkR8AVgHXF2vMTPz8sxsycyWkSNH1mtYSZIkSVKTGdrfAUiSpGqKiFOA9wNHZGaWzcuB3Wq6jSnb2Ei7JEmSJEk95pXXkiTpj0TEZOCzwDGZ+VLNpnnACRGxVUSMA8YDdwP3AOMjYlxEbEnxUMd5fR23JEmSJKl5eOW1JEmDXERcAxwO7BwRrcB5wDnAVsCCiAC4MzNPz8wHI2IO8CuK6UTOyMxXy3E+CdwIbAHMyMwH+/xkJEmSJElNw+K1JEmDXGae2EnzFRvpfxFwUSft84H5dQxNkiRJkjSIOW2IJEmSJEmSJKlyLF5LkiRJkiRJkirH4rUkSZIkSZIkqXIsXkuSJEmSJEmSKsfitSRJkiRJkiSpcixeS5IkSZIkSZIqx+K1JEmSJEmSJKlyLF5LkiRJkiRJkirH4rUkSZIkSZIkqXIsXkuSJEmSJEmSKsfitSRJkiRJkiSpcixeS5IkSZIkSZIqx+K1JEmSJEmSJKlyLF5LkiRJkiRJkiqnYcXriBgeEXdHxH0R8WBEXFC2j4uIuyJiSURcGxFblu1bletLyu1ja8Y6p2x/JCKObFTMkiRJkiRJkqRqaOSV168Af5aZE4H9gMkRcRBwMXBpZr4ZeA44rex/GvBc2X5p2Y+I2Bs4AZgATAa+GRFbNDBuSZIkSZIkSVI/a1jxOgu/K1eHla8E/gyYW7bPBI4tl6eU65Tbj4iIKNtnZ+Yrmfk4sAQ4sFFxS5IkSZI0kETEWeUdzw9ExDXlndA9vutZkqSqaeic1xGxRUQsBlYAC4D/AVZl5rqySyswulweDSwDKLevBnaqbe9kn9pjTYuIhRGxsK2trRGnI0mSJElSpUTEaOBMoCUz9wG2oLh7uUd3PUuSVEUNLV5n5quZuR8whuJq6b0aeKzLM7MlM1tGjhzZqMNIkiRJklQ1Q4HXRcRQYGvgKXp+17MkSZXT0OJ1u8xcBdwMvBPYoUyoUBS1l5fLy4HdAMrt2wMra9s72UeSJEmSpEErM5cDXwGepCharwYW0fO7njfg3c2SpCpoWPE6IkZGxA7l8uuA9wAPURSxP1h2mwr8oFyeV65Tbv9pZmbZfkI5L9c4YDxwd6PiliRJkiRpoIiIERRXU48D3gBsA0zu7bje3SxJqoKhm+6y2XYFZkbEFhRF8jmZeX1E/AqYHREXAv8NXFH2vwK4KiKWAM9SzNFFZj4YEXOAXwHrgDMy89UGxi1JkiRJ0kDx58DjmdkGEBH/Bbyb8q7n8urqzu56bu1w17MkSZXTsOJ1Zt4P7N9J+2MU8193bF8DHNfFWBcBF9U7RkmSJEmSBrgngYMiYmvgZeAIYCF/uOt5Np3f9XwHG971LElS5fTJnNeSJEmSJKn+MvMuigcv3gv8kuJ7/uXA54BPl3c378SGdz3vVLZ/Gpje50FLktRNjZw2RJIkSZIkNVhmngec16G5x3c9S5JUNV55LUmSJEmSJEmqHIvXkiRJkiRJkqTKsXgtSZIkSZIkSaoci9eSJEmSJEmSpMqxeC1JkiRJkiRJqhyL15IkSZIkSZKkyrF4LUmSJEmSJEmqHIvXkiRJkiRJkqTKsXgtSZIkSZIkSaoci9eSJEmSJEmSpMqxeC1J0iAXETMiYkVEPFDTtmNELIiIR8s/R5TtERGXRcSSiLg/IibV7DO17P9oREztj3ORJEmSJDUPi9eSJOlKYHKHtunATZk5HripXAc4ChhfvqYB34Ki2A2cB7wDOBA4r73gLUmSJEnS5rB4LUnSIJeZtwLPdmieAswsl2cCx9a0z8rCncAOEbErcCSwIDOfzczngAX8cUFckiRJkqRus3gtSZI6s0tmPlUuPw3sUi6PBpbV9Gst27pqlyRJkiRps1i8liRJG5WZCWS9xouIaRGxMCIWtrW11WtYSZIkSVKTsXgtSZI680w5HQjlnyvK9uXAbjX9xpRtXbX/kcy8PDNbMrNl5MiRdQ9ckiRJktQcLF5LkqTOzAOmlstTgR/UtJ8chYOA1eX0IjcC742IEeWDGt9btkmSJEmStFmG9ncAkiSpf0XENcDhwM4R0QqcB3wZmBMRpwFPAB8qu88HjgaWAC8BHwPIzGcj4kvAPWW/L2Zmx4dASpIkSZLUbRavJUka5DLzxC42HdFJ3wTO6GKcGcCMOoYmSZIkSRrEnDZEkiRJkiRJklQ5Fq8lSZIkSZIkSZVj8VqSJEmSJEmSVDkWryVJkiRJkiRJlWPxWpIkSZIkSZJUORavJUmSJEmSJEmVY/FakiRJkiRJklQ5Fq8lSZIkSZIkSZVj8VqSJEmSJEmSVDkWryVJkiRJkiRJlWPxWpIkSZIkSZJUORavJUmSJEmSJEmVY/FakiRJkiRJklQ5Fq8lSZIkSZIkSZVj8VqSJEmSJEmSVDkWryVJkiRJkiRJlWPxWpIkSZIkSZJUOZssXkfELhFxRUT8qFzfOyJOa3xokiSpJ8zZkiRVn/lakqTu686V11cCNwJvKNd/DfxdowKSJEmb7UrM2ZIkVd2VmK8lSeqW7hSvd87MOcBrAJm5Dni1oVFJkqTNYc6WJKn6zNeSJHVTd4rXL0bETkACRMRBwOqGRiVJkjaHOVuSpOozX0uS1E1Du9Hn08A84E0R8QtgJPDBhkYlSZI2hzlbkqTqM19LktRNmyxeZ+a9EXEYsCcQwCOZubbhkUmSpB4xZ0uSVH3ma0mSum+TxeuIOLlD06SIIDNnNSgmSZK0GczZkiRVn/lakqTu6860IW+vWR4OHAHcC5hYJUmqFnO2JEnVZ76WJKmbujNtyKdq1yNiB2B2wyKSJEmbxZwtSVL1ma8lSeq+IZuxz4vAuHoHIkmS6s6cLUlS9ZmvJUnqQnfmvP4hkOXqEGBvYE4jg5IkST1nzpYkqfrM15IkdV935rz+Ss3yOuCJzGxtUDySJGnzmbMlSao+87UkSd3UnTmvf9YXgUiSpN4xZ0uSVH3ma0mSuq/L4nVEvMAfbmXaYBOQmfknDYtKkiR1mzlbkqTqM19LktRzXRavM3O7vgxEkiRtHnO2JEnVZ76WJKnnujPnNQARMQoY3r6emU82JCJJktQr5mxJkqrPfC1J0qYN2VSHiDgmIh4FHgd+BiwFftTguCRJUg+ZsyVJqr5G5OuI2CEi5kbEwxHxUES8MyJ2jIgFEfFo+eeIsm9ExGURsSQi7o+ISb0+KUmSGmSTxWvgS8BBwK8zcxxwBHBnQ6OSJEmbw5wtSVL1NSJffw24ITP3AiYCDwHTgZsyczxwU7kOcBQwvnxNA77Vy2NLktQw3Sler83MlcCQiBiSmTcDLQ2OS5Ik9Zw5W5Kk6qtrvo6I7YFDgSsAMvP3mbkKmALMLLvNBI4tl6cAs7JwJ7BDROy6uceXJKmRujPn9aqI2Ba4Dbg6IlYALzY2LEmStBnqnrMj4izg40ACvwQ+BuwKzAZ2AhYBH83M30fEVsAs4ABgJXB8Zi7tzfElSWpC9c7X44A24DsRMZEiN/8tsEtmPlX2eRrYpVweDSyr2b+1bHuqpo2ImEZxZTa77757L8KTJGnzdefK65uB7SmS3w3A/wB/0cigJEnSZqlrzo6I0cCZQEtm7gNsAZwAXAxcmplvBp4DTit3OQ14rmy/tOwnSZI2VO/v2EOBScC3MnN/ikL49NoOmZkUP0R3W2ZenpktmdkycuTIXoQnSdLm607xeijwY+AWYDvg2vIWJ0mSVC2NyNlDgddFxFBga4qrsv4MmFtu73gbcvvtyXOBIyIienl8SZKaTb3zdSvQmpl3letzKYrZz7RPB1L+uaLcvhzYrWb/MWWbJEmVs8nidWZekJkTgDMobhP+WUT8pOGRSZKkHql3zs7M5cBXgCcpitarKW5FXpWZ68pu7bcaQ81tyOX21RRTi2wgIqZFxMKIWNjW1ra54UmSNCA1IF8/DSyLiD3LpiOAXwHzgKll21TgB+XyPODkKBwErK6ZXkSSpErpzpzX7VZQzJO1EhjVmHAkSVId1CVnR8QIiqupxwGrgP8DTO5tcJl5OXA5QEtLS49uYZYkqYnU8zv2pyjmz94SeIziGRVDgDkRcRrwBPChsu984GhgCfBS2VeSpEraZPE6Ij5BkeRGUnxp/evM/FWjA5MkST3TgJz958DjmdlWjv9fwLuBHSJiaHl1de2txu23IbeW04xsT/GFXJIklRrxHTszFwMtnWw6opO+SXHVtyRJldedK693A/6uTIaSJKm66p2znwQOioitgZcpvgAvpHjQ1AeB2fzxbchTgTvK7T8tvyBLkqQ/8Du2JEndtMnidWae0xeBSJKk3ql3zs7MuyJiLnAvsA74b4rpPv4fMDsiLizbrih3uQK4KiKWAM8CJ9QzHkmSmoHfsSVJ6r6ezHktSZIGmcw8DzivQ/NjwIGd9F0DHNcXcUmSJEmSmt+Q/g5AkiRJkiRJkqSOLF5LkiRJkiRJkirH4rUkSZIkSZIkqXIsXkuSJEmSJEmSKsfitSRJkiRJkiSpcob2dwADxQF/P6u/Q2gKiy45ub9DkCRJkiRJkjQANKx4HRG7AbOAXYAELs/Mr0XEjsC1wFhgKfChzHwuIgL4GnA08BJwSmbeW441FfiHcugLM3Nmo+KWJEmSJEmN5QVi9eEFYpKaXSOnDVkHnJ2ZewMHAWdExN7AdOCmzBwP3FSuAxwFjC9f04BvAZTF7vOAdwAHAudFxIgGxi1JkiRJkiRJ6mcNK15n5lPtV05n5gvAQ8BoYArQfuX0TODYcnkKMCsLdwI7RMSuwJHAgsx8NjOfAxYAkxsVtyRJkiRJkiSp//XJAxsjYiywP3AXsEtmPlVueppiWhEoCtvLanZrLdu6au94jGkRsTAiFra1tdU1fkmSJEmSJElS32p48ToitgX+L/B3mfl87bbMTIr5sHstMy/PzJbMbBk5cmQ9hpQkSZIkSZIk9ZOGFq8jYhhF4frqzPyvsvmZcjoQyj9XlO3Lgd1qdh9TtnXVLkmSJEmSJElqUg0rXkdEAFcAD2Xm/67ZNA+YWi5PBX5Q035yFA4CVpfTi9wIvDciRpQPanxv2SZJkiRJkiRJalJDGzj2u4GPAr+MiMVl2+eBLwNzIuI04AngQ+W2+cDRwBLgJeBjAJn5bER8Cbin7PfFzHy2gXFLkiRJkiRJkvpZw4rXmflzILrYfEQn/RM4o4uxZgAz6hedJEmSJEmSJKnKGv7ARkmSJEmSJEmSesritSRJkiRJkiSpcixeS5IkSZIkSZIqx+K1JEmSJEmSJKlyLF5LkiRJkiRJkirH4rUkSZIkSZIkqXIsXkuSJEmSJEmSKsfitSRJkiRJkiSpcob2dwCSJEn1csDfz+rvEJrCoktO7u8QJEmSJMkrryVJkiRJkiRJ1WPxWpIkSZIkSZJUORavJUmSJEmSJEmVY/FakiRJkiRJklQ5Fq8lSZIkSZIkSZVj8VqSJEmSJEmSVDkWryVJkiRJkiRJlWPxWpIkSZIkSZJUORavJUmSJEmSJEmVY/FakiRJkiRJklQ5Fq8lSZIkSZIkSZVj8VqSJEmSJEmSVDkWryVJUpciYoeImBsRD0fEQxHxzojYMSIWRMSj5Z8jyr4REZdFxJKIuD8iJvV3/JIkSZKkgcvitSRJ2pivATdk5l7AROAhYDpwU2aOB24q1wGOAsaXr2nAt/o+XEmSJElSs7B4LUmSOhUR2wOHAlcAZObvM3MVMAWYWXabCRxbLk8BZmXhTmCHiNi1j8OWJEmSJDUJi9eSJKkr44A24DsR8d8R8Z8RsQ2wS2Y+VfZ5GtilXB4NLKvZv7Vs20BETIuIhRGxsK2trYHhS5IkSZIGMovXkiSpK0OBScC3MnN/4EX+MEUIAJmZQPZk0My8PDNbMrNl5MiRdQtWkiRJktRcLF5LkqSutAKtmXlXuT6Xopj9TPt0IOWfK8rty4HdavYfU7ZJkiRJktRj/7+9uw+6tC7vA/69yqrERAFxpXR369qR2mKnIbglGELGSJsKsYHMEEJCZYfQ2T9KExNjI0k7Q8ZMW5xpQyRt7DDCuEyZFI0m7KRUh0FRaQbrisiLxLJlZNgdYLeKxEjVEK/+8fxID8s+7AvPy32e/Xxmdp7793Lfz3V25jzXzPeccx/hNQBwQN39eJJHq+oNY+qcJF9OsiPJ1jG3Nckt43hHkktrwZlJnpq5vQgAAAAclnWrXQAAMGm/mOSmqnppkoeTXJaFF78/XFWXJ3kkyUVj761JzkuyK8nTYy8AAAAcEeE1ALCo7r4nyZYDLJ1zgL2d5IplLwoAAICjgtuGAAAAAAAwOcJrAAAAAAAmR3gNAAAAAMDkCK8BAABgzlXVMVX1xar64zF+XVV9rqp2VdXN48uXU1UvG+NdY33zatYNAC9EeA0AAADz751JHpwZvy/JNd39+iRPJrl8zF+e5Mkxf83YBwCTJLwGAACAOVZVG5P8ZJIPjnEleWuSPxhbtie5YByfP8YZ6+eM/QAwOcJrAAAAmG+/k+TXknxvjE9M8o3ufmaMdyfZMI43JHk0Scb6U2P/c1TVtqraWVU79+3bt5y1A8CihNcAAAAwp6rq7Un2dvcXlvK63X1dd2/p7i3r169fyksDwCFbt9oFAAAAAEfsrCQ/VVXnJTk2ySuTvD/J8VW1bry7emOSPWP/niSbkuyuqnVJjkvytZUvGwAOzjuvAQAAYE51969398bu3pzk4iSf7O5LknwqyYVj29Ykt4zjHWOcsf7J7u4VLBkADpnwGgAAANae9yR5V1XtysI9ra8f89cnOXHMvyvJlatUHwAclNuGAAAAwBrQ3XckuWMcP5zkjAPs+XaSn1nRwgDgCHnnNQAAAAAAkyO8BgAAAABgcoTXAAAAAABMjvAaAAAAAIDJEV4DAAAAADA5wmsAAAAAACZHeA0AAAAAwOQIrwEAAAAAmBzhNQAAAAAAkyO8BgAAAABgcoTXAAAAAABMjvAaAAAAAIDJEV4DAAAAADA5wmsAAAAAACZHeA0AAAAAwOQIrwEAAAAAmBzhNQAAAAAAkyO8BgAAAABgcoTXAAAAAABMjvAaAAAAAIDJEV4DAAAAADA5wmsAAAAAACZHeA0AAAAAwOQIrwGARVXVMVX1xar64zF+XVV9rqp2VdXNVfXSMf+yMd411jevZt0AAADMP+E1APBC3pnkwZnx+5Jc092vT/JkksvH/OVJnhzz14x9AAAAcMSE1wDAAVXVxiQ/meSDY1xJ3prkD8aW7UkuGMfnj3HG+jljPwAAABwR4TUAsJjfSfJrSb43xicm+UZ3PzPGu5NsGMcbkjyaJGP9qbH/eapqW1XtrKqd+/btW67aAQAAmHPCawDgearq7Un2dvcXlvra3X1dd2/p7i3r169f6ssDAACwRqxb7QIAgEk6K8lPVdV5SY5N8sok709yfFWtG++u3phkz9i/J8mmJLural2S45J8beXLBgAAYK3wzmsA4Hm6+9e7e2N3b05ycZJPdvclST6V5MKxbWuSW8bxjjHOWP9kd/cKlgwAAMAaI7wGAA7He5K8q6p2ZeGe1teP+euTnDjm35XkylWqDwAAgDVi2cLrqrqhqvZW1f0zc6+qqtuq6qHx84QxX1V1bVXtqqp7q+r0mXO2jv0PVdXWA/0uAGD5dPcd3f32cfxwd5/R3a/v7p/p7u+M+W+P8evH+sOrWzUAAADzbjnfef2hJG/bb+7KJLd39ylJbs//f1fWuUlOGf+2JflAshB2J7kqyQ8nOSPJVc8G3gAAAAAArF3LFl5392eSfH2/6fOTbB/H25NcMDN/Yy+4KwtfBnVykn+c5Lbu/np3P5nktjw/EAcAAAAAYI1Z6Xten9Tdj43jx5OcNI43JHl0Zt/uMbfY/PNU1baq2llVO/ft27e0VQMAAAAAsKJW7Qsbu7uT9BJe77ru3tLdW9avX79UlwUAAAAAYBWsdHj9xLgdSMbPvWN+T5JNM/s2jrnF5gEAAAAAWMNWOrzekWTrON6a5JaZ+UtrwZlJnhq3F/lEkp+oqhPGFzX+xJgDAAAAAGANW7dcF66q30/yliSvrqrdSa5KcnWSD1fV5UkeSXLR2H5rkvOS7ErydJLLkqS7v15Vv5Xk82Pfe7t7/y+BBAAAAABgjVm28Lq7f26RpXMOsLeTXLHIdW5IcsMSlgYAAAAAwMSt2hc2AgAAAADAYoTXAAAAAABMjvAaAAAAAIDJEV4DAAAAADA5wmsAAAAAACZHeA0AAAAAwOQIrwEAAAAAmBzhNQAAAAAAkyO8BgAAAABgcoTXAAAAAABMjvAaAAAAAIDJEV4DAAAAADA5wmsAAACYU1W1qao+VVVfrqoHquqdY/5VVXVbVT00fp4w5quqrq2qXVV1b1WdvrqPAAAWJ7wGAACA+fVMkl/t7lOTnJnkiqo6NcmVSW7v7lOS3D7GSXJuklPGv21JPrDyJQPAoRFeAwAAwJzq7se6++5x/M0kDybZkOT8JNvHtu1JLhjH5ye5sRfcleT4qjp5hcsGgEMivAYAAIA1oKo2J/mhJJ9LclJ3PzaWHk9y0jjekOTRmdN2j7n9r7WtqnZW1c59+/YtW80A8EKE1wAAADDnquoHknw0yS9395/NrnV3J+nDuV53X9fdW7p7y/r165ewUgA4dMJrAAAAmGNV9ZIsBNc3dffHxvQTz94OZPzcO+b3JNk0c/rGMQcAkyO8BgAAgDlVVZXk+iQPdvdvzyztSLJ1HG9NcsvM/KW14MwkT83cXgQAJmXdahcAAAAAHLGzkrwjyX1Vdc+Y+40kVyf5cFVdnuSRJBeNtVuTnJdkV5Knk1y2suUCwKETXgMAAMCc6u47k9Qiy+ccYH8nuWJZiwKAJeK2IQAAAAAATI7wGgAAAACAyRFeAwAAAAAwOcJrAAAAAAAmR3gNAAAAAMDkCK8BAAAAAJgc4TUAAAAAAJMjvAYADqiqNlXVp6rqy1X1QFW9c8y/qqpuq6qHxs8TxnxV1bVVtauq7q2q01f3EQAAADDPhNcAwGKeSfKr3X1qkjOTXFFVpya5Msnt3X1KktvHOEnOTXLK+LctyQdWvmQAAADWCuE1AHBA3f1Yd989jr+Z5MEkG5Kcn2T72LY9yQXj+PwkN/aCu5IcX1Unr3DZAAAArBHCawDgoKpqc5IfSvK5JCd192Nj6fEkJ43jDUkenTlt95jb/1rbqmpnVe3ct2/fstUMAADAfBNeAwAvqKp+IMlHk/xyd//Z7Fp3d5I+nOt193XdvaW7t6xfv34JKwUAAGAtEV4DAIuqqpdkIbi+qbs/NqafePZ2IOPn3jG/J8mmmdM3jjkAAAA4bMJrAOCAqqqSXJ/kwe7+7ZmlHUm2juOtSW6Zmb+0FpyZ5KmZ24sAAADAYVm32gUAAJN1VpJ3JLmvqu4Zc7+R5OokH66qy5M8kuSisXZrkvOS7ErydJLLVrZcAAAA1hLhNQBwQN19Z5JaZPmcA+zvJFcsa1EAAAAcNdw2BAAAAACAyRFeAwAAAAAwOcJrAAAAAAAmR3gNAAAAAMDkCK8BAAAAAJgc4TUAAAAAAJMjvAYAAAAAYHKE1wAAAAAATI7wGgAAAACAyRFeAwAAAAAwOcJrAAAAAAAmR3gNAAAAAMDkCK8BAAAAAJgc4TUAAAAAAJMjvAYAAAAAYHKE1wAAAAAATI7wGgAAAACAyRFeAwAAAAAwOcJrAAAAAAAmR3gNAAAAAMDkCK8BAAAAAJgc4TUAAAAAAJMjvAYAAAAAYHKE1wAAAAAATI7wGgAAAACAyRFeAwAAAAAwOcJrAAAAAAAmR3gNAAAAAMDkCK8BAAAAAJgc4TUAAAAAAJMjvAYAAAAAYHKE1wAAAAAATI7wGgAAAACAyRFeAwAAAAAwOcJrAAAAAAAmR3gNAAAAAMDkzE14XVVvq6qvVNWuqrpytesBAJ5PvwaA6dOvAZgXcxFeV9UxSf5TknOTnJrk56rq1NWtCgCYpV8DwPTp1wDMk7kIr5OckWRXdz/c3d9N8l+TnL/KNQEAz6VfA8D06dcAzI11q13AIdqQ5NGZ8e4kPzy7oaq2Jdk2hn9eVV9Zodo4DPXvt746yf9Z7TpgjnjOLIWrajmu+trluOicO2i/TvTseaBfw2HznFkK+vVK0a/XED0bDpvnzFJY+p69aL+el/D6oLr7uiTXrXYdvLCq2tndW1a7DpgXnjOsRXr29PnbA4fHc4a1SL+eD/7+wOHxnJk/83LbkD1JNs2MN445AGA69GsAmD79GoC5MS/hbLcCAAAABrhJREFU9eeTnFJVr6uqlya5OMmOVa4JAHgu/RoApk+/BmBuzMVtQ7r7mar6F0k+keSYJDd09wOrXBZHxsfO4PB4zjA39Os1xd8eODyeM8wN/XrN8fcHDo/nzJyp7l7tGgAAAAAA4Dnm5bYhAAAAAAAcRYTXAAAAAABMjvAaYIlV1W9W1buX8fr/vao2VtXZVfVAVd1TVX+3qu4/yHmbq+rnl6suAJg3ejYATJ9+fXQTXgPMkar6viQndvfuJJck+XfdfVqS/3sIp29OorECwArQswFg+vTr6RNesyzGq0/3z4zfPV4pu6Oq3j9exbq/qs5YzTphqVTVv6qq/1VVdyZ5w5g7raruqqp7q+oPq+qEqnpNVX1hrP9gVXVV/c0x/t9V9fKq+lBVXVtVf1JVD1fVhTO/6i1J7qiqf5bkoiS/VVU37VfL5qr6bFXdPf79yFi6OsnZ4/n3K8v7PwLMCz2bo42eDcwj/ZqjjX7Ns4TXrIaXj1ex/nmSG1a7GHixqupNSS5OclqS85L8g7F0Y5L3dPffT3Jfkqu6e2+SY6vqlUnOTrIzC83utUn2dvfT49yTk/xokrdnoSE+69wkH+/uDybZkeRfdvcl+5W0N8k/6u7Tk/xskmvH/JVJPtvdp3X3NUv08IG1Tc9mTdGzgTVKv2ZN0a+ZtW61C+Co9PtJ0t2fqapXVtXx3f2N1S4KXoSzk/zhs02xqnYk+f4kx3f3p8ee7Uk+Mo7/JMlZSX4syb9N8rYkleSzM9f8o+7+XpIvV9VJM/NnJTnYvb5ekuQ/VtVpSf4yyd8+0gcGHPX0bNYaPRtYi/Rr1hr9mr8ivGa5PJPnvrP/2Jnj3m/v/mNY6z6ThWb82iS3JHlPFp4H/21mz3dmjitJqupvJXm0u797kOv/SpInkvxgFp6H316asoE1Ss+GxenZwFTo17A4/XoNc9sQlssTSV5TVSdW1cuy8LGMZ/1sklTVjyZ5qrufWo0CYQl9JskFVfV9VfWKJP8kybeSPFlVZ48970jy7CvEn03yT5M8NF75/XoWPgp150F+z7lJPn4I9RyX5LFx7XckOWbMfzPJKw7tIQFHET2bo4meDcwr/ZqjiX7NX/HOa5ZFd/9FVb03yf9MsifJn84sf7uqvpiFj138wmrUB0upu++uqpuTfCkL98L6/FjamuQ/V9XLkzyc5LKx/6tVVVloyMlCQ93Y3U8e5Fe9LckvHkJJv5fko1V1aRYa8bfG/L1J/rKqvpTkQ+7JBSR6NkcXPRuYV/o1RxP9mlnV7dMkrJyquiPJu7t752rXAvNkvLvif3T3ltWuBTg66NlwZPRsYCXp13Bk9Ov54Z3XAHOgu7+TRFMFgInTswFg+vTr+eGd1wAAAAAATI4vbAQAAAAAYHKE1wAAAAAATI7wGgAAAACAyRFew1Gqqm6tquMPsufPF5n/UFVduDyVAQDP0q8BYPr0a1g+61a7AGBlVVVl4ctaz1vtWgCAA9OvAWD69GtYft55DXOqqq6uqitmxr9ZVf+6qm6vqrur6r6qOn+sba6qr1TVjUnuT7Kpqr5aVa8e639UVV+oqgeqatt+v+eaMX97Va0/QB1vqqpPj/M/UVUnL+8jB4D5oV8DwPTp1zBdwmuYXzcnuWhmfFGS7Ul+urtPT/LjSf7DeCU4SU5J8nvd/cbufmS/a/1Cd78pyZYkv1RVJ47570+ys7vfmOTTSa6aPamqXpLkd5NcOM6/Icm/WbJHCADzT78GgOnTr2Gi3DYE5lR3f7GqXlNVfyPJ+iRPJnk8yTVV9WNJvpdkQ5KTximPdPddi1zul6rqp8fxpiw04q+Na9w85v9Lko/td94bkvy9JLeNHn5Mksde7GMDgLVCvwaA6dOvYbqE1zDfPpLkwiR/PQtN8JIsNNo3dfdfVNVXkxw79n7rQBeoqrck+YdJ3tzdT1fVHTPn7K/3Pz3JA9395hfxGABgrdOvAWD69GuYILcNgfl2c5KLs9BgP5LkuCR7R2P98SSvPYRrHJfkydFY/06SM2fW/tq4dpL8fJI79zv3K0nWV9Wbk4WPOVXVG4/40QDA2qRfA8D06dcwQcJrmGPd/UCSVyTZ092PJbkpyZaqui/JpUn+9BAu8/Ek66rqwSRXJ5n96NO3kpxRVfcneWuS9+73+7+bheb7vqr6UpJ7kvzIi3tUALC26NcAMH36NUxTde//KQUAAAAAAFhd3nkNAAAAAMDkCK8BAAAAAJgc4TUAAAAAAJMjvAYAAAAAYHKE1wAAAAAATI7wGgAAAACAyRFeAwAAAAAwOf8Ph3z4rZ6IhN0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1800x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createFinalData_RemoveLateAfternoonData(arr, labels):\n",
        "\n",
        "  assert arr.shape[0] == len(labels), \"X data do not match length of y labels\"\n",
        "\n",
        "  step_count = 0\n",
        "  filtered_y_labels = []\n",
        "\n",
        "  for i in range(arr.shape[0]):\n",
        "\n",
        "    if i == 0:\n",
        "      final_arr = arr[i]\n",
        "      filtered_y_labels.append(labels[i])\n",
        "      #print(f'Appending index {i}, step_count: {step_count}')\n",
        "      step_count += 1\n",
        "\n",
        "    elif i == 1:\n",
        "\n",
        "      final_arr = np.stack((final_arr, arr[i]))\n",
        "      filtered_y_labels.append(labels[i])\n",
        "      step_count += 1\n",
        "\n",
        "    elif step_count == 0: \n",
        "      final_arr = np.vstack((final_arr, arr[i][None]))\n",
        "      filtered_y_labels.append(labels[i])\n",
        "      #print(f'Appending index {i}, step_count: {step_count}')\n",
        "      step_count += 1\n",
        "    \n",
        "    elif (step_count) % 5 == 0:\n",
        "      #print(f'skipping {i} array, step_count: {step_count}')\n",
        "      step_count += 1\n",
        "\n",
        "    elif (step_count) % 6 == 0:\n",
        "      #print(f'skipping {i} array, step_count: {step_count}')\n",
        "      step_count += 1\n",
        "\n",
        "    elif (step_count) % 7 == 0:\n",
        "      #print(f'skipping {i} array, step_count: {step_count}')\n",
        "      step_count = 0\n",
        "    \n",
        "    else:\n",
        "      final_arr = np.vstack((final_arr, arr[i][None]))\n",
        "      filtered_y_labels.append(labels[i])\n",
        "      #print(f'Appending index {i}, step_count: {step_count}')\n",
        "      step_count += 1\n",
        "  \n",
        "  return final_arr, filtered_y_labels\n",
        "\n",
        "X_train, y_train = createFinalData_RemoveLateAfternoonData(X_train_pre_final, y_train_pre_final)\n",
        "X_val, y_val = createFinalData_RemoveLateAfternoonData(X_val_pre_final, y_val_pre_final)\n",
        "X_test, y_test = createFinalData_RemoveLateAfternoonData(X_test_pre_final, y_test_pre_final)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "1XdpMcVCo2_b"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check it arrays are made correctly\n",
        "train[12:48]"
      ],
      "metadata": {
        "id": "ZyvritE4qPNR",
        "outputId": "317fa6ec-1531-4863-9038-5b1fc89b6d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a15fe9fd-57d1-4560-bc43-2f78ac999c83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeWeightedAvgPrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:30:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:35:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:40:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:45:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:50:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 10:55:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:00:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:05:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:10:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:15:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:20:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:25:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:30:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:35:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:40:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:45:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:50:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 11:55:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:00:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:05:00-05:00</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:10:00-05:00</th>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>6.8300</td>\n",
              "      <td>1171.0</td>\n",
              "      <td>6.83000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:15:00-05:00</th>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>6.8201</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>6.82010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:20:00-05:00</th>\n",
              "      <td>6.8200</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8200</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>3129.0</td>\n",
              "      <td>6.83032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:25:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:30:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:35:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:40:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:45:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:50:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.84000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 12:55:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:00:00-05:00</th>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>200.0</td>\n",
              "      <td>6.83830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:05:00-05:00</th>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:10:00-05:00</th>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:15:00-05:00</th>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>6.8383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:20:00-05:00</th>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>6.8400</td>\n",
              "      <td>500.0</td>\n",
              "      <td>6.84000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-12-20 13:25:00-05:00</th>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>6.8474</td>\n",
              "      <td>400.0</td>\n",
              "      <td>6.84740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a15fe9fd-57d1-4560-bc43-2f78ac999c83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a15fe9fd-57d1-4560-bc43-2f78ac999c83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a15fe9fd-57d1-4560-bc43-2f78ac999c83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             Open    High     Low   Close  Volume  \\\n",
              "Time                                                                \n",
              "2016-12-20 10:30:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 10:35:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 10:40:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 10:45:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 10:50:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 10:55:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:00:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:05:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:10:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:15:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:20:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:25:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:30:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:35:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:40:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:45:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:50:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 11:55:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 12:00:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 12:05:00-05:00  0.0000  0.0000  0.0000  0.0000     0.0   \n",
              "2016-12-20 12:10:00-05:00  6.8300  6.8300  6.8300  6.8300  1171.0   \n",
              "2016-12-20 12:15:00-05:00  6.8201  6.8201  6.8201  6.8201  5000.0   \n",
              "2016-12-20 12:20:00-05:00  6.8200  6.8400  6.8200  6.8400  3129.0   \n",
              "2016-12-20 12:25:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 12:30:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 12:35:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 12:40:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 12:45:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 12:50:00-05:00  6.8400  6.8400  6.8400  6.8400   100.0   \n",
              "2016-12-20 12:55:00-05:00  6.8400  6.8400  6.8400  6.8400     0.0   \n",
              "2016-12-20 13:00:00-05:00  6.8383  6.8383  6.8383  6.8383   200.0   \n",
              "2016-12-20 13:05:00-05:00  6.8383  6.8383  6.8383  6.8383     0.0   \n",
              "2016-12-20 13:10:00-05:00  6.8383  6.8383  6.8383  6.8383     0.0   \n",
              "2016-12-20 13:15:00-05:00  6.8383  6.8383  6.8383  6.8383     0.0   \n",
              "2016-12-20 13:20:00-05:00  6.8400  6.8400  6.8400  6.8400   500.0   \n",
              "2016-12-20 13:25:00-05:00  6.8474  6.8474  6.8474  6.8474   400.0   \n",
              "\n",
              "                           VolumeWeightedAvgPrice  \n",
              "Time                                               \n",
              "2016-12-20 10:30:00-05:00                 0.00000  \n",
              "2016-12-20 10:35:00-05:00                 0.00000  \n",
              "2016-12-20 10:40:00-05:00                 0.00000  \n",
              "2016-12-20 10:45:00-05:00                 0.00000  \n",
              "2016-12-20 10:50:00-05:00                 0.00000  \n",
              "2016-12-20 10:55:00-05:00                 0.00000  \n",
              "2016-12-20 11:00:00-05:00                 0.00000  \n",
              "2016-12-20 11:05:00-05:00                 0.00000  \n",
              "2016-12-20 11:10:00-05:00                 0.00000  \n",
              "2016-12-20 11:15:00-05:00                 0.00000  \n",
              "2016-12-20 11:20:00-05:00                 0.00000  \n",
              "2016-12-20 11:25:00-05:00                 0.00000  \n",
              "2016-12-20 11:30:00-05:00                 0.00000  \n",
              "2016-12-20 11:35:00-05:00                 0.00000  \n",
              "2016-12-20 11:40:00-05:00                 0.00000  \n",
              "2016-12-20 11:45:00-05:00                 0.00000  \n",
              "2016-12-20 11:50:00-05:00                 0.00000  \n",
              "2016-12-20 11:55:00-05:00                 0.00000  \n",
              "2016-12-20 12:00:00-05:00                 0.00000  \n",
              "2016-12-20 12:05:00-05:00                 0.00000  \n",
              "2016-12-20 12:10:00-05:00                 6.83000  \n",
              "2016-12-20 12:15:00-05:00                 6.82010  \n",
              "2016-12-20 12:20:00-05:00                 6.83032  \n",
              "2016-12-20 12:25:00-05:00                 0.00000  \n",
              "2016-12-20 12:30:00-05:00                 0.00000  \n",
              "2016-12-20 12:35:00-05:00                 0.00000  \n",
              "2016-12-20 12:40:00-05:00                 0.00000  \n",
              "2016-12-20 12:45:00-05:00                 0.00000  \n",
              "2016-12-20 12:50:00-05:00                 6.84000  \n",
              "2016-12-20 12:55:00-05:00                 0.00000  \n",
              "2016-12-20 13:00:00-05:00                 6.83830  \n",
              "2016-12-20 13:05:00-05:00                 0.00000  \n",
              "2016-12-20 13:10:00-05:00                 0.00000  \n",
              "2016-12-20 13:15:00-05:00                 0.00000  \n",
              "2016-12-20 13:20:00-05:00                 6.84000  \n",
              "2016-12-20 13:25:00-05:00                 6.84740  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(threshold=200)\n",
        "y_train_pre_final[50:75]"
      ],
      "metadata": {
        "id": "Bi-1VYrmn0Eb",
        "outputId": "bb2c5662-445b-4a88-ed1e-da1b90b95752",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# Code fro scaling at a later date\n",
        "######\n",
        "\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scalers = {}\n",
        "for i in range(X_train.shape[1]):\n",
        "    scalers[i] = StandardScaler()\n",
        "    X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :]) \n",
        "\n",
        "for i in range(X_val.shape[1]):\n",
        "    X_val[:, i, :] = scalers[i].transform(X_val[:, i, :]) \n",
        "\n",
        "for i in range(X_test.shape[1]):\n",
        "    X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) \n",
        "    "
      ],
      "metadata": {
        "id": "xPkrkhqV4Ef-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_distribution(obj):\n",
        "    count_dict = {\n",
        "        \"up\": 0,\n",
        "        \"down/flat\": 0,\n",
        "    }\n",
        "    \n",
        "    for i in obj:\n",
        "        if i == 1: \n",
        "            count_dict['up'] += 1\n",
        "        elif i == 0: \n",
        "            count_dict['down/flat'] += 1\n",
        "        # elif i == 0: \n",
        "        #     count_dict['flat'] += 1             \n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "            \n",
        "    return count_dict"
      ],
      "metadata": {
        "id": "kNH38ORXLGfn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25,7))\n",
        "# Train\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_train)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')\n",
        "# Validation\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_val)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
        "# Test\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_test)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[2]).set_title('Class Distribution in Test Set')"
      ],
      "metadata": {
        "outputId": "e2fc1893-1c20-4042-e1a1-605a2cd09f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "qqTz9-J7LGft"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution in Test Set')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABa8AAAG5CAYAAACJPcgFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdfbxVZZnw8d+FoOTLKBISAYklab6k4smsfJthKrVGbCYzs8SyYXzSbMxmpHrGl8p5dGrGcipnKCkoU3mYMcmHLDJJzTQPDplmJmMoEMoJBU3FQb2eP9Z9dEPnwIFz9jl77/P7fj77s9e6173ufe210evsa691r8hMJEmSJEmSJElqJEMGOgBJkiRJkiRJkjZm8VqSJEmSJEmS1HAsXkuSJEmSJEmSGo7Fa0mSJEmSJElSw7F4LUmSJEmSJElqOBavJUmSJEmSJEkNx+K1WkZEXBAR3x7oOGpFxPcjYmofjXV4RNxfs740Iv68L8Yu490bEUf11Xg14/bZMWjmGCRJm2Ye7/X4LZXHIyIjYs/+fl1J0h8zR/d6/JbK0VJ/s3itphIR74uI9oj4Q0SsLP+zPmyAYsmIeKrEsjoiboyIE2v7ZOYxmTmrh2Nt8gtaZt6SmXv1Nu7yet+MiM9tNP6+mbmwL8bfaNweHYONlePa+XghIp6pWT+5P2IocRwWEbdFxNqIeCwifhoRb+jhvn7xlqQa5vFBlcdviIjPdNE+JSIeiYihWxtTROwbET8seXlNRCyKiGN7uG+fFiQkqVWYowdVju6z79plvIUR8eHN9DktIn4dEU9GxKMRMT8idurB2EdFxPItjUmtxeK1mkZEfBz4IvCPwGjgVcBXgSkDGNYBmbkjsBfwTeDLEXF+X79Ib77gNavM3LHzATwM/EVN25Wd/ep5bCLiT4DrgX8FdgXGAhcCz9brNSWpVZnHB51ZwPsjIjZq/wBwZWY+14uxvwcsAF4B7AacBTzRi/EkaVAzRw8uPf2u3Vci4kiqf1snZeZOwOuAa/r6ddTCMtOHj4Z/ADsDfwBO2ESfC4Bv16z/X+ARYC1wM7BvzbZjgV8BTwIrgE+U9pdTFSvXAI8BtwBDunm9BPbcqO3dwDpgZFlfCHy4LO8J/KTE83vgmtJ+cxnrqfIeTwSOApYD55b38K3OtprXWgp8sryPx4FvAMPLtlOBW7uKF5gGrAf+p7ze92rG+/OyvB3VHy+/K48vAtuVbZ2xnQOsAlYCH9zE51J7DE4FbgW+UGL+LXBMDz7/2ti6OjYjyufWUca9HhjX2xiANmDNZmL7EHBfGesHwO7dfa4D/d+RDx8+fAzUA/P4oMvjwMvKsTqipm1EOb4HAIcAPyuf1Urgy8C2m/p8aj7jBHbZRMzvBBaXsW8DXl/avwW8ADxTjt3fD/R/Gz58+PAx0A/M0YMuR280Rm1sQ4DpwH8Dq4E5wK5l23Dg26V9DXAn1Q8dFwHPl8/mD8CXu3iNTwDf3UQM25W4HwYeBf6N6u+IHahy9gtl7D8Arxzo/2Z89P/DM6/VLN5E9T/La7dgn+8DE6nOyLkLqP0F8Qrgb7L61W8/4Mel/RyqZDGK6n/En6JKRD11HTCU6gvZxj4L/JDqi9s4qrN5ycwjyvYDsvqls/MXyFdQne27O1US7MrJwNuB1wCvBf735gLMzBlUx+Kfyuv9RRfdPg0cChzIS18wa8d+BdUfOWOB04CvRMSIzb128Ubgfqo/Xv4JuKKLs7I2Z+NjM4TqD4rdqc4SeIbqS3BvY/gN8HxEzIqIYzZ+jxExherfyF9S/Zu5BbgKNvm5StJgZB7vWsvm8cx8hupL7yk1ze8Bfp2Zv6D6ont2GedNwGTgIz14/dXAEuDbEXF8RIyu3RgRBwEzgb8BRgL/DsyLiO0y8wNseIbZP/XwPUtSKzNHd61lc/QmfBQ4HjgSeCVVEfwrZdvUEtd4qvx6OvBMZn6a6nvwmeU9n9nFuHcAb4+ICyPiLRGx3UbbL6Y6xgdS/QgwFjgvM58CjgF+ly+dGf67LXg/ahEWr9UsRgK/zy24xDQzZ2bmk5n5LNUvxQdExM5l83pgn4j4k8x8PDPvqmkfQ3X27Pqs5r7qcULNzPVUv/Tu2sXm9VTJ8ZWZuS4zb93McC8A52fms+ULYFe+nJnLMvMxql88T+pprJtxMvCZzFyVmR1UU2V8oGb7+rJ9fWbOp/oFtKdzhD2UmV/LzOepLikeQ/XHy5bY4Nhk5urM/I/MfDozn6Q6Fkf2NobMfAI4jOqPqq8BHRExr+aL8unA/8nM+8q/zX8EDoyI3bfw/UhSqzOPd63V8/gs4N0RMbysn1LayMxFmXl7Zj6XmUupisybyt2U/RL4U6ozxf4ZWBkRN0fExNJlGvDvmXlHZj6f1Vygz1IVCiRJf8wc3bVWz9FdOR34dGYur/ls312mVllP9W9lz5JfF5Xvy5uVmbdQnfA1Cfh/wOqI+JeI2KYU16cBZ2fmY+X7/D8C792CuNXiLF6rWawGXt7T+ajK/wQvjoj/jognqL7gQPULJMBfUV3O9FBE/CQi3lTaP091Ns8PI+LBiJi+JUFGxDCqX5If62Lz3wMB/Dyquw1/aDPDdWTmus30WVaz/BDVr6N94ZVlvO7GXr3RHzdPAzv2cOxHOhcy8+my2NN9O21wbCJi+4j494h4qHzeNwO7RMQ2vY2hFKZPzcxxVGcOvJLq0i6o/kD6UrlZVOflb0H1S7Ek6SXm8a61dB4vxYPfA8dHxGuozi77DkBEvDYiro/q5o1PUH1RfXlX43Qx7vLMPDMzX0OVi58CZpfNuwPndObmkp/H03fHVpJajTm6ay2do7uxO3BtTf68j+pKqdFU06v8ALg6In4XEf9UPpMeyczvZ3Um+q5Uc6mfCnyY6jPdHlhU87o3lHYJsHit5vEzqrNmju9h//dR/Q/xz6kubZlQ2gMgM+/MzClUlzl9l+qyVsqvx+dk5quB44CPR8TkLYhzCvAc8PONN2TmI5n515n5SqpLWb8am77rcU9+hR5fs/wqqjmzoPoSt33nhoh4xRaO/TuqxNXV2I1g4/jPofo1+o2Z+SdA5+VhWzodyaZfNPPXVDcL2a80LaO6JG6XmsfLMvO2vnxdSWoB5vGuDYY8PpvqjOv3Az/IzEdL++XAr4GJJXd/iq3I25m5jOqS5trcfNFGuXn7zLyqc5devBdJakXm6K4Nhhy9sWVU82TX5tDhmbminAl+YWbuA7yZ6v4SnVODbckZ9C9k5o1U08nsR/Uj9zNU86Z3vubOWd1McovGVuuyeK2mkJlrgfOo5ns6vpxpO6zMQ9zVfIU7USXg1VSJ5R87N0TEthFxckTsXC49eoLqsiEi4p0RsWe5dGUt1a+ML2wuvojYNSJOpvrydElmru6izwkRMa6sPk71P+HOsR8FXt2DQ7GxMyJiXETsSjV3VuccXr8A9o2IA8uluhdstN/mXu8q4H9HxKiIeDnVsf/2VsTXX3aiSnhryrE4vy8GjYi9I+Kczs8tIsZTXS52e+nyb8AnI2Lfsn3niDihZoit/VwlqaWYx7s1GPL4bKoCx19TpgwpdqL67P4QEXsD/6sng0XEiKjmzNwzIoaU9/chXsrNXwNOj4g3RmWHiHhHROxUtpubJamGObpbgyFHb+zfgIuiTINZYpxSlv80IvaP6urmJ6imEenRMY6IKRHx3pLDIyIOoZoq7PbMfIEqd18aEbuV/mMj4u01Y4+Ml6al0SBk8VpNIzP/Gfg41c0MOqh+FTyT6tfcjc2muvxmBdUdgm/faPsHgKVRXeZ0OtW8U1DddOJHVPNK/Qz4ambetImwfhERf6C6/OnDVPM0nddN3zcAd5T+84CPZeaDZdsFwKxymcx7NvF6G/sO1Y0pHqS6I/DnADLzN8Bnynt5gOquw7WuoJqHbE1EdHX8Pge0A3cDv6S6CcfntiCu/vZFqrsR/57qs76hj8Z9kuqmF3dExFNl7HuozvQmM68FLqG6dOqJsu2Ymv0vYOs+V0lqOebxLrV8Hs9qPuvbgB2ojlunT1Cdvfck1ZfWnt7Y+H+ozvL7EdWX53uoiiinltdrpyqUf5mqgLGkc1vxf6iKBmsi4hNb/o4kqfWYo7vU8jm6C1+iOn4/jIgnqT7bN5ZtrwDmUuXe+4CfUE0l0rnfuyPi8Yi4rItxH6fKzQ+U/b8NfD4zO2/0eS7V53x7+XfzI8o83+Xq56uAB8sxdRqwQSi2YH58SZIkSZIkSZL6hWdeS5IkSZIkSZIajsVrSZIkSZIkSVLDsXgtSZIkSZIkSWo4Fq8lSZIkSZIkSQ1n6EAHUA8vf/nLc8KECQMdhiSphS1atOj3mTlqoONoduZsSVI9ma/7hvlaklRPm8rXLVm8njBhAu3t7QMdhiSphUXEQwMdQyswZ0uS6sl83TfM15KketpUvnbaEEmSJEmSJElSw7F4LUmSJEmSJElqOBavJUmSJEmSJEkNpyXnvO7K+vXrWb58OevWrRvoUJra8OHDGTduHMOGDRvoUCRJLcqc3TfM2ZKkejJf9w3ztSRt2qApXi9fvpyddtqJCRMmEBEDHU5TykxWr17N8uXL2WOPPQY6HElSizJn9545W5JUb+br3jNfS9LmDZppQ9atW8fIkSNNqr0QEYwcOdJf1iVJdWXO7j1ztiSp3szXvWe+lqTNGzTFa8Ck2gc8hpKk/mC+6T2PoSSp3sw1vecxlKRNG1TFa0mSJEmSJElSc7B4PcCOPfZY1qxZs8k+O+64Y5ftp556KnPnzq1HWJIkqYb5WpKk5mDOlqTWMmhu2NhoMpPMZP78+QMdiiRJ6ob5WpKk5mDOlqTW5JnXvTR9+nS+8pWvvLh+wQUX8LnPfY7JkyczadIk9t9/f6677joAli5dyl577cUpp5zCfvvtx7Jly5gwYQK///3vATj++OM5+OCD2XfffZkxY8YGr3P22Wez7777MnnyZDo6Ov4ojkWLFnHkkUdy8MEH8/a3v52VK1fW8V1LktRczNeSJDUHc7YkqZbF61468cQTmTNnzovrc+bMYerUqVx77bXcdddd3HTTTZxzzjlkJgAPPPAAH/nIR7j33nvZfffdNxhr5syZLFq0iPb2di677DJWr14NwFNPPUVbWxv33nsvRx55JBdeeOEG+61fv56PfvSjzJ07l0WLFvGhD32IT3/603V+55KkVhERMyNiVUTcU9O2a0QsiIgHyvOI0h4RcVlELImIuyNiUs0+U0v/ByJi6kC8l+6YryVJag7mbElSLacN6aWDDjqIVatW8bvf/Y6Ojg5GjBjBK17xCs4++2xuvvlmhgwZwooVK3j00UcB2H333Tn00EO7HOuyyy7j2muvBWDZsmU88MADjBw5kiFDhnDiiScC8P73v5+//Mu/3GC/+++/n3vuuYe3vvWtADz//POMGTOmXm9ZktR6vgl8GZhd0zYduDEzL46I6WX9XOAYYGJ5vBG4HHhjROwKnA+0AQksioh5mfl4v72LTTBfS5LUHMzZkqRaFq/7wAknnMDcuXN55JFHOPHEE7nyyivp6Ohg0aJFDBs2jAkTJrBu3ToAdthhhy7HWLhwIT/60Y/42c9+xvbbb89RRx314j4bi4gN1jOTfffdl5/97Gd9+8YkSYNCZt4cERM2ap4CHFWWZwELqYrXU4DZWZ3udHtE7BIRY0rfBZn5GEBELACOBq6qc/g9Zr6WJKk5mLMlSZ2cNqQPnHjiiVx99dXMnTuXE044gbVr17LbbrsxbNgwbrrpJh566KHNjrF27VpGjBjB9ttvz69//Wtuv/32F7e98MILL97x+Dvf+Q6HHXbYBvvutddedHR0vJhY169fz7333tuH71CSNAiNzszOyR0fAUaX5bHAspp+y0tbd+1/JCKmRUR7RLR3NcdkvZivJUlqDuZsSVIni9d9YN999+XJJ59k7NixjBkzhpNPPpn29nb2339/Zs+ezd57773ZMY4++miee+45Xve61zF9+vQNLnvaYYcd+PnPf85+++3Hj3/8Y84777wN9t12222ZO3cu5557LgcccAAHHnggt912W5+/T0nS4FTOss4+HG9GZrZlZtuoUaP6atjNMl9LktQczNmSpE7ReZODVtLW1pbt7e0btN1333287nWvG6CIWovHUuo/D39m/4EOoSW86rxf9vmYEbEoM9v6fOABUqYNuT4z9yvr9wNHZebKMi3IwszcKyL+vSxfVduv85GZf1PaN+jXHXN2fXkspf5jzu4bfZ2zWy1fDxTzdX15LKX+Y77uG/2Zrz3zWpIkdWUeMLUsTwWuq2k/JSqHAmvL9CI/AN4WESMiYgTwttImSZIkSdJW8YaNkiQNchFxFdWZ0y+PiOXA+cDFwJyIOA14CHhP6T4fOBZYAjwNfBAgMx+LiM8Cd5Z+n+m8eaMkSZIkSVvD4rUkSYNcZp7UzabJXfRN4IxuxpkJzOzD0CRJkiRJg5jThkiSJEmSJEmSGo7Fa0mSJEmSJElSw7F4LUmSJElSk4qIvSJicc3jiYj424jYNSIWRMQD5XlE6R8RcVlELImIuyNi0kC/B0mSujNo57w++O9m9+l4iz5/Sp+OJ0mSKuZsSZK6l5n3AwcCRMQ2wArgWmA6cGNmXhwR08v6ucAxwMTyeCNweXnuFfO1JKkePPNakiRJkqTWMBn478x8CJgCzCrts4Djy/IUYHZWbgd2iYgx/R+qJEmbN2jPvB4IS5cu5Z3vfCf33HMPAF/4whf4wx/+wMKFCznggAP4yU9+wnPPPcfMmTM55JBDBjhaSZIGL3O2JKlJvRe4qiyPzsyVZfkRYHRZHgssq9lneWlbWdNGREwDpgG86lWvqle8vWK+lqTW55nXDeLpp59m8eLFfPWrX+VDH/rQQIcjSZK6Yc6WJDWiiNgWOA74vxtvy8wEckvGy8wZmdmWmW2jRo3qoyj7j/laklqDxesGcdJJJwFwxBFH8MQTT7BmzZoBjkiSJHXFnC1JalDHAHdl5qNl/dHO6UDK86rSvgIYX7PfuNLWUszXktQaLF73o6FDh/LCCy+8uL5u3boXlyNig74br0uSpP5jzpYkNaGTeGnKEIB5wNSyPBW4rqb9lKgcCqytmV6kqZivJan11a14HRHjI+KmiPhVRNwbER8r7RdExIqIWFwex9bs88mIWBIR90fE22vajy5tS8pdkpvS6NGjWbVqFatXr+bZZ5/l+uuvf3HbNddcA8Ctt97KzjvvzM477zxQYUqSNOiZsyVJzSQidgDeCvxnTfPFwFsj4gHgz8s6wHzgQWAJ8DXgI/0Yap8yX0tS66vnDRufA87JzLsiYidgUUQsKNsuzcwv1HaOiH2obi6xL/BK4EcR8dqy+StUiXg5cGdEzMvMX/UmuEWfP6U3u2+VYcOGcd5553HIIYcwduxY9t577xe3DR8+nIMOOoj169czc+bMfo9NkqRGZc6WJGnTMvMpYORGbauByV30TeCMvo7BfC1Jqoe6Fa/LZUcry/KTEXEf1R2MuzMFuDoznwV+GxFLgM7bAS/JzAcBIuLq0rdXxeuBctZZZ3HWWWdt0HbUUUfx/ve/ny9+8YsDFJUkSdqYOVuSpMZnvpak1tYvc15HxATgIOCO0nRmRNwdETMjYkRpGwssq9lteWnrrn3j15gWEe0R0d7R0dHH70CSJEmSJEmS1J/qOW0IABGxI/AfwN9m5hMRcTnwWSDL8z8DH+rt62TmDGAGQFtbW/Z2vP60cOHCgQ5BkiT1gDlbkqTGZ76WpNZR1+J1RAyjKlxfmZn/CZCZj9Zs/xrQeUeFFcD4mt3HlTY20S5JkiRJkiRJakF1mzYkIgK4ArgvM/+lpn1MTbd3AfeU5XnAeyNiu4jYA5gI/By4E5gYEXtExLZUN3WcV6+4JUmSJEmSJEkDr55nXr8F+ADwy4hYXNo+BZwUEQdSTRuyFPgbgMy8NyLmUN2I8TngjMx8HiAizgR+AGwDzMzMe+sYtyRJkiRJkiRpgNWteJ2ZtwLRxab5m9jnIuCiLtrnb2o/SZIkSZIkSVJrqfsNGxvVw5/Zv0/He9V5v9zifS644AJ23HFHPvGJT/RpLJ2OOeYYvva1r/Hb3/6W008/nWHDhnHVVVdxwgkncM8993S739KlS7ntttt43/veV5e4JEnaEgOds83XkiRt3kDnazBnS1Irqtuc1xpYzzzzDKtXr2bcuHFceeWVfPKTn2Tx4sW87GUv2+y+S5cu5Tvf+U4/RClJ0uBmvpYkqTmYsyVpYFi87mcXXXQRr33taznssMO4//77AVi8eDGHHnoor3/963nXu97F448/zqpVqzj44IMB+MUvfkFE8PDDDwPwmte8hqeffppTTz2Vs846ize/+c28+tWvZu7cuS++zsKFCznqqKP4+te/zpw5c/iHf/gHTj755A1iWbp0KYcffjiTJk1i0qRJ3HbbbQBMnz6dW265hQMPPJBLL720Pw6LJEkNxXwtSVJzMGdLUmuzeN2PFi1axNVXX83ixYuZP38+d955JwCnnHIKl1xyCXfffTf7778/F154Ibvtthvr1q3jiSee4JZbbqGtrY1bbrmFhx56iN12243tt98egJUrV3Lrrbdy/fXXM3369Bdf6/vf/z5HH300H/7whznuuOP4/Oc/z5VXXrlBPLvtthsLFizgrrvu4pprruGss84C4OKLL+bwww9n8eLFnH322f10dCRJagzma0mSmoM5W5Ja36Cd83og3HLLLbzrXe96MSked9xxPPXUU6xZs4YjjzwSgKlTp3LCCScA8OY3v5mf/vSn3HzzzXzqU5/ihhtuIDM5/PDDXxzz+OOPZ8iQIeyzzz48+uijL7b/9Kc/5Qtf+MIm41m/fj1nnnkmixcvZptttuE3v/lNX79lSZKajvlakqTmYM6WpNZn8bqBHXHEES/+EjxlyhQuueQSIoJ3vOMdL/bZbrvtXlzOTAAefPBBxo8fz7bbbrvJ8S+99FJGjx7NL37xC1544QWGDx9enzciSVILM19LktQczNmS1HycNqQfHXHEEXz3u9/lmWee4cknn+R73/seO+ywAyNGjOCWW24B4Fvf+taLvxAffvjhfPvb32bixIkMGTKEXXfdlfnz53PYYYdt8nU6L2fanLVr1zJmzBiGDBnCt771LZ5//nkAdtppJ5588slevltJkpqT+VqSpOZgzpak1jdoz7x+1Xm/7PfXnDRpEieeeCIHHHAAu+22G294wxsAmDVrFqeffjpPP/00r371q/nGN74BwIQJE8hMjjjiCAAOO+wwli9fzogRIzb5OjfccAP/+q//utl4PvKRj/BXf/VXzJ49m6OPPpoddtgBgNe//vVss802HHDAAZx66qnOySVJGlD9nbPN15IkbTm/Y5uzJakeovMymFbS1taW7e3tG7Tdd999vO51rxugiPrPs88+y1ve8hY2fv99abAcS6kRPPyZ/Qc6hJZQjy9TEbEoM9v6fOBBZrDm7P7I1zA4jqXUKMzZfaOvc7b5um8M1nwNfseWWo35um/0Z7522pAWs91229X9i7AkSeod87UkSc3BnC1JA8vitSRJkiRJkiSp4Qyq4nUrTpHS3zyGkqT+YL7pPY+hJKnezDW95zGUpE0bNMXr4cOHs3r1ahNDL2Qmq1evZvjw4QMdiiSphZmze8+cLUmqN/N175mvJWnzhg50AP1l3LhxLF++nI6OjoEOpakNHz6ccePGDXQYkqQWZs7uG+ZsSVI9ma/7hvlakjZt0BSvhw0bxh577DHQYUiSpM0wZ0uS1PjM15Kk/jBopg2RJEmSJEmSJDUPi9eSJEmSJEmSpIZj8VqSJEmSJEmS1HAsXkuSJEmSJEmSGo7Fa0mSJEmSJElSw7F4LUmSJEmSJElqOBavJUmSJEmSJEkNx+K1JEmSJEmSJKnhWLyWJEmSJEmSJDUci9eSJEmSJEmSpIZj8VqSJEmSJEmS1HAsXkuSJEmSJEmSGo7Fa0mSJEmSJElSw7F4LUmSJEmSJElqOBavJUmSJEmSJEkNx+K1JEmSJEmSJKnhWLyWJEmSJEmSJDUci9eSJEmSJEmSpIZj8VqSJEmSJEmS1HAsXkuSJEmSJEmSGo7Fa0mSJEmSmlhE7BIRcyPi1xFxX0S8KSJ2jYgFEfFAeR5R+kZEXBYRSyLi7oiYNNDxS5LUHYvXkiRJkiQ1ty8BN2Tm3sABwH3AdODGzJwI3FjWAY4BJpbHNODy/g9XkqSesXgtSZIkSVKTioidgSOAKwAy838ycw0wBZhVus0Cji/LU4DZWbkd2CUixvRz2JIk9YjFa0mSJEmSmtceQAfwjYj4r4j4ekTsAIzOzJWlzyPA6LI8FlhWs//y0raBiJgWEe0R0d7R0VHH8CVJ6p7Fa0mSJEmSmtdQYBJweWYeBDzFS1OEAJCZCeSWDJqZMzKzLTPbRo0a1WfBSpK0JSxeS5IkSZLUvJYDyzPzjrI+l6qY/WjndCDleVXZvgIYX7P/uNImSVLDsXgtSZIkSVKTysxHgGURsVdpmgz8CpgHTC1tU4HryvI84JSoHAqsrZleRJKkhjJ0oAOQJEmSJEm98lHgyojYFngQ+CDVyWpzIuI04CHgPaXvfOBYYAnwdOkrSVJDsngtSZIkSVITy8zFQFsXmyZ30TeBM+oelCRJfcBpQyRJkiRJkiRJDcfitSRJkiRJkiSp4Vi8liRJ3YqIsyPi3oi4JyKuiojhEbFHRNwREUsi4poyvyYRsV1ZX1K2TxjY6CVJkiRJzczitSRJ6lJEjAXOAtoycz9gG+C9wCXApZm5J/A4cFrZ5TTg8dJ+aeknSZIkSdJWsXgtSZI2ZSjwsogYCmwPrAT+DJhbts8Cji/LU8o6ZfvkiIh+jFWSJEmS1EIsXkuSpC5l5grgC8DDVEXrtcAiYE1mPle6LQfGluWxwLKy73Ol/8iNx42IaRHRHhHtHR0d9X0TkiRJkqSmZfFakiR1KSJGUJ1NvQfwSmAH4OjejpuZMzKzLTPbRo0a1dvhJEmSJEktyuK1JEnqzp8Dv83MjsxcD/wn8BZglzKNCMA4YEVZXgGMByjbdwZW92/IkiRJkqRWYfFakiR152Hg0IjYvsxdPYLZRoEAACAASURBVBn4FXAT8O7SZypwXVmeV9Yp23+cmdmP8UqSJEmSWojFa0mS1KXMvIPqxot3Ab+k+rthBnAu8PGIWEI1p/UVZZcrgJGl/ePA9H4PWpIkSZLUMoZuvoskSRqsMvN84PyNmh8EDumi7zrghP6IS5IkSZLU+jzzWpIkSZIkSZLUcCxeS5IkSZIkSZIajsVrSZIkSZIkSVLDsXgtSZIkSZIkSWo4Fq8lSZIkSZIkSQ2nbsXriBgfETdFxK8i4t6I+Fhp3zUiFkTEA+V5RGmPiLgsIpZExN0RMalmrKml/wMRMbVeMUuSJEmSJEmSGkM9z7x+DjgnM/cBDgXOiIh9gOnAjZk5EbixrAMcA0wsj2nA5VAVu4HzgTcChwDndxa8JUmSJEmSJEmtqW7F68xcmZl3leUngfuAscAUYFbpNgs4vixPAWZn5XZgl4gYA7wdWJCZj2Xm48AC4Oh6xS1JkiRJkiRJGnj9Mud1REwADgLuAEZn5sqy6RFgdFkeCyyr2W15aeuuXZIkSZIkSZLUoupevI6IHYH/AP42M5+o3ZaZCWQfvc60iGiPiPaOjo6+GFKSJEmSJEmSNEDqWryOiGFUhesrM/M/S/OjZToQyvOq0r4CGF+z+7jS1l37BjJzRma2ZWbbqFGj+vaNSJIkSZIkSZL6Vd2K1xERwBXAfZn5LzWb5gFTy/JU4Lqa9lOiciiwtkwv8gPgbRExotyo8W2lTZIkSZIkSZLUoobWcey3AB8AfhkRi0vbp4CLgTkRcRrwEPCesm0+cCywBHga+CBAZj4WEZ8F7iz9PpOZj9UxbkmSJEmSJEnSAKtb8TozbwWim82Tu+ifwBndjDUTmNl30UmSJEmSJEmSGlndb9goSZIkSZIkSdKWsngtSZIkSZIkSWo4Fq8lSZIkSZIkSQ3H4rUkSZIkSZIkqeFYvJYkSZIkSZIkNRyL15IkSZIkSZKkhmPxWpIkSZIkSZLUcCxeS5IkSZIkSZIajsVrSZIkSZIkSVLDsXgtSZIkSZIkSWo4Fq8lSZIkSZIkSQ3H4rUkSZIkSZIkqeFYvJYkSZIkSZIkNRyL15IkSZIkSZKkhmPxWpIkSZIkSZLUcCxeS5IkSZIkSZIajsVrSZIkSZKaWEQsjYhfRsTiiGgvbbtGxIKIeKA8jyjtERGXRcSSiLg7IiYNbPSSJHXP4rUkSZIkSc3vTzPzwMxsK+vTgRszcyJwY1kHOAaYWB7TgMv7PVJJknrI4rUkSZIkSa1nCjCrLM8Cjq9pn52V24FdImLMQAQoSdLmWLyWJEmSJKm5JfDDiFgUEdNK2+jMXFmWHwFGl+WxwLKafZeXtg1ExLSIaI+I9o6OjnrFLUnSJg0d6AAkSZIkSVKvHJaZKyJiN2BBRPy6dmNmZkTklgyYmTOAGQBtbW1btK8kSX3FM68lSZIkSWpimbmiPK8CrgUOAR7tnA6kPK8q3VcA42t2H1faJElqOBavJUmSJElqUhGxQ0Ts1LkMvA24B5gHTC3dpgLXleV5wClRORRYWzO9iCRJDcVpQyRJkiRJal6jgWsjAqrv+N/JzBsi4k5gTkScBjwEvKf0nw8cCywBngY+2P8hS5LUMxavJUmSJElqUpn5IHBAF+2rgcldtCdwRj+EJklSrzltiCRJkiRJkiSp4Vi8liRJkiRJkiQ1HIvXkiRJkiRJkqSGY/FakiRJkiRJktRwLF5LkiRJkiRJkhqOxWtJkiRJkiRJUsOxeC1JkiRJkiRJajgWryVJkiRJkiRJDcfitSRJkiRJkiSp4Vi8liRJkiRJkiQ1HIvXkiRJkiRJkqSGY/FakiRJkiRJktRwLF5LkiRJkiRJkhqOxWtJkiRJkiRJUsOxeC1JkiRJkiRJajgWryVJkiRJkiRJDcfitSRJkiRJkiSp4Vi8liRJkiRJkiQ1HIvXkiRJkiRJkqSGY/FakiRJkiRJktRwLF5LkiRJkiRJkhqOxWtJkiRJkiRJUsOxeC1JkiRJkiRJajgWryVJkiRJkiRJDcfitSRJkiRJkiSp4Vi8liRJ3YqIXSJibkT8OiLui4g3RcSuEbEgIh4ozyNK34iIyyJiSUTcHRGTBjp+SZIkSVLzsngtSZI25UvADZm5N3AAcB8wHbgxMycCN5Z1gGOAieUxDbi8/8OVJEmSJLUKi9eSJKlLEbEzcARwBUBm/k9mrgGmALNKt1nA8WV5CjA7K7cDu0TEmH4OW5IkSZLUIixeS5Kk7uwBdADfiIj/ioivR8QOwOjMXFn6PAKMLstjgWU1+y8vbRuIiGkR0R4R7R0dHXUMX5IkSZLUzCxeS5Kk7gwFJgGXZ+ZBwFO8NEUIAJmZQG7JoJk5IzPbMrNt1KhRfRasJEmSJKm1WLyWJEndWQ4sz8w7yvpcqmL2o53TgZTnVWX7CmB8zf7jSpskSZIkSVvM4rUkSepSZj4CLIuIvUrTZOBXwDxgammbClxXlucBp0TlUGBtzfQikiRJkiRtkaEDHYAkSWpoHwWujIhtgQeBD1L9+D0nIk4DHgLeU/rOB44FlgBPl76SJEmSJG0Vi9eSJKlbmbkYaOti0+Qu+iZwRt2DkiRJkiQNCk4bIkmSJEmSJElqOBavJUmSJEmSJEkNp27F64iYGRGrIuKemrYLImJFRCwuj2Nrtn0yIpZExP0R8faa9qNL25KImF6veCVJkiRJkiRJjaOeZ15/Ezi6i/ZLM/PA8pgPEBH7AO8F9i37fDUitomIbYCvAMcA+wAnlb6SJEmSJEmSpBZWtxs2ZubNETGhh92nAFdn5rPAbyNiCXBI2bYkMx8EiIirS99f9XG4kiRJkiRJkqQGMhBzXp8ZEXeXaUVGlLaxwLKaPstLW3ftfyQipkVEe0S0d3R01CNuSZIkSZIkSVI/6e/i9eXAa4ADgZXAP/fVwJk5IzPbMrNt1KhRfTWsJEmSJEmSJGkA1G3akK5k5qOdyxHxNeD6sroCGF/TdVxpYxPtkiRJkiRJkqQW1a9nXkfEmJrVdwH3lOV5wHsjYruI2AOYCPwcuBOYGBF7RMS2VDd1nNefMUuSJEmS1OgiYpuI+K+IuL6s7xERd0TEkoi4pnynpnzvvqa037EF96qSJKnf1a14HRFXAT8D9oqI5RFxGvBPEfHLiLgb+FPgbIDMvBeYQ3UjxhuAMzLz+cx8DjgT+AFwHzCn9JUkSZIkSS/5GNX35k6XAJdm5p7A48Bppf004PHSfmnpJ0lSQ6rbtCGZeVIXzVdsov9FwEVdtM8H5vdhaJIkSZIktYyIGAe8g+o79ccjIoA/A95XuswCLqC6D9WUsgwwF/hyRERmZn/GLElST/T3DRslSZIkSVLf+iLw98ALZX0ksKZczQywHBhblscCywDK9rWl/wYiYlpEtEdEe0dHRz1jlySpW5s98zoiRgP/CLwyM4+JiH2AN2Vmt2dRt6KD/272QIfQEhZ9/pSBDkGSWpY5W5Kk5rY1uTwi3gmsysxFEXFUX8WSmTOAGQBtbW2elS1JGhA9OfP6m1RzTr+yrP8G+Nt6BSRJkrbaNzFnS5LUzL7JlufytwDHRcRS4Gqq6UK+BOwSEZ0nrI0DVpTlFcB4gLJ9Z2B134QvSVLf6knx+uWZOYdy+VG5rOj5ukYlSZK2hjlbkqTmtsW5PDM/mZnjMnMC8F7gx5l5MnAT8O7SbSpwXVmeV9Yp23/sfNeSpEbVk+L1UxExEkiAiDiUak4sSZLUWMzZkiQ1t77M5edS3bxxCdWc1p1Tj1wBjCztHwem9y5kSZLqZ7NzXlMls3nAayLip8AoXvr1VpIkNQ5ztiRJza1XuTwzFwILy/KDwCFd9FkHnNAHsUqSVHebLV5n5l0RcSSwFxDA/Zm5vu6RSZKkLWLOliSpuZnLJUna0GaL1xFxykZNkyKCzJxdp5gkSdJWMGdLktTczOWSJG2oJ9OGvKFmeTgwGbgLMHlKktRYzNmSJDU3c7kkSTV6Mm3IR2vXI2IX4Oq6RSRJkraKOVuSpOZmLpckaUNDtmKfp4A9+joQSZLU58zZkiQ1N3O5JGlQ68mc198DsqwOAfYB5tQzKEmStOXM2ZIkNTdzuSRJG+rJnNdfqFl+DngoM5fXKR5JkrT1zNmSJDU3c7kkSTV6Muf1T/ojEEmS1DvmbEmSmpu5XJKkDXVbvI6IJ3npcqUNNgGZmX9St6gkSVKPmbMlSWpugzGXH/x3swc6hJaw6POnDHQIklRX3RavM3On/gxEkiRtHXO2JEnNzVwuSVLXejLnNQARsRswvHM9Mx+uS0SSJKlXzNmSJDU3c7kkSZUhm+sQEcdFxAPAb4GfAEuB79c5LkmStIXM2ZIkNTdzuSRJG9ps8Rr4LHAo8JvM3AOYDNxe16gkSdLWMGdLktTczOWSJNXoSfF6fWauBoZExJDMvAloq3NckiRpy5mzJUlqbuZySZJq9GTO6zURsSNwC3BlRKwCnqpvWJIkaSuYsyVJam7mckmSavTkzOubgJ2BjwE3AP8N/EU9g5IkSVvFnC1JUnMzl0uSVKMnxeuhwA+BhcBOwDXlMiZJktRYzNmSJDU3c7kkSTU2W7zOzAszc1/gDGAM8JOI+FHdI5MkSVvEnC1JUnMzl0uStKGenHndaRXwCLAa2K0+4UiSpD5gzpYkqbmZyyVJogfF64j4SEQsBG4ERgJ/nZmvr3dgkiRpy5izJUlqbuZySZI2NLQHfcYDf5uZi+sdjCRJ6hVztiRJzc1cLklSjc0WrzPzk/0RiCRJ6h1ztiRJzc1cLknShrZkzmtJkiRJkiRJkvqFxWtJkiRJkiRJUsOxeC1JkiRJkiRJajgWryVJkiRJkiRJDcfitSRJkiRJkiSp4Vi8liRJkiRJkiQ1HIvXkiRJkiRJkqSGY/FakiRJkiRJktRwLF5LkiRJkiRJkhqOxWtJkiRJkiRJUsOxeC1JkiRJkiRJajgWryVJkiRJkiRJDcfitSRJkiRJkiSp4Qwd6AAkSZL6ysF/N3ugQ2gJiz5/ykCHIEmSJEmeeS1JkiRJkiRJajwWryVJkiRJkiRJDcfitSRJkiRJkiSp4Vi8liRJkiRJkiQ1HIvXkiRJkiRJkqSGY/FakiRJkqQmFRHDI+LnEfGLiLg3Ii4s7XtExB0RsSQiromIbUv7dmV9Sdk+YSDjlyRpUyxeS5IkSZLUvJ4F/iwzDwAOBI6OiEOBS4BLM3NP4HHgtNL/NODx0n5p6SdJUkOyeC1JkiRJUpPKyh/K6rDySODPgLmlfRZwfFmeUtYp2ydHRPRTuJIkbRGL15IkSZIkNbGI2CYiFgOrgAXAfwNrMvO50mU5MLYsjwWWAZTta4GRXYw5LSLaI6K9o6Oj3m9BkqQuWbyWJEmSJKmJZebzmXkgMA44BNi7D8ackZltmdk2atSoXscoSdLWsHgtSZIkSVILyMw1wE3Am4BdImJo2TQOWFGWVwDjAcr2nYHV/RyqJEk9YvFakiR1q1yG/F8RcX1Z3yMi7oiIJRFxTURsW9q3K+tLyvYJAxm3JEmDRUSMiohdyvLLgLcC91EVsd9duk0FrivL88o6ZfuPMzP7L2JJknrO4rUkSdqUj1F9Ae50CXBpZu4JPA6cVtpPAx4v7ZeWfpIkqf7GADdFxN3AncCCzLweOBf4eEQsoZrT+orS/wpgZGn/ODB9AGKWJKlHhm6+iyRJGowiYhzwDuAiqi+/AfwZ8L7SZRZwAXA5MKUsA8wFvhwR4ZlckiTVV2beDRzURfuDVPNfb9y+DjihH0KTJKnXPPNakiR154vA3wMvlPWRwJrMfK6sLwfGluWxwDKAsn1t6f9HImJaRLRHRHtHR0e9YpckSZIkNTmL15Ik6Y9ExDuBVZm5qK/HzswZmdmWmW2jRo3q6+ElSZIkSS3CaUMkSVJX3gIcFxHHAsOBPwG+BOwSEUPL2dXjgBWl/wpgPLA8IoYCOwOr+z9sSZIkSVKr8MxrSZL0RzLzk5k5LjMnAO8FfpyZJwM3Ae8u3aYC15XleWWdsv3HznctSZIkSeqNuhWvI2JmRKyKiHtq2naNiAUR8UB5HlHaIyIui4glEXF3REyq2Wdq6f9AREzt6rUkSVK/OZfq5o1LqOa0vqK0XwGMLO0fB6YPUHySJEmSpBZRzzOvvwkcvVHbdODGzJwI3MhLX2yPASaWxzTgcqiK3cD5wBup7pJ8fmfBW5Ik9Y/MXJiZ7yzLD2bmIZm5Z2aekJnPlvZ1ZX3Psv3BgY1akiRJktTs6la8zsybgcc2ap4CzCrLs4Dja9pnZ+V2qvk0xwBvBxZk5mOZ+TiwgD8uiEuSJEmSJEmSWkx/z3k9OjNXluVHgNFleSywrKbf8tLWXfsfiYhpEdEeEe0dHR19G7UkSZIkSZIkqV8N2A0by02c+uxGTpk5IzPbMrNt1KhRfTWsJEmSJEmSJGkA9Hfx+tEyHQjleVVpXwGMr+k3rrR11y5JkiRJkiRJamH9XbyeB0wty1OB62raT4nKocDaMr3ID4C3RcSIcqPGt5U2SZIkSZIkSVILG1qvgSPiKuAo4OURsRw4H7gYmBMRpwEPAe8p3ecDxwJLgKeBDwJk5mMR8VngztLvM5m58U0gJUmSJEmSJEktpm7F68w8qZtNk7vom8AZ3YwzE5jZh6FJkiRJkiRJkhrcgN2wUZIkSZIkSZKk7li8liRJkiRJkiQ1HIvXkiTp/7d39zGbnXWdwL/fpawIIuVlGLttl65JfSlGapnFItTAohvaaIoJqSjSBjHzh/U1srFxN8G40e0mu5Lt7sqmWQltllUggDQR0aaRl2qqDLX0hYJUQtM2Q2dUrEhVRC//eM6Ym3GGeWGeua/7mc8neXKfc52X+3cmOc8v873vcz0AAAAwHeE1AAAAAADTEV4DAAAAADAd4TUAAAAAANMRXgMAAAAAMB3hNQAAAAAA0xFeAwAAAAAwHeE1AAAAAADTEV4DAAAAADAd4TUAAAAAANMRXgMAAAAAMB3hNQAAAAAA0xFeAwAAAAAwHeE1AAAAAADTEV4DAAAAADAd4TUAAAAAANMRXgMAAAAAMB3hNQAAAAAA0xFeAwAAAAAwHeE1AAAAAADTEV4DAAAAADAd4TUAAAAAANMRXgMAAAAAMB3hNQAAAAAA0xFeAwAAAAAwHeE1AAAAAADTEV4DAAAAADAd4TUAAABsqLbnt/3dth9re1/bn1zGn9H21rafXF6fvoy37Q1tH2h7d9tL1nsFAHB0wmsAAADYXF9M8jNjjIuSXJrk2rYXJbkuyW1jjAuT3LasJ8nlSS5cfvYmedPpLxkAjo/wGgAAADbUGGP/GOPOZflzSe5Pcm6SK5PctOx2U5JXLMtXJrl5bLkjydltzznNZQPAcRFeAwAAwA7Q9oIk35bkD5LsHmPsXzZ9JsnuZfncJA+tHPbwMnb4ufa23dd238GDB7etZgD4coTXAAAAsOHafk2Sdyb5qTHGX65uG2OMJONEzjfGuHGMsWeMsWfXrl2nsFIAOH7CawAAANhgbZ+YreD6rWOMdy3Djx6aDmR5PbCMP5Lk/JXDz1vGAGA6wmsAAADYUG2b5FeT3D/G+OWVTbckuWZZvibJe1bGr+6WS5M8tjK9CABM5ax1FwAAAACctBcleU2Se9retYz9XJLrk7y97euSPJjkqmXbe5NckeSBJI8nee3pLRcAjp/wGgAAADbUGOP2JD3K5pcdYf+R5NptLQoAThHThgAAAAAAMB3hNQAAAAAA0xFeAwAAAAAwHeE1AAAAAADTEV4DAAAAADAd4TUAAAAAANMRXgMAAAAAMB3hNQAAAAAA0xFeAwAAAAAwHeE1AAAAAADTEV4DAAAAADAd4TUAAAAAANMRXgMAAAAAMB3hNQAAAAAA0xFeAwAAAAAwHeE1AAAAAADTEV4DAAAAADAd4TUAAAAAANMRXgMAAAAAMB3hNQBwRG3Pb/u7bT/W9r62P7mMP6PtrW0/ubw+fRlv2xvaPtD27raXrPcKAAAA2GTCawDgaL6Y5GfGGBcluTTJtW0vSnJdktvGGBcmuW1ZT5LLk1y4/OxN8qbTXzIAAAA7hfAaADiiMcb+Mcady/Lnktyf5NwkVya5adntpiSvWJavTHLz2HJHkrPbnnOaywYAAGCHWEt43fbTbe9pe1fbfcuYR5ABYFJtL0jybUn+IMnuMcb+ZdNnkuxels9N8tDKYQ8vY4efa2/bfW33HTx4cNtqBgAAYLOt85vXLx1jXDzG2LOsewQZACbU9muSvDPJT40x/nJ12xhjJBkncr4xxo1jjD1jjD27du06hZUCAACwk8w0bYhHkAFgMm2fmK3g+q1jjHctw48e6sXL64Fl/JEk568cft4yBgAAACdsXeH1SPI7bT/Sdu8y5hFkAJhI2yb51ST3jzF+eWXTLUmuWZavSfKelfGrlym/Lk3y2EpvBwAAgBNy1pre98VjjEfaPjvJrW0/vrpxjDHanvAjyEluTJI9e/ac0LEAwBG9KMlrktzT9q5l7OeSXJ/k7W1fl+TBJFct296b5IokDyR5PMlrT2+5AAAA7CRrCa/HGI8srwfavjvJC7I8gjzG2O8RZABYvzHG7Ul6lM0vO8L+I8m121oUAAAAZ4zTPm1I26e0feqh5ST/Psm98QgyAAAAAACLdXzzeneSd29No5mzkvz/Mcb72n44HkEGAAAAACBrCK/HGJ9K8rwjjP9ZPIIMAAAAAEDWMG0IAAAAAAAci/AaAAAAAIDpCK8BAAAAAJiO8BoAAAAAgOkIrwEAAAAAmI7wGgAAAACA6QivAQAAAACYjvAaAAAAAIDpCK8BAAAAAJiO8BoAAAAAgOkIrwEAAGBDtX1z2wNt710Ze0bbW9t+cnl9+jLetje0faDt3W0vWV/lAHBswmsAAADYXG9J8vLDxq5LctsY48Ikty3rSXJ5kguXn71J3nSaagSAkyK8BgAAgA01xvhgkj8/bPjKJDctyzclecXK+M1jyx1Jzm57zumpFABOnPAaAAAAdpbdY4z9y/Jnkuxels9N8tDKfg8vY/9M271t97Xdd/Dgwe2rFAC+DOE1AAAA7FBjjJFknMRxN44x9owx9uzatWsbKgOAYxNeAwAAwM7y6KHpQJbXA8v4I0nOX9nvvGUMAKYkvAYAAICd5ZYk1yzL1yR5z8r41d1yaZLHVqYXAYDpnLXuAgAAAICT0/bXkrwkybPaPpzkDUmuT/L2tq9L8mCSq5bd35vkiiQPJHk8yWtPe8EAcAKE1wAAALChxhg/cJRNLzvCviPJtdtbEQCcOqYNAQAAAABgOsJrAAAAAACmI7wGAAAAAGA6wmsAAAAAAKYjvAYAAAAAYDrCawAAAAAApiO8BgAAAABgOsJrAAAAAACmI7wGAAAAAGA6wmsAAAAAAKYjvAYAAAAAYDrCawAAAAAApiO8BgAAAABgOsJrAAAAAACmI7wGAAAAAGA6wmsAAAAAAKYjvAYAAAAAYDrCawAAAAAApiO8BgAAAABgOsJrAAAAAACmI7wGAAAAAGA6wmsAAAAAAKYjvAYAAAAAYDrCawAAAAAApiO8BgAAAABgOsJrAAAAAACmI7wGAAAAAGA6wmsAAAAAAKYjvAYAAAAAYDrCawAAAAAApiO8BgAAAABgOsJrAAAAAACmI7wGAAAAAGA6wmsAAAAAAKYjvAYAAAAAYDrCawAAAAAApiO8BgAAAABgOsJrAAAAAACmI7wGAAAAAGA6wmsAAAAAAKYjvAYAAAAAYDrCawAAAAAAprMx4XXbl7f9RNsH2l637noAgH9OvwaAzaBnA7AJNiK8bvuEJP87yeVJLkryA20vWm9VAMAq/RoANoOeDcCm2IjwOskLkjwwxvjUGOMLSX49yZVrrgkA+FL6NQBsBj0bgI1w1roLOE7nJnloZf3hJN++ukPbvUn2Lqt/1fYTp6k2TkD/2zXPSvKn664DNoh75lR4Q7fjrM/ZjpNuuGP260TP3gT6NZwU982pcOp7tn59ZP6PvUPo2XDC3DOnwmns15sSXh/TGOPGJDeuuw6+vLb7xhh71l0HbAr3DDuRnj0/v3vgxLlv2Gn0683gdw+cGPfM5tmUaUMeSXL+yvp5yxgAMA/9GgA2g54NwEbYlPD6w0kubPtv2v7LJK9KcsuaawIAvpR+DQCbQc8GYCNsxLQhY4wvtv2xJL+d5AlJ3jzGuG/NZXFyPHYGJ8Y9w8bQr3cUv3vgxLlv2Bh69o7idw+cGPfMhukYY901AAAAAADAl9iUaUMAAAAAADiDCK8BAAAAAJiO8BrgFGv7821fv43n/62257W9rO19be9q+81t7z3GcRe0/cHtqgsANo2eDQDz06/PbMJrgA3S9quTPHOM8XCSVyf5L2OMi5P89XEcfkESjRUATgM9GwDmp1/PT3jNtlk+gbp3Zf31y6dl72/7P5ZPsu5t+4J11gmnQtv/2PaP296e5BuXsYvb3tH27rbvbvv0ts9u+5Fl+/Pajrb/eln/k7ZPbvuWtje0/f22n2r7ypW3ekmS97f9kSRXJfnPbd96WC0XtP1Q2zuXn+9YNl2f5LLl3vvp7f0XATaFfs2ZRs8GNpF+zZlGv+YQ4TXr8uTlk6wfTfLmdRcDX4m2z0/yqiQXJ7kiyb9dNt2c5GfHGN+a5J4kbxhjHEjypLZfm+SyJPuy1eyek+TAGOPx5dhzkrw4yfdkqyEecnmS940x/m+SW5L8hzHGqw8r6UCS7x5jXJLk+5PcsIxfl+RDY4yLxxhvPEWXD+xs+jU7ip4N7FD6NTuKfs2qs9ZdAGesX0uSMcYH235t27PHGH+x7qLgJF2W5N2HmmLbW5I8JcnZY4wPLPvclOQdy/LvJ3lRku9M8ktJXp6kST60cs7fGGP8Q5KPtd29Mv6iJMea6+uJSf5X24uT/H2SbzjZCwPOePo1O42eDexE+jU7jX7NPxFes52+mC/9dv+TVpbHOgKrYQAABDpJREFUYfsevg472Qez1Yyfk+Q9SX42W/fAb67s87cry02Stl+f5KExxheOcf6fTvJokudl6x78m1NTNrBD6ddwdHo2MAv9Go5Ov97BTBvCdno0ybPbPrPtV2Xr0YxDvj9J2r44yWNjjMfWUSCcIh9M8oq2X932qUm+N8nnk3y27WXLPq9JcugT4g8l+aEkn1w++f3zbD0Kdfsx3ufyJO87jnqelmT/cu7XJHnCMv65JE89vksCziD6NWcSPRvYVPo1ZxL9mn/im9dsmzHG37X9hSR/mOSRJB9f2fw3bf8oW49e/PA66oNTZYxxZ9u3JflotubC+vCy6Zok/6ftk5N8Kslrl/0/3bbZasjJVkM9b4zx2WO81cuT/PhxlPQrSd7Z9upsNeLPL+N3J/n7th9N8hZzcgGJfs2ZRc8GNpV+zZlEv2ZVx/A0CadX2/cnef0YY9+6a4FNsXy74vfGGHvWXQtwZtCv4eTo2cDppF/DydGvN4dvXgNsgDHG3ybRVAFgcno2AMxPv94cvnkNAAAAAMB0/MFGAAAAAACmI7wGAAAAAGA6wmsAAAAAAKYjvIYzVNv3tj37GPv81VHG39L2ldtTGQBwiH4NAPPTr2H7nLXuAoDTq22z9cdar1h3LQDAkenXADA//Rq2n29ew4Zqe33ba1fWf77tf2p7W9s7297T9spl2wVtP9H25iT3Jjm/7afbPmvZ/httP9L2vrZ7D3ufNy7jt7XddYQ6nt/2A8vxv932nO29cgDYHPo1AMxPv4Z5Ca9hc70tyVUr61cluSnJ940xLkny0iT/ffkkOEkuTPIrY4znjjEePOxcPzzGeH6SPUl+ou0zl/GnJNk3xnhukg8kecPqQW2fmOR/Jnnlcvybk/ziKbtCANh8+jUAzE+/hkmZNgQ21Bjjj9o+u+2/SrIryWeTfCbJG9t+Z5J/SHJukt3LIQ+OMe44yul+ou33LcvnZ6sR/9lyjrct4/8vybsOO+4bk3xLkluXHv6EJPu/0msDgJ1CvwaA+enXMC/hNWy2dyR5ZZKvy1YTfHW2Gu3zxxh/1/bTSZ607Pv5I52g7UuSfFeSF44xHm/7/pVjDjcOPzzJfWOMF34F1wAAO51+DQDz069hQqYNgc32tiSvylaDfUeSpyU5sDTWlyZ5znGc42lJPrs01m9KcunKtn+xnDtJfjDJ7Ycd+4kku9q+MNl6zKntc0/6agBgZ9KvAWB++jVMSHgNG2yMcV+SpyZ5ZIyxP8lbk+xpe0+Sq5N8/DhO874kZ7W9P8n1SVYfffp8khe0vTfJv0vyC4e9/xey1Xz/a9uPJrkryXd8ZVcFADuLfg0A89OvYU4d4/CnFAAAAAAAYL188xoAAAAAgOkIrwEAAAAAmI7wGgAAAACA6QivAQAAAACYjvAaAAAAAIDpCK8BAAAAAJiO8BoAAAAAgOn8I1eFE/cpVcjMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1800x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sPIGmfTgaiEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras Model Parelle Conv2D"
      ],
      "metadata": {
        "id": "YP6SuhRkao27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import concatenate, Input\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Flatten, Dense, Activation\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "class CyclicLR(Callback):\n",
        "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
        "    The method cycles the learning rate between two boundaries with\n",
        "    some constant frequency.\n",
        "    # Arguments\n",
        "        base_lr: initial learning rate which is the\n",
        "            lower boundary in the cycle.\n",
        "        max_lr: upper boundary in the cycle. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore\n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size: number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch.\n",
        "        mode: one of {triangular, triangular2, exp_range}.\n",
        "            Default 'triangular'.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "        gamma: constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "        scale_fn: Custom scaling policy defined by a single\n",
        "            argument lambda function, where\n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored\n",
        "        scale_mode: {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on\n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle). Default is 'cycle'.\n",
        "    The amplitude of the cycle can be scaled on a per-iteration or\n",
        "    per-cycle basis.\n",
        "    This class has three built-in policies, as put forth in the paper.\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
        "        cycle iteration.\n",
        "    For more detail, please see paper.\n",
        "    # Example for CIFAR-10 w/ batch size 100:\n",
        "        ```python\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., mode='triangular')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "    Class also supports custom scaling functions:\n",
        "        ```python\n",
        "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., scale_fn=clr_fn,\n",
        "                                scale_mode='cycle')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "    # References\n",
        "      - [Cyclical Learning Rates for Training Neural Networks](\n",
        "      https://arxiv.org/abs/1506.01186)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            base_lr=0.001,\n",
        "            max_lr=0.006,\n",
        "            step_size=2000.,\n",
        "            mode='triangular',\n",
        "            gamma=1.,\n",
        "            scale_fn=None,\n",
        "            scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        if mode not in ['triangular', 'triangular2',\n",
        "                        'exp_range']:\n",
        "            raise KeyError(\"mode must be one of 'triangular', \"\n",
        "                            \"'triangular2', or 'exp_range'\")\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn is None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1 / (2.**(x - 1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma ** x\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "                new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr is not None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr is not None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size is not None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "\n",
        "    def clr(self):\n",
        "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr - self.base_lr) * \\\n",
        "                np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr - self.base_lr) * \\\n",
        "                np.maximum(0, (1 - x)) * self.scale_fn(self.clr_iterations)\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "        self.history.setdefault(\n",
        "            'lr', []).append(\n",
        "            K.get_value(\n",
        "                self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
      ],
      "metadata": {
        "id": "BFFvAg4varHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_2d = X_train.reshape(X_train.shape[0], \n",
        "                            X_train.shape[1], \n",
        "                            X_train.shape[2],\n",
        "                            1\n",
        "                            )\n",
        "X_val_2d = X_val.reshape(X_val.shape[0],\n",
        "                          X_val.shape[1], \n",
        "                          X_val.shape[2],\n",
        "                          1\n",
        "                          )\n",
        "X_test_2d = X_test.reshape(X_test.shape[0],\n",
        "                          X_test.shape[1], \n",
        "                          X_test.shape[2],\n",
        "                          1\n",
        "                          )\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_val = to_categorical(y_val, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "print(f'X Train Length {X_train_2d.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val_2d.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test_2d.shape}, y Test Label Length {y_test.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyMN3AS0a_78",
        "outputId": "8440d3cb-35ea-4566-f965-37b9de927702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4055, 5, 24, 1), y Train Label Length (4055, 3)\n",
            "X Val Length (1430, 5, 24, 1), y Val Label Length (1430, 3)\n",
            "X Test Length (1065, 5, 24, 1), y Test Label Length (1065, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create model\n",
        "\n",
        "def create_convnet(img_path='network_image.png'):\n",
        "    input_shape = Input(shape=(X_train_2d.shape[1],X_train_2d.shape[2],X_train_2d.shape[3]))\n",
        "\n",
        "    tower_1 = Convolution2D(filters=32, kernel_size=(1, 3), strides=(1, 1), padding='same', activation='relu')(input_shape)\n",
        "    tower_1 = MaxPooling2D(pool_size=(1, 3), strides=(1, 1), padding='same')(tower_1)\n",
        "    tower_1 = Dropout(0.5)(tower_1)\n",
        "\n",
        "    tower_2 = Convolution2D(filters=32, kernel_size=(1, 6), strides=(1, 1), padding='same', activation='relu')(input_shape)\n",
        "    tower_2 = MaxPooling2D(pool_size=(1, 1), strides=(1, 1), padding='same')(tower_2)\n",
        "    tower_2 = Dropout(0.5)(tower_2)\n",
        "\n",
        "    tower_3 = Convolution2D(filters=32, kernel_size=(1, 12), strides=(1, 1), padding='same', activation='relu')(input_shape)\n",
        "    tower_3 = MaxPooling2D(pool_size=(1, 1), strides=(1, 1), padding='same')(tower_3)\n",
        "    tower_3 = Dropout(0.5)(tower_3)\n",
        "\n",
        "    merged = concatenate([tower_1, tower_2, tower_3], axis=1)\n",
        "    merged = Flatten()(merged)\n",
        "\n",
        "    out = Dense(1000, activation='relu')(merged)\n",
        "    out = Dense(500, activation='relu')(out)\n",
        "    out = Dense(3, activation='softmax')(out)\n",
        "\n",
        "    model = Model(input_shape, out)\n",
        "    plot_model(model, to_file=img_path)\n",
        "    return model\n",
        "\n",
        "model = create_convnet(img_path='network_image.png')\n",
        "\n",
        "print(model.summary())\n",
        "plot_model(model, to_file=f'model_plot_{date}.png', show_shapes=True, show_layer_names=True, show_dtype=True, show_layer_activations=True)\n",
        "\n",
        "adam = Adam(learning_rate=0.001, decay=0.0001)\n",
        "nadam = Nadam(learning_rate=0.002, schedule_decay=0.004)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"]) \n",
        "\n",
        "batch_size = 12\n",
        "\n",
        "clr = CyclicLR()\n",
        "callback = EarlyStopping(monitor='loss', patience=5)\n",
        "hist = model.fit(X_train_2d, y_train, batch_size=batch_size, epochs=10, callbacks=[clr, callback], validation_data=(X_val_2d, y_val)) #, class_weight={0:1, 1:1.5, 2:1.5})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ggxSbEJbBzK",
        "outputId": "689b549a-f119-4fed-92bd-f031b8ea91c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 5, 24, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 5, 24, 32)    128         ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 5, 24, 32)    224         ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 5, 24, 32)    416         ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d_19 (MaxPooling2D  (None, 5, 24, 32)   0           ['conv2d_20[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_20 (MaxPooling2D  (None, 5, 24, 32)   0           ['conv2d_21[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_21 (MaxPooling2D  (None, 5, 24, 32)   0           ['conv2d_22[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 5, 24, 32)    0           ['max_pooling2d_19[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 5, 24, 32)    0           ['max_pooling2d_20[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 5, 24, 32)    0           ['max_pooling2d_21[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 15, 24, 32)   0           ['dropout_18[0][0]',             \n",
            "                                                                  'dropout_19[0][0]',             \n",
            "                                                                  'dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 11520)        0           ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 1000)         11521000    ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 500)          500500      ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 3)            1503        ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 12,023,771\n",
            "Trainable params: 12,023,771\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "332/338 [============================>.] - ETA: 0s - loss: 1.1306 - accuracy: 0.4566"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  \n",
        "  # model_name = f'cdt2d_model_{date}'\n",
        "  # model.save(f'models/{model_name}')\n",
        "\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(hist.history['loss'], label='train loss')\n",
        "  plt.plot(hist.history['val_loss'], label='val loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(f'plots/LossVal_loss_{date}.png')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(hist.history['accuracy'], label='train acc')\n",
        "  plt.plot(hist.history['val_accuracy'], label='val acc')\n",
        "  plt.legend()\n",
        "  plt.savefig(f'plots/AccVal_acc_{date}.png')\n",
        "  plt.show()\n",
        "  \n",
        "  y_pred = model.predict(X_test_2d)\n",
        "  \n",
        "  # Calculate the accuracy\n",
        "  test_preds = np.argmax(y_pred, axis=1)\n",
        "  y_true = np.argmax(y_test, axis=1)\n",
        "  test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "\n",
        "  # Recall for each class\n",
        "  recall_vals = []\n",
        "  for i in range(3):\n",
        "      class_idx = np.argwhere(y_true==i)\n",
        "      total = len(class_idx)\n",
        "      correct = np.sum(test_preds[class_idx]==i)\n",
        "      recall = correct / total\n",
        "      recall_vals.append(recall)\n",
        "\n",
        "  classes = [0,1,2]\n",
        "  # Calculate the test set accuracy and recall for each class\n",
        "  print('Test set accuracy is {:.3f}'.format(test_acc))\n",
        "  for i in range(3):\n",
        "      print('For class {}, recall is {:.3f}'.format(classes[i],recall_vals[i]))\n",
        "\n",
        "  print(\"Accuracy is {:.3f}\".format(test_acc))\n",
        "  # print(\"Weighted F score is {:.3f}\".format(calculate_weighted_f_score(y_true, y_pred)))\n",
        "  \n",
        "  def plot_confusion_matrix(cm,\n",
        "                            target_names,\n",
        "                            title='Confusion matrix',\n",
        "                            cmap=None,\n",
        "                            normalize=True):\n",
        "      \"\"\"\n",
        "      given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "      Arguments\n",
        "      ---------\n",
        "      cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "      target_names: given classification classes such as [0, 1, 2]\n",
        "                    the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "      title:        the text to display at the top of the matrix\n",
        "\n",
        "      cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                    see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                    plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "      normalize:    If False, plot the raw numbers\n",
        "                    If True, plot the proportions\n",
        "\n",
        "      Usage\n",
        "      -----\n",
        "      plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                                # sklearn.metrics.confusion_matrix\n",
        "                            normalize    = True,                # show proportions\n",
        "                            target_names = y_labels_vals,       # list of names of the classes\n",
        "                            title        = best_estimator_name) # title of graph\n",
        "\n",
        "      Citiation\n",
        "      ---------\n",
        "      http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "      import itertools\n",
        "\n",
        "      accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "      misclass = 1 - accuracy\n",
        "\n",
        "      if cmap is None:\n",
        "          cmap = plt.get_cmap('Blues')\n",
        "\n",
        "      plt.figure(figsize=(8, 6))\n",
        "      plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "      plt.title(title)\n",
        "      plt.colorbar()\n",
        "\n",
        "      if target_names is not None:\n",
        "          tick_marks = np.arange(len(target_names))\n",
        "          plt.xticks(tick_marks, target_names, rotation=45)\n",
        "          plt.yticks(tick_marks, target_names)\n",
        "\n",
        "      if normalize:\n",
        "          cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "      thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "      for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "          if normalize:\n",
        "              plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                        horizontalalignment=\"center\",\n",
        "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "          else:\n",
        "              plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                        horizontalalignment=\"center\",\n",
        "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.ylabel('True label')\n",
        "      plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "      plt.savefig(f'plots/Confusion_{date}.png')\n",
        "      plt.show()\n",
        "\n",
        "  def calculate_weighted_f_score(y_true, y_pred):\n",
        "      test_preds = np.argmax(y_pred, axis=-1)\n",
        "      Ntu = sum((test_preds == 2) & (y_true == 2))\n",
        "      Ntd = sum((test_preds == 1) & (y_true == 1))\n",
        "      Ntf = sum((test_preds == 0) & (y_true == 0))\n",
        "      Ewutd = sum((test_preds == 2) & (y_true == 1))\n",
        "      Ewdtu = sum((test_preds == 1) & (y_true == 2))\n",
        "      Ewutf = sum((test_preds == 2) & (y_true == 0))\n",
        "      Ewdtf = sum((test_preds == 1) & (y_true == 0))\n",
        "      Ewftu = sum((test_preds == 0) & (y_true == 2))\n",
        "      Ewftd = sum((test_preds == 0) & (y_true == 1))\n",
        "\n",
        "      beta_1 = 0.5\n",
        "      beta_2 = 0.125\n",
        "      beta_3 = 0.125\n",
        "\n",
        "      Ntp = Ntu + Ntd + beta_3**2 * Ntf\n",
        "      E1 = Ewutd + Ewdtu\n",
        "      E2 = Ewutf + Ewdtf\n",
        "      E3 = Ewftu + Ewftd\n",
        "\n",
        "      F = (1 + beta_1**2 + beta_2**2) * Ntp / ((1+beta_1**2+beta_2**2) * Ntp + E1 + beta_1**2 * E2 + beta_2**2 * E3)\n",
        "      return  F\n",
        "\n",
        " \n",
        "  print(f'Weight CDT F Score: {calculate_weighted_f_score(y_true, y_pred)}')\n",
        "  \n",
        "  nb_classes = 3\n",
        "\n",
        "  # Confusion matrix\n",
        "  conf_mat=confusion_matrix(y_true, np.argmax(y_pred, axis=-1))\n",
        "  \n",
        "  plot_confusion_matrix(conf_mat, [\"flat\",\"down\",\"up\"])\n",
        "\n",
        "  precision_score(y_true, np.argmax(y_pred, axis=-1), average='weighted')\n",
        "  \n",
        "  print(classification_report(y_true, np.argmax(y_pred, axis=-1), target_names=[\"flat\",\"down\", \"up\"], digits=4))"
      ],
      "metadata": {
        "id": "WL81xLUDa6mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V3ARLrnGarS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xsf-zToLarWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MPZ_wt4UaraU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keras Model Conv2D"
      ],
      "metadata": {
        "id": "L5x9jWH_L6nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Flatten, Dense, Activation\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n"
      ],
      "metadata": {
        "id": "26CyV_XvOgVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### ONLY EXECUTE FOR KERAS 2D CNN #####\n",
        "\n",
        "X_train_2d = X_train.reshape(X_train.shape[0], \n",
        "                          X_train.shape[1], \n",
        "                          X_train.shape[2],\n",
        "                          1\n",
        "                          )\n",
        "X_val_2d = X_val.reshape(X_val.shape[0],\n",
        "                          X_val.shape[1], \n",
        "                          X_val.shape[2],\n",
        "                          1\n",
        "                          )\n",
        "X_test_2d = X_test.reshape(X_test.shape[0],\n",
        "                          X_test.shape[1], \n",
        "                          X_test.shape[2],\n",
        "                          1\n",
        "                          )"
      ],
      "metadata": {
        "id": "Hc2wmJbsL-lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_val = to_categorical(y_val, 3)\n",
        "y_test = to_categorical(y_test, 3)"
      ],
      "metadata": {
        "id": "DCG85tZ1L-xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X Train Length {X_train_2d.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val_2d.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test_2d.shape}, y Test Label Length {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeoTjcx5L-s5",
        "outputId": "1909e0ab-736a-48a2-f4b8-9bb98827519c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4055, 5, 24, 1), y Train Label Length (4055, 3)\n",
            "X Val Length (1430, 5, 24, 1), y Val Label Length (1430, 3)\n",
            "X Test Length (1040, 5, 24, 1), y Test Label Length (1040, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_format='channels_first'\n",
        "#Create model\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(filters=32, kernel_size=(1, 4), padding='same', activation='relu', input_shape=(X_train_2d.shape[1],X_train_2d.shape[2],X_train_2d.shape[3])))\n",
        "model.add(MaxPooling2D(pool_size=(1,4), strides=(1, 4), padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Convolution2D(filters=64, kernel_size=(1,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1,3), strides=(1, 3), padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Convolution2D(filters=128, kernel_size=(1,2), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dense(500,activation=\"relu\"))\n",
        "model.add(Dense(3,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-fjU2wxL-1j",
        "outputId": "3842b9ce-98ae-481d-e835-337aa647da07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 5, 24, 32)         160       \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 5, 6, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 5, 6, 32)          0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 5, 6, 64)          6208      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 5, 2, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 5, 2, 64)          0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 5, 2, 128)         16512     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 5, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 5, 1, 128)         0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 640)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1000)              641000    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 3)                 1503      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,165,883\n",
            "Trainable params: 1,165,883\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001, decay=0.0001)\n",
        "nadam = Nadam(learning_rate=0.002, schedule_decay=0.004)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"]) "
      ],
      "metadata": {
        "id": "I7rjbRGgQqKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 12\n",
        "hist = model.fit(X_train_2d, y_train, batch_size=batch_size, epochs=350, validation_data=(X_val_2d, y_val)) #, class_weight={0:1, 1:1.5})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3d2512-b612-4080-bb81-107e458dfa5e",
        "id": "nKnSxLyGQqKm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/350\n",
            "338/338 [==============================] - 9s 21ms/step - loss: 1.1181 - accuracy: 0.3988 - val_loss: 1.0789 - val_accuracy: 0.4210\n",
            "Epoch 2/350\n",
            "338/338 [==============================] - 7s 20ms/step - loss: 1.0796 - accuracy: 0.4197 - val_loss: 1.0738 - val_accuracy: 0.4189\n",
            "Epoch 3/350\n",
            "338/338 [==============================] - 7s 20ms/step - loss: 1.0775 - accuracy: 0.4229 - val_loss: 1.0732 - val_accuracy: 0.4182\n",
            "Epoch 4/350\n",
            "338/338 [==============================] - 7s 21ms/step - loss: 1.0739 - accuracy: 0.4266 - val_loss: 1.0721 - val_accuracy: 0.4189\n",
            "Epoch 5/350\n",
            "338/338 [==============================] - 8s 25ms/step - loss: 1.0715 - accuracy: 0.4252 - val_loss: 1.0666 - val_accuracy: 0.4175\n",
            "Epoch 6/350\n",
            "338/338 [==============================] - 7s 21ms/step - loss: 1.0744 - accuracy: 0.4192 - val_loss: 1.0659 - val_accuracy: 0.4203\n",
            "Epoch 7/350\n",
            " 39/338 [==>...........................] - ETA: 5s - loss: 1.0857 - accuracy: 0.4060"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['loss'], label='train loss')\n",
        "plt.plot(hist.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')"
      ],
      "metadata": {
        "id": "HaiFRJBaRXAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'], label='train acc')\n",
        "plt.plot(hist.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "metadata": {
        "id": "2S1lgtOARXAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_2d)"
      ],
      "metadata": {
        "id": "ylr2HaMKRXAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "FkTepZ32Ui5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy\n",
        "test_preds = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "\n",
        "# Recall for each class\n",
        "recall_vals = []\n",
        "for i in range(3):\n",
        "    class_idx = np.argwhere(y_true==i)\n",
        "    total = len(class_idx)\n",
        "    correct = np.sum(test_preds[class_idx]==i)\n",
        "    recall = correct / total\n",
        "    recall_vals.append(recall)\n",
        "\n",
        "classes = [0,1,2]\n",
        "# Calculate the test set accuracy and recall for each class\n",
        "print('Test set accuracy is {:.3f}'.format(test_acc))\n",
        "for i in range(3):\n",
        "    print('For class {}, recall is {:.3f}'.format(classes[i],recall_vals[i]))\n",
        "\n",
        "print(\"Accuracy is {:.3f}\".format(test_acc))\n",
        "# print(\"Weighted F score is {:.3f}\".format(calculate_weighted_f_score(y_true, y_pred)))"
      ],
      "metadata": {
        "id": "84_JU0KURXAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "nb_classes = 3\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat=confusion_matrix(y_true, np.argmax(y_pred, axis=-1))\n",
        "plot_confusion_matrix(conf_mat, [\"flat\",\"down\",\"up\"])\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_score(y_true, np.argmax(y_pred, axis=-1), average='weighted')\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true, np.argmax(y_pred, axis=-1), target_names=[\"flat\",\"down\", \"up\"], digits=4))"
      ],
      "metadata": {
        "id": "3SjFsSeFRXAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_weighted_f_score(y_true, y_pred):\n",
        "  test_preds = np.argmax(y_pred, axis=-1)\n",
        "  Ntu = sum((test_preds == 2) & (y_true == 2))\n",
        "  Ntd = sum((test_preds == 1) & (y_true == 1))\n",
        "  Ntf = sum((test_preds == 0) & (y_true == 0))\n",
        "  Ewutd = sum((test_preds == 2) & (y_true == 1))\n",
        "  Ewdtu = sum((test_preds == 1) & (y_true == 2))\n",
        "  Ewutf = sum((test_preds == 2) & (y_true == 0))\n",
        "  Ewdtf = sum((test_preds == 1) & (y_true == 0))\n",
        "  Ewftu = sum((test_preds == 0) & (y_true == 2))\n",
        "  Ewftd = sum((test_preds == 0) & (y_true == 1))\n",
        "\n",
        "  beta_1 = 0.5\n",
        "  beta_2 = 0.125\n",
        "  beta_3 = 0.125\n",
        "\n",
        "  Ntp = Ntu + Ntd + beta_3**2 * Ntf\n",
        "  E1 = Ewutd + Ewdtu\n",
        "  E2 = Ewutf + Ewdtf\n",
        "  E3 = Ewftu + Ewftd\n",
        "\n",
        "  F = (1 + beta_1**2 + beta_2**2) * Ntp / ((1+beta_1**2+beta_2**2) * Ntp + E1 + beta_1**2 * E2 + beta_2**2 * E3)\n",
        "  return  F\n",
        "\n",
        "print(f'Weight CDT F Score: {calculate_weighted_f_score(y_true, y_pred)}')"
      ],
      "metadata": {
        "id": "AIqC-zeNRXAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Model Conv2D"
      ],
      "metadata": {
        "id": "aXbU1Pz7oKam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### ONLY EXECUTE FOR PYTORCH 2D CNN #####\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], \n",
        "                          1,\n",
        "                          X_train.shape[1], \n",
        "                          X_train.shape[2]\n",
        "                          )\n",
        "X_val = X_val.reshape(X_val.shape[0],\n",
        "                          1,\n",
        "                          X_val.shape[1], \n",
        "                          X_val.shape[2],\n",
        "                          )\n",
        "X_test = X_test.reshape(X_test.shape[0],\n",
        "                          1,\n",
        "                          X_test.shape[1], \n",
        "                          X_test.shape[2],\n",
        "                          )"
      ],
      "metadata": {
        "id": "tdeD0Rsc4rqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X Train Length {X_train.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test.shape}, y Test Label Length {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLv4oER44svp",
        "outputId": "b2341834-1a59-4136-84de-75bea8879181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4060, 1, 5, 24), y Train Label Length (4060,)\n",
            "X Val Length (1435, 1, 5, 24), y Val Label Length (1435,)\n",
            "X Test Length (1040, 1, 5, 24), y Test Label Length (1040,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = TensorDataset(torch.from_numpy(X_train).float(), \n",
        "                         torch.from_numpy(y_train).long())\n",
        "testset = TensorDataset(torch.from_numpy(X_test).float(), \n",
        "                        torch.from_numpy(y_test).long())"
      ],
      "metadata": {
        "id": "_ncbTnJ4oPhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(trainset, shuffle=False)\n",
        "i1, l1 = next(iter(train_loader))\n",
        "print(i1.shape)\n",
        "\n",
        "# val_data = []\n",
        "# for i in range(len(X_val)):\n",
        "#    val_data.append([X_val[i].astype('float'), y_val[i]])\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(testset, shuffle=False)\n",
        "i1, l1 = next(iter(val_loader))\n",
        "print(i1.shape)"
      ],
      "metadata": {
        "id": "TQl5pGL7opIj",
        "outputId": "7c2b101d-c683-4272-8316-08861205e201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 5, 24])\n",
            "torch.Size([1, 1, 5, 24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get next batch of training images\n",
        "windows, labels = iter(train_loader).next()\n",
        "print(windows.shape)\n",
        "windows = windows.numpy()\n",
        "batch_size = 12\n",
        "# plot the windows in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "for idx in range(batch_size):\n",
        "    print(labels)"
      ],
      "metadata": {
        "id": "WOiXPp7popOT",
        "outputId": "a3310111-1bb1-4154-c9f4-105f116ef214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 5, 24])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n",
            "tensor([0])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up dict for dataloaders\n",
        "dataloaders = {'train':train_loader,'val':val_loader}\n",
        "# Store size of training and validation sets\n",
        "dataset_sizes = {'train':len(train_loader),'val':len(val_loader)}\n",
        "# Get class names associated with labels\n",
        "classes = [0,1,2]"
      ],
      "metadata": {
        "id": "96KWdOCcKgtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockShiftClassification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(StockShiftClassification, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool1 = nn.MaxPool2d((1,4),4)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool2 = nn.MaxPool2d((1,3),3)  \n",
        "\n",
        "    self.conv3 = nn.Conv2d(64, 128, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool3 = nn.MaxPool2d((1,2),2)\n",
        "\n",
        "    self.fc1 = nn.Linear(256,1000) #calculate this\n",
        "    self.fc2 = nn.Linear(1000,500)\n",
        "    self.fc3 = nn.Linear(500,3)\n",
        "\n",
        "    self.drop = nn.Dropout(p=0.7)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    x = self.drop(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool2(x)\n",
        "    x = self.drop(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.pool3(x)\n",
        "    x = self.drop(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    # Linear layer\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    output = x #F.log_softmax(x, dim=1)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "1hHxQyq1opQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "net = StockShiftClassification().float()\n",
        "\n",
        "# Display a summary of the layers of the model and output shape after each layer\n",
        "summary(net,(windows.shape[1:]),batch_size=batch_size,device=\"cpu\")"
      ],
      "metadata": {
        "id": "_QVWUvZ2opU6",
        "outputId": "b4c6acd2-1011-41f0-9ae0-9a001fd9a66c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [12, 32, 7, 24]             128\n",
            "         MaxPool2d-2             [12, 32, 2, 6]               0\n",
            "           Dropout-3             [12, 32, 2, 6]               0\n",
            "            Conv2d-4             [12, 64, 4, 6]           6,208\n",
            "         MaxPool2d-5             [12, 64, 2, 2]               0\n",
            "           Dropout-6             [12, 64, 2, 2]               0\n",
            "            Conv2d-7            [12, 128, 4, 2]          24,704\n",
            "         MaxPool2d-8            [12, 128, 2, 1]               0\n",
            "           Dropout-9            [12, 128, 2, 1]               0\n",
            "           Linear-10                 [12, 1000]         257,000\n",
            "           Linear-11                  [12, 500]         500,500\n",
            "           Linear-12                    [12, 3]           1,503\n",
            "================================================================\n",
            "Total params: 790,043\n",
            "Trainable params: 790,043\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.03\n",
            "Params size (MB): 3.01\n",
            "Estimated Total Size (MB): 4.05\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = torch.from_numpy(X_train).float()\n",
        "train_y = torch.from_numpy(y_train).long()\n",
        "val_x = torch.from_numpy(X_val).float()\n",
        "val_y = torch.from_numpy(y_val).long()"
      ],
      "metadata": {
        "id": "Mg6bEz7orEsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, train_loaders, device, num_epochs=50, scheduler):\n",
        "\n",
        "    model = model.to(device) # Send model to GPU if available\n",
        "\n",
        "    writer = SummaryWriter() # Instantiate TensorBoard\n",
        "\n",
        "    iter_num = {'train':0,'val':0} # Track total number of iterations\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Get the input images and labels, and send to GPU if available\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the weight gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass to get outputs and calculate loss\n",
        "                # Track gradient only for training data\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    # print(outputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backpropagation to get the gradients with respect to each weight\n",
        "                    # Only if in train\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        # Update the weights\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Convert loss into a scalar and add it to running_loss\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                # Track number of correct predictions\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                # Iterate count of iterations\n",
        "                iter_num[phase] += 1\n",
        "\n",
        "                # Write loss for batch to TensorBoard\n",
        "                writer.add_scalar(\"{} / batch loss\".format(phase), loss.item(), iter_num[phase])\n",
        "\n",
        "                # scheduler.step()\n",
        "\n",
        "            # Calculate and display average loss and accuracy for the epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # Write loss and accuracy for epoch to TensorBoard\n",
        "            writer.add_scalar(\"{} / epoch loss\".format(phase), epoch_loss, epoch)\n",
        "            writer.add_scalar(\"{} / epoch accuracy\".format(phase), epoch_acc, epoch)\n",
        "\n",
        "    writer.close()\n",
        "    \n",
        "    return"
      ],
      "metadata": {
        "id": "7-A3kueTqlai",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "2116a4d3-c02a-40f9-86f4-3cacf96241e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-6a0f5bcddbc5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def train_model(model, criterion, optimizer, train_loaders, device, num_epochs=50, scheduler):\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Cross entropy loss combines softmax and nn.NLLLoss() in one single class.\n",
        "weights = torch.tensor([1.5, 2.25, 1.]).to(device)\n",
        "criterion_weighted = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.00001)\n",
        "\n",
        "\n",
        "n_epochs= 500 # For demo purposes.  Use epochs>100 for actual training\n",
        "\n",
        "onecycle_scheduler = optim.lr_scheduler.OneCycleLR(optimizer,\n",
        "                                        max_lr=0.01,\n",
        "                                        base_momentum = 0.8,\n",
        "                                        steps_per_epoch=len(train_loader),\n",
        "                                        epochs=n_epochs)\n",
        "\n",
        "\n",
        "train_model(net, criterion, optimizer, dataloaders, device, num_epochs=n_epochs, scheduler=onecycle_scheduler)"
      ],
      "metadata": {
        "id": "cnrwBuUoqljR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "ff304399-4c0b-4c5f-b30f-9f2f1eddbec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-262565c34f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monecycle_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train_model() got an unexpected keyword argument 'scheduler'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KERAS 1D Model"
      ],
      "metadata": {
        "id": "qtbdKWSK7l7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_val = to_categorical(y_val, 3)\n",
        "y_test = to_categorical(y_test, 3)\n"
      ],
      "metadata": {
        "id": "lNIh0H7JVnF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X Train Length {X_train.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test.shape}, y Test Label Length {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2cc2486-914a-4084-d04e-80ea556ea146",
        "id": "xUtWCihJoI1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4060, 5, 24), y Train Label Length (4060, 3)\n",
            "X Val Length (1435, 5, 24), y Val Label Length (1435, 3)\n",
            "X Test Length (1040, 5, 24), y Test Label Length (1040, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam, Nadam"
      ],
      "metadata": {
        "id": "MUE5rS-l7z9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=4, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dense(500,activation=\"relu\"))\n",
        "model.add(Dense(3,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYwZW6eJ2HBu",
        "outputId": "0aae7496-e12d-4f1a-f760-59840802643d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (None, 5, 32)             2336      \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 2, 32)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 2, 32)             0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 2, 64)             6208      \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 1, 64)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 1, 64)             0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 1, 128)            24704     \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 1, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 1, 128)            0         \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1000)              129000    \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 3)                 1503      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664,251\n",
            "Trainable params: 664,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001, decay=0.0001)\n",
        "nadam = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
        "\n",
        "def custom_loss_function(y_true, y_pred):\n",
        "   squared_difference = tf.square(y_true - y_pred)\n",
        "   return tf.reduce_mean(squared_difference, axis=-1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"]) "
      ],
      "metadata": {
        "id": "SOmAeEzs2HGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 12\n",
        "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=350, validation_data=(X_val, y_val)) #, class_weight={0:1, 1:1.5})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ux9JsTrE2HJz",
        "outputId": "f5f69606-1105-44bd-de38-d792e7710063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/350\n",
            "335/339 [============================>.] - ETA: 0s - loss: 0.9849 - accuracy: 0.5032"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-da5fffad1253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, class_weight={0:1, 1:1.5})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['loss'], label='train loss')\n",
        "plt.plot(hist.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')"
      ],
      "metadata": {
        "id": "CMsqd9n02HMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'], label='train acc')\n",
        "plt.plot(hist.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "metadata": {
        "id": "M_S_jaA_2ubl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Gct8IuVa25GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy\n",
        "test_preds = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "\n",
        "# Recall for each class\n",
        "recall_vals = []\n",
        "for i in range(3):\n",
        "    class_idx = np.argwhere(y_true==i)\n",
        "    total = len(class_idx)\n",
        "    correct = np.sum(test_preds[class_idx]==i)\n",
        "    recall = correct / total\n",
        "    recall_vals.append(recall)\n",
        "\n",
        "classes = [0,1,2]\n",
        "# Calculate the test set accuracy and recall for each class\n",
        "print('Test set accuracy is {:.3f}'.format(test_acc))\n",
        "for i in range(3):\n",
        "    print('For class {}, recall is {:.3f}'.format(classes[i],recall_vals[i]))\n",
        "\n",
        "print(\"Accuracy is {:.3f}\".format(test_acc))\n",
        "# print(\"Weighted F score is {:.3f}\".format(calculate_weighted_f_score(y_true, y_pred)))"
      ],
      "metadata": {
        "id": "rk2qkycw25Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "nb_classes = 2\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat=confusion_matrix(y_true, np.argmax(y_pred, axis=-1))\n",
        "plot_confusion_matrix(conf_mat, [0,1,2])\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_score(y_true, np.argmax(y_pred, axis=-1), average='weighted')\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true, np.argmax(y_pred, axis=-1), target_names=[\"flat\",\"down\", \"up\"], digits=4))"
      ],
      "metadata": {
        "id": "coQSJfRo2uoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_weighted_f_score(y_true, y_pred):\n",
        "  test_preds = np.argmax(y_pred, axis=-1)\n",
        "  Ntu = sum((test_preds == 2) & (y_true == 2))\n",
        "  Ntd = sum((test_preds == 1) & (y_true == 1))\n",
        "  Ntf = sum((test_preds == 0) & (y_true == 0))\n",
        "  Ewutd = sum((test_preds == 2) & (y_true == 1))\n",
        "  Ewdtu = sum((test_preds == 1) & (y_true == 2))\n",
        "  Ewutf = sum((test_preds == 2) & (y_true == 0))\n",
        "  Ewdtf = sum((test_preds == 1) & (y_true == 0))\n",
        "  Ewftu = sum((test_preds == 0) & (y_true == 2))\n",
        "  Ewftd = sum((test_preds == 0) & (y_true == 1))\n",
        "\n",
        "  beta_1 = 0.5\n",
        "  beta_2 = 0.125\n",
        "  beta_3 = 0.125\n",
        "\n",
        "  Ntp = Ntu + Ntd + beta_3**2 * Ntf\n",
        "  E1 = Ewutd + Ewdtu\n",
        "  E2 = Ewutf + Ewdtf\n",
        "  E3 = Ewftu + Ewftd\n",
        "\n",
        "  F = (1 + beta_1**2 + beta_2**2) * Ntp / ((1+beta_1**2+beta_2**2) * Ntp + E1 + beta_1**2 * E2 + beta_2**2 * E3)\n",
        "  return  F\n",
        "\n",
        "print(f'Weight CDT F Score: {calculate_weighted_f_score(y_true, y_pred)}')"
      ],
      "metadata": {
        "id": "F7n6lPZp2uvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7v0QHbxx2uyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_weighted_f_score(y_true, y_pred):\n",
        "  test_preds = np.argmax(y_pred, axis=1)\n",
        "  Ntu = sum((test_preds == 1) & (y_true == 1))\n",
        "  Ntd = sum((test_preds == 0) & (y_true == 0))\n",
        "  Ntf = sum((test_preds == 2) & (y_true == 2))\n",
        "  Ewutd = sum((test_preds == 1) & (y_true == 0))\n",
        "  Ewdtu = sum((test_preds == 0) & (y_true == 1))\n",
        "  Ewutf = sum((test_preds == 1) & (y_true == 2))\n",
        "  Ewdtf = sum((test_preds == 0) & (y_true == 2))\n",
        "  Ewftu = sum((test_preds == 2) & (y_true == 1))\n",
        "  Ewftd = sum((test_preds == 2) & (y_true == 0))\n",
        "\n",
        "  beta_1 = 0.5\n",
        "  beta_2 = 0.125\n",
        "  beta_3 = 0.125\n",
        "\n",
        "  Ntp = Ntu + Ntd + beta_3**2 * Ntf\n",
        "  E1 = Ewutd + Ewdtu\n",
        "  E2 = Ewutf + Ewdtf\n",
        "  E3 = Ewftu + Ewftd\n",
        "\n",
        "  F = (1 + beta_1**2 + beta_2**2) * Ntp / ((1+beta_1**2+beta_2**2) * Ntp + E1 + beta_1**2 * E2 + beta_2**2 * E3)\n",
        "  return F"
      ],
      "metadata": {
        "id": "Z9EfhZEA70xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape[1],X_train.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ytUuvub8xcJ",
        "outputId": "d7408444-1252-4153-95d4-1d7e14e813f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=4, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3, strides=2, padding='same'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dense(500,activation=\"relu\"))\n",
        "model.add(Dense(2,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q50kVGG076-F",
        "outputId": "99b837fa-103d-4eee-dc58-98a42a0fdee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_18 (Conv1D)          (None, 5, 32)             2336      \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 2, 32)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 2, 32)             0         \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 2, 64)             6208      \n",
            "                                                                 \n",
            " max_pooling1d_19 (MaxPoolin  (None, 1, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 1, 64)             0         \n",
            "                                                                 \n",
            " conv1d_20 (Conv1D)          (None, 1, 128)            24704     \n",
            "                                                                 \n",
            " max_pooling1d_20 (MaxPoolin  (None, 1, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 1, 128)            0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1000)              129000    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 2)                 1002      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 663,750\n",
            "Trainable params: 663,750\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001, decay=0.0001)\n",
        "nadam = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
        "\n",
        "def custom_loss_function(y_true, y_pred):\n",
        "   squared_difference = tf.square(y_true - y_pred)\n",
        "   return tf.reduce_mean(squared_difference, axis=-1)\n",
        "\n",
        "def calculate_weighted_f_score(y_true, y_pred):\n",
        "  test_preds = np.argmax(y_pred, axis=-1)\n",
        "  print(test_preds)\n",
        "  Ntu = sum((test_preds == 1) & (y_true == 1))\n",
        "  Ntd = sum((test_preds == 0) & (y_true == 0))\n",
        "  Ntf = sum((test_preds == 2) & (y_true == 2))\n",
        "  Ewutd = sum((test_preds == 1) & (y_true == 0))\n",
        "  Ewdtu = sum((test_preds == 0) & (y_true == 1))\n",
        "  Ewutf = sum((test_preds == 1) & (y_true == 2))\n",
        "  Ewdtf = sum((test_preds == 0) & (y_true == 2))\n",
        "  Ewftu = sum((test_preds == 2) & (y_true == 1))\n",
        "  Ewftd = sum((test_preds == 2) & (y_true == 0))\n",
        "\n",
        "  beta_1 = 0.5\n",
        "  beta_2 = 0.125\n",
        "  beta_3 = 0.125\n",
        "\n",
        "  Ntp = Ntu + Ntd + beta_3**2 * Ntf\n",
        "  E1 = Ewutd + Ewdtu\n",
        "  E2 = Ewutf + Ewdtf\n",
        "  E3 = Ewftu + Ewftd\n",
        "\n",
        "  F = (1 + beta_1**2 + beta_2**2) * Ntp / ((1+beta_1**2+beta_2**2) * Ntp + E1 + beta_1**2 * E2 + beta_2**2 * E3)\n",
        "  return  F\n",
        "\n",
        "prec = tf.keras.metrics.Precision()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[prec]) "
      ],
      "metadata": {
        "id": "vKDmE-h59Lv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 12\n",
        "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, validation_data=(X_val, y_val)) #, class_weight={0:2, 1:3, 2:1})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK4V5UIa9ORe",
        "outputId": "8b6e9317-44ba-438e-aab9-e9ed3113f482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 3s 6ms/step - loss: 0.6739 - precision_7: 0.6014 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6746 - precision_7: 0.6019 - val_loss: 0.6747 - val_precision_7: 0.6007\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6734 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6727 - precision_7: 0.6019 - val_loss: 0.6751 - val_precision_7: 0.6007\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6733 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6730 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 7/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6728 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6737 - val_precision_7: 0.6007\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6728 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6729 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 11/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6732 - precision_7: 0.6019 - val_loss: 0.6734 - val_precision_7: 0.6007\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6730 - val_precision_7: 0.6007\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6730 - val_precision_7: 0.6007\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6728 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 19/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6017 - val_loss: 0.6731 - val_precision_7: 0.6007\n",
            "Epoch 20/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6730 - val_precision_7: 0.6007\n",
            "Epoch 21/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6727 - precision_7: 0.6019 - val_loss: 0.6730 - val_precision_7: 0.6007\n",
            "Epoch 22/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6727 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 23/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 24/50\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 25/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6730 - val_precision_7: 0.6007\n",
            "Epoch 26/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 27/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6726 - precision_7: 0.6019 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 28/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 29/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 30/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 31/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 32/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6723 - precision_7: 0.6019 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 33/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6026 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 34/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6017 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 35/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6019 - val_loss: 0.6729 - val_precision_7: 0.6007\n",
            "Epoch 36/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 37/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6727 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 38/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 39/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 40/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 41/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 42/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 43/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 44/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6019 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 45/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6727 - precision_7: 0.6014 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 46/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6722 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 47/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6017 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 48/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6725 - precision_7: 0.6019 - val_loss: 0.6728 - val_precision_7: 0.6007\n",
            "Epoch 49/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6017 - val_loss: 0.6727 - val_precision_7: 0.6007\n",
            "Epoch 50/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6724 - precision_7: 0.6009 - val_loss: 0.6738 - val_precision_7: 0.6007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj9-LfyGhwZz",
        "outputId": "b3e8eb0b-0d48-4d9b-91af-3f1dc7360708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.6739199161529541,\n",
              "  0.6745873689651489,\n",
              "  0.673353374004364,\n",
              "  0.6727477312088013,\n",
              "  0.6732865571975708,\n",
              "  0.6729598045349121,\n",
              "  0.6728412508964539,\n",
              "  0.6726021766662598,\n",
              "  0.6728477478027344,\n",
              "  0.6728655695915222,\n",
              "  0.6732037663459778,\n",
              "  0.6726383566856384,\n",
              "  0.6725048422813416,\n",
              "  0.6726340055465698,\n",
              "  0.6724653244018555,\n",
              "  0.6726179718971252,\n",
              "  0.6727598905563354,\n",
              "  0.6725648641586304,\n",
              "  0.6725471615791321,\n",
              "  0.6725770235061646,\n",
              "  0.6726747155189514,\n",
              "  0.6726670861244202,\n",
              "  0.6725931167602539,\n",
              "  0.6725555658340454,\n",
              "  0.6725409030914307,\n",
              "  0.6725565195083618,\n",
              "  0.6725572943687439,\n",
              "  0.6725035905838013,\n",
              "  0.6724714040756226,\n",
              "  0.6725125908851624,\n",
              "  0.672520101070404,\n",
              "  0.6723334193229675,\n",
              "  0.6723588705062866,\n",
              "  0.6725103259086609,\n",
              "  0.6724315285682678,\n",
              "  0.6723941564559937,\n",
              "  0.672657310962677,\n",
              "  0.6724977493286133,\n",
              "  0.6724774241447449,\n",
              "  0.6724062561988831,\n",
              "  0.6724578142166138,\n",
              "  0.6725069880485535,\n",
              "  0.6724458336830139,\n",
              "  0.672408938407898,\n",
              "  0.672699511051178,\n",
              "  0.6722479462623596,\n",
              "  0.6723613739013672,\n",
              "  0.6724828481674194,\n",
              "  0.6723563075065613,\n",
              "  0.672439694404602],\n",
              " 'precision_7': [0.6014217734336853,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6016587615013123,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6026066541671753,\n",
              "  0.6016587615013123,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6018957495689392,\n",
              "  0.6014217734336853,\n",
              "  0.6018957495689392,\n",
              "  0.6016587615013123,\n",
              "  0.6018957495689392,\n",
              "  0.6016587615013123,\n",
              "  0.6009478569030762],\n",
              " 'val_loss': [0.6729004979133606,\n",
              "  0.6747092604637146,\n",
              "  0.6727417707443237,\n",
              "  0.6751312613487244,\n",
              "  0.6727463006973267,\n",
              "  0.672755241394043,\n",
              "  0.6727584600448608,\n",
              "  0.6737393736839294,\n",
              "  0.6728079319000244,\n",
              "  0.6728230714797974,\n",
              "  0.6733888387680054,\n",
              "  0.6727582812309265,\n",
              "  0.6729012131690979,\n",
              "  0.672968327999115,\n",
              "  0.6730093359947205,\n",
              "  0.6727268695831299,\n",
              "  0.6727235913276672,\n",
              "  0.672727644443512,\n",
              "  0.6730960011482239,\n",
              "  0.6729731559753418,\n",
              "  0.6729639172554016,\n",
              "  0.6727637052536011,\n",
              "  0.6727550029754639,\n",
              "  0.6728544235229492,\n",
              "  0.6729679107666016,\n",
              "  0.6727513670921326,\n",
              "  0.6728929877281189,\n",
              "  0.6727278828620911,\n",
              "  0.672716498374939,\n",
              "  0.672760546207428,\n",
              "  0.6728389263153076,\n",
              "  0.6729355454444885,\n",
              "  0.6727286577224731,\n",
              "  0.6727634072303772,\n",
              "  0.6728515028953552,\n",
              "  0.67275470495224,\n",
              "  0.6727381944656372,\n",
              "  0.6727297306060791,\n",
              "  0.6727380156517029,\n",
              "  0.672787606716156,\n",
              "  0.6727962493896484,\n",
              "  0.6727461218833923,\n",
              "  0.6727689504623413,\n",
              "  0.6727339029312134,\n",
              "  0.6727678775787354,\n",
              "  0.6728211045265198,\n",
              "  0.6727349162101746,\n",
              "  0.6727569699287415,\n",
              "  0.6727298498153687,\n",
              "  0.6737827062606812],\n",
              " 'val_precision_7': [0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628,\n",
              "  0.6006993055343628]}"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['loss'], label='train loss')\n",
        "plt.plot(hist.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "PP75W71D9ij8",
        "outputId": "93ecd498-1356-42bf-bd10-6db42c5d3c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['precision_7'], label='train acc')\n",
        "plt.plot(hist.history['val_precision_7'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "esQzOZTb9p48",
        "outputId": "8ac28837-c403-4d2a-ed6b-58803bd453b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "MNh51nKK9u15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy\n",
        "test_preds = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "\n",
        "# Recall for each class\n",
        "recall_vals = []\n",
        "for i in range(3):\n",
        "    class_idx = np.argwhere(y_true==i)\n",
        "    total = len(class_idx)\n",
        "    correct = np.sum(test_preds[class_idx]==i)\n",
        "    recall = correct / total\n",
        "    recall_vals.append(recall)\n",
        "\n",
        "classes = [0,1]\n",
        "# Calculate the test set accuracy and recall for each class\n",
        "print('Test set accuracy is {:.3f}'.format(test_acc))\n",
        "for i in range(2):\n",
        "    print('For class {}, recall is {:.3f}'.format(classes[i],recall_vals[i]))\n",
        "\n",
        "print(\"Weighted F score is {:.3f}\".format(test_acc))\n",
        "# print(\"Weighted F score is {:.3f}\".format(calculate_weighted_f_score(y_true, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuLzuden9xuZ",
        "outputId": "440cf5f8-14b0-4d88-ecc1-12a09fae9cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy is 0.608\n",
            "For class 0, recall is 1.000\n",
            "For class 1, recall is 0.000\n",
            "Weighted F score is 0.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Completely New Model Build"
      ],
      "metadata": {
        "id": "KHDKw2Fj3Q9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D"
      ],
      "metadata": {
        "id": "uBUl4s7dF9ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (1, 3), activation='relu', padding='same', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n",
        "model.add(MaxPooling2D((1, 4), strides=4))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv2D(64, (1, 3), activation='relu', padding='same',))\n",
        "model.add(MaxPooling2D((1, 3), strides=3))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv2D(128, (1, 3), activation='relu', padding='same',))\n",
        "model.add(MaxPooling2D((1, 2), strides=2))\n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dense(500,activation=\"relu\"))\n",
        "model.add(Dense(3,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "hFN0cl_cSjwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KKO5LSUTB1v",
        "outputId": "f16f4296-8e3b-4f7b-b141-9a6623e31a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22 (Conv2D)          (None, 5, 24, 32)         128       \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 2, 6, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 2, 6, 32)          0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 2, 6, 64)          6208      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 1, 2, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 1, 2, 64)          0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 1, 2, 128)         24704     \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 1, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 1, 1, 128)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1000)              129000    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 3)                 1503      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 662,043\n",
            "Trainable params: 662,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy']) "
      ],
      "metadata": {
        "id": "NRIZjV2-THkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 12\n",
        "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, validation_data=(X_val, y_val))\n",
        "\n",
        "##### LABLES NEED TO BY 1x3 ARRAY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EDJJqlJUMHb",
        "outputId": "a214b6fc-c9d2-435d-9a02-b8a3db3829cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 10s 5ms/step - loss: 1.1026 - accuracy: 0.3635 - val_loss: 1.0981 - val_accuracy: 0.3671\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0940 - accuracy: 0.3780 - val_loss: 1.0986 - val_accuracy: 0.3671\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0958 - accuracy: 0.3765 - val_loss: 1.0988 - val_accuracy: 0.3671\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0938 - accuracy: 0.3770 - val_loss: 1.0990 - val_accuracy: 0.3671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5S0IDmg7URVU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}