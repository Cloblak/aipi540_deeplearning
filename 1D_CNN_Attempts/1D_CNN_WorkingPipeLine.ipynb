{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "35b0c6a641f74b7a8a5a17696c771999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5435c22875e1449bba6f514dc362fb86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2174b8eaf379476aa207a7d3553a23cb",
              "IPY_MODEL_d2eea602e1f44679b9dca81d02cef6a9",
              "IPY_MODEL_4c4ee8d44be44753b86d2334ed5201d9"
            ]
          }
        },
        "5435c22875e1449bba6f514dc362fb86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2174b8eaf379476aa207a7d3553a23cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d07aa40726741bba6d08a741f239b2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 63%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae9e58658d6e45a0ae4f071d65facbd8"
          }
        },
        "d2eea602e1f44679b9dca81d02cef6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39c656c52a3b41f4912ae2f141bf1291",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 188,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_101532c20c604f9cbddaae38f83cb611"
          }
        },
        "4c4ee8d44be44753b86d2334ed5201d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a809155bf81340c88a359f8e8b52b1a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 188/300 [1:25:16&lt;50:49, 27.23s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a927038a7cb49a6a64673ce556a0c8e"
          }
        },
        "2d07aa40726741bba6d08a741f239b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae9e58658d6e45a0ae4f071d65facbd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39c656c52a3b41f4912ae2f141bf1291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "101532c20c604f9cbddaae38f83cb611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a809155bf81340c88a359f8e8b52b1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a927038a7cb49a6a64673ce556a0c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb7c9f3f250d4f37923a9ad7a3130a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af033a719fd04de3b4c61ae772b2d7f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b274d8f4515c4a0fb5d16f748fb9ecaa",
              "IPY_MODEL_b986c5f0b0884798a911cbf6098cfed1",
              "IPY_MODEL_7b583b3725514b618b448fe651360da6"
            ]
          }
        },
        "af033a719fd04de3b4c61ae772b2d7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b274d8f4515c4a0fb5d16f748fb9ecaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_239b2669ac5d4a06871258137955bb5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9ae8ac19b274f4fa1d67a6da52e5952"
          }
        },
        "b986c5f0b0884798a911cbf6098cfed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4cb9db32a0dc4cfa80df2aef87700fc2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59fd93c3786d446db0298a0be0244929"
          }
        },
        "7b583b3725514b618b448fe651360da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18edccce3ce54ae1940062f7d6b56d33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/300 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37cd085fd4b34d6ba130eb897c098f72"
          }
        },
        "239b2669ac5d4a06871258137955bb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9ae8ac19b274f4fa1d67a6da52e5952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cb9db32a0dc4cfa80df2aef87700fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59fd93c3786d446db0298a0be0244929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18edccce3ce54ae1940062f7d6b56d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37cd085fd4b34d6ba130eb897c098f72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cloblak/aipi540_deeplearning/blob/main/1D_CNN_Attempts/1D_CNN_WorkingPipeLine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alpaca_trade_api"
      ],
      "metadata": {
        "id": "Xj0pR3efRVrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09330500-a2e8-4750-d41d-3999aa41be85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: alpaca_trade_api in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: websockets<10,>=8.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (9.1)\n",
            "Requirement already satisfied: msgpack==1.0.2 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.19.5)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (2.1.0)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.1.5)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.24.3)\n",
            "Requirement already satisfied: PyYAML==5.4.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (5.4.1)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.2.3)\n",
            "Requirement already satisfied: aiohttp==3.7.4 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (3.7.4)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (2.23.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (21.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (3.0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation==2.1.0->alpaca_trade_api) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.1->alpaca_trade_api) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->alpaca_trade_api) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->alpaca_trade_api) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation==2.1.0->alpaca_trade_api) (3.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features To Consider\n",
        " - Targets are only predicting sell within market hours, i.e. at 1530, target is prediciting price for 1100 the next day.  Data from pre and post market is taken into consideration, and a sell or buy will be indicated if the price will flucuate after close."
      ],
      "metadata": {
        "id": "hdKRKIogGAu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "import alpaca_trade_api as tradeapi\n",
        "from datetime import datetime, timedelta, tzinfo, timezone, time\n",
        "import os.path\n",
        "import ast\n",
        "import threading\n",
        "import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "metadata": {
        "id": "J1fWNRnTQZX-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 101\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "id": "DrI_WR501Iis",
        "outputId": "87ad442f-9b2c-4da5-d68a-286ca5bd8ae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb54a8f1530>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAPER_API_KEY = \"PKE39LILN9SL1FMJMFV7\"\n",
        "PAPER_SECRET_KEY = \"TkU7fXH6WhP15MewgWlSnQG5RUoHGOPQ7yqlD6xq\"\n",
        "PAPER_BASE_URL = 'https://paper-api.alpaca.markets'"
      ],
      "metadata": {
        "id": "IXnO8ykgRIuv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api = tradeapi.REST(PAPER_API_KEY, PAPER_SECRET_KEY, PAPER_BASE_URL, api_version='v2')"
      ],
      "metadata": {
        "id": "_3XShkLcRQMs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepost_train_test_validate_offset_data(api, ticker, interval, train_days=180, test_days=60, validate_days=30, offset_days = 0):\n",
        "    ticker_data_dict = None\n",
        "    ticker_data_dict = {}\n",
        "    monthly_data_dict = None\n",
        "    monthly_data_dict = {}\n",
        "    interval_loop_data = None\n",
        "    interval_loop_data = pd.DataFrame()\n",
        "    stock_data = None\n",
        "    \n",
        "    days_to_collect = train_days + test_days + validate_days + offset_days\n",
        "\n",
        "    TZ = 'US/Eastern'\n",
        "\n",
        "    start = pd.to_datetime((datetime.now() - timedelta(days=days_to_collect)).strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "    end = pd.to_datetime(datetime.now().strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "\n",
        "    stock_data = api.get_bars(ticker, interval, start = start.isoformat(), end=end.isoformat(), adjustment=\"raw\").df\n",
        "    \n",
        "    interval_loop_data = interval_loop_data.append(stock_data)\n",
        "    df_start_ref = interval_loop_data.index[0]\n",
        "    start_str_ref = pd.to_datetime(start, utc=True)\n",
        "\n",
        "    while start_str_ref.value < ( pd.to_datetime(df_start_ref, utc=True) - pd.Timedelta(days=2.5)).value:\n",
        "        end_new = pd.to_datetime(interval_loop_data.index[0].strftime(\"%Y-%m-%d %H:%M\"), utc=True).isoformat()\n",
        "        stock_data_new = None\n",
        "        stock_data_new = api.get_bars(ticker, interval, start=start, end=end_new, adjustment=\"raw\").df\n",
        "        #stock_data_new = stock_data_new.reset_index()\n",
        "        interval_loop_data = interval_loop_data.append(stock_data_new).sort_values(by=['index'], ascending=True)\n",
        "        df_start_ref = interval_loop_data.index[0]\n",
        "        \n",
        "    stock_yr_min_df = interval_loop_data.copy()\n",
        "    stock_yr_min_df[\"Open\"] = stock_yr_min_df['open']\n",
        "    stock_yr_min_df[\"High\"]= stock_yr_min_df[\"high\"]\n",
        "    stock_yr_min_df[\"Low\"] = stock_yr_min_df[\"low\"]\n",
        "    stock_yr_min_df[\"Close\"] = stock_yr_min_df[\"close\"]\n",
        "    stock_yr_min_df[\"Volume\"] = stock_yr_min_df[\"volume\"]\n",
        "    stock_yr_min_df[\"VolumeWeightedAvgPrice\"] = stock_yr_min_df[\"vwap\"]\n",
        "    stock_yr_min_df[\"Time\"] = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    stock_yr_min_df.index = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    final_df = stock_yr_min_df.filter([\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"VolumeWeightedAvgPrice\"], axis = 1)\n",
        "    \n",
        "    first_day = final_df.index[0]\n",
        "    traintest_day = final_df.index[-1] - pd.Timedelta(days= test_days+validate_days+offset_days)\n",
        "    valtest_day = final_df.index[-1] - pd.Timedelta(days= test_days+offset_days)\n",
        "    last_day = final_df.index[-1] - pd.Timedelta(days= offset_days)\n",
        "    training_df =  final_df.loc[first_day:traintest_day] #(data_split - pd.Timedelta(days=1))]\n",
        "    validate_df = final_df.loc[traintest_day:valtest_day]\n",
        "    testing_df =  final_df.loc[valtest_day:last_day]\n",
        "    full_train = final_df.loc[first_day:last_day]\n",
        "    offset_df =  final_df.loc[last_day:]\n",
        "\n",
        "    return training_df, validate_df, testing_df, full_train, offset_df, final_df, traintest_day, valtest_day\n",
        "\n",
        "def markethours_train_test_validate_offset_data(api, ticker, interval, train_days=180, test_days=60, validate_days=30, offset_days = 0):\n",
        "    ticker_data_dict = None\n",
        "    ticker_data_dict = {}\n",
        "    monthly_data_dict = None\n",
        "    monthly_data_dict = {}\n",
        "    interval_loop_data = None\n",
        "    interval_loop_data = pd.DataFrame()\n",
        "    stock_data = None\n",
        "    \n",
        "    days_to_collect = train_days + test_days + validate_days + offset_days\n",
        "\n",
        "    TZ = 'US/Eastern'\n",
        "\n",
        "    start = pd.to_datetime((datetime.now() - timedelta(days=days_to_collect)).strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "    end = pd.to_datetime(datetime.now().strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "\n",
        "    stock_data = api.get_barset(ticker, interval, start = start.isoformat(), end=end.isoformat()).df\n",
        "    \n",
        "    interval_loop_data = interval_loop_data.append(stock_data)\n",
        "    df_start_ref = interval_loop_data.index[0]\n",
        "    start_str_ref = pd.to_datetime(start, utc=True)\n",
        "\n",
        "    while start_str_ref.value < ( pd.to_datetime(df_start_ref, utc=True) - pd.Timedelta(days=2.5)).value:\n",
        "        end_new = pd.to_datetime(interval_loop_data.index[0].strftime(\"%Y-%m-%d %H:%M\"), utc=True).isoformat()\n",
        "        stock_data_new = None\n",
        "        stock_data_new = api.get_barset(ticker, interval, start=start, end=end_new).df\n",
        "        interval_loop_data = interval_loop_data.append(stock_data_new).sort_values(by=['time'], ascending=True)\n",
        "        df_start_ref = interval_loop_data.index[0]\n",
        "        \n",
        "    stock_yr_min_df = interval_loop_data.copy()\n",
        "    pre_final = pd.DataFrame()\n",
        "    pre_final[\"Open\"] = stock_yr_min_df[ticker]['open']\n",
        "    pre_final[\"High\"]= stock_yr_min_df[ticker][\"high\"]\n",
        "    pre_final[\"Low\"] = stock_yr_min_df[ticker][\"low\"]\n",
        "    pre_final[\"Close\"] = stock_yr_min_df[ticker][\"close\"]\n",
        "    pre_final[\"Volume\"] = stock_yr_min_df[ticker][\"volume\"]\n",
        "    pre_final[\"Time\"] = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    pre_final.index = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    \n",
        "    final_df = pre_final.filter([\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"], axis = 1).between_time('9:29', '16:05')\n",
        "    \n",
        "    first_day = final_df.index[0]\n",
        "    traintest_day = final_df.index[-1] - pd.Timedelta(days= test_days+validate_days+offset_days)\n",
        "    valtest_day = final_df.index[-1] - pd.Timedelta(days= test_days+offset_days)\n",
        "    last_day = final_df.index[-1] - pd.Timedelta(days= offset_days)\n",
        "    training_df =  final_df.loc[first_day:traintest_day] #(data_split - pd.Timedelta(days=1))]\n",
        "    validate_df = final_df.loc[traintest_day:valtest_day]\n",
        "    testing_df =  final_df.loc[valtest_day:last_day]\n",
        "    full_train = final_df.loc[first_day:last_day]\n",
        "    offset_df =  final_df.loc[last_day:]\n",
        "\n",
        "\n",
        "    return training_df, validate_df, testing_df, full_train, offset_df, final_df, traintest_day, valtest_day\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tINNlljbRaDs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "\n",
        "train_start = date(2017, 1, 1)\n",
        "train_end = date(2019, 10, 31)\n",
        "train_delta = train_end - train_start\n",
        "print(f'Number of days of Training Data {train_delta.days}')\n",
        "\n",
        "val_day_num = 400\n",
        "print(f'Number of days of Validation Data {val_day_num}')\n",
        "\n",
        "test_start = train_end + timedelta(val_day_num)\n",
        "test_end = date.today()\n",
        "test_delta = (test_end - test_start)\n",
        "print(f'Number of days of Holdout Test Data {test_delta.days}')\n",
        "\n",
        "ticker = \"WMT\" # Ticker Symbol to Test\n",
        "interval = \"5Min\" # Interval of bars\n",
        "train_day_int = train_delta.days # Size of training set (Jan 2010 - Oct 2017)\n",
        "val_day_int = val_day_num # Size of validation set\n",
        "test_day_int = test_delta.days # Size of test set\n",
        "offset_day_int = 0 # Number of days to off set the training data\n",
        "train, val, test, full, offset, complete, traintest_day, testval_day = prepost_train_test_validate_offset_data(api, ticker, \n",
        "                                                                                     interval, \n",
        "                                                                                     train_days=train_day_int, \n",
        "                                                                                     test_days=test_day_int, \n",
        "                                                                                     validate_days=val_day_int,\n",
        "                                                                                     offset_days = offset_day_int)"
      ],
      "metadata": {
        "id": "rRFxnqAiRcnE",
        "outputId": "cdbdf104-b88f-4392-a522-7baf29af571b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of days of Training Data 1033\n",
            "Number of days of Validation Data 400\n",
            "Number of days of Holdout Test Data 421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def timeFilterAndBackfill(df):\n",
        "  \"\"\" \n",
        "  Prep df to be filled out for each trading day:\n",
        "  Time Frame: 0730-1730\n",
        "  Backfilling NaNs\n",
        "  Adjusting Volume to Zero if no Trading data is present\n",
        "     - Assumption is that there were no trades duing that time  \n",
        "  \"\"\"\n",
        "  \n",
        "  df = df.between_time('07:29','17:26')\n",
        "\n",
        "  TZ = 'US/Eastern'\n",
        "\n",
        "  start_dateTime = pd.Timestamp(year = df.index[0].year, \n",
        "                                month = df.index[0].month, \n",
        "                                day = df.index[0].day, \n",
        "                                hour = 7, minute = 25, tz = TZ)\n",
        "\n",
        "  end_dateTime = pd.Timestamp(year = df.index[-1].year, \n",
        "                              month = df.index[-1].month, \n",
        "                              day = df.index[-1].day, \n",
        "                              hour = 17, minute = 35, tz = TZ)\n",
        "\n",
        "  dateTime_index = pd.date_range(start_dateTime,\n",
        "                                end_dateTime, \n",
        "                                freq='5min').tolist()\n",
        "\n",
        "  dateTime_index_df = pd.DataFrame()\n",
        "  dateTime_index_df[\"Time\"] = dateTime_index \n",
        "  filtered_df = pd.merge_asof(dateTime_index_df, df,  \n",
        "                              on='Time', \n",
        "                              direction='backward').set_index(\"Time\").between_time('07:29','17:26')\n",
        "\n",
        "  volumeset_list = []\n",
        "  prev_v = None\n",
        "\n",
        "  for v in filtered_df[\"Volume\"]:\n",
        "    \n",
        "    if prev_v == None:\n",
        "      if math.isnan(v):\n",
        "        prev_v = 0\n",
        "        volumeset_list.append(0)\n",
        "      else:\n",
        "        prev_v = v\n",
        "        volumeset_list.append(v)\n",
        "\n",
        "    elif prev_v != None:\n",
        "      if v == prev_v:\n",
        "        volumeset_list.append(0)\n",
        "        prev_v = v\n",
        "      elif math.isnan(v):\n",
        "        volumeset_list.append(0)\n",
        "        prev_v = 0\n",
        "      else:\n",
        "        volumeset_list.append(v)\n",
        "        prev_v = v\n",
        "\n",
        "\n",
        "  filtered_df[\"Volume\"] = volumeset_list\n",
        "  adjvolumeset_list = []\n",
        "\n",
        "  prev_v = None\n",
        "\n",
        "  for v in filtered_df[\"VolumeWeightedAvgPrice\"]:\n",
        "    if prev_v == None:\n",
        "      if math.isnan(v):\n",
        "        prev_v = 0\n",
        "        adjvolumeset_list.append(0)\n",
        "      else:\n",
        "        prev_v = v\n",
        "        adjvolumeset_list.append(v)\n",
        "    elif prev_v != None:\n",
        "      if v == prev_v:\n",
        "        adjvolumeset_list.append(0)\n",
        "        prev_v = v\n",
        "      elif math.isnan(v):\n",
        "        adjvolumeset_list.append(0)\n",
        "        prev_v = 0\n",
        "      else:\n",
        "        adjvolumeset_list.append(v)\n",
        "        prev_v = v\n",
        "\n",
        "  filtered_df[\"VolumeWeightedAvgPrice\"] = adjvolumeset_list\n",
        "\n",
        "  preped_df = filtered_df.backfill()\n",
        "\n",
        "  return preped_df\n",
        "\n",
        "def blockshaped(arr, nrows, ncols):\n",
        "    \"\"\"\n",
        "    Return an array of shape (n, nrows, ncols) where\n",
        "    n * nrows * ncols = arr.size\n",
        "\n",
        "    If arr is a 2D array, the returned array should look like n subblocks with\n",
        "    each subblock preserving the \"physical\" layout of arr.\n",
        "    \"\"\"\n",
        "    h, w = arr.shape\n",
        "    assert h % nrows == 0, f\"{h} rows is not evenly divisible by {nrows}\"\n",
        "    assert w % ncols == 0, f\"{w} cols is not evenly divisible by {ncols}\"\n",
        "    return np.flip(np.rot90((arr.reshape(h//nrows, nrows, -1, ncols)\n",
        "               .swapaxes(1,2)\n",
        "               .reshape(-1, nrows, ncols)), axes = (1, 2)), axis = 1)\n",
        "  \n",
        "\n",
        "def buildOutData_TorchPrep(train_df = train, val_df = val, test_df = test):\n",
        "  pass"
      ],
      "metadata": {
        "id": "bbrVHNazd27v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = timeFilterAndBackfill(train)\n",
        "val = timeFilterAndBackfill(val)\n",
        "test = timeFilterAndBackfill(test)"
      ],
      "metadata": {
        "id": "wW4vHhnfgne4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "1f2Wzmb9ovu-",
        "outputId": "82c7cd51-8dbf-463b-9721-dccdb527a581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-172914b2-7856-4944-8cf4-fde15bdaf051\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeWeightedAvgPrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-03 07:30:00-05:00</th>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 07:35:00-05:00</th>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 07:40:00-05:00</th>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 07:45:00-05:00</th>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 07:50:00-05:00</th>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>69.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:05:00-04:00</th>\n",
              "      <td>118.10</td>\n",
              "      <td>118.11</td>\n",
              "      <td>118.10</td>\n",
              "      <td>118.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:10:00-04:00</th>\n",
              "      <td>118.10</td>\n",
              "      <td>118.11</td>\n",
              "      <td>118.10</td>\n",
              "      <td>118.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:15:00-04:00</th>\n",
              "      <td>118.10</td>\n",
              "      <td>118.11</td>\n",
              "      <td>118.10</td>\n",
              "      <td>118.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:20:00-04:00</th>\n",
              "      <td>118.10</td>\n",
              "      <td>118.11</td>\n",
              "      <td>118.10</td>\n",
              "      <td>118.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:25:00-04:00</th>\n",
              "      <td>118.10</td>\n",
              "      <td>118.11</td>\n",
              "      <td>118.10</td>\n",
              "      <td>118.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>123720 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-172914b2-7856-4944-8cf4-fde15bdaf051')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-172914b2-7856-4944-8cf4-fde15bdaf051 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-172914b2-7856-4944-8cf4-fde15bdaf051');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             Open    High  ...  Volume  VolumeWeightedAvgPrice\n",
              "Time                                       ...                                \n",
              "2017-01-03 07:30:00-05:00   69.15   69.15  ...     0.0                     0.0\n",
              "2017-01-03 07:35:00-05:00   69.15   69.15  ...     0.0                     0.0\n",
              "2017-01-03 07:40:00-05:00   69.15   69.15  ...     0.0                     0.0\n",
              "2017-01-03 07:45:00-05:00   69.15   69.15  ...     0.0                     0.0\n",
              "2017-01-03 07:50:00-05:00   69.15   69.15  ...     0.0                     0.0\n",
              "...                           ...     ...  ...     ...                     ...\n",
              "2019-10-30 17:05:00-04:00  118.10  118.11  ...     0.0                     0.0\n",
              "2019-10-30 17:10:00-04:00  118.10  118.11  ...     0.0                     0.0\n",
              "2019-10-30 17:15:00-04:00  118.10  118.11  ...     0.0                     0.0\n",
              "2019-10-30 17:20:00-04:00  118.10  118.11  ...     0.0                     0.0\n",
              "2019-10-30 17:25:00-04:00  118.10  118.11  ...     0.0                     0.0\n",
              "\n",
              "[123720 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tonp = train[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "val_tonp = val[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "test_tonp = test[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "train_array = train_tonp.to_numpy()\n",
        "val_array = val_tonp.to_numpy()\n",
        "test_array = test_tonp.to_numpy()\n",
        "X_train = blockshaped(train_array, 24, 5)\n",
        "X_val = blockshaped(val_array, 24, 5)\n",
        "X_test = blockshaped(test_array, 24, 5)"
      ],
      "metadata": {
        "id": "eYe9V9P9iFyn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[24:48]"
      ],
      "metadata": {
        "id": "BdgQFubuscWf",
        "outputId": "b80b84e6-4259-453b-b474-6563ca694a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e26477d3-ee64-44ee-8276-86760a74c4d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeWeightedAvgPrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-12-04 09:30:00-05:00</th>\n",
              "      <td>149.5100</td>\n",
              "      <td>149.5100</td>\n",
              "      <td>148.7100</td>\n",
              "      <td>148.8600</td>\n",
              "      <td>231923.0</td>\n",
              "      <td>149.180813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 09:35:00-05:00</th>\n",
              "      <td>148.8600</td>\n",
              "      <td>149.0000</td>\n",
              "      <td>148.1751</td>\n",
              "      <td>148.4200</td>\n",
              "      <td>149407.0</td>\n",
              "      <td>148.595039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 09:40:00-05:00</th>\n",
              "      <td>148.3775</td>\n",
              "      <td>148.8900</td>\n",
              "      <td>148.3000</td>\n",
              "      <td>148.3200</td>\n",
              "      <td>111228.0</td>\n",
              "      <td>148.548161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 09:45:00-05:00</th>\n",
              "      <td>148.4100</td>\n",
              "      <td>148.7000</td>\n",
              "      <td>148.2370</td>\n",
              "      <td>148.6750</td>\n",
              "      <td>77056.0</td>\n",
              "      <td>148.457488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 09:50:00-05:00</th>\n",
              "      <td>148.6686</td>\n",
              "      <td>148.9100</td>\n",
              "      <td>148.6100</td>\n",
              "      <td>148.7300</td>\n",
              "      <td>99921.0</td>\n",
              "      <td>148.786323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 09:55:00-05:00</th>\n",
              "      <td>148.7000</td>\n",
              "      <td>148.7000</td>\n",
              "      <td>148.5200</td>\n",
              "      <td>148.6450</td>\n",
              "      <td>75181.0</td>\n",
              "      <td>148.592995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:00:00-05:00</th>\n",
              "      <td>148.6700</td>\n",
              "      <td>148.6750</td>\n",
              "      <td>148.2800</td>\n",
              "      <td>148.4800</td>\n",
              "      <td>100701.0</td>\n",
              "      <td>148.416309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:05:00-05:00</th>\n",
              "      <td>148.4800</td>\n",
              "      <td>148.6300</td>\n",
              "      <td>148.2600</td>\n",
              "      <td>148.3294</td>\n",
              "      <td>88675.0</td>\n",
              "      <td>148.401629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:10:00-05:00</th>\n",
              "      <td>148.3000</td>\n",
              "      <td>148.3181</td>\n",
              "      <td>148.1000</td>\n",
              "      <td>148.1801</td>\n",
              "      <td>128189.0</td>\n",
              "      <td>148.188385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:15:00-05:00</th>\n",
              "      <td>148.1800</td>\n",
              "      <td>148.5100</td>\n",
              "      <td>148.1800</td>\n",
              "      <td>148.4200</td>\n",
              "      <td>60346.0</td>\n",
              "      <td>148.378918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:20:00-05:00</th>\n",
              "      <td>148.4100</td>\n",
              "      <td>148.4600</td>\n",
              "      <td>148.2450</td>\n",
              "      <td>148.2450</td>\n",
              "      <td>60548.0</td>\n",
              "      <td>148.347318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:25:00-05:00</th>\n",
              "      <td>148.2400</td>\n",
              "      <td>148.2486</td>\n",
              "      <td>148.0500</td>\n",
              "      <td>148.1350</td>\n",
              "      <td>90012.0</td>\n",
              "      <td>148.142328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:30:00-05:00</th>\n",
              "      <td>148.1300</td>\n",
              "      <td>148.1800</td>\n",
              "      <td>148.0200</td>\n",
              "      <td>148.1100</td>\n",
              "      <td>80801.0</td>\n",
              "      <td>148.125026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:35:00-05:00</th>\n",
              "      <td>148.1100</td>\n",
              "      <td>148.1800</td>\n",
              "      <td>148.0300</td>\n",
              "      <td>148.0799</td>\n",
              "      <td>72854.0</td>\n",
              "      <td>148.121727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:40:00-05:00</th>\n",
              "      <td>148.0534</td>\n",
              "      <td>148.3000</td>\n",
              "      <td>147.8500</td>\n",
              "      <td>148.2150</td>\n",
              "      <td>161004.0</td>\n",
              "      <td>148.042476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:45:00-05:00</th>\n",
              "      <td>148.2250</td>\n",
              "      <td>148.5000</td>\n",
              "      <td>148.2000</td>\n",
              "      <td>148.4200</td>\n",
              "      <td>58539.0</td>\n",
              "      <td>148.377793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:50:00-05:00</th>\n",
              "      <td>148.4100</td>\n",
              "      <td>148.5700</td>\n",
              "      <td>148.4019</td>\n",
              "      <td>148.4799</td>\n",
              "      <td>73105.0</td>\n",
              "      <td>148.494108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 10:55:00-05:00</th>\n",
              "      <td>148.4664</td>\n",
              "      <td>148.4850</td>\n",
              "      <td>148.2400</td>\n",
              "      <td>148.2800</td>\n",
              "      <td>61953.0</td>\n",
              "      <td>148.359386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 11:00:00-05:00</th>\n",
              "      <td>148.2800</td>\n",
              "      <td>148.4432</td>\n",
              "      <td>148.2701</td>\n",
              "      <td>148.3500</td>\n",
              "      <td>45327.0</td>\n",
              "      <td>148.342833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 11:05:00-05:00</th>\n",
              "      <td>148.3750</td>\n",
              "      <td>148.3750</td>\n",
              "      <td>148.1100</td>\n",
              "      <td>148.1100</td>\n",
              "      <td>57415.0</td>\n",
              "      <td>148.215265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 11:10:00-05:00</th>\n",
              "      <td>148.1400</td>\n",
              "      <td>148.1500</td>\n",
              "      <td>147.7700</td>\n",
              "      <td>147.8200</td>\n",
              "      <td>123864.0</td>\n",
              "      <td>147.946730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 11:15:00-05:00</th>\n",
              "      <td>147.8179</td>\n",
              "      <td>147.8890</td>\n",
              "      <td>147.7600</td>\n",
              "      <td>147.8300</td>\n",
              "      <td>82851.0</td>\n",
              "      <td>147.830223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 11:20:00-05:00</th>\n",
              "      <td>147.8500</td>\n",
              "      <td>147.9500</td>\n",
              "      <td>147.8300</td>\n",
              "      <td>147.9000</td>\n",
              "      <td>55347.0</td>\n",
              "      <td>147.887461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04 11:25:00-05:00</th>\n",
              "      <td>147.9000</td>\n",
              "      <td>148.0000</td>\n",
              "      <td>147.8800</td>\n",
              "      <td>148.0000</td>\n",
              "      <td>71875.0</td>\n",
              "      <td>147.952053</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e26477d3-ee64-44ee-8276-86760a74c4d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e26477d3-ee64-44ee-8276-86760a74c4d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e26477d3-ee64-44ee-8276-86760a74c4d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               Open      High  ...    Volume  VolumeWeightedAvgPrice\n",
              "Time                                           ...                                  \n",
              "2020-12-04 09:30:00-05:00  149.5100  149.5100  ...  231923.0              149.180813\n",
              "2020-12-04 09:35:00-05:00  148.8600  149.0000  ...  149407.0              148.595039\n",
              "2020-12-04 09:40:00-05:00  148.3775  148.8900  ...  111228.0              148.548161\n",
              "2020-12-04 09:45:00-05:00  148.4100  148.7000  ...   77056.0              148.457488\n",
              "2020-12-04 09:50:00-05:00  148.6686  148.9100  ...   99921.0              148.786323\n",
              "2020-12-04 09:55:00-05:00  148.7000  148.7000  ...   75181.0              148.592995\n",
              "2020-12-04 10:00:00-05:00  148.6700  148.6750  ...  100701.0              148.416309\n",
              "2020-12-04 10:05:00-05:00  148.4800  148.6300  ...   88675.0              148.401629\n",
              "2020-12-04 10:10:00-05:00  148.3000  148.3181  ...  128189.0              148.188385\n",
              "2020-12-04 10:15:00-05:00  148.1800  148.5100  ...   60346.0              148.378918\n",
              "2020-12-04 10:20:00-05:00  148.4100  148.4600  ...   60548.0              148.347318\n",
              "2020-12-04 10:25:00-05:00  148.2400  148.2486  ...   90012.0              148.142328\n",
              "2020-12-04 10:30:00-05:00  148.1300  148.1800  ...   80801.0              148.125026\n",
              "2020-12-04 10:35:00-05:00  148.1100  148.1800  ...   72854.0              148.121727\n",
              "2020-12-04 10:40:00-05:00  148.0534  148.3000  ...  161004.0              148.042476\n",
              "2020-12-04 10:45:00-05:00  148.2250  148.5000  ...   58539.0              148.377793\n",
              "2020-12-04 10:50:00-05:00  148.4100  148.5700  ...   73105.0              148.494108\n",
              "2020-12-04 10:55:00-05:00  148.4664  148.4850  ...   61953.0              148.359386\n",
              "2020-12-04 11:00:00-05:00  148.2800  148.4432  ...   45327.0              148.342833\n",
              "2020-12-04 11:05:00-05:00  148.3750  148.3750  ...   57415.0              148.215265\n",
              "2020-12-04 11:10:00-05:00  148.1400  148.1500  ...  123864.0              147.946730\n",
              "2020-12-04 11:15:00-05:00  147.8179  147.8890  ...   82851.0              147.830223\n",
              "2020-12-04 11:20:00-05:00  147.8500  147.9500  ...   55347.0              147.887461\n",
              "2020-12-04 11:25:00-05:00  147.9000  148.0000  ...   71875.0              147.952053\n",
              "\n",
              "[24 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=1000)\n",
        "X_train[0]"
      ],
      "metadata": {
        "id": "b3HFZ-jSsXBW",
        "outputId": "31fffeb1-2d12-41c9-f9c0-4cf46027d56b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.12,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.35,   69.35,   69.35,   69.35,   69.35,   69.35,   69.3 ,   69.22],\n",
              "       [  69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.12,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.35,   69.35,   69.35,   69.35,   69.35,   69.35,   69.3 ,   69.24],\n",
              "       [  69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.12,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.35,   69.35,   69.35,   69.35,   69.35,   69.35,   69.2 ,   68.9 ],\n",
              "       [  69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.12,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.35,   69.35,   69.35,   69.35,   69.35,   69.35,   69.23,   69.01],\n",
              "       [   0.  ,    0.  ,    0.  ,    0.  ,    0.  ,    0.  ,  111.  ,    0.  ,    0.  ,    0.  , 1729.  ,  210.  ,  500.  ,    0.  ,    0.  ,    0.  ,  685.  ,    0.  ,    0.  ,    0.  ,    0.  ,    0.  , 1687.  , 6207.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0][3][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX6Xlpo-N3u1",
        "outputId": "0f3da52d-76ea-4aab-8725-a7e333358eec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69.01"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create target from OHLC and Volume Data\n",
        "def buildTargets(obs_array,  \n",
        "                 alph = .55, \n",
        "                 volity_int = 8):\n",
        "\n",
        "  \"\"\" \n",
        "  This function will take a complete set of train, val, and test \n",
        "  data and return the targets. Volitility will be calculated over \n",
        "  the 24 5min incriments. The Target shift is looking at 2 hours \n",
        "  shift from current time\n",
        "\n",
        "  shift_2hour = The amount of time the data interval take to equal 2 hours \n",
        "                (i.e. 5 min data interval is equal to 24)\n",
        "  alph = The alpha value for calculating the shift in price\n",
        "  volity_int = the number of incriments used to calculate volitility \n",
        "  \"\"\"\n",
        "\n",
        "  target_close_list =[]\n",
        "\n",
        "  for arr in obs_array:\n",
        "    target_close_list.append(arr[3][-1])\n",
        "  \n",
        "  target_close_df = pd.DataFrame()\n",
        "  target_close_df[\"Close\"] = target_close_list\n",
        "\n",
        "  returns = np.log(target_close_df['Close']/(target_close_df['Close'].shift(1)))\n",
        "  returns.fillna(0, inplace=True)\n",
        "  volatility = returns.rolling(window=volity_int).std()*np.sqrt(volity_int)\n",
        "  \n",
        "  targets = [2] * len(target_close_df.Close)\n",
        "\n",
        "  targets = np.where(target_close_df.Close.shift(-1) >= (target_close_df.Close * (1 + alph * volatility)), \n",
        "           1, targets)\n",
        "  \n",
        "  targets = np.where(target_close_df.Close.shift(-1) <= (target_close_df.Close * (1 - alph * volatility)), \n",
        "           0, targets)\n",
        "\n",
        "  return targets"
      ],
      "metadata": {
        "id": "Pe89LdnsLltO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "volity_val = 2\n",
        "y_train = buildTargets(X_train, volity_int = volity_val)\n",
        "y_val = buildTargets(X_val, volity_int = volity_val)\n",
        "y_test = buildTargets(X_test, volity_int = volity_val)"
      ],
      "metadata": {
        "id": "4aYPOa7INyAl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 1,\n",
        "                          X_train.shape[1], \n",
        "                          X_train.shape[2])\n",
        "X_val = X_val.reshape(X_val.shape[0], 1,\n",
        "                          X_val.shape[1], \n",
        "                          X_val.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1,\n",
        "                          X_test.shape[1], \n",
        "                          X_test.shape[2])"
      ],
      "metadata": {
        "id": "SxB_AzoBf4Xe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X Train Length {X_train.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test.shape}, y Test Label Length {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIYp1XKJPCNL",
        "outputId": "9bf2b22d-53b8-4b30-f4e9-2e419812c6a9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (5155, 1, 5, 24), y Train Label Length (5155,)\n",
            "X Val Length (2000, 1, 5, 24), y Val Label Length (2000,)\n",
            "X Test Length (2105, 1, 5, 24), y Test Label Length (2105,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYHL1ekIYzDV",
        "outputId": "bbf4476c-cbc5-4d2f-a89f-40d233ed6825"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.12,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.35,   69.35,   69.35,   69.35,   69.35,   69.35,   69.3 ,   69.22],\n",
              "        [  69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.12,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.35,   69.35,   69.35,   69.35,   69.35,   69.35,   69.3 ,   69.24],\n",
              "        [  69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.12,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.35,   69.35,   69.35,   69.35,   69.35,   69.35,   69.2 ,   68.9 ],\n",
              "        [  69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.15,   69.12,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.3 ,   69.35,   69.35,   69.35,   69.35,   69.35,   69.35,   69.23,   69.01],\n",
              "        [   0.  ,    0.  ,    0.  ,    0.  ,    0.  ,    0.  ,  111.  ,    0.  ,    0.  ,    0.  , 1729.  ,  210.  ,  500.  ,    0.  ,    0.  ,    0.  ,  685.  ,    0.  ,    0.  ,    0.  ,    0.  ,    0.  , 1687.  , 6207.  ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_distribution(obj):\n",
        "    count_dict = {\n",
        "        \"up\": 0,\n",
        "        \"flat\": 0,\n",
        "        \"down\": 0,\n",
        "    }\n",
        "    \n",
        "    for i in obj:\n",
        "        if i == 1: \n",
        "            count_dict['up'] += 1\n",
        "        elif i == 0: \n",
        "            count_dict['down'] += 1\n",
        "        elif i == 2: \n",
        "            count_dict['flat'] += 1             \n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "            \n",
        "    return count_dict"
      ],
      "metadata": {
        "id": "vWIY2rwEYCfM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25,7))\n",
        "# Train\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_train)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')\n",
        "# Validation\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_val)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
        "# Test\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_test)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[2]).set_title('Class Distribution in Test Set')"
      ],
      "metadata": {
        "id": "-BsVCfr8YCiX",
        "outputId": "3908c3b2-b090-407c-b18d-62e04dd36b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution in Test Set')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# Code fro scaling at a later date\n",
        "######\n",
        "\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# scalers = {}\n",
        "# for i in range(X_train.shape[1]):\n",
        "#     scalers[i] = MinMaxScaler()\n",
        "#     X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :]) \n",
        "\n",
        "# for i in range(X_val.shape[1]):\n",
        "#     X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) \n",
        "\n",
        "# for i in range(X_test.shape[1]):\n",
        "#     X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) "
      ],
      "metadata": {
        "id": "3pzFa-UjYCKu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X Train Length {X_train.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test.shape}, y Test Label Length {y_test.shape}')\n",
        "print(\"\")\n",
        "print('Training data window: ', len(X_train))\n",
        "print('Val data windows: ', len(X_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ThCmAdYCX9",
        "outputId": "65621d0b-f7d5-4285-8650-fdfe52c70774"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (5155, 1, 5, 24), y Train Label Length (5155,)\n",
            "X Val Length (2000, 1, 5, 24), y Val Label Length (2000,)\n",
            "X Test Length (2105, 1, 5, 24), y Test Label Length (2105,)\n",
            "\n",
            "Training data window:  5155\n",
            "Val data windows:  2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0].dtype"
      ],
      "metadata": {
        "id": "EAdhr0KLy-72",
        "outputId": "0a883526-668c-4612-b359-b43b31a7475d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "\n",
        "train_data = []\n",
        "for i in range(len(X_train)):\n",
        "   train_data.append([X_train[i].astype('float'), y_train[i]])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=batch_size)\n",
        "i1, l1 = next(iter(train_loader))\n",
        "print(i1.shape)\n",
        "\n",
        "val_data = []\n",
        "for i in range(len(X_val)):\n",
        "   val_data.append([X_val[i].astype('float'), y_val[i]])\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size)\n",
        "i1, l1 = next(iter(val_loader))\n",
        "print(i1.shape)"
      ],
      "metadata": {
        "id": "5Zun8GwOiBlW",
        "outputId": "b3c09ba8-d313-4047-8af5-071ed3569a38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 5, 24])\n",
            "torch.Size([5, 1, 5, 24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get next batch of training images\n",
        "windows, labels = iter(train_loader).next()\n",
        "print(windows.shape)\n",
        "windows = windows.numpy()\n",
        "\n",
        "# plot the windows in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "for idx in range(batch_size):\n",
        "    print(labels[idx])"
      ],
      "metadata": {
        "id": "BaDGe3DSpg6f",
        "outputId": "2239af76-a9ee-431b-a86d-aa1c64b4fc61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 5, 24])\n",
            "tensor(2)\n",
            "tensor(2)\n",
            "tensor(2)\n",
            "tensor(1)\n",
            "tensor(0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StockShiftClassification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(StockShiftClassification, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool1 = nn.MaxPool2d(4,4)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool2 = nn.MaxPool2d(3,3)  \n",
        "\n",
        "    self.conv3 = nn.Conv2d(64, 128, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool3 = nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.fc1 = nn.Linear(128,1000)\n",
        "    self.fc2 = nn.Linear(1000,500)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool2(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.pool3(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    # Linear layer\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "YSLUlwla8BSU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "net = StockShiftClassification().float()\n",
        "\n",
        "# Display a summary of the layers of the model and output shape after each layer\n",
        "summary(net,(windows.shape[1:]),batch_size=batch_size,device=\"cpu\")"
      ],
      "metadata": {
        "id": "IAw7OiPS8BNu",
        "outputId": "cd55f127-b122-4840-e659-901929d1db21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1             [5, 32, 7, 24]             128\n",
            "         MaxPool2d-2              [5, 32, 1, 6]               0\n",
            "            Conv2d-3              [5, 64, 3, 6]           6,208\n",
            "         MaxPool2d-4              [5, 64, 1, 2]               0\n",
            "            Conv2d-5             [5, 128, 3, 2]          24,704\n",
            "         MaxPool2d-6             [5, 128, 1, 1]               0\n",
            "            Linear-7                  [5, 1000]         129,000\n",
            "            Linear-8                   [5, 500]         500,500\n",
            "================================================================\n",
            "Total params: 660,540\n",
            "Trainable params: 660,540\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.35\n",
            "Params size (MB): 2.52\n",
            "Estimated Total Size (MB): 2.87\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross entropy loss combines softmax and nn.NLLLoss() in one single class.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "rZGSLKkq8BIu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,criterion,optimizer,train_loader,n_epochs,device):\n",
        "    \n",
        "    loss_over_time = [] # to track the loss as the network trains\n",
        "    \n",
        "    model = model.to(device).double() # Send model to GPU if available\n",
        "    model.train() # Set the model to training mode\n",
        "    \n",
        "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            \n",
        "            # Get the input images and labels, and send to GPU if available\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # Zero the weight gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass to get outputs\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backpropagation to get the gradients with respect to each weight\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Convert loss into a scalar and add it to running_loss\n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            if i % 1000 == 999:    # print every 1000 batches\n",
        "                avg_loss = running_loss/1000\n",
        "                # record and print the avg loss over the 1000 batches\n",
        "                loss_over_time.append(avg_loss)\n",
        "                print('Epoch: {}, Batch: {}, Avg. Loss: {:.4f}'.format(epoch + 1, i+1, avg_loss))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    return loss_over_time"
      ],
      "metadata": {
        "id": "lAgQIWqA8BEW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_epochs = 100\n",
        "cost_path = train_model(net.float(),criterion,optimizer,train_loader,n_epochs,device)\n",
        "\n",
        "# visualize the loss as the network trained\n",
        "plt.plot(cost_path)\n",
        "plt.xlabel('Batch (1000s)')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mx3XtDf_8A_O",
        "outputId": "86cf1312-8e8e-418e-a9d1-fe2740d81a08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch: 1000, Avg. Loss: 1.0334\n",
            "Epoch: 2, Batch: 1000, Avg. Loss: 1.0312\n",
            "Epoch: 3, Batch: 1000, Avg. Loss: 1.0294\n",
            "Epoch: 4, Batch: 1000, Avg. Loss: 1.0279\n",
            "Epoch: 5, Batch: 1000, Avg. Loss: 1.0267\n",
            "Epoch: 6, Batch: 1000, Avg. Loss: 1.0255\n",
            "Epoch: 7, Batch: 1000, Avg. Loss: 1.0246\n",
            "Epoch: 8, Batch: 1000, Avg. Loss: 1.0238\n",
            "Epoch: 9, Batch: 1000, Avg. Loss: 1.0231\n",
            "Epoch: 10, Batch: 1000, Avg. Loss: 1.0224\n",
            "Epoch: 11, Batch: 1000, Avg. Loss: 1.0218\n",
            "Epoch: 12, Batch: 1000, Avg. Loss: 1.0212\n",
            "Epoch: 13, Batch: 1000, Avg. Loss: 1.0208\n",
            "Epoch: 14, Batch: 1000, Avg. Loss: 1.0203\n",
            "Epoch: 15, Batch: 1000, Avg. Loss: 1.0198\n",
            "Epoch: 16, Batch: 1000, Avg. Loss: 1.0196\n",
            "Epoch: 17, Batch: 1000, Avg. Loss: 1.0191\n",
            "Epoch: 18, Batch: 1000, Avg. Loss: 1.0188\n",
            "Epoch: 19, Batch: 1000, Avg. Loss: 1.0184\n",
            "Epoch: 20, Batch: 1000, Avg. Loss: 1.0181\n",
            "Epoch: 21, Batch: 1000, Avg. Loss: 1.0178\n",
            "Epoch: 22, Batch: 1000, Avg. Loss: 1.0175\n",
            "Epoch: 23, Batch: 1000, Avg. Loss: 1.0174\n",
            "Epoch: 24, Batch: 1000, Avg. Loss: 1.0171\n",
            "Epoch: 25, Batch: 1000, Avg. Loss: 1.0168\n",
            "Epoch: 26, Batch: 1000, Avg. Loss: 1.0166\n",
            "Epoch: 27, Batch: 1000, Avg. Loss: 1.0163\n",
            "Epoch: 28, Batch: 1000, Avg. Loss: 1.0162\n",
            "Epoch: 29, Batch: 1000, Avg. Loss: 1.0160\n",
            "Epoch: 30, Batch: 1000, Avg. Loss: 1.0158\n",
            "Epoch: 31, Batch: 1000, Avg. Loss: 1.0156\n",
            "Epoch: 32, Batch: 1000, Avg. Loss: 1.0155\n",
            "Epoch: 33, Batch: 1000, Avg. Loss: 1.0153\n",
            "Epoch: 34, Batch: 1000, Avg. Loss: 1.0151\n",
            "Epoch: 35, Batch: 1000, Avg. Loss: 1.0150\n",
            "Epoch: 36, Batch: 1000, Avg. Loss: 1.0148\n",
            "Epoch: 37, Batch: 1000, Avg. Loss: 1.0147\n",
            "Epoch: 38, Batch: 1000, Avg. Loss: 1.0147\n",
            "Epoch: 39, Batch: 1000, Avg. Loss: 1.0148\n",
            "Epoch: 40, Batch: 1000, Avg. Loss: 1.0144\n",
            "Epoch: 41, Batch: 1000, Avg. Loss: 1.0142\n",
            "Epoch: 42, Batch: 1000, Avg. Loss: 1.0141\n",
            "Epoch: 43, Batch: 1000, Avg. Loss: 1.0142\n",
            "Epoch: 44, Batch: 1000, Avg. Loss: 1.0139\n",
            "Epoch: 45, Batch: 1000, Avg. Loss: 1.0137\n",
            "Epoch: 46, Batch: 1000, Avg. Loss: 1.0137\n",
            "Epoch: 47, Batch: 1000, Avg. Loss: 1.0136\n",
            "Epoch: 48, Batch: 1000, Avg. Loss: 1.0134\n",
            "Epoch: 49, Batch: 1000, Avg. Loss: 1.0133\n",
            "Epoch: 50, Batch: 1000, Avg. Loss: 1.0132\n",
            "Epoch: 51, Batch: 1000, Avg. Loss: 1.0131\n",
            "Epoch: 52, Batch: 1000, Avg. Loss: 1.0131\n",
            "Epoch: 53, Batch: 1000, Avg. Loss: 1.0129\n",
            "Epoch: 54, Batch: 1000, Avg. Loss: 1.0129\n",
            "Epoch: 55, Batch: 1000, Avg. Loss: 1.0129\n",
            "Epoch: 56, Batch: 1000, Avg. Loss: 1.0128\n",
            "Epoch: 57, Batch: 1000, Avg. Loss: 1.0127\n",
            "Epoch: 58, Batch: 1000, Avg. Loss: 1.0125\n",
            "Epoch: 59, Batch: 1000, Avg. Loss: 1.0124\n",
            "Epoch: 60, Batch: 1000, Avg. Loss: 1.0123\n",
            "Epoch: 61, Batch: 1000, Avg. Loss: 1.0123\n",
            "Epoch: 62, Batch: 1000, Avg. Loss: 1.0121\n",
            "Epoch: 63, Batch: 1000, Avg. Loss: 1.0121\n",
            "Epoch: 64, Batch: 1000, Avg. Loss: 1.0122\n",
            "Epoch: 65, Batch: 1000, Avg. Loss: 1.0121\n",
            "Epoch: 66, Batch: 1000, Avg. Loss: 1.0119\n",
            "Epoch: 67, Batch: 1000, Avg. Loss: 1.0118\n",
            "Epoch: 68, Batch: 1000, Avg. Loss: 1.0117\n",
            "Epoch: 69, Batch: 1000, Avg. Loss: 1.0116\n",
            "Epoch: 70, Batch: 1000, Avg. Loss: 1.0115\n",
            "Epoch: 71, Batch: 1000, Avg. Loss: 1.0114\n",
            "Epoch: 72, Batch: 1000, Avg. Loss: 1.0113\n",
            "Epoch: 73, Batch: 1000, Avg. Loss: 1.0113\n",
            "Epoch: 74, Batch: 1000, Avg. Loss: 1.0112\n",
            "Epoch: 75, Batch: 1000, Avg. Loss: 1.0111\n",
            "Epoch: 76, Batch: 1000, Avg. Loss: 1.0113\n",
            "Epoch: 77, Batch: 1000, Avg. Loss: 1.0110\n",
            "Epoch: 78, Batch: 1000, Avg. Loss: 1.0110\n",
            "Epoch: 79, Batch: 1000, Avg. Loss: 1.0110\n",
            "Epoch: 80, Batch: 1000, Avg. Loss: 1.0109\n",
            "Epoch: 81, Batch: 1000, Avg. Loss: 1.0108\n",
            "Epoch: 82, Batch: 1000, Avg. Loss: 1.0108\n",
            "Epoch: 83, Batch: 1000, Avg. Loss: 1.0108\n",
            "Epoch: 84, Batch: 1000, Avg. Loss: 1.0107\n",
            "Epoch: 85, Batch: 1000, Avg. Loss: 1.0107\n",
            "Epoch: 86, Batch: 1000, Avg. Loss: 1.0107\n",
            "Epoch: 87, Batch: 1000, Avg. Loss: 1.0106\n",
            "Epoch: 88, Batch: 1000, Avg. Loss: 1.0106\n",
            "Epoch: 89, Batch: 1000, Avg. Loss: 1.0106\n",
            "Epoch: 90, Batch: 1000, Avg. Loss: 1.0106\n",
            "Epoch: 91, Batch: 1000, Avg. Loss: 1.0105\n",
            "Epoch: 92, Batch: 1000, Avg. Loss: 1.0105\n",
            "Epoch: 93, Batch: 1000, Avg. Loss: 1.0105\n",
            "Epoch: 94, Batch: 1000, Avg. Loss: 1.0104\n",
            "Epoch: 95, Batch: 1000, Avg. Loss: 1.0107\n",
            "Epoch: 96, Batch: 1000, Avg. Loss: 1.0104\n",
            "Epoch: 97, Batch: 1000, Avg. Loss: 1.0104\n",
            "Epoch: 98, Batch: 1000, Avg. Loss: 1.0104\n",
            "Epoch: 99, Batch: 1000, Avg. Loss: 1.0105\n",
            "Epoch: 100, Batch: 1000, Avg. Loss: 1.0103\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model,test_loader,device):\n",
        "    # Turn autograd off\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Set the model to evaluation mode\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        # Set up lists to store true and predicted values\n",
        "        y_true = []\n",
        "        test_preds = []\n",
        "\n",
        "        # Calculate the predictions on the test set and add to list\n",
        "        for data in test_loader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            # Feed inputs through model to get raw scores\n",
        "            logits = model.forward(inputs)\n",
        "            # Convert raw scores to probabilities (not necessary since we just care about discrete probs in this case)\n",
        "            probs = F.softmax(logits,dim=1)\n",
        "            # Get discrete predictions using argmax\n",
        "            preds = np.argmax(probs.cpu().numpy(),axis=1)\n",
        "            # Add predictions and actuals to lists\n",
        "            test_preds.extend(preds)\n",
        "            y_true.extend(labels)\n",
        "\n",
        "        # Calculate the accuracy\n",
        "        test_preds = np.array(test_preds)\n",
        "        y_true = np.array(y_true)\n",
        "        test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "        \n",
        "        # Recall for each class\n",
        "        recall_vals = []\n",
        "        for i in range(3):\n",
        "            class_idx = np.argwhere(y_true==i)\n",
        "            total = len(class_idx)\n",
        "            correct = np.sum(test_preds[class_idx]==i)\n",
        "            recall = correct / total\n",
        "            recall_vals.append(recall)\n",
        "    \n",
        "    return test_acc,recall_vals"
      ],
      "metadata": {
        "id": "Sg6m09eT8A4W"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [0,1,2]"
      ],
      "metadata": {
        "id": "pGIu_p7XCACy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the test set accuracy and recall for each class\n",
        "acc,recall_vals = test_model(net,val_loader,device)\n",
        "print('Test set accuracy is {:.3f}'.format(acc))\n",
        "for i in range(3):\n",
        "    print('For class {}, recall is {}'.format(classes[i],recall_vals[i]))"
      ],
      "metadata": {
        "id": "uvnTKH0fBzo2",
        "outputId": "e69fddb7-d646-4051-8ee9-6975dba37b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy is 0.352\n",
            "For class 0, recall is 1.0\n",
            "For class 1, recall is 0.0\n",
            "For class 2, recall is 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working Code"
      ],
      "metadata": {
        "id": "6BCMz6zXgtxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class StockClassificationBase(nn.Module):\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        windows, labels = batch \n",
        "        out = self(windows)                 # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels.long()) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        windows, labels = batch \n",
        "        out = self(windows)                   # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels.long())   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        if len(batch_losses) == 0:\n",
        "          epoch_loss = torch.stack(torch.FloatTensor((0))).mean()\n",
        "        else:\n",
        "          epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        if len(batch_accs) == 0:\n",
        "          epoch_acc = torch.stack(torch.FloatTensor((0))).mean()\n",
        "        else:\n",
        "          epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "rqrkb-0puMHj"
      },
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockShiftClassification(StockClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(1, 32, kernel_size = (1,3), stride=1, padding = 0).double(),\n",
        "            nn.MaxPool2d(4,4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32,64, kernel_size = (1,3), stride = 1, padding = 1).double(),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3,3),\n",
        "            nn.Conv2d(64, 128, kernel_size = (1,3), stride = 1, padding = 1).double(),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128,500).double(),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(500, 3).double()\n",
        "\n",
        "        )\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "metadata": {
        "id": "_WYY_gw_t6HT"
      },
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "  \n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "  \n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
        "    \n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(),lr)\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    \n",
        "    return history"
      ],
      "metadata": {
        "id": "lz5bvyy4t6Uk"
      },
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = StockShiftClassification()"
      ],
      "metadata": {
        "id": "q47Br6aJ2UI9"
      },
      "execution_count": 483,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001\n",
        "#fitting the model on training data and record the result after each epoch\n",
        "history = fit(num_epochs, lr, model, train_loader, val_loader, opt_func)"
      ],
      "metadata": {
        "id": "V75yN32gt6Y7",
        "outputId": "3edb5ee7-213c-4660-f3bb-35136db68935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": 484,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-484-737b2e6251a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#fitting the model on training data and record the result after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-482-ce213bce9de3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-482-ce213bce9de3>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-480-695185efab90>\u001b[0m in \u001b[0;36mvalidation_epoch_end\u001b[0;34m(self, outputs)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mbatch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m           \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Combine losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P840VkA9t6ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2JpYyBDjt6fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        #Input shape: (batch_size,1,5,24)\n",
        "        \n",
        "        # Convolutional 1 layer: 1x3 kernel, stride=1, padding=0, 32 output channels / feature maps\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=(1,3), stride=1, padding=1)\n",
        "        # Conv1 layer output size = (W-F+2P)/S+1 = (5-(3))/1+1 = 1\n",
        "        # Conv1 layer output shape for one image: [1,5,24]\n",
        "        \n",
        "        # Maxpool layer: kernel_size=4, stride=4\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=4, stride=4)\n",
        "        # Pool output shape for one image: [10,13,13]\n",
        "        \n",
        "        # Convolutional 2 layer: 3x3 kernel, stride=1, padding=0, 20 output channels / feature maps\n",
        "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=(1,3), stride=1, padding=0)\n",
        "        # Conv2 layer output size = (W-F+2P)/S+1 = (13-3)/1+1 = 11\n",
        "        # Conv2 layer output shape for one image: [20,11,11]\n",
        "        \n",
        "        # Maxpool layer: kernel_size=2, stride=2\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "        # Pool output shape for one image: [20,5,5]\n",
        "\n",
        "        # Convolutional 2 layer: 3x3 kernel, stride=1, padding=0, 20 output channels / feature maps\n",
        "        self.conv3 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=(1,3), stride=1, padding=0)\n",
        "        # Conv2 layer output size = (W-F+2P)/S+1 = (13-3)/1+1 = 11\n",
        "        # Conv2 layer output shape for one image: [20,11,11]\n",
        "        \n",
        "        # Maxpool layer: kernel_size=2, stride=2\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Pool output shape for one image: [20,5,5]\n",
        "        \n",
        "        # Input size: 20 * 5 * 5 = 500 from pool2 pooling layer\n",
        "        # 10 output channels (for the 10 classes)\n",
        "        self.fc1 = nn.Linear(1000, 3)\n",
        "\n",
        "        self.fc2 = nn.Linear(500, 3)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Two convolutional layers followed by relu and then pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # Flatten into a vector to feed into linear layer\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # Linear layer\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "2pYziwM8jixU"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "net = ConvNet()\n",
        "\n",
        "# Display a summary of the layers of the model and output shape after each layer\n",
        "summary(net,(windows.shape[1:]),batch_size=batch_size,device=\"cpu\")"
      ],
      "metadata": {
        "id": "iqovPJgsji5l",
        "outputId": "80b08329-23c3-4763-f5c3-ee9320062b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-248-c95153ad921c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Display a summary of the layers of the model and output shape after each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-247-3c9fa9d6e17f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Two convolutional layers followed by relu and then pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     88\u001b[0m         return F.max_pool1d(input, self.kernel_size, self.stride,\n\u001b[1;32m     89\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool1d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 2 to 3 dimensions, but got 4-dimensional tensor for argument #1 'self' (while checking arguments for max_pool1d)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            Conv2d(1, 32, kernel_size=(1,3), stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool2d(kernel_size=1, stride=4),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(32, 64, kernel_size=(1,3), stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool2d(kernel_size=1, stride=3),\n",
        "        )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(4 * 7 * 7, 10)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8_sqJggVfOMj"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.07)\n",
        "# defining the loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    \n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi-Y6h3lfOPC",
        "outputId": "ffb95a21-69e7-4631-9ac3-cc340883f394"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=1, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=1, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=196, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    # getting the training set\n",
        "    x_train, y_train = Variable(train_x), Variable(train_y)\n",
        "    # getting the validation set\n",
        "    x_val, y_val = Variable(val_x), Variable(val_y)\n",
        "    # converting the data into GPU format\n",
        "    if torch.cuda.is_available():\n",
        "        x_train = x_train.cuda()\n",
        "        y_train = y_train.cuda()\n",
        "        x_val = x_val.cuda()\n",
        "        y_val = y_val.cuda()\n",
        "\n",
        "    # clearing the Gradients of the model parameters\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # prediction for training and validation set\n",
        "    output_train = model(x_train)\n",
        "    output_val = model(x_val)\n",
        "\n",
        "    # computing the training and validation loss\n",
        "    loss_train = criterion(output_train, y_train)\n",
        "    loss_val = criterion(output_val, y_val)\n",
        "    train_losses.append(loss_train)\n",
        "    val_losses.append(loss_val)\n",
        "\n",
        "    # computing the updated weights of all the model parameters\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    tr_loss = loss_train.item()\n",
        "    if epoch%2 == 0:\n",
        "        # printing the validation loss\n",
        "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)"
      ],
      "metadata": {
        "id": "jKPFOKxOfORP"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the number of epochs\n",
        "n_epochs = 25\n",
        "# empty list to store training losses\n",
        "train_losses = []\n",
        "# empty list to store validation losses\n",
        "val_losses = []\n",
        "# training the model\n",
        "for epoch in range(n_epochs):\n",
        "    train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "1pE-ATsFfOVJ",
        "outputId": "4131b224-7e71-4fe3-ca77-96d2d22b327e"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-200-6618bd6c6ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-197-bfc961c39402>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# prediction for training and validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0moutput_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moutput_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-195-ea006f1a9164>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Defining the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ppUSwLlffOYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lGrkKxXpfObh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "87wjhtIUfOei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eTahPMf3fOgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tUSRmSLtfOi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierDataset():\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "\n",
        "train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "val_dataset = ClassifierDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
        "test_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())"
      ],
      "metadata": {
        "id": "T4aSyHl1YCmE"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 300\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 0.0007\n",
        "NUM_FEATURES = 24\n",
        "NUM_CLASSES = 3"
      ],
      "metadata": {
        "id": "F1mco0NhYCqd"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE\n",
        ")\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=1)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "iww7ffyrYCuU"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class MulticlassClassification(nn.Module):\n",
        "#     def __init__(self, num_feature, num_class):\n",
        "#         super(MulticlassClassification, self).__init__()\n",
        "        \n",
        "#         self.layer_1 = nn.Linear(num_feature, 32)\n",
        "#         self.layer_2 = nn.Linear(32, 64)\n",
        "#         self.layer_3 = nn.Linear(64, 128)\n",
        "#         self.layer_out = nn.Linear(128, num_class) \n",
        "        \n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.dropout = nn.Dropout(p=0.2)\n",
        "#         self.batchnorm1 = nn.BatchNorm1d(5)\n",
        "#         self.batchnorm2 = nn.BatchNorm1d(5)\n",
        "#         self.batchnorm3 = nn.BatchNorm1d(5)\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         x = self.layer_1(x)\n",
        "#         x = self.batchnorm1(x)\n",
        "#         x = self.relu(x)\n",
        "        \n",
        "#         x = self.layer_2(x)\n",
        "#         x = self.batchnorm2(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.dropout(x)\n",
        "        \n",
        "#         x = self.layer_3(x)\n",
        "#         x = self.batchnorm3(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.dropout(x)\n",
        "        \n",
        "#         x = self.layer_out(x)\n",
        "        \n",
        "#         return x\n",
        "\n",
        "class MulticlassClassification(nn.Module):\n",
        "    def __init__(self,D_in,H,D_out):\n",
        "        super(MulticlassClassification,self).__init__()\n",
        "        self.linear1=nn.Linear(D_in,H)\n",
        "        self.linear2=nn.Linear(H,D_out)\n",
        "\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x=torch.sigmoid(self.linear1(x))  \n",
        "        x=self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "OebWQr9rYCxf"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "###################### OUTPUT ######################\n",
        "cuda:0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAagy-FIYC0N",
        "outputId": "7ca0af2e-ace9-41bc-b43a-b370f12c7c15"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim= 24     # how many Variables are in the dataset\n",
        "hidden_dim = 32 # hidden layers\n",
        "output_dim= 1   # number of classes"
      ],
      "metadata": {
        "id": "p2wHGM9Ydxdx"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MulticlassClassification(input_dim,hidden_dim,output_dim)#num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S40u_AdscKq5",
        "outputId": "ed7570e3-9bc6-45e5-9375-f26fc0478168"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MulticlassClassification(\n",
            "  (linear1): Linear(in_features=24, out_features=32, bias=True)\n",
            "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
        "    \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum() / len(correct_pred)\n",
        "    \n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "metadata": {
        "id": "hZAv8QiccK5q"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_stats = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}\n",
        "loss_stats = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}"
      ],
      "metadata": {
        "id": "g9DgGw-wcK9x"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Begin training.\")\n",
        "\n",
        "for e in tqdm(range(1, EPOCHS+1)):\n",
        "    \n",
        "  # TRAINING\n",
        "  train_epoch_loss = 0\n",
        "  train_epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for X_train_batch, y_train_batch in train_loader:\n",
        "\n",
        "    X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    y_train_pred = model(X_train_batch)\n",
        "    \n",
        "    train_loss = criterion(y_train_pred, y_train_batch)\n",
        "    train_acc = multi_acc(y_train_pred, y_train_batch)\n",
        "    \n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    train_epoch_loss += train_loss.item()\n",
        "    train_epoch_acc += train_acc.item()\n",
        "      \n",
        "      \n",
        "  # VALIDATION    \n",
        "  with torch.no_grad():\n",
        "      \n",
        "    val_epoch_loss = 0\n",
        "    val_epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    for X_val_batch, y_val_batch in val_loader:\n",
        "      X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
        "      \n",
        "      y_val_pred = model(X_val_batch)\n",
        "                  \n",
        "      val_loss = criterion(y_val_pred, y_val_batch)\n",
        "      val_acc = multi_acc(y_val_pred, y_val_batch)\n",
        "      \n",
        "      val_epoch_loss += val_loss.item()\n",
        "      val_epoch_acc += val_acc.item()\n",
        "          \n",
        "  loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
        "  loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
        "  accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
        "  accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
        "                                \n",
        "      \n",
        "  print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429,
          "referenced_widgets": [
            "cb7c9f3f250d4f37923a9ad7a3130a11",
            "af033a719fd04de3b4c61ae772b2d7f8",
            "b274d8f4515c4a0fb5d16f748fb9ecaa",
            "b986c5f0b0884798a911cbf6098cfed1",
            "7b583b3725514b618b448fe651360da6",
            "239b2669ac5d4a06871258137955bb5a",
            "d9ae8ac19b274f4fa1d67a6da52e5952",
            "4cb9db32a0dc4cfa80df2aef87700fc2",
            "59fd93c3786d446db0298a0be0244929",
            "18edccce3ce54ae1940062f7d6b56d33",
            "37cd085fd4b34d6ba130eb897c098f72"
          ]
        },
        "id": "ZCQIwNiwcLBh",
        "outputId": "6a44bc0d-a612-4dfb-e9ad-def77f7608fb"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb7c9f3f250d4f37923a9ad7a3130a11",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-9697e09c84a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [1, 1], got [1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "21avcJKEcLE6"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_x = torch.Tensor(X_train) # transform to torch tensor\n",
        "tensor_y = torch.Tensor(y_train)\n",
        "\n",
        "my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
        "my_dataloader = DataLoader(my_dataset) # create your dataloader"
      ],
      "metadata": {
        "id": "z5IITTxfVgNg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, BatchNorm2d, Dropout, Sigmoid\n",
        "\n",
        "# def define_model(num_features, num_filter, drop):\n",
        "#     model = Sequential()\n",
        "#     model.add_module('conv1', Conv2d(1, num_filter, kernel_size=(1, num_features)))\n",
        "#     model.add_module('relu1', ReLU())\n",
        "#     model.add_module('conv2', Conv2d(num_filter, num_filter, kernel_size=(3, 1)))\n",
        "#     model.add_module('relu2', ReLU())\n",
        "#     model.add_module('pool1', MaxPool2d(kernel_size=(2, 1)))\n",
        "#     model.add_module('conv3', Conv2d(num_filter, num_filter, kernel_size=(3, 1)))\n",
        "#     model.add_module('relu3', ReLU())\n",
        "#     model.add_module('pool2', MaxPool2d(kernel_size=(2, 1)))\n",
        "\n",
        "\n",
        "class CNNpred(Module):\n",
        "    def __init__(self, num_features, num_filter, drop):\n",
        "        super(CNNpred, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2d(1, 1, kernel_size=(1, 3))\n",
        "        self.relu1 = ReLU()\n",
        "        # self.conv2 = Conv2d(num_filter, num_filter, kernel_size=(3, 1))\n",
        "        # self.relu2 = ReLU()\n",
        "        # self.pool1 = MaxPool2d(kernel_size=(2, 1))\n",
        "        # self.conv3 = Conv2d(num_filter, num_filter, kernel_size=(3, 1))\n",
        "        # self.relu3 = ReLU()\n",
        "        # self.pool2 = MaxPool2d(kernel_size=(2, 1))\n",
        "        # self.drop1 = Dropout(drop)\n",
        "        self.fc1 = Linear(100, 1)\n",
        "        self.sig1 = Sigmoid()\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.conv1(x))\n",
        "        # x = self.relu2(self.conv2(x))\n",
        "        # x = self.pool1(x)\n",
        "        # x = self.relu3(self.conv3(x))\n",
        "        # x = self.pool2(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.sig1(self.fc1(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZAle1rBOVs-3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "net = CNNpred(3, 32, 0)\n",
        "\n",
        "# Display a summary of the layers of the model and output shape after each layer\n",
        "summary(net,(X_train.shape[1:]),batch_size=batchSize,device=\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "KFHObysQVtFI",
        "outputId": "027059ed-201f-435f-fb44-1335f98a7aa6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-93e905d35214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Display a summary of the layers of the model and output shape after each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-b450c58e8188>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Defining the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# x = self.relu2(self.conv2(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# x = self.pool1(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [1, 1, 1, 3], but got 3-dimensional input of size [2, 5, 24] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PR6eilJcVtKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0RugbaScVtO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "for i in range(len(X_train)):\n",
        "   train_data.append([X_train[i], y_train[i]])\n",
        "\n",
        "batchSize = 10 # attempting to do not use batch to begin with\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, \n",
        "                                          shuffle=False)\n",
        "i1, l1 = next(iter(trainloader))\n",
        "print(i1.shape, l1.shape)"
      ],
      "metadata": {
        "id": "36-O49VmD5lC",
        "outputId": "cfd890f6-cb37-4fcd-9115-223cb9481bda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 24]) torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h-7_hPZTtM1",
        "outputId": "f01534c1-f3ad-47dd-af29-aaec20813c94"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
            "    the given dataset.\n",
            "\n",
            "    The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
            "    iterable-style datasets with single- or multi-process loading, customizing\n",
            "    loading order and optional automatic batching (collation) and memory pinning.\n",
            "\n",
            "    See :py:mod:`torch.utils.data` documentation page for more details.\n",
            "\n",
            "    Args:\n",
            "        dataset (Dataset): dataset from which to load the data.\n",
            "        batch_size (int, optional): how many samples per batch to load\n",
            "            (default: ``1``).\n",
            "        shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
            "            at every epoch (default: ``False``).\n",
            "        sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
            "            samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
            "            implemented. If specified, :attr:`shuffle` must not be specified.\n",
            "        batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
            "            returns a batch of indices at a time. Mutually exclusive with\n",
            "            :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
            "            and :attr:`drop_last`.\n",
            "        num_workers (int, optional): how many subprocesses to use for data\n",
            "            loading. ``0`` means that the data will be loaded in the main process.\n",
            "            (default: ``0``)\n",
            "        collate_fn (callable, optional): merges a list of samples to form a\n",
            "            mini-batch of Tensor(s).  Used when using batched loading from a\n",
            "            map-style dataset.\n",
            "        pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
            "            into CUDA pinned memory before returning them.  If your data elements\n",
            "            are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
            "            see the example below.\n",
            "        drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
            "            if the dataset size is not divisible by the batch size. If ``False`` and\n",
            "            the size of dataset is not divisible by the batch size, then the last batch\n",
            "            will be smaller. (default: ``False``)\n",
            "        timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
            "            from workers. Should always be non-negative. (default: ``0``)\n",
            "        worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
            "            worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
            "            input, after seeding and before data loading. (default: ``None``)\n",
            "        generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
            "            by RandomSampler to generate random indexes and multiprocessing to generate\n",
            "            `base_seed` for workers. (default: ``None``)\n",
            "        prefetch_factor (int, optional, keyword-only arg): Number of samples loaded\n",
            "            in advance by each worker. ``2`` means there will be a total of\n",
            "            2 * num_workers samples prefetched across all workers. (default: ``2``)\n",
            "        persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
            "            the worker processes after a dataset has been consumed once. This allows to\n",
            "            maintain the workers `Dataset` instances alive. (default: ``False``)\n",
            "\n",
            "\n",
            "    .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
            "                 cannot be an unpicklable object, e.g., a lambda function. See\n",
            "                 :ref:`multiprocessing-best-practices` on more details related\n",
            "                 to multiprocessing in PyTorch.\n",
            "\n",
            "    .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
            "                 When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
            "                 it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
            "                 rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
            "                 configurations. This represents the best guess PyTorch can make because PyTorch\n",
            "                 trusts user :attr:`dataset` code in correctly handling multi-process\n",
            "                 loading to avoid duplicate data.\n",
            "\n",
            "                 However, if sharding results in multiple workers having incomplete last batches,\n",
            "                 this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
            "                 be broken into multiple ones and (2) more than one batch worth of samples can be\n",
            "                 dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
            "                 cases in general.\n",
            "\n",
            "                 See `Dataset Types`_ for more details on these two types of datasets and how\n",
            "                 :class:`~torch.utils.data.IterableDataset` interacts with\n",
            "                 `Multi-process data loading`_.\n",
            "\n",
            "    .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
            "                 :ref:`data-loading-randomness` notes for random seed related questions.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "\n",
        "train_data = TrainData(X_train, \n",
        "                       y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "maZIheiYTecl",
        "outputId": "2c972422-5cce-416a-9883-9e486066a2ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a8a9fe8d606e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTrainData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  class ConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        #Input shape: (batch_size,1,5,24)\n",
        "        \n",
        "        # Convolutional 1 layer: 3x1 kernel, stride=1, padding=0, 10 output channels / feature maps\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,3), stride=1, padding=1)\n",
        "        # Conv1 layer output size = (W-F+2P)/S+1 = (5-3)/1+1 = 3\n",
        "        # Conv1 layer output shape for one array: [32,3,24]\n",
        "        \n",
        "        # Maxpool layer: kernel_size=4, stride=4\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=4, stride=4)\n",
        "        # Pool output shape for one image: [32,13,13]\n",
        "        \n",
        "        # # Convolutional 2 layer: 3x3 kernel, stride=1, padding=0, 20 output channels / feature maps\n",
        "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=(1,3), stride=1, padding=0)\n",
        "        # # Conv2 layer output size = (W-F+2P)/S+1 = (13-3)/1+1 = 11\n",
        "        # # Conv2 layer output shape for one image: [20,11,11]\n",
        "        \n",
        "        # # Maxpool layer: kernel_size=3, stride=3\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "        # # Pool output shape for one image: [20,5,5]\n",
        "        \n",
        "        # Input size: 20 * 5 * 5 = 500 from pool2 pooling layer\n",
        "        # 10 output channels (for the 10 classes)\n",
        "        self.fc1 = nn.Linear(100*3*24, 3)\n",
        "        self.fc2 = nn.Linear(100*3*24, 3)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Two convolutional layers followed by relu and then pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Flatten into a vector to feed into linear layer\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # Linear layer\n",
        "        x = self.fc1(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "9sJcmOJlD6mL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "net = ConvNet()\n",
        "\n",
        "# Display a summary of the layers of the model and output shape after each layer\n",
        "summary(net,(X_train.shape[1:]),batch_size=batchSize,device=\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "MpnkUKlsRsIT",
        "outputId": "68a646a5-a4e8-40dd-90ec-6264fddd84d0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-bd1bb5491dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Display a summary of the layers of the model and output shape after each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-2249c4384693>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;31m# Two convolutional layers followed by relu and then pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 1, 1, 3], but got 3-dimensional input of size [2, 5, 24] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "28fTMaQjJRJa",
        "outputId": "363233cf-b4e0-4e2f-c703-5bef324aa04d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNet(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=7200, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6V1E-likJRR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4IQpShuaJRVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AGriOafiJRYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AmiJKBpFJRcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tMWV1z-AJRfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCNNClassifier(nn.Module):\n",
        "    def __init__(self, in_c, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_c, 10, kernel_size=(1,3), stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(5, 5, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32 * 28 * 28, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(1024, n_classes)\n",
        "        )\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1) # flat\n",
        "        \n",
        "        x = self.decoder(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "vRnOtPPfJRAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  class ConvNet(nn.Module):\n",
        "\n",
        "     def __init__(self):\n",
        "\n",
        "       super(ConvNet, self).__init__()\n",
        "        #Input shape: (batch_size,1,5,24)\n",
        "\n",
        "       self.conv1 = nn.Conv2d(in_channels=1, out_channels=1000, kernel_size=(1,3), stride=1, padding=0)\n",
        "\n",
        "       self.pool1 = nn.Softmax2d()"
      ],
      "metadata": {
        "id": "BTYFSqv0C6GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "net = ConvNet()\n",
        "\n",
        "# Display a summary of the layers of the model and output shape after each layer\n",
        "summary(net,(X_train.shape[1:]),batch_size=batchSize,device=\"cpu\")"
      ],
      "metadata": {
        "id": "jAoO0wQCD6xE",
        "outputId": "187bd3ab-0268-4e2b-d6ab-836b55a71162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-bd1bb5491dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Display a summary of the layers of the model and output shape after each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-c841e2238479>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;31m# Two convolutional layers followed by relu and then pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [1000, 1, 1, 3], but got 3-dimensional input of size [2, 5, 24] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2XLg_I1oD7F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xhHP1aZFD7dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o55iMw16D7w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load necessary Pytorch packages\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import Tensor\n",
        "\n",
        "# Create dataset from several tensors with matching first dimension\n",
        "# Samples will be drawn from the first dimension (rows)\n",
        "dataset = TensorDataset(Tensor(X_train), Tensor(y_train))\n",
        "\n",
        "# Create a data loader from the dataset\n",
        "# Type of sampling and batch size are specified at this step\n",
        "loader = DataLoader(dataset, batch_size= 10)\n",
        "\n",
        "# Quick test\n",
        "# next(iter(loader))"
      ],
      "metadata": {
        "id": "nndqzAwWaDkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training 2 Hour Data Arrays: ', len(X_train))\n",
        "print('Test 2 Hour Data Arrays: ', len(X_test))\n",
        "\n",
        "# Specify the image classes\n",
        "classes = ['down', 'up', 'flat']\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgr6Wqww_ysP",
        "outputId": "e3f760cc-ba97-4520-e577-f268a340efad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 2 Hour Data Arrays:  5150\n",
            "Test 2 Hour Data Arrays:  2075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "igWE1iXMAiUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AisORvtID2qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Tacb8dQnD3on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iMemvboKD4tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MnQ70KkVAg-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LWzrD4TfaCfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create target from OHLC and Volume Data\n",
        "def buildTargets(full_df = full, train_observations = train.shape[0], \n",
        "                 val_observations = val.shape[0], \n",
        "                 test_observations = test.shape[0], \n",
        "                 shift_2hour = 24,\n",
        "                 alph = .55, \n",
        "                 volity_int = 10):\n",
        "\n",
        "  \"\"\" \n",
        "  This function will take a complete set of train, val, and test \n",
        "  data and return the targets. Volitility will be calculated over \n",
        "  the 252 5min incriments. The Target shift is looking at 2 hours \n",
        "  shift from current time\n",
        "\n",
        "  shift_2hour = The amount of time the data interval take to equal 2 hours \n",
        "                (i.e. 5 min data interval is equal to 25)\n",
        "  alph = The alpha value for calculating the shift in price\n",
        "  volity_int = the number of incriments used to calculate volitility \n",
        "  \"\"\"\n",
        "\n",
        "  returns = np.log(full_df['Close']/(full_df['Close'].shift(1)))\n",
        "  returns.fillna(0, inplace=True)\n",
        "  #volatility = returns.std()*np.sqrt(volity_int)\n",
        "  volatility = returns.rolling(window=volity_int).std()*np.sqrt(volity_int)\n",
        "\n",
        "  #print(len(full_df.Close), len(volatility))\n",
        "\n",
        "  targets = [\"flat\"] * len(full_df.Close)\n",
        "\n",
        "  targets = np.where(full_df.Close.shift(-shift_2hour) >= (full_df.Close * (1 + alph * volatility)), \n",
        "           \"up\", targets)\n",
        "  \n",
        "  targets = np.where(full_df.Close.shift(-shift_2hour) <= (full_df.Close * (1 - alph * volatility)), \n",
        "           \"down\", targets)\n",
        "\n",
        "  train_split = train_observations\n",
        "  val_split = train_observations + val_observations\n",
        "  test_split = train_observations + val_observations + test_observations\n",
        "\n",
        "  train_targets = targets[:train_split]\n",
        "  val_targets = targets[train_split:val_split]\n",
        "  test_targets = targets[val_split:test_split]\n",
        "  full_targets = targets\n",
        "\n",
        "  return train_targets, val_targets, test_targets, full_targets"
      ],
      "metadata": {
        "id": "9QkJt9YFBjz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9ylmZNfoLe4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_filtered = train.loc[:][train.index.indexer_between_time(time(7,30), time(16))]\n",
        "train_filtered = train.between_time('08:29','16:30')"
      ],
      "metadata": {
        "id": "7h1nzV77iNr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_filtered.index[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRbKVjtTnrDo",
        "outputId": "8f4092b7-f9e0-40cc-fecb-d46021f9877d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Timestamp('2017-01-03 09:00:00-0500', tz='US/Eastern')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_filtered.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ovajAAREl2HK",
        "outputId": "b440341d-81a0-43ea-ff06-d89861f4d8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7dc50b84-eca3-40b7-ae8d-0063f1d17194\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeWeightedAvgPrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:00:00-05:00</th>\n",
              "      <td>2017-01-03 09:00:00-05:00</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>7500</td>\n",
              "      <td>4.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:25:00-05:00</th>\n",
              "      <td>2017-01-03 09:25:00-05:00</td>\n",
              "      <td>4.58</td>\n",
              "      <td>4.58</td>\n",
              "      <td>4.55</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>1763</td>\n",
              "      <td>4.562643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:30:00-05:00</th>\n",
              "      <td>2017-01-03 09:30:00-05:00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>4.59</td>\n",
              "      <td>4.40</td>\n",
              "      <td>4.5701</td>\n",
              "      <td>358250</td>\n",
              "      <td>4.437890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:35:00-05:00</th>\n",
              "      <td>2017-01-03 09:35:00-05:00</td>\n",
              "      <td>4.57</td>\n",
              "      <td>4.58</td>\n",
              "      <td>4.51</td>\n",
              "      <td>4.5450</td>\n",
              "      <td>61552</td>\n",
              "      <td>4.536080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:40:00-05:00</th>\n",
              "      <td>2017-01-03 09:40:00-05:00</td>\n",
              "      <td>4.54</td>\n",
              "      <td>4.59</td>\n",
              "      <td>4.53</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>87664</td>\n",
              "      <td>4.561307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dc50b84-eca3-40b7-ae8d-0063f1d17194')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7dc50b84-eca3-40b7-ae8d-0063f1d17194 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7dc50b84-eca3-40b7-ae8d-0063f1d17194');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               Time  ...  VolumeWeightedAvgPrice\n",
              "timestamp                                            ...                        \n",
              "2017-01-03 09:00:00-05:00 2017-01-03 09:00:00-05:00  ...                4.560000\n",
              "2017-01-03 09:25:00-05:00 2017-01-03 09:25:00-05:00  ...                4.562643\n",
              "2017-01-03 09:30:00-05:00 2017-01-03 09:30:00-05:00  ...                4.437890\n",
              "2017-01-03 09:35:00-05:00 2017-01-03 09:35:00-05:00  ...                4.536080\n",
              "2017-01-03 09:40:00-05:00 2017-01-03 09:40:00-05:00  ...                4.561307\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_filtered.index[0].month"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaJe2QCUpahP",
        "outputId": "199c9ec5-b188-4a08-a8be-5946269cf406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TZ = 'US/Eastern'\n",
        "\n",
        "start_dateTime = pd.Timestamp(year = train_filtered.index[0].year, \n",
        "                              month = train_filtered.index[0].month, \n",
        "                              day = train_filtered.index[0].day, \n",
        "                              hour = 7, minute = 25, tz = TZ)\n",
        "\n",
        "end_dateTime = pd.Timestamp(year = train_filtered.index[-1].year, \n",
        "                            month = train_filtered.index[-1].month, \n",
        "                            day = train_filtered.index[-1].day, \n",
        "                            hour = 17, minute = 30, tz = TZ)\n",
        "\n",
        "dateTime_index = pd.date_range(start_dateTime,\n",
        "                               end_dateTime, \n",
        "                               freq='5min').tolist()"
      ],
      "metadata": {
        "id": "o6lCrvvRoFGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dateTime_index_df = pd.DataFrame()\n",
        "dateTime_index_df[\"Time\"] = dateTime_index \n",
        "dateTime_index_df = dateTime_index_df.set_index(\"Time\")\n",
        "dateTime_index_df = dateTime_index_df.between_time('07:30','17:25')\n",
        "len(dateTime_index_df) % 24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6I4ajnwp3iN",
        "outputId": "c9f0949a-3855-4c90-b1b0-48142b6ff596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dateTime_index_df[0:240][-24:]"
      ],
      "metadata": {
        "id": "49mZ-bIbmYYT",
        "outputId": "b83c8796-d0a7-4e21-a812-fc8c51d916ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5fefdbae-7181-4879-a5a8-5901f73824aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-04 15:25:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 15:30:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 15:35:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 15:40:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 15:45:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 15:50:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 15:55:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:00:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:05:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:10:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:15:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:20:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:25:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:30:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:35:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:40:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:45:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:50:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 16:55:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 17:00:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 17:05:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 17:10:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 17:15:00-05:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 17:20:00-05:00</th>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fefdbae-7181-4879-a5a8-5901f73824aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5fefdbae-7181-4879-a5a8-5901f73824aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5fefdbae-7181-4879-a5a8-5901f73824aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: [2017-01-04 15:25:00-05:00, 2017-01-04 15:30:00-05:00, 2017-01-04 15:35:00-05:00, 2017-01-04 15:40:00-05:00, 2017-01-04 15:45:00-05:00, 2017-01-04 15:50:00-05:00, 2017-01-04 15:55:00-05:00, 2017-01-04 16:00:00-05:00, 2017-01-04 16:05:00-05:00, 2017-01-04 16:10:00-05:00, 2017-01-04 16:15:00-05:00, 2017-01-04 16:20:00-05:00, 2017-01-04 16:25:00-05:00, 2017-01-04 16:30:00-05:00, 2017-01-04 16:35:00-05:00, 2017-01-04 16:40:00-05:00, 2017-01-04 16:45:00-05:00, 2017-01-04 16:50:00-05:00, 2017-01-04 16:55:00-05:00, 2017-01-04 17:00:00-05:00, 2017-01-04 17:05:00-05:00, 2017-01-04 17:10:00-05:00, 2017-01-04 17:15:00-05:00, 2017-01-04 17:20:00-05:00]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dateTime_index_df[24:48])"
      ],
      "metadata": {
        "id": "LBvxUL8vmSRs",
        "outputId": "7075158a-24f4-4e11-b61f-d5a075ee8b68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dateTime_index_df[-48:]"
      ],
      "metadata": {
        "id": "fYnzIkB9lwI0",
        "outputId": "98f6bbaf-ea9c-4a60-db95-8c6c0d7245c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b56ce570-3783-4f61-a996-ddc86112a517\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-10-30 13:35:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 13:40:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 13:45:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 13:50:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 13:55:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:00:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:05:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:10:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:15:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:20:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:25:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:30:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:35:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:40:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:45:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:50:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 14:55:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:00:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:05:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:10:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:15:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:20:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:25:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:30:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:35:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:40:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:45:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:50:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 15:55:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:00:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:05:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:10:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:15:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:20:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:25:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:30:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:35:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:40:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:45:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:50:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 16:55:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:00:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:05:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:10:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:15:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:20:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:25:00-04:00</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-30 17:30:00-04:00</th>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b56ce570-3783-4f61-a996-ddc86112a517')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b56ce570-3783-4f61-a996-ddc86112a517 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b56ce570-3783-4f61-a996-ddc86112a517');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: [2019-10-30 13:35:00-04:00, 2019-10-30 13:40:00-04:00, 2019-10-30 13:45:00-04:00, 2019-10-30 13:50:00-04:00, 2019-10-30 13:55:00-04:00, 2019-10-30 14:00:00-04:00, 2019-10-30 14:05:00-04:00, 2019-10-30 14:10:00-04:00, 2019-10-30 14:15:00-04:00, 2019-10-30 14:20:00-04:00, 2019-10-30 14:25:00-04:00, 2019-10-30 14:30:00-04:00, 2019-10-30 14:35:00-04:00, 2019-10-30 14:40:00-04:00, 2019-10-30 14:45:00-04:00, 2019-10-30 14:50:00-04:00, 2019-10-30 14:55:00-04:00, 2019-10-30 15:00:00-04:00, 2019-10-30 15:05:00-04:00, 2019-10-30 15:10:00-04:00, 2019-10-30 15:15:00-04:00, 2019-10-30 15:20:00-04:00, 2019-10-30 15:25:00-04:00, 2019-10-30 15:30:00-04:00, 2019-10-30 15:35:00-04:00, 2019-10-30 15:40:00-04:00, 2019-10-30 15:45:00-04:00, 2019-10-30 15:50:00-04:00, 2019-10-30 15:55:00-04:00, 2019-10-30 16:00:00-04:00, 2019-10-30 16:05:00-04:00, 2019-10-30 16:10:00-04:00, 2019-10-30 16:15:00-04:00, 2019-10-30 16:20:00-04:00, 2019-10-30 16:25:00-04:00, 2019-10-30 16:30:00-04:00, 2019-10-30 16:35:00-04:00, 2019-10-30 16:40:00-04:00, 2019-10-30 16:45:00-04:00, 2019-10-30 16:50:00-04:00, 2019-10-30 16:55:00-04:00, 2019-10-30 17:00:00-04:00, 2019-10-30 17:05:00-04:00, 2019-10-30 17:10:00-04:00, 2019-10-30 17:15:00-04:00, 2019-10-30 17:20:00-04:00, 2019-10-30 17:25:00-04:00, 2019-10-30 17:30:00-04:00]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dateTime_index[18] == train_filtered[\"Time\"][0]"
      ],
      "metadata": {
        "id": "ODzRQAYNEL_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a4b51a-53f5-4125-d3ca-8abbf9cc485e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dateTime_index_df = pd.DataFrame()\n",
        "dateTime_index_df[\"Time\"] = dateTime_index \n",
        "final_train = pd.merge_asof(dateTime_index_df, train_filtered, on='Time', direction='backward').set_index(\"Time\").between_time('08:29','16:30')"
      ],
      "metadata": {
        "id": "sHmgnwvRJptC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "volumeset_list = []\n",
        "\n",
        "prev_v = None\n",
        "\n",
        "for v in final_train[\"Volume\"]:\n",
        "  \n",
        "  if prev_v == None:\n",
        "      \n",
        "    if math.isnan(v):\n",
        "      prev_v = 0\n",
        "      volumeset_list.append(0)\n",
        "\n",
        "    else:\n",
        "      prev_v = v\n",
        "      volumeset_list.append(v)\n",
        "\n",
        "  elif prev_v != None:\n",
        "    \n",
        "    if v == prev_v:\n",
        "      volumeset_list.append(0)\n",
        "      prev_v = v\n",
        "\n",
        "    elif math.isnan(v):\n",
        "      volumeset_list.append(0)\n",
        "      prev_v = 0\n",
        "    \n",
        "    else:\n",
        "      volumeset_list.append(v)\n",
        "      prev_v = v\n",
        "\n",
        "\n",
        "final_train[\"Volume\"] = volumeset_list\n",
        "\n",
        "adjvolumeset_list = []\n",
        "\n",
        "prev_v = None\n",
        "\n",
        "for v in final_train[\"VolumeWeightedAvgPrice\"]:\n",
        "  \n",
        "  if prev_v == None:\n",
        "    \n",
        "    if math.isnan(v):\n",
        "      prev_v = 0\n",
        "      adjvolumeset_list.append(0)\n",
        "\n",
        "    else:\n",
        "      prev_v = v\n",
        "      adjvolumeset_list.append(v)\n",
        "\n",
        "  elif prev_v != None:\n",
        "    \n",
        "    if v == prev_v:\n",
        "      adjvolumeset_list.append(0)\n",
        "      prev_v = v\n",
        "\n",
        "    elif math.isnan(v):\n",
        "      adjvolumeset_list.append(0)\n",
        "      prev_v = 0\n",
        "    \n",
        "    else:\n",
        "      adjvolumeset_list.append(v)\n",
        "      prev_v = v\n",
        "\n",
        "\n",
        "final_train[\"VolumeWeightedAvgPrice\"] = adjvolumeset_list"
      ],
      "metadata": {
        "id": "xv_VAgq2TNYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_train.backfill().head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "0KcWRUydKZHw",
        "outputId": "b491db76-e257-41fb-8fab-dc2d5172eaa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b8ddd389-2c57-4dc4-b80a-bfb4a6138d49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeWeightedAvgPrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-03 08:30:00-05:00</th>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 08:35:00-05:00</th>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 08:40:00-05:00</th>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 08:45:00-05:00</th>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 08:50:00-05:00</th>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8ddd389-2c57-4dc4-b80a-bfb4a6138d49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8ddd389-2c57-4dc4-b80a-bfb4a6138d49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8ddd389-2c57-4dc4-b80a-bfb4a6138d49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           Open  High  ...  Volume  VolumeWeightedAvgPrice\n",
              "Time                                   ...                                \n",
              "2017-01-03 08:30:00-05:00  4.56  4.56  ...     0.0                     0.0\n",
              "2017-01-03 08:35:00-05:00  4.56  4.56  ...     0.0                     0.0\n",
              "2017-01-03 08:40:00-05:00  4.56  4.56  ...     0.0                     0.0\n",
              "2017-01-03 08:45:00-05:00  4.56  4.56  ...     0.0                     0.0\n",
              "2017-01-03 08:50:00-05:00  4.56  4.56  ...     0.0                     0.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0P0EAJKoTKYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_train[150:175]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "LIMD8D_gJlHX",
        "outputId": "b5d76df5-82b4-4f98-f03b-da69b5812921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f86fd4c1-0018-4088-961d-7ef344999181\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeWeightedAvgPrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-04 12:55:00-05:00</th>\n",
              "      <td>4.705</td>\n",
              "      <td>4.7050</td>\n",
              "      <td>4.680</td>\n",
              "      <td>4.6800</td>\n",
              "      <td>8393.0</td>\n",
              "      <td>4.694557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:00:00-05:00</th>\n",
              "      <td>4.681</td>\n",
              "      <td>4.6950</td>\n",
              "      <td>4.680</td>\n",
              "      <td>4.6950</td>\n",
              "      <td>17365.0</td>\n",
              "      <td>4.683002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:05:00-05:00</th>\n",
              "      <td>4.695</td>\n",
              "      <td>4.6950</td>\n",
              "      <td>4.670</td>\n",
              "      <td>4.6900</td>\n",
              "      <td>23142.0</td>\n",
              "      <td>4.682517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:10:00-05:00</th>\n",
              "      <td>4.680</td>\n",
              "      <td>4.7000</td>\n",
              "      <td>4.680</td>\n",
              "      <td>4.6950</td>\n",
              "      <td>13843.0</td>\n",
              "      <td>4.696232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:15:00-05:00</th>\n",
              "      <td>4.695</td>\n",
              "      <td>4.7000</td>\n",
              "      <td>4.690</td>\n",
              "      <td>4.6950</td>\n",
              "      <td>6904.0</td>\n",
              "      <td>4.692220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:20:00-05:00</th>\n",
              "      <td>4.695</td>\n",
              "      <td>4.7100</td>\n",
              "      <td>4.690</td>\n",
              "      <td>4.6950</td>\n",
              "      <td>9336.0</td>\n",
              "      <td>4.697439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:25:00-05:00</th>\n",
              "      <td>4.690</td>\n",
              "      <td>4.6950</td>\n",
              "      <td>4.680</td>\n",
              "      <td>4.6850</td>\n",
              "      <td>22448.0</td>\n",
              "      <td>4.683402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:30:00-05:00</th>\n",
              "      <td>4.680</td>\n",
              "      <td>4.6950</td>\n",
              "      <td>4.670</td>\n",
              "      <td>4.6700</td>\n",
              "      <td>27062.0</td>\n",
              "      <td>4.674104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:35:00-05:00</th>\n",
              "      <td>4.665</td>\n",
              "      <td>4.6741</td>\n",
              "      <td>4.660</td>\n",
              "      <td>4.6700</td>\n",
              "      <td>6519.0</td>\n",
              "      <td>4.669227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:40:00-05:00</th>\n",
              "      <td>4.670</td>\n",
              "      <td>4.6700</td>\n",
              "      <td>4.660</td>\n",
              "      <td>4.6650</td>\n",
              "      <td>5500.0</td>\n",
              "      <td>4.661091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:45:00-05:00</th>\n",
              "      <td>4.660</td>\n",
              "      <td>4.6650</td>\n",
              "      <td>4.660</td>\n",
              "      <td>4.6600</td>\n",
              "      <td>13388.0</td>\n",
              "      <td>4.660073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:50:00-05:00</th>\n",
              "      <td>4.660</td>\n",
              "      <td>4.6600</td>\n",
              "      <td>4.650</td>\n",
              "      <td>4.6550</td>\n",
              "      <td>3902.0</td>\n",
              "      <td>4.654708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 13:55:00-05:00</th>\n",
              "      <td>4.660</td>\n",
              "      <td>4.6650</td>\n",
              "      <td>4.640</td>\n",
              "      <td>4.6400</td>\n",
              "      <td>6948.0</td>\n",
              "      <td>4.652804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:00:00-05:00</th>\n",
              "      <td>4.650</td>\n",
              "      <td>4.7000</td>\n",
              "      <td>4.650</td>\n",
              "      <td>4.6800</td>\n",
              "      <td>40412.0</td>\n",
              "      <td>4.679453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:05:00-05:00</th>\n",
              "      <td>4.680</td>\n",
              "      <td>4.7200</td>\n",
              "      <td>4.680</td>\n",
              "      <td>4.7063</td>\n",
              "      <td>13691.0</td>\n",
              "      <td>4.703559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:10:00-05:00</th>\n",
              "      <td>4.705</td>\n",
              "      <td>4.7400</td>\n",
              "      <td>4.700</td>\n",
              "      <td>4.7300</td>\n",
              "      <td>64218.0</td>\n",
              "      <td>4.724667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:15:00-05:00</th>\n",
              "      <td>4.730</td>\n",
              "      <td>4.7400</td>\n",
              "      <td>4.720</td>\n",
              "      <td>4.7400</td>\n",
              "      <td>35029.0</td>\n",
              "      <td>4.732411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:20:00-05:00</th>\n",
              "      <td>4.740</td>\n",
              "      <td>4.7400</td>\n",
              "      <td>4.705</td>\n",
              "      <td>4.7100</td>\n",
              "      <td>15670.0</td>\n",
              "      <td>4.725815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:25:00-05:00</th>\n",
              "      <td>4.710</td>\n",
              "      <td>4.7200</td>\n",
              "      <td>4.700</td>\n",
              "      <td>4.7000</td>\n",
              "      <td>11255.0</td>\n",
              "      <td>4.710061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:30:00-05:00</th>\n",
              "      <td>4.707</td>\n",
              "      <td>4.7070</td>\n",
              "      <td>4.680</td>\n",
              "      <td>4.6800</td>\n",
              "      <td>4567.0</td>\n",
              "      <td>4.694620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:35:00-05:00</th>\n",
              "      <td>4.680</td>\n",
              "      <td>4.6858</td>\n",
              "      <td>4.670</td>\n",
              "      <td>4.6700</td>\n",
              "      <td>11589.0</td>\n",
              "      <td>4.677072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:40:00-05:00</th>\n",
              "      <td>4.665</td>\n",
              "      <td>4.6800</td>\n",
              "      <td>4.650</td>\n",
              "      <td>4.6600</td>\n",
              "      <td>19472.0</td>\n",
              "      <td>4.663844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:45:00-05:00</th>\n",
              "      <td>4.665</td>\n",
              "      <td>4.6650</td>\n",
              "      <td>4.620</td>\n",
              "      <td>4.6300</td>\n",
              "      <td>47022.0</td>\n",
              "      <td>4.634922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:50:00-05:00</th>\n",
              "      <td>4.630</td>\n",
              "      <td>4.6400</td>\n",
              "      <td>4.620</td>\n",
              "      <td>4.6300</td>\n",
              "      <td>26628.0</td>\n",
              "      <td>4.628909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04 14:55:00-05:00</th>\n",
              "      <td>4.640</td>\n",
              "      <td>4.6600</td>\n",
              "      <td>4.640</td>\n",
              "      <td>4.6600</td>\n",
              "      <td>6104.0</td>\n",
              "      <td>4.650120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f86fd4c1-0018-4088-961d-7ef344999181')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f86fd4c1-0018-4088-961d-7ef344999181 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f86fd4c1-0018-4088-961d-7ef344999181');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                            Open    High  ...   Volume  VolumeWeightedAvgPrice\n",
              "Time                                      ...                                 \n",
              "2017-01-04 12:55:00-05:00  4.705  4.7050  ...   8393.0                4.694557\n",
              "2017-01-04 13:00:00-05:00  4.681  4.6950  ...  17365.0                4.683002\n",
              "2017-01-04 13:05:00-05:00  4.695  4.6950  ...  23142.0                4.682517\n",
              "2017-01-04 13:10:00-05:00  4.680  4.7000  ...  13843.0                4.696232\n",
              "2017-01-04 13:15:00-05:00  4.695  4.7000  ...   6904.0                4.692220\n",
              "2017-01-04 13:20:00-05:00  4.695  4.7100  ...   9336.0                4.697439\n",
              "2017-01-04 13:25:00-05:00  4.690  4.6950  ...  22448.0                4.683402\n",
              "2017-01-04 13:30:00-05:00  4.680  4.6950  ...  27062.0                4.674104\n",
              "2017-01-04 13:35:00-05:00  4.665  4.6741  ...   6519.0                4.669227\n",
              "2017-01-04 13:40:00-05:00  4.670  4.6700  ...   5500.0                4.661091\n",
              "2017-01-04 13:45:00-05:00  4.660  4.6650  ...  13388.0                4.660073\n",
              "2017-01-04 13:50:00-05:00  4.660  4.6600  ...   3902.0                4.654708\n",
              "2017-01-04 13:55:00-05:00  4.660  4.6650  ...   6948.0                4.652804\n",
              "2017-01-04 14:00:00-05:00  4.650  4.7000  ...  40412.0                4.679453\n",
              "2017-01-04 14:05:00-05:00  4.680  4.7200  ...  13691.0                4.703559\n",
              "2017-01-04 14:10:00-05:00  4.705  4.7400  ...  64218.0                4.724667\n",
              "2017-01-04 14:15:00-05:00  4.730  4.7400  ...  35029.0                4.732411\n",
              "2017-01-04 14:20:00-05:00  4.740  4.7400  ...  15670.0                4.725815\n",
              "2017-01-04 14:25:00-05:00  4.710  4.7200  ...  11255.0                4.710061\n",
              "2017-01-04 14:30:00-05:00  4.707  4.7070  ...   4567.0                4.694620\n",
              "2017-01-04 14:35:00-05:00  4.680  4.6858  ...  11589.0                4.677072\n",
              "2017-01-04 14:40:00-05:00  4.665  4.6800  ...  19472.0                4.663844\n",
              "2017-01-04 14:45:00-05:00  4.665  4.6650  ...  47022.0                4.634922\n",
              "2017-01-04 14:50:00-05:00  4.630  4.6400  ...  26628.0                4.628909\n",
              "2017-01-04 14:55:00-05:00  4.640  4.6600  ...   6104.0                4.650120\n",
              "\n",
              "[25 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(buildTargets.__doc__)\n",
        "train_targets, val_targets, test_targets, full_targets = buildTargets()"
      ],
      "metadata": {
        "id": "F6mH1R0qiKx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VuAVCxY2gMww",
        "outputId": "33bad82e-ff31-43e8-8e5e-51e247d1f231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-33614987-12cf-43f6-98fe-269a4b73b2bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeWeightedAvgPrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:00:00-05:00</th>\n",
              "      <td>2017-01-03 09:00:00-05:00</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>7500</td>\n",
              "      <td>4.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:25:00-05:00</th>\n",
              "      <td>2017-01-03 09:25:00-05:00</td>\n",
              "      <td>4.5800</td>\n",
              "      <td>4.5800</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>1763</td>\n",
              "      <td>4.562643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:30:00-05:00</th>\n",
              "      <td>2017-01-03 09:30:00-05:00</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>4.5900</td>\n",
              "      <td>4.4000</td>\n",
              "      <td>4.5701</td>\n",
              "      <td>358250</td>\n",
              "      <td>4.437890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:35:00-05:00</th>\n",
              "      <td>2017-01-03 09:35:00-05:00</td>\n",
              "      <td>4.5700</td>\n",
              "      <td>4.5800</td>\n",
              "      <td>4.5100</td>\n",
              "      <td>4.5450</td>\n",
              "      <td>61552</td>\n",
              "      <td>4.536080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:40:00-05:00</th>\n",
              "      <td>2017-01-03 09:40:00-05:00</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.5900</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>87664</td>\n",
              "      <td>4.561307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:45:00-05:00</th>\n",
              "      <td>2017-01-03 09:45:00-05:00</td>\n",
              "      <td>4.5700</td>\n",
              "      <td>4.6000</td>\n",
              "      <td>4.5650</td>\n",
              "      <td>4.5951</td>\n",
              "      <td>43690</td>\n",
              "      <td>4.584177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:50:00-05:00</th>\n",
              "      <td>2017-01-03 09:50:00-05:00</td>\n",
              "      <td>4.5950</td>\n",
              "      <td>4.6100</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>61430</td>\n",
              "      <td>4.587768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 09:55:00-05:00</th>\n",
              "      <td>2017-01-03 09:55:00-05:00</td>\n",
              "      <td>4.5550</td>\n",
              "      <td>4.5550</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>43106</td>\n",
              "      <td>4.535946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:00:00-05:00</th>\n",
              "      <td>2017-01-03 10:00:00-05:00</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.4500</td>\n",
              "      <td>4.4500</td>\n",
              "      <td>55444</td>\n",
              "      <td>4.488263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:05:00-05:00</th>\n",
              "      <td>2017-01-03 10:05:00-05:00</td>\n",
              "      <td>4.4550</td>\n",
              "      <td>4.4900</td>\n",
              "      <td>4.4500</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>38115</td>\n",
              "      <td>4.465588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:10:00-05:00</th>\n",
              "      <td>2017-01-03 10:10:00-05:00</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>4.4400</td>\n",
              "      <td>4.4429</td>\n",
              "      <td>39241</td>\n",
              "      <td>4.457837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:15:00-05:00</th>\n",
              "      <td>2017-01-03 10:15:00-05:00</td>\n",
              "      <td>4.4450</td>\n",
              "      <td>4.4700</td>\n",
              "      <td>4.4401</td>\n",
              "      <td>4.4600</td>\n",
              "      <td>52688</td>\n",
              "      <td>4.456842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:20:00-05:00</th>\n",
              "      <td>2017-01-03 10:20:00-05:00</td>\n",
              "      <td>4.4700</td>\n",
              "      <td>4.4890</td>\n",
              "      <td>4.4500</td>\n",
              "      <td>4.4643</td>\n",
              "      <td>95614</td>\n",
              "      <td>4.466767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:25:00-05:00</th>\n",
              "      <td>2017-01-03 10:25:00-05:00</td>\n",
              "      <td>4.4647</td>\n",
              "      <td>4.4870</td>\n",
              "      <td>4.4500</td>\n",
              "      <td>4.4847</td>\n",
              "      <td>71238</td>\n",
              "      <td>4.467272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:30:00-05:00</th>\n",
              "      <td>2017-01-03 10:30:00-05:00</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>4.4850</td>\n",
              "      <td>4.4400</td>\n",
              "      <td>4.4600</td>\n",
              "      <td>41404</td>\n",
              "      <td>4.453634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:35:00-05:00</th>\n",
              "      <td>2017-01-03 10:35:00-05:00</td>\n",
              "      <td>4.4550</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>4.4550</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>69770</td>\n",
              "      <td>4.463656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:40:00-05:00</th>\n",
              "      <td>2017-01-03 10:40:00-05:00</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>4.4900</td>\n",
              "      <td>4.4684</td>\n",
              "      <td>4.4684</td>\n",
              "      <td>31250</td>\n",
              "      <td>4.482387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:45:00-05:00</th>\n",
              "      <td>2017-01-03 10:45:00-05:00</td>\n",
              "      <td>4.4600</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>4.4600</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>23458</td>\n",
              "      <td>4.466456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:50:00-05:00</th>\n",
              "      <td>2017-01-03 10:50:00-05:00</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>43415</td>\n",
              "      <td>4.506305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 10:55:00-05:00</th>\n",
              "      <td>2017-01-03 10:55:00-05:00</td>\n",
              "      <td>4.5150</td>\n",
              "      <td>4.5250</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>4.5100</td>\n",
              "      <td>42144</td>\n",
              "      <td>4.516741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:00:00-05:00</th>\n",
              "      <td>2017-01-03 11:00:00-05:00</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5557</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>52934</td>\n",
              "      <td>4.532203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:05:00-05:00</th>\n",
              "      <td>2017-01-03 11:05:00-05:00</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>4.5165</td>\n",
              "      <td>21103</td>\n",
              "      <td>4.515950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:10:00-05:00</th>\n",
              "      <td>2017-01-03 11:10:00-05:00</td>\n",
              "      <td>4.5110</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5110</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>23062</td>\n",
              "      <td>4.530024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:15:00-05:00</th>\n",
              "      <td>2017-01-03 11:15:00-05:00</td>\n",
              "      <td>4.5100</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.4900</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>39054</td>\n",
              "      <td>4.510359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:20:00-05:00</th>\n",
              "      <td>2017-01-03 11:20:00-05:00</td>\n",
              "      <td>4.5350</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>31882</td>\n",
              "      <td>4.540344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:25:00-05:00</th>\n",
              "      <td>2017-01-03 11:25:00-05:00</td>\n",
              "      <td>4.5250</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.5250</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>17834</td>\n",
              "      <td>4.536608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:30:00-05:00</th>\n",
              "      <td>2017-01-03 11:30:00-05:00</td>\n",
              "      <td>4.5350</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>4.5100</td>\n",
              "      <td>13444</td>\n",
              "      <td>4.520468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:35:00-05:00</th>\n",
              "      <td>2017-01-03 11:35:00-05:00</td>\n",
              "      <td>4.5100</td>\n",
              "      <td>4.5150</td>\n",
              "      <td>4.4900</td>\n",
              "      <td>4.4984</td>\n",
              "      <td>16834</td>\n",
              "      <td>4.506870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:40:00-05:00</th>\n",
              "      <td>2017-01-03 11:40:00-05:00</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>4.5550</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>4.5456</td>\n",
              "      <td>57267</td>\n",
              "      <td>4.532815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:45:00-05:00</th>\n",
              "      <td>2017-01-03 11:45:00-05:00</td>\n",
              "      <td>4.5420</td>\n",
              "      <td>4.5900</td>\n",
              "      <td>4.5420</td>\n",
              "      <td>4.5710</td>\n",
              "      <td>80619</td>\n",
              "      <td>4.566270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:50:00-05:00</th>\n",
              "      <td>2017-01-03 11:50:00-05:00</td>\n",
              "      <td>4.5750</td>\n",
              "      <td>4.5750</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5256</td>\n",
              "      <td>52237</td>\n",
              "      <td>4.542966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 11:55:00-05:00</th>\n",
              "      <td>2017-01-03 11:55:00-05:00</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5250</td>\n",
              "      <td>4.5450</td>\n",
              "      <td>26438</td>\n",
              "      <td>4.533011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:00:00-05:00</th>\n",
              "      <td>2017-01-03 12:00:00-05:00</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5700</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>29467</td>\n",
              "      <td>4.543804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:05:00-05:00</th>\n",
              "      <td>2017-01-03 12:05:00-05:00</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5100</td>\n",
              "      <td>4.5150</td>\n",
              "      <td>10059</td>\n",
              "      <td>4.529591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:10:00-05:00</th>\n",
              "      <td>2017-01-03 12:10:00-05:00</td>\n",
              "      <td>4.5100</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.4800</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>76838</td>\n",
              "      <td>4.499523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:15:00-05:00</th>\n",
              "      <td>2017-01-03 12:15:00-05:00</td>\n",
              "      <td>4.5150</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>4.5150</td>\n",
              "      <td>9294</td>\n",
              "      <td>4.509715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:20:00-05:00</th>\n",
              "      <td>2017-01-03 12:20:00-05:00</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.5101</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>24381</td>\n",
              "      <td>4.521724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:25:00-05:00</th>\n",
              "      <td>2017-01-03 12:25:00-05:00</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.5150</td>\n",
              "      <td>4.5150</td>\n",
              "      <td>35693</td>\n",
              "      <td>4.528504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:30:00-05:00</th>\n",
              "      <td>2017-01-03 12:30:00-05:00</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>12900</td>\n",
              "      <td>4.523440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:35:00-05:00</th>\n",
              "      <td>2017-01-03 12:35:00-05:00</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.5550</td>\n",
              "      <td>4.5300</td>\n",
              "      <td>4.5450</td>\n",
              "      <td>17534</td>\n",
              "      <td>4.537848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:40:00-05:00</th>\n",
              "      <td>2017-01-03 12:40:00-05:00</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5550</td>\n",
              "      <td>8050</td>\n",
              "      <td>4.551894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:45:00-05:00</th>\n",
              "      <td>2017-01-03 12:45:00-05:00</td>\n",
              "      <td>4.5550</td>\n",
              "      <td>4.5700</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>29271</td>\n",
              "      <td>4.560563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:50:00-05:00</th>\n",
              "      <td>2017-01-03 12:50:00-05:00</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>5938</td>\n",
              "      <td>4.552849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 12:55:00-05:00</th>\n",
              "      <td>2017-01-03 12:55:00-05:00</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5700</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>20498</td>\n",
              "      <td>4.553835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 13:00:00-05:00</th>\n",
              "      <td>2017-01-03 13:00:00-05:00</td>\n",
              "      <td>4.5700</td>\n",
              "      <td>4.5800</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>15500</td>\n",
              "      <td>4.567958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 13:05:00-05:00</th>\n",
              "      <td>2017-01-03 13:05:00-05:00</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>10995</td>\n",
              "      <td>4.549926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 13:10:00-05:00</th>\n",
              "      <td>2017-01-03 13:10:00-05:00</td>\n",
              "      <td>4.5499</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>14047</td>\n",
              "      <td>4.551328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 13:15:00-05:00</th>\n",
              "      <td>2017-01-03 13:15:00-05:00</td>\n",
              "      <td>4.5600</td>\n",
              "      <td>4.5700</td>\n",
              "      <td>4.5400</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>45100</td>\n",
              "      <td>4.556153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 13:20:00-05:00</th>\n",
              "      <td>2017-01-03 13:20:00-05:00</td>\n",
              "      <td>4.5475</td>\n",
              "      <td>4.5500</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>29500</td>\n",
              "      <td>4.536898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-03 13:25:00-05:00</th>\n",
              "      <td>2017-01-03 13:25:00-05:00</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5650</td>\n",
              "      <td>4.5200</td>\n",
              "      <td>4.5650</td>\n",
              "      <td>37415</td>\n",
              "      <td>4.545181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33614987-12cf-43f6-98fe-269a4b73b2bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33614987-12cf-43f6-98fe-269a4b73b2bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33614987-12cf-43f6-98fe-269a4b73b2bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               Time  ...  VolumeWeightedAvgPrice\n",
              "timestamp                                            ...                        \n",
              "2017-01-03 09:00:00-05:00 2017-01-03 09:00:00-05:00  ...                4.560000\n",
              "2017-01-03 09:25:00-05:00 2017-01-03 09:25:00-05:00  ...                4.562643\n",
              "2017-01-03 09:30:00-05:00 2017-01-03 09:30:00-05:00  ...                4.437890\n",
              "2017-01-03 09:35:00-05:00 2017-01-03 09:35:00-05:00  ...                4.536080\n",
              "2017-01-03 09:40:00-05:00 2017-01-03 09:40:00-05:00  ...                4.561307\n",
              "2017-01-03 09:45:00-05:00 2017-01-03 09:45:00-05:00  ...                4.584177\n",
              "2017-01-03 09:50:00-05:00 2017-01-03 09:50:00-05:00  ...                4.587768\n",
              "2017-01-03 09:55:00-05:00 2017-01-03 09:55:00-05:00  ...                4.535946\n",
              "2017-01-03 10:00:00-05:00 2017-01-03 10:00:00-05:00  ...                4.488263\n",
              "2017-01-03 10:05:00-05:00 2017-01-03 10:05:00-05:00  ...                4.465588\n",
              "2017-01-03 10:10:00-05:00 2017-01-03 10:10:00-05:00  ...                4.457837\n",
              "2017-01-03 10:15:00-05:00 2017-01-03 10:15:00-05:00  ...                4.456842\n",
              "2017-01-03 10:20:00-05:00 2017-01-03 10:20:00-05:00  ...                4.466767\n",
              "2017-01-03 10:25:00-05:00 2017-01-03 10:25:00-05:00  ...                4.467272\n",
              "2017-01-03 10:30:00-05:00 2017-01-03 10:30:00-05:00  ...                4.453634\n",
              "2017-01-03 10:35:00-05:00 2017-01-03 10:35:00-05:00  ...                4.463656\n",
              "2017-01-03 10:40:00-05:00 2017-01-03 10:40:00-05:00  ...                4.482387\n",
              "2017-01-03 10:45:00-05:00 2017-01-03 10:45:00-05:00  ...                4.466456\n",
              "2017-01-03 10:50:00-05:00 2017-01-03 10:50:00-05:00  ...                4.506305\n",
              "2017-01-03 10:55:00-05:00 2017-01-03 10:55:00-05:00  ...                4.516741\n",
              "2017-01-03 11:00:00-05:00 2017-01-03 11:00:00-05:00  ...                4.532203\n",
              "2017-01-03 11:05:00-05:00 2017-01-03 11:05:00-05:00  ...                4.515950\n",
              "2017-01-03 11:10:00-05:00 2017-01-03 11:10:00-05:00  ...                4.530024\n",
              "2017-01-03 11:15:00-05:00 2017-01-03 11:15:00-05:00  ...                4.510359\n",
              "2017-01-03 11:20:00-05:00 2017-01-03 11:20:00-05:00  ...                4.540344\n",
              "2017-01-03 11:25:00-05:00 2017-01-03 11:25:00-05:00  ...                4.536608\n",
              "2017-01-03 11:30:00-05:00 2017-01-03 11:30:00-05:00  ...                4.520468\n",
              "2017-01-03 11:35:00-05:00 2017-01-03 11:35:00-05:00  ...                4.506870\n",
              "2017-01-03 11:40:00-05:00 2017-01-03 11:40:00-05:00  ...                4.532815\n",
              "2017-01-03 11:45:00-05:00 2017-01-03 11:45:00-05:00  ...                4.566270\n",
              "2017-01-03 11:50:00-05:00 2017-01-03 11:50:00-05:00  ...                4.542966\n",
              "2017-01-03 11:55:00-05:00 2017-01-03 11:55:00-05:00  ...                4.533011\n",
              "2017-01-03 12:00:00-05:00 2017-01-03 12:00:00-05:00  ...                4.543804\n",
              "2017-01-03 12:05:00-05:00 2017-01-03 12:05:00-05:00  ...                4.529591\n",
              "2017-01-03 12:10:00-05:00 2017-01-03 12:10:00-05:00  ...                4.499523\n",
              "2017-01-03 12:15:00-05:00 2017-01-03 12:15:00-05:00  ...                4.509715\n",
              "2017-01-03 12:20:00-05:00 2017-01-03 12:20:00-05:00  ...                4.521724\n",
              "2017-01-03 12:25:00-05:00 2017-01-03 12:25:00-05:00  ...                4.528504\n",
              "2017-01-03 12:30:00-05:00 2017-01-03 12:30:00-05:00  ...                4.523440\n",
              "2017-01-03 12:35:00-05:00 2017-01-03 12:35:00-05:00  ...                4.537848\n",
              "2017-01-03 12:40:00-05:00 2017-01-03 12:40:00-05:00  ...                4.551894\n",
              "2017-01-03 12:45:00-05:00 2017-01-03 12:45:00-05:00  ...                4.560563\n",
              "2017-01-03 12:50:00-05:00 2017-01-03 12:50:00-05:00  ...                4.552849\n",
              "2017-01-03 12:55:00-05:00 2017-01-03 12:55:00-05:00  ...                4.553835\n",
              "2017-01-03 13:00:00-05:00 2017-01-03 13:00:00-05:00  ...                4.567958\n",
              "2017-01-03 13:05:00-05:00 2017-01-03 13:05:00-05:00  ...                4.549926\n",
              "2017-01-03 13:10:00-05:00 2017-01-03 13:10:00-05:00  ...                4.551328\n",
              "2017-01-03 13:15:00-05:00 2017-01-03 13:15:00-05:00  ...                4.556153\n",
              "2017-01-03 13:20:00-05:00 2017-01-03 13:20:00-05:00  ...                4.536898\n",
              "2017-01-03 13:25:00-05:00 2017-01-03 13:25:00-05:00  ...                4.545181\n",
              "\n",
              "[50 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_targets[48:-1:24]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o30Rh1rZdNXz",
        "outputId": "2a0c5a63-f479-4876-c96e-05618613b163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['up', 'up', 'down', ..., 'flat', 'up', 'up'], dtype='<U4')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.iloc[71][\"Close\"])\n",
        "print(train.iloc[94][\"Close\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7O_fQOyfanl",
        "outputId": "3132a203-19b0-4fdb-f8b4-a4934d34e486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.57\n",
            "4.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test split pd DataFrame into arrays for running CNN on\n",
        "test_train_tonp = train[[\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "test_train_array = test_train_tonp.to_numpy()"
      ],
      "metadata": {
        "id": "CadOMouVfmrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hourmin_list = []\n",
        "\n",
        "for stamp in test_train_tonp[\"Time\"]:\n",
        "  hourmin_list.append(f'{stamp.hour}:{stamp.minute}')\n",
        "\n",
        "def unique(list1):\n",
        " \n",
        "    # initialize a null list\n",
        "    unique_list = []\n",
        "     \n",
        "    # traverse for all elements\n",
        "    for x in list1:\n",
        "        # check if exists in unique_list or not\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "    return unique_list\n",
        "     \n",
        "print(len(unique(hourmin_list)))\n",
        "sorted(unique(hourmin_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS5Kzi8q2kGB",
        "outputId": "1e55eda0-afc0-4a8b-c901-981c6c66e0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "183\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['10:0',\n",
              " '10:10',\n",
              " '10:15',\n",
              " '10:20',\n",
              " '10:25',\n",
              " '10:30',\n",
              " '10:35',\n",
              " '10:40',\n",
              " '10:45',\n",
              " '10:5',\n",
              " '10:50',\n",
              " '10:55',\n",
              " '11:0',\n",
              " '11:10',\n",
              " '11:15',\n",
              " '11:20',\n",
              " '11:25',\n",
              " '11:30',\n",
              " '11:35',\n",
              " '11:40',\n",
              " '11:45',\n",
              " '11:5',\n",
              " '11:50',\n",
              " '11:55',\n",
              " '12:0',\n",
              " '12:10',\n",
              " '12:15',\n",
              " '12:20',\n",
              " '12:25',\n",
              " '12:30',\n",
              " '12:35',\n",
              " '12:40',\n",
              " '12:45',\n",
              " '12:5',\n",
              " '12:50',\n",
              " '12:55',\n",
              " '13:0',\n",
              " '13:10',\n",
              " '13:15',\n",
              " '13:20',\n",
              " '13:25',\n",
              " '13:30',\n",
              " '13:35',\n",
              " '13:40',\n",
              " '13:45',\n",
              " '13:5',\n",
              " '13:50',\n",
              " '13:55',\n",
              " '14:0',\n",
              " '14:10',\n",
              " '14:15',\n",
              " '14:20',\n",
              " '14:25',\n",
              " '14:30',\n",
              " '14:35',\n",
              " '14:40',\n",
              " '14:45',\n",
              " '14:5',\n",
              " '14:50',\n",
              " '14:55',\n",
              " '15:0',\n",
              " '15:10',\n",
              " '15:15',\n",
              " '15:20',\n",
              " '15:25',\n",
              " '15:30',\n",
              " '15:35',\n",
              " '15:40',\n",
              " '15:45',\n",
              " '15:5',\n",
              " '15:50',\n",
              " '15:55',\n",
              " '16:0',\n",
              " '16:10',\n",
              " '16:15',\n",
              " '16:20',\n",
              " '16:25',\n",
              " '16:30',\n",
              " '16:35',\n",
              " '16:40',\n",
              " '16:45',\n",
              " '16:5',\n",
              " '16:50',\n",
              " '16:55',\n",
              " '17:0',\n",
              " '17:10',\n",
              " '17:15',\n",
              " '17:20',\n",
              " '17:25',\n",
              " '17:30',\n",
              " '17:35',\n",
              " '17:40',\n",
              " '17:45',\n",
              " '17:5',\n",
              " '17:50',\n",
              " '17:55',\n",
              " '18:0',\n",
              " '18:10',\n",
              " '18:15',\n",
              " '18:20',\n",
              " '18:25',\n",
              " '18:30',\n",
              " '18:35',\n",
              " '18:40',\n",
              " '18:45',\n",
              " '18:5',\n",
              " '18:50',\n",
              " '18:55',\n",
              " '19:0',\n",
              " '19:10',\n",
              " '19:15',\n",
              " '19:20',\n",
              " '19:25',\n",
              " '19:30',\n",
              " '19:35',\n",
              " '19:40',\n",
              " '19:45',\n",
              " '19:5',\n",
              " '19:50',\n",
              " '19:55',\n",
              " '20:0',\n",
              " '20:10',\n",
              " '20:15',\n",
              " '20:20',\n",
              " '20:5',\n",
              " '4:0',\n",
              " '4:15',\n",
              " '4:20',\n",
              " '4:25',\n",
              " '4:35',\n",
              " '4:40',\n",
              " '4:5',\n",
              " '5:0',\n",
              " '5:25',\n",
              " '5:30',\n",
              " '5:35',\n",
              " '5:40',\n",
              " '5:45',\n",
              " '5:5',\n",
              " '5:50',\n",
              " '6:0',\n",
              " '6:15',\n",
              " '6:20',\n",
              " '6:35',\n",
              " '6:40',\n",
              " '6:45',\n",
              " '6:50',\n",
              " '7:0',\n",
              " '7:10',\n",
              " '7:15',\n",
              " '7:20',\n",
              " '7:25',\n",
              " '7:30',\n",
              " '7:35',\n",
              " '7:40',\n",
              " '7:45',\n",
              " '7:5',\n",
              " '7:50',\n",
              " '7:55',\n",
              " '8:0',\n",
              " '8:10',\n",
              " '8:15',\n",
              " '8:20',\n",
              " '8:25',\n",
              " '8:30',\n",
              " '8:35',\n",
              " '8:40',\n",
              " '8:45',\n",
              " '8:5',\n",
              " '8:50',\n",
              " '8:55',\n",
              " '9:0',\n",
              " '9:10',\n",
              " '9:15',\n",
              " '9:20',\n",
              " '9:25',\n",
              " '9:30',\n",
              " '9:35',\n",
              " '9:40',\n",
              " '9:45',\n",
              " '9:5',\n",
              " '9:50',\n",
              " '9:55']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff = len(test_train_array) % 24\n",
        "test_train_array = test_train_array[:-cutoff]\n",
        "len(test_train_array) % 24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H4r7Yczjnpt",
        "outputId": "08186638-eb92-49b0-f012-caa9d6f31504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff = len(test_train_array) % 24\n",
        "test_train_array = test_train_array[:-cutoff]\n",
        "len(test_train_array) % 24\n",
        "\n",
        "def blockshaped(arr, nrows, ncols):\n",
        "    \"\"\"\n",
        "    Return an array of shape (n, nrows, ncols) where\n",
        "    n * nrows * ncols = arr.size\n",
        "\n",
        "    If arr is a 2D array, the returned array should look like n subblocks with\n",
        "    each subblock preserving the \"physical\" layout of arr.\n",
        "    \"\"\"\n",
        "    h, w = arr.shape\n",
        "    assert h % nrows == 0, f\"{h} rows is not evenly divisible by {nrows}\"\n",
        "    assert w % ncols == 0, f\"{w} cols is not evenly divisible by {ncols}\"\n",
        "    return (arr.reshape(h//nrows, nrows, -1, ncols)\n",
        "               .swapaxes(1,2)\n",
        "               .reshape(-1, nrows, ncols))\n",
        "  \n",
        "\n",
        "np.set_printoptions(linewidth=100)\n",
        "print(blockshaped(test_train_array, 24, 6)[1].shape)\n",
        "X_Train = blockshaped(test_train_array, 24, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU_9osOThQ0k",
        "outputId": "f39934e4-3709-46a2-e089-d99e9375c2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=110)\n",
        "X_Train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxOt0QXI1jkn",
        "outputId": "8399b424-e85c-4cc5-e3e9-6ca148fe7e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2403, 24, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=210)\n",
        "np.flip(np.rot90(X_Train[0], 1), axis=0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz45hu4VtxvT",
        "outputId": "94cd33e1-2c86-4222-cdcc-c368414f790a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_dataset(series_x, series_y, batch_size, shuffle_buffer, shuffle=True):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((series_x, series_y))\n",
        "    if shuffle:\n",
        "        ds = ds.cache().shuffle(shuffle_buffer).batch(batch_size).repeat()\n",
        "    else:\n",
        "        ds = ds.cache().batch(batch_size).repeat()\n",
        "\n",
        "    return ds\n",
        "\n",
        "def create_window_dataset(ds, window_size):\n",
        "    windowed_dataset = []\n",
        "\n",
        "    for i in range(window_size, ds.shape[0] + 1):\n",
        "        windowed_dataset.append(ds[i - window_size:])\n",
        "\n",
        "        \n",
        "    return np.array(windowed_dataset)"
      ],
      "metadata": {
        "id": "pBWHqagHcNpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaled_df = pd.DataFrame()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaled_train = scaler.fit_transform(train[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
        "scaled_val = scaler.fit_transform(val[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
        "scaled_test = scaler.fit_transform(test[['Open', 'High', 'Low', 'Close', 'Volume']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ZlbOS2pJcNw2",
        "outputId": "42225d99-57c1-431a-9a48-18928cb92fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-62674d583b5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscaled_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mscaled_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mscaled_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         )\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m             )\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required by MinMaxScaler."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 25\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "windowed_dataset_train = create_window_dataset(scaled_train[:, 0:-1], WINDOW_SIZE)\n",
        "\n"
      ],
      "metadata": {
        "id": "gILmupjYcNzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowed_dataset_train[1].shape"
      ],
      "metadata": {
        "id": "k0MiuNJbc2Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowed_dataset_train, labels_train = create_window_dataset(train_dataset_normalized, train_dataset[:, -1], WINDOW_SIZE)\n",
        "train_set = tf_dataset(windowed_dataset_train, labels_train, BATCH_SIZE, 1000)\n",
        "unshuffled_train_set = tf_dataset(windowed_dataset_train, labels_train, BATCH_SIZE, 1000, False)\n",
        "\n",
        "windowed_dataset_validation, labels_validation = create_window_dataset(cross_validation_dataset_normalized, cross_validation_dataset[:, -1], WINDOW_SIZE)\n",
        "cross_validation_set = tf_dataset(windowed_dataset_validation, labels_validation, BATCH_SIZE, 1000, False)\n",
        "\n",
        "windowed_dataset_dev, labels_dev = create_window_dataset(dev_dataset_normalized, dev_dataset[:, -1], WINDOW_SIZE)\n",
        "dev_set = tf_dataset(windowed_dataset_dev, labels_dev, 1, 1000, False)"
      ],
      "metadata": {
        "id": "4yGUbYPQcN1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DE9sAqIlcN33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rJuN0MqwcN6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Pr1KvdHcN8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h7NHSyxa78z",
        "outputId": "af486437-51e4-4eda-a98b-25f84110bb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[Timestamp('2016-04-25 10:30:00-0400', tz='US/Eastern'), 68.81,\n",
              "        68.88, ..., 68.88, 52095, 68.824087],\n",
              "       [Timestamp('2016-04-25 10:35:00-0400', tz='US/Eastern'), 68.88,\n",
              "        68.92, ..., 68.905, 55508, 68.901144],\n",
              "       [Timestamp('2016-04-25 10:40:00-0400', tz='US/Eastern'), 68.91,\n",
              "        68.9301, ..., 68.9, 37356, 68.911471],\n",
              "       ...,\n",
              "       [Timestamp('2019-01-18 17:00:00-0500', tz='US/Eastern'), 97.73,\n",
              "        97.73, ..., 97.73, 100, 97.73],\n",
              "       [Timestamp('2019-01-18 17:25:00-0500', tz='US/Eastern'), 97.7299,\n",
              "        97.73, ..., 97.73, 627, 97.729968],\n",
              "       [Timestamp('2019-01-18 19:55:00-0500', tz='US/Eastern'), 97.73,\n",
              "        97.73, ..., 97.73, 100, 97.73]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif out_end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# covert into input/output\n",
        "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
        "print(X.shape, y.shape)\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "\tprint(X[i], y[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmuw4hzsXWeI",
        "outputId": "62d53422-e7cb-4e9b-94db-c7dc2c2bfde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 3, 3) (5, 2, 3)\n",
            "[[10 15 25]\n",
            " [20 25 45]\n",
            " [30 35 65]] [[ 40  45  85]\n",
            " [ 50  55 105]]\n",
            "[[20 25 45]\n",
            " [30 35 65]\n",
            " [40 45 85]] [[ 50  55 105]\n",
            " [ 60  65 125]]\n",
            "[[ 30  35  65]\n",
            " [ 40  45  85]\n",
            " [ 50  55 105]] [[ 60  65 125]\n",
            " [ 70  75 145]]\n",
            "[[ 40  45  85]\n",
            " [ 50  55 105]\n",
            " [ 60  65 125]] [[ 70  75 145]\n",
            " [ 80  85 165]]\n",
            "[[ 50  55 105]\n",
            " [ 60  65 125]\n",
            " [ 70  75 145]] [[ 80  85 165]\n",
            " [ 90  95 185]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7on_GbUXuT8",
        "outputId": "0a8e4f28-7852-408f-99da-cb35987503bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10,  15,  25],\n",
              "       [ 20,  25,  45],\n",
              "       [ 30,  35,  65],\n",
              "       [ 40,  45,  85],\n",
              "       [ 50,  55, 105],\n",
              "       [ 60,  65, 125],\n",
              "       [ 70,  75, 145],\n",
              "       [ 80,  85, 165],\n",
              "       [ 90,  95, 185]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(df):\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(50, df.shape[0]):\n",
        "        x.append(df[i-50:i, 0])\n",
        "        y.append(df[i, 0])\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "-OJ9XpuoNqhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = create_dataset(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "RW7ef3O_abDf",
        "outputId": "9ddd2bcd-2e0e-4e66-c39d-bd09ca4cd378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-edfd3ccc8cfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-e856df345e51>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(slice(0, 50, None), 0)' is an invalid key"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HOBCUubqNqDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training Days: {train_day_int}, Set Start: {train.index[0].strftime(\"%d-%b-%Y\")}, End: {train.index[-1].strftime(\"%d-%b-%Y\")}, Shape: {train.shape}')\n",
        "print(f'Validation Days: {val_day_int}, Set Start: {val.index[0].strftime(\"%d-%b-%Y\")}, End: {val.index[-1].strftime(\"%d-%b-%Y\")}, Shape: {val.shape}')\n",
        "print(f'Testing Days: {test_day_int}, Start: {test.index[0].strftime(\"%d-%b-%Y\")}, End: {test.index[-1].strftime(\"%d-%b-%Y\")}, Shape: {test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9rM5V1BHyBl",
        "outputId": "1fceb257-8107-42bf-b289-7dbc66401600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Days: 1000, Set Start: 25-Apr-2016, End: 18-Jan-2019, Shape: (67653, 7)\n",
            "Validation Days: 365, Set Start: 22-Jan-2019, End: 17-Jan-2020, Shape: (25027, 7)\n",
            "Testing Days: 365, Start: 21-Jan-2020, End: 19-Jan-2021, Shape: (31494, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of Rows Between all Sets: {(train.shape[0] + val.shape[0] + test.shape[0])}, Shape of Full Set: {full.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqbVlKwLKN-l",
        "outputId": "73d801bb-1ff8-472c-c4dc-fcacde9a3339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rows Between all Sets: 124174, Shape of Full Set: 124174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Preparing The Data"
      ],
      "metadata": {
        "id": "IMY3MYh4D7sR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create target from OHLC and Volume Data\n",
        "def buildTargets(full_df = full, train_observations = train.shape[0], \n",
        "                 val_observations = val.shape[0], \n",
        "                 test_observations = test.shape[0], \n",
        "                 shift_2hour = 24,\n",
        "                 alph = .55, \n",
        "                 volity_int = 10):\n",
        "\n",
        "  \"\"\" \n",
        "  This function will take a complete set of train, val, and test \n",
        "  data and return the targets. Volitility will be calculated over \n",
        "  the 252 5min incriments. The Target shift is looking at 2 hours \n",
        "  shift from current time\n",
        "\n",
        "  shift_2hour = The amount of time the data interval take to equal 2 hours \n",
        "                (i.e. 5 min data interval is equal to 25)\n",
        "  alph = The alpha value for calculating the shift in price\n",
        "  volity_int = the number of incriments used to calculate volitility \n",
        "  \"\"\"\n",
        "\n",
        "  returns = np.log(full_df['Close']/(full_df['Close'].shift(1)))\n",
        "  returns.fillna(0, inplace=True)\n",
        "  #volatility = returns.std()*np.sqrt(volity_int)\n",
        "  volatility = returns.rolling(window=volity_int).std()*np.sqrt(volity_int)\n",
        "\n",
        "  #print(len(full_df.Close), len(volatility))\n",
        "\n",
        "  targets = [\"flat\"] * len(full_df.Close)\n",
        "\n",
        "  targets = np.where(full_df.Close.shift(-shift_2hour) >= (full_df.Close * (1 + alph * volatility)), \n",
        "           \"up\", targets)\n",
        "  \n",
        "  targets = np.where(full_df.Close.shift(-shift_2hour) <= (full_df.Close * (1 - alph * volatility)), \n",
        "           \"down\", targets)\n",
        "\n",
        "  train_split = train_observations\n",
        "  val_split = train_observations + val_observations\n",
        "  test_split = train_observations + val_observations + test_observations\n",
        "\n",
        "  train_targets = targets[:train_split]\n",
        "  val_targets = targets[train_split:val_split]\n",
        "  test_targets = targets[val_split:test_split]\n",
        "  full_targets = targets\n",
        "\n",
        "  return train_targets, val_targets, test_targets, full_targets\n",
        "\n",
        "# print(buildTargets.__doc__)\n",
        "train_targets, val_targets, test_targets, full_targets = buildTargets()"
      ],
      "metadata": {
        "id": "NmTD5JViEFMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OJlf0UBTsEfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_df = pd.DataFrame(full_targets, columns=[\"FuturePrice\"])\n",
        "plot_df[\"FuturePrice\"].value_counts().plot(kind = 'bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "EUEpy7cSajI_",
        "outputId": "c29eda79-cd3a-4005-c18b-b02c8a04ab91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f40c201a910>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mulitclass Classification (None CDT 1D CNN)"
      ],
      "metadata": {
        "id": "W-hurH5w70Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TfD1r6R9IbN",
        "outputId": "fde42bac-23b9-4821-e276-e62a1e05ccff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Time', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
              "       'VolumeWeightedAvgPrice'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full[\"Open\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KybVva6t9Xwx",
        "outputId": "04188c38-aa11-4833-85de-6ad39f479301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "timestamp\n",
              "2016-04-25 10:30:00-04:00     68.81\n",
              "2016-04-25 10:35:00-04:00     68.88\n",
              "2016-04-25 10:40:00-04:00     68.91\n",
              "2016-04-25 10:45:00-04:00     68.90\n",
              "2016-04-25 10:50:00-04:00     68.94\n",
              "                              ...  \n",
              "2021-01-19 08:50:00-05:00    145.00\n",
              "2021-01-19 09:00:00-05:00    144.98\n",
              "2021-01-19 09:10:00-05:00    144.98\n",
              "2021-01-19 09:15:00-05:00    144.93\n",
              "2021-01-19 09:20:00-05:00    144.81\n",
              "Name: Open, Length: 124174, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaled_df = pd.DataFrame()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaled_train = scaler.fit_transform(train[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
        "scaled_val = scaler.fit_transform(val[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
        "scaled_test = scaler.fit_transform(test[['Open', 'High', 'Low', 'Close', 'Volume']])"
      ],
      "metadata": {
        "id": "YYCBKN4uu-FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_targets_df = pd.DataFrame(train_targets)\n",
        "val_targets_df = pd.DataFrame(val_targets)\n",
        "test_targets_df = pd.DataFrame(test_targets)\n",
        "\n",
        "class2idx = {\n",
        "    \"up\":0,\n",
        "    \"flat\":1,\n",
        "    \"down\":2,\n",
        "}\n",
        "\n",
        "idx2class = {v: k for k, v in class2idx.items()}\n",
        "\n",
        "train_targets_df.replace(class2idx, inplace=True)\n",
        "val_targets_df.replace(class2idx, inplace=True)\n",
        "test_targets_df.replace(class2idx, inplace=True)"
      ],
      "metadata": {
        "id": "TCETOevJpk81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_targets_df[0].value_counts().plot(kind = 'bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "V9bV2_jpp6Qx",
        "outputId": "bde9e731-1d9c-448f-d877-e65c51fe7cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f40c529f910>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(scaled_train)\n",
        "X_val = np.array(scaled_val)\n",
        "X_test= np.array(scaled_test)\n",
        "\n",
        "y_train = np.array(train_targets_df[0])\n",
        "y_val = np.array(val_targets_df[0])\n",
        "y_test = np.array(test_targets_df[0])"
      ],
      "metadata": {
        "id": "cRJ-EbOPqEs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Type of X Train: {type(X_train)}, Length of X: {X_train.shape}')\n",
        "print(f'Type of y Train: {type(y_train)}, Length of y: {y_train.shape}')\n",
        "print(f'Type of X Val: {type(X_val)}, Length of X: {X_val.shape}')\n",
        "print(f'Type of y Val: {type(y_val)}, Length of y: {y_val.shape}')\n",
        "print(f'Type of X Val: {type(X_test)}, Length of X: {X_test.shape}')\n",
        "print(f'Type of y Val: {type(y_test)}, Length of y: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJFXeknpqP7y",
        "outputId": "96a5204c-e548-4d5d-ec6e-59591cca9a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of X Train: <class 'numpy.ndarray'>, Length of X: (67653, 5)\n",
            "Type of y Train: <class 'numpy.ndarray'>, Length of y: (67653,)\n",
            "Type of X Val: <class 'numpy.ndarray'>, Length of X: (25027, 5)\n",
            "Type of y Val: <class 'numpy.ndarray'>, Length of y: (25027,)\n",
            "Type of X Val: <class 'numpy.ndarray'>, Length of X: (31494, 5)\n",
            "Type of y Val: <class 'numpy.ndarray'>, Length of y: (31494,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.asarray(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH5tzBJ9Ew4a",
        "outputId": "b0d23569-3149-4780-aa72-4c9c434e9acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[Timestamp('2016-04-25 10:30:00-0400', tz='US/Eastern'), 68.81,\n",
              "        68.88, ..., 68.88, 52095, 68.824087],\n",
              "       [Timestamp('2016-04-25 10:35:00-0400', tz='US/Eastern'), 68.88,\n",
              "        68.92, ..., 68.905, 55508, 68.901144],\n",
              "       [Timestamp('2016-04-25 10:40:00-0400', tz='US/Eastern'), 68.91,\n",
              "        68.9301, ..., 68.9, 37356, 68.911471],\n",
              "       ...,\n",
              "       [Timestamp('2019-01-18 17:00:00-0500', tz='US/Eastern'), 97.73,\n",
              "        97.73, ..., 97.73, 100, 97.73],\n",
              "       [Timestamp('2019-01-18 17:25:00-0500', tz='US/Eastern'), 97.7299,\n",
              "        97.73, ..., 97.73, 627, 97.729968],\n",
              "       [Timestamp('2019-01-18 19:55:00-0500', tz='US/Eastern'), 97.73,\n",
              "        97.73, ..., 97.73, 100, 97.73]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierDataset():\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "\n",
        "train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "val_dataset = ClassifierDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
        "test_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())"
      ],
      "metadata": {
        "id": "41IFYHMvucBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtO8sN6lvVAu",
        "outputId": "e9cc706e-338b-4f7a-c7aa-47b7a79856ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 300\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.0007\n",
        "NUM_FEATURES = scaled_train.shape[1]\n",
        "NUM_CLASSES = 3"
      ],
      "metadata": {
        "id": "Z0qU88rZu5Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        ")\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=1)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "n1UlEevhvcgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MulticlassClassification(nn.Module):\n",
        "    def __init__(self, num_feature, num_class):\n",
        "        super(MulticlassClassification, self).__init__()\n",
        "        \n",
        "        self.layer_1 = nn.Linear(num_feature, 512)\n",
        "        self.layer_2 = nn.Linear(512, 128)\n",
        "        self.layer_3 = nn.Linear(128, 64)\n",
        "        self.layer_out = nn.Linear(64, num_class) \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.layer_2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.layer_3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.layer_out(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "MwPC11JAvjnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk3Y-M6lvnEx",
        "outputId": "be238fd9-2e5d-4a42-c4da-1ea8bb28562a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SVhPeVgvrbB",
        "outputId": "d94c12ee-5687-4a1e-dc6b-6cce46af6508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MulticlassClassification(\n",
            "  (layer_1): Linear(in_features=5, out_features=512, bias=True)\n",
            "  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (layer_out): Linear(in_features=64, out_features=3, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
        "    \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum() / len(correct_pred)\n",
        "    \n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "metadata": {
        "id": "Jx5CwK8Qvxos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_stats = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}\n",
        "loss_stats = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}"
      ],
      "metadata": {
        "id": "wYRwPyN5vzAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Begin training.\")\n",
        "\n",
        "for e in tqdm(range(1, EPOCHS+1)):\n",
        "  \n",
        "  # TRAINING\n",
        "  train_epoch_loss = 0\n",
        "  train_epoch_acc = 0\n",
        "\n",
        "\n",
        "  model.train()\n",
        "  for X_train_batch, y_train_batch in train_loader:\n",
        "      X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      y_train_pred = model(X_train_batch)\n",
        "      \n",
        "      train_loss = criterion(y_train_pred, y_train_batch)\n",
        "      train_acc = multi_acc(y_train_pred, y_train_batch)\n",
        "      \n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      train_epoch_loss += train_loss.item()\n",
        "      train_epoch_acc += train_acc.item()\n",
        "      \n",
        "      \n",
        "  # VALIDATION    \n",
        "  with torch.no_grad():\n",
        "      \n",
        "      val_epoch_loss = 0\n",
        "      val_epoch_acc = 0\n",
        "      \n",
        "      model.eval()\n",
        "      for X_val_batch, y_val_batch in val_loader:\n",
        "          X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
        "          \n",
        "          y_val_pred = model(X_val_batch)\n",
        "                      \n",
        "          val_loss = criterion(y_val_pred, y_val_batch)\n",
        "          val_acc = multi_acc(y_val_pred, y_val_batch)\n",
        "          \n",
        "          val_epoch_loss += val_loss.item()\n",
        "          val_epoch_acc += val_acc.item()\n",
        "\n",
        "  loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
        "  loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
        "  accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
        "  accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
        "                            \n",
        "\n",
        "  print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "35b0c6a641f74b7a8a5a17696c771999",
            "5435c22875e1449bba6f514dc362fb86",
            "2174b8eaf379476aa207a7d3553a23cb",
            "d2eea602e1f44679b9dca81d02cef6a9",
            "4c4ee8d44be44753b86d2334ed5201d9",
            "2d07aa40726741bba6d08a741f239b2a",
            "ae9e58658d6e45a0ae4f071d65facbd8",
            "39c656c52a3b41f4912ae2f141bf1291",
            "101532c20c604f9cbddaae38f83cb611",
            "a809155bf81340c88a359f8e8b52b1a7",
            "8a927038a7cb49a6a64673ce556a0c8e"
          ]
        },
        "id": "8f5oKsuRvz21",
        "outputId": "b29c559b-8c71-422a-eb0f-83e583c0dd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35b0c6a641f74b7a8a5a17696c771999",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001: | Train Loss: 1.03773 | Val Loss: 18.28548 | Train Acc: 46.339| Val Acc: 35.978\n",
            "Epoch 002: | Train Loss: 1.03568 | Val Loss: 14.71919 | Train Acc: 46.572| Val Acc: 35.846\n",
            "Epoch 003: | Train Loss: 1.03342 | Val Loss: 16.51808 | Train Acc: 46.793| Val Acc: 36.061\n",
            "Epoch 004: | Train Loss: 1.03213 | Val Loss: 21.83980 | Train Acc: 46.823| Val Acc: 36.041\n",
            "Epoch 005: | Train Loss: 1.03002 | Val Loss: 22.58325 | Train Acc: 47.167| Val Acc: 35.862\n",
            "Epoch 006: | Train Loss: 1.02964 | Val Loss: 22.80922 | Train Acc: 47.228| Val Acc: 35.958\n",
            "Epoch 007: | Train Loss: 1.02630 | Val Loss: 22.72420 | Train Acc: 47.528| Val Acc: 35.934\n",
            "Epoch 008: | Train Loss: 1.02479 | Val Loss: 22.38807 | Train Acc: 47.576| Val Acc: 35.902\n",
            "Epoch 009: | Train Loss: 1.02515 | Val Loss: 22.53223 | Train Acc: 47.479| Val Acc: 36.077\n",
            "Epoch 010: | Train Loss: 1.02227 | Val Loss: 23.79687 | Train Acc: 47.802| Val Acc: 35.974\n",
            "Epoch 011: | Train Loss: 1.02061 | Val Loss: 24.85404 | Train Acc: 47.934| Val Acc: 35.866\n",
            "Epoch 012: | Train Loss: 1.01874 | Val Loss: 25.26233 | Train Acc: 48.206| Val Acc: 35.902\n",
            "Epoch 013: | Train Loss: 1.01619 | Val Loss: 21.64190 | Train Acc: 48.439| Val Acc: 36.133\n",
            "Epoch 014: | Train Loss: 1.01631 | Val Loss: 27.45609 | Train Acc: 48.294| Val Acc: 35.802\n",
            "Epoch 015: | Train Loss: 1.01460 | Val Loss: 22.39434 | Train Acc: 48.581| Val Acc: 36.010\n",
            "Epoch 016: | Train Loss: 1.01442 | Val Loss: 27.13374 | Train Acc: 48.710| Val Acc: 35.890\n",
            "Epoch 017: | Train Loss: 1.01151 | Val Loss: 32.04726 | Train Acc: 48.914| Val Acc: 35.802\n",
            "Epoch 018: | Train Loss: 1.01259 | Val Loss: 34.88230 | Train Acc: 48.686| Val Acc: 35.886\n",
            "Epoch 019: | Train Loss: 1.00837 | Val Loss: 42.48577 | Train Acc: 49.032| Val Acc: 35.758\n",
            "Epoch 020: | Train Loss: 1.00575 | Val Loss: 36.52548 | Train Acc: 49.444| Val Acc: 35.850\n",
            "Epoch 021: | Train Loss: 1.00665 | Val Loss: 35.56726 | Train Acc: 49.083| Val Acc: 35.814\n",
            "Epoch 022: | Train Loss: 1.00381 | Val Loss: 35.14205 | Train Acc: 49.472| Val Acc: 35.846\n",
            "Epoch 023: | Train Loss: 1.00146 | Val Loss: 38.23703 | Train Acc: 49.552| Val Acc: 35.886\n",
            "Epoch 024: | Train Loss: 1.00012 | Val Loss: 39.01895 | Train Acc: 49.718| Val Acc: 35.906\n",
            "Epoch 025: | Train Loss: 1.00085 | Val Loss: 42.14128 | Train Acc: 49.702| Val Acc: 35.846\n",
            "Epoch 026: | Train Loss: 0.99834 | Val Loss: 48.55490 | Train Acc: 49.822| Val Acc: 35.890\n",
            "Epoch 027: | Train Loss: 0.99707 | Val Loss: 39.29040 | Train Acc: 49.774| Val Acc: 35.878\n",
            "Epoch 028: | Train Loss: 0.99660 | Val Loss: 41.46110 | Train Acc: 50.079| Val Acc: 35.954\n",
            "Epoch 029: | Train Loss: 0.99407 | Val Loss: 46.91596 | Train Acc: 50.052| Val Acc: 36.029\n",
            "Epoch 030: | Train Loss: 0.99352 | Val Loss: 42.53436 | Train Acc: 50.019| Val Acc: 35.938\n",
            "Epoch 031: | Train Loss: 0.99270 | Val Loss: 41.23104 | Train Acc: 50.393| Val Acc: 35.268\n",
            "Epoch 032: | Train Loss: 0.99107 | Val Loss: 46.56323 | Train Acc: 50.326| Val Acc: 35.846\n",
            "Epoch 033: | Train Loss: 0.99041 | Val Loss: 46.38457 | Train Acc: 50.346| Val Acc: 35.870\n",
            "Epoch 034: | Train Loss: 0.98960 | Val Loss: 38.29024 | Train Acc: 50.368| Val Acc: 35.862\n",
            "Epoch 035: | Train Loss: 0.98835 | Val Loss: 48.10986 | Train Acc: 50.696| Val Acc: 35.946\n",
            "Epoch 036: | Train Loss: 0.98682 | Val Loss: 50.63705 | Train Acc: 50.424| Val Acc: 35.918\n",
            "Epoch 037: | Train Loss: 0.98614 | Val Loss: 54.64801 | Train Acc: 50.604| Val Acc: 35.830\n",
            "Epoch 038: | Train Loss: 0.98347 | Val Loss: 56.06499 | Train Acc: 50.920| Val Acc: 35.659\n",
            "Epoch 039: | Train Loss: 0.98360 | Val Loss: 55.96591 | Train Acc: 50.815| Val Acc: 35.954\n",
            "Epoch 040: | Train Loss: 0.98382 | Val Loss: 49.68804 | Train Acc: 51.094| Val Acc: 35.986\n",
            "Epoch 041: | Train Loss: 0.98386 | Val Loss: 50.84728 | Train Acc: 50.751| Val Acc: 35.970\n",
            "Epoch 042: | Train Loss: 0.97935 | Val Loss: 56.94556 | Train Acc: 51.201| Val Acc: 35.906\n",
            "Epoch 043: | Train Loss: 0.97944 | Val Loss: 61.34190 | Train Acc: 51.260| Val Acc: 35.902\n",
            "Epoch 044: | Train Loss: 0.97816 | Val Loss: 48.00104 | Train Acc: 51.431| Val Acc: 35.790\n",
            "Epoch 045: | Train Loss: 0.97301 | Val Loss: 52.67190 | Train Acc: 51.501| Val Acc: 36.117\n",
            "Epoch 046: | Train Loss: 0.97485 | Val Loss: 59.17818 | Train Acc: 51.496| Val Acc: 35.906\n",
            "Epoch 047: | Train Loss: 0.97499 | Val Loss: 65.28648 | Train Acc: 51.647| Val Acc: 35.882\n",
            "Epoch 048: | Train Loss: 0.97311 | Val Loss: 54.39216 | Train Acc: 51.569| Val Acc: 36.026\n",
            "Epoch 049: | Train Loss: 0.97351 | Val Loss: 44.34307 | Train Acc: 51.847| Val Acc: 35.727\n",
            "Epoch 050: | Train Loss: 0.96935 | Val Loss: 57.58184 | Train Acc: 52.052| Val Acc: 35.958\n",
            "Epoch 051: | Train Loss: 0.96926 | Val Loss: 65.54543 | Train Acc: 51.996| Val Acc: 35.898\n",
            "Epoch 052: | Train Loss: 0.96741 | Val Loss: 42.53718 | Train Acc: 52.229| Val Acc: 35.886\n",
            "Epoch 053: | Train Loss: 0.96689 | Val Loss: 56.03723 | Train Acc: 52.268| Val Acc: 36.093\n",
            "Epoch 054: | Train Loss: 0.96595 | Val Loss: 54.89665 | Train Acc: 52.240| Val Acc: 36.010\n",
            "Epoch 055: | Train Loss: 0.96384 | Val Loss: 55.37905 | Train Acc: 52.521| Val Acc: 35.830\n",
            "Epoch 056: | Train Loss: 0.96428 | Val Loss: 58.25829 | Train Acc: 52.276| Val Acc: 36.026\n",
            "Epoch 057: | Train Loss: 0.96330 | Val Loss: 57.48329 | Train Acc: 52.342| Val Acc: 36.029\n",
            "Epoch 058: | Train Loss: 0.96121 | Val Loss: 47.57709 | Train Acc: 52.694| Val Acc: 35.998\n",
            "Epoch 059: | Train Loss: 0.96057 | Val Loss: 50.21600 | Train Acc: 52.605| Val Acc: 35.838\n",
            "Epoch 060: | Train Loss: 0.95756 | Val Loss: 55.00718 | Train Acc: 53.107| Val Acc: 36.006\n",
            "Epoch 061: | Train Loss: 0.95794 | Val Loss: 61.02519 | Train Acc: 52.805| Val Acc: 35.822\n",
            "Epoch 062: | Train Loss: 0.95516 | Val Loss: 51.33713 | Train Acc: 53.103| Val Acc: 35.938\n",
            "Epoch 063: | Train Loss: 0.95546 | Val Loss: 55.24835 | Train Acc: 53.142| Val Acc: 35.970\n",
            "Epoch 064: | Train Loss: 0.95535 | Val Loss: 60.38786 | Train Acc: 53.043| Val Acc: 35.882\n",
            "Epoch 065: | Train Loss: 0.95326 | Val Loss: 61.13352 | Train Acc: 53.405| Val Acc: 36.014\n",
            "Epoch 066: | Train Loss: 0.95002 | Val Loss: 67.09717 | Train Acc: 53.337| Val Acc: 36.006\n",
            "Epoch 067: | Train Loss: 0.94862 | Val Loss: 48.98560 | Train Acc: 53.654| Val Acc: 35.918\n",
            "Epoch 068: | Train Loss: 0.94942 | Val Loss: 50.85423 | Train Acc: 53.552| Val Acc: 35.982\n",
            "Epoch 069: | Train Loss: 0.95021 | Val Loss: 55.76363 | Train Acc: 53.528| Val Acc: 35.922\n",
            "Epoch 070: | Train Loss: 0.94842 | Val Loss: 64.29850 | Train Acc: 53.530| Val Acc: 35.938\n",
            "Epoch 071: | Train Loss: 0.94498 | Val Loss: 65.09526 | Train Acc: 53.623| Val Acc: 35.727\n",
            "Epoch 072: | Train Loss: 0.94611 | Val Loss: 53.36845 | Train Acc: 53.795| Val Acc: 35.073\n",
            "Epoch 073: | Train Loss: 0.94559 | Val Loss: 53.11786 | Train Acc: 53.801| Val Acc: 36.053\n",
            "Epoch 074: | Train Loss: 0.94210 | Val Loss: 59.21576 | Train Acc: 54.012| Val Acc: 36.049\n",
            "Epoch 075: | Train Loss: 0.94273 | Val Loss: 66.27225 | Train Acc: 53.881| Val Acc: 36.057\n",
            "Epoch 076: | Train Loss: 0.94513 | Val Loss: 53.46854 | Train Acc: 53.835| Val Acc: 36.281\n",
            "Epoch 077: | Train Loss: 0.93879 | Val Loss: 46.96310 | Train Acc: 54.409| Val Acc: 36.137\n",
            "Epoch 078: | Train Loss: 0.93832 | Val Loss: 52.83578 | Train Acc: 54.327| Val Acc: 35.639\n",
            "Epoch 079: | Train Loss: 0.93885 | Val Loss: 42.54730 | Train Acc: 54.417| Val Acc: 36.177\n",
            "Epoch 080: | Train Loss: 0.93529 | Val Loss: 50.41648 | Train Acc: 54.734| Val Acc: 36.137\n",
            "Epoch 081: | Train Loss: 0.93607 | Val Loss: 46.55207 | Train Acc: 54.076| Val Acc: 36.073\n",
            "Epoch 082: | Train Loss: 0.93454 | Val Loss: 76.95360 | Train Acc: 54.491| Val Acc: 35.934\n",
            "Epoch 083: | Train Loss: 0.93377 | Val Loss: 68.89742 | Train Acc: 54.645| Val Acc: 35.994\n",
            "Epoch 084: | Train Loss: 0.93435 | Val Loss: 57.23074 | Train Acc: 54.493| Val Acc: 36.261\n",
            "Epoch 085: | Train Loss: 0.92999 | Val Loss: 73.35243 | Train Acc: 54.959| Val Acc: 36.137\n",
            "Epoch 086: | Train Loss: 0.92828 | Val Loss: 74.65684 | Train Acc: 54.931| Val Acc: 36.217\n",
            "Epoch 087: | Train Loss: 0.92981 | Val Loss: 58.95812 | Train Acc: 54.781| Val Acc: 36.141\n",
            "Epoch 088: | Train Loss: 0.92561 | Val Loss: 71.39651 | Train Acc: 54.954| Val Acc: 36.336\n",
            "Epoch 089: | Train Loss: 0.92389 | Val Loss: 59.62870 | Train Acc: 55.071| Val Acc: 36.352\n",
            "Epoch 090: | Train Loss: 0.92331 | Val Loss: 38.46428 | Train Acc: 55.271| Val Acc: 36.201\n",
            "Epoch 091: | Train Loss: 0.92517 | Val Loss: 42.62886 | Train Acc: 55.228| Val Acc: 36.213\n",
            "Epoch 092: | Train Loss: 0.91907 | Val Loss: 51.41695 | Train Acc: 55.352| Val Acc: 36.117\n",
            "Epoch 093: | Train Loss: 0.92204 | Val Loss: 48.36184 | Train Acc: 55.327| Val Acc: 36.464\n",
            "Epoch 094: | Train Loss: 0.92134 | Val Loss: 45.72194 | Train Acc: 55.610| Val Acc: 36.205\n",
            "Epoch 095: | Train Loss: 0.91856 | Val Loss: 50.06196 | Train Acc: 55.715| Val Acc: 36.229\n",
            "Epoch 096: | Train Loss: 0.91479 | Val Loss: 53.72951 | Train Acc: 55.969| Val Acc: 36.372\n",
            "Epoch 097: | Train Loss: 0.91685 | Val Loss: 31.64838 | Train Acc: 55.743| Val Acc: 36.121\n",
            "Epoch 098: | Train Loss: 0.91438 | Val Loss: 63.94009 | Train Acc: 55.661| Val Acc: 36.241\n",
            "Epoch 099: | Train Loss: 0.91564 | Val Loss: 31.72633 | Train Acc: 55.733| Val Acc: 36.037\n",
            "Epoch 100: | Train Loss: 0.91364 | Val Loss: 48.22221 | Train Acc: 55.620| Val Acc: 36.225\n",
            "Epoch 101: | Train Loss: 0.91095 | Val Loss: 54.42397 | Train Acc: 56.062| Val Acc: 36.269\n",
            "Epoch 102: | Train Loss: 0.91041 | Val Loss: 50.81663 | Train Acc: 56.208| Val Acc: 36.189\n",
            "Epoch 103: | Train Loss: 0.90579 | Val Loss: 49.51678 | Train Acc: 56.250| Val Acc: 36.181\n",
            "Epoch 104: | Train Loss: 0.91100 | Val Loss: 57.90573 | Train Acc: 56.148| Val Acc: 36.097\n",
            "Epoch 105: | Train Loss: 0.91013 | Val Loss: 48.70327 | Train Acc: 56.116| Val Acc: 36.249\n",
            "Epoch 106: | Train Loss: 0.90439 | Val Loss: 53.61910 | Train Acc: 56.474| Val Acc: 36.400\n",
            "Epoch 107: | Train Loss: 0.90536 | Val Loss: 53.45957 | Train Acc: 56.655| Val Acc: 36.085\n",
            "Epoch 108: | Train Loss: 0.90200 | Val Loss: 43.10108 | Train Acc: 56.489| Val Acc: 36.364\n",
            "Epoch 109: | Train Loss: 0.90089 | Val Loss: 40.50897 | Train Acc: 56.572| Val Acc: 36.332\n",
            "Epoch 110: | Train Loss: 0.90226 | Val Loss: 57.36740 | Train Acc: 56.627| Val Acc: 36.133\n",
            "Epoch 111: | Train Loss: 0.89964 | Val Loss: 41.31016 | Train Acc: 56.814| Val Acc: 36.125\n",
            "Epoch 112: | Train Loss: 0.90043 | Val Loss: 44.83579 | Train Acc: 56.405| Val Acc: 36.173\n",
            "Epoch 113: | Train Loss: 0.89853 | Val Loss: 43.95112 | Train Acc: 56.914| Val Acc: 36.328\n",
            "Epoch 114: | Train Loss: 0.89548 | Val Loss: 48.75519 | Train Acc: 57.081| Val Acc: 36.412\n",
            "Epoch 115: | Train Loss: 0.89465 | Val Loss: 41.63435 | Train Acc: 56.929| Val Acc: 36.500\n",
            "Epoch 116: | Train Loss: 0.89509 | Val Loss: 67.38322 | Train Acc: 56.954| Val Acc: 36.384\n",
            "Epoch 117: | Train Loss: 0.89713 | Val Loss: 52.03984 | Train Acc: 57.014| Val Acc: 36.205\n",
            "Epoch 118: | Train Loss: 0.89351 | Val Loss: 45.97796 | Train Acc: 56.879| Val Acc: 36.448\n",
            "Epoch 119: | Train Loss: 0.89223 | Val Loss: 65.18914 | Train Acc: 57.305| Val Acc: 36.293\n",
            "Epoch 120: | Train Loss: 0.88792 | Val Loss: 39.41584 | Train Acc: 57.549| Val Acc: 36.053\n",
            "Epoch 121: | Train Loss: 0.88764 | Val Loss: 37.83593 | Train Acc: 57.646| Val Acc: 36.360\n",
            "Epoch 122: | Train Loss: 0.88669 | Val Loss: 36.00223 | Train Acc: 57.638| Val Acc: 36.317\n",
            "Epoch 123: | Train Loss: 0.88559 | Val Loss: 31.98377 | Train Acc: 57.677| Val Acc: 36.396\n",
            "Epoch 124: | Train Loss: 0.88573 | Val Loss: 40.24111 | Train Acc: 57.835| Val Acc: 36.237\n",
            "Epoch 125: | Train Loss: 0.88257 | Val Loss: 59.22653 | Train Acc: 57.817| Val Acc: 36.324\n",
            "Epoch 126: | Train Loss: 0.88364 | Val Loss: 42.74998 | Train Acc: 57.798| Val Acc: 36.372\n",
            "Epoch 127: | Train Loss: 0.88062 | Val Loss: 42.72222 | Train Acc: 58.098| Val Acc: 36.472\n",
            "Epoch 128: | Train Loss: 0.88004 | Val Loss: 41.00631 | Train Acc: 57.767| Val Acc: 36.201\n",
            "Epoch 129: | Train Loss: 0.88109 | Val Loss: 34.59373 | Train Acc: 58.119| Val Acc: 36.336\n",
            "Epoch 130: | Train Loss: 0.87749 | Val Loss: 38.29935 | Train Acc: 58.275| Val Acc: 36.253\n",
            "Epoch 131: | Train Loss: 0.87694 | Val Loss: 29.02172 | Train Acc: 57.956| Val Acc: 36.404\n",
            "Epoch 132: | Train Loss: 0.87692 | Val Loss: 32.72198 | Train Acc: 58.161| Val Acc: 36.392\n",
            "Epoch 133: | Train Loss: 0.87265 | Val Loss: 40.77891 | Train Acc: 58.397| Val Acc: 36.512\n",
            "Epoch 134: | Train Loss: 0.87513 | Val Loss: 37.43953 | Train Acc: 58.242| Val Acc: 36.261\n",
            "Epoch 135: | Train Loss: 0.87333 | Val Loss: 34.67797 | Train Acc: 58.597| Val Acc: 36.416\n",
            "Epoch 136: | Train Loss: 0.87301 | Val Loss: 40.11558 | Train Acc: 58.622| Val Acc: 36.069\n",
            "Epoch 137: | Train Loss: 0.87193 | Val Loss: 36.48601 | Train Acc: 58.376| Val Acc: 36.340\n",
            "Epoch 138: | Train Loss: 0.86881 | Val Loss: 44.89180 | Train Acc: 58.507| Val Acc: 36.249\n",
            "Epoch 139: | Train Loss: 0.86902 | Val Loss: 36.81583 | Train Acc: 58.889| Val Acc: 36.257\n",
            "Epoch 140: | Train Loss: 0.87121 | Val Loss: 32.80822 | Train Acc: 58.475| Val Acc: 36.400\n",
            "Epoch 141: | Train Loss: 0.87340 | Val Loss: 36.92319 | Train Acc: 58.488| Val Acc: 36.452\n",
            "Epoch 142: | Train Loss: 0.86699 | Val Loss: 28.78332 | Train Acc: 58.645| Val Acc: 36.285\n",
            "Epoch 143: | Train Loss: 0.87130 | Val Loss: 41.32294 | Train Acc: 58.467| Val Acc: 36.197\n",
            "Epoch 144: | Train Loss: 0.86106 | Val Loss: 41.97705 | Train Acc: 59.151| Val Acc: 36.157\n",
            "Epoch 145: | Train Loss: 0.87009 | Val Loss: 49.16172 | Train Acc: 58.592| Val Acc: 36.301\n",
            "Epoch 146: | Train Loss: 0.86423 | Val Loss: 52.38777 | Train Acc: 59.114| Val Acc: 36.121\n",
            "Epoch 147: | Train Loss: 0.86333 | Val Loss: 51.05564 | Train Acc: 59.116| Val Acc: 36.169\n",
            "Epoch 148: | Train Loss: 0.86276 | Val Loss: 30.99604 | Train Acc: 59.183| Val Acc: 36.081\n",
            "Epoch 149: | Train Loss: 0.85988 | Val Loss: 51.52852 | Train Acc: 59.279| Val Acc: 36.265\n",
            "Epoch 150: | Train Loss: 0.86540 | Val Loss: 53.16078 | Train Acc: 58.780| Val Acc: 36.313\n",
            "Epoch 151: | Train Loss: 0.85481 | Val Loss: 60.12736 | Train Acc: 59.525| Val Acc: 36.081\n",
            "Epoch 152: | Train Loss: 0.86499 | Val Loss: 37.30025 | Train Acc: 58.743| Val Acc: 36.041\n",
            "Epoch 153: | Train Loss: 0.85688 | Val Loss: 41.30300 | Train Acc: 59.365| Val Acc: 36.201\n",
            "Epoch 154: | Train Loss: 0.85733 | Val Loss: 40.48661 | Train Acc: 59.557| Val Acc: 36.153\n",
            "Epoch 155: | Train Loss: 0.85468 | Val Loss: 33.74834 | Train Acc: 59.677| Val Acc: 36.225\n",
            "Epoch 156: | Train Loss: 0.85272 | Val Loss: 34.98886 | Train Acc: 59.542| Val Acc: 36.153\n",
            "Epoch 157: | Train Loss: 0.85270 | Val Loss: 48.54581 | Train Acc: 59.723| Val Acc: 36.065\n",
            "Epoch 158: | Train Loss: 0.85048 | Val Loss: 42.49513 | Train Acc: 59.692| Val Acc: 36.153\n",
            "Epoch 159: | Train Loss: 0.84920 | Val Loss: 35.11881 | Train Acc: 59.665| Val Acc: 36.261\n",
            "Epoch 160: | Train Loss: 0.85216 | Val Loss: 29.53816 | Train Acc: 59.648| Val Acc: 36.412\n",
            "Epoch 161: | Train Loss: 0.85149 | Val Loss: 40.91609 | Train Acc: 59.619| Val Acc: 36.057\n",
            "Epoch 162: | Train Loss: 0.85031 | Val Loss: 46.43221 | Train Acc: 59.607| Val Acc: 36.201\n",
            "Epoch 163: | Train Loss: 0.84934 | Val Loss: 49.58376 | Train Acc: 59.905| Val Acc: 36.037\n",
            "Epoch 164: | Train Loss: 0.84644 | Val Loss: 35.32785 | Train Acc: 60.108| Val Acc: 36.097\n",
            "Epoch 165: | Train Loss: 0.84282 | Val Loss: 45.99948 | Train Acc: 60.381| Val Acc: 35.982\n",
            "Epoch 166: | Train Loss: 0.84430 | Val Loss: 60.52897 | Train Acc: 60.116| Val Acc: 36.041\n",
            "Epoch 167: | Train Loss: 0.84157 | Val Loss: 50.27751 | Train Acc: 60.304| Val Acc: 35.966\n",
            "Epoch 168: | Train Loss: 0.84110 | Val Loss: 44.85651 | Train Acc: 60.211| Val Acc: 36.177\n",
            "Epoch 169: | Train Loss: 0.84410 | Val Loss: 37.01279 | Train Acc: 60.181| Val Acc: 36.029\n",
            "Epoch 170: | Train Loss: 0.84234 | Val Loss: 46.77090 | Train Acc: 60.224| Val Acc: 36.313\n",
            "Epoch 171: | Train Loss: 0.84089 | Val Loss: 48.12755 | Train Acc: 60.470| Val Acc: 36.117\n",
            "Epoch 172: | Train Loss: 0.84329 | Val Loss: 52.33008 | Train Acc: 60.501| Val Acc: 36.233\n",
            "Epoch 173: | Train Loss: 0.83895 | Val Loss: 50.74819 | Train Acc: 60.462| Val Acc: 36.277\n",
            "Epoch 174: | Train Loss: 0.83892 | Val Loss: 40.94375 | Train Acc: 60.491| Val Acc: 36.364\n",
            "Epoch 175: | Train Loss: 0.84176 | Val Loss: 53.58597 | Train Acc: 60.583| Val Acc: 36.281\n",
            "Epoch 176: | Train Loss: 0.83454 | Val Loss: 53.97118 | Train Acc: 60.559| Val Acc: 36.301\n",
            "Epoch 177: | Train Loss: 0.83481 | Val Loss: 44.03920 | Train Acc: 60.746| Val Acc: 36.376\n",
            "Epoch 178: | Train Loss: 0.83578 | Val Loss: 48.62105 | Train Acc: 60.689| Val Acc: 36.265\n",
            "Epoch 179: | Train Loss: 0.83304 | Val Loss: 62.92916 | Train Acc: 60.652| Val Acc: 36.396\n",
            "Epoch 180: | Train Loss: 0.83344 | Val Loss: 53.76933 | Train Acc: 60.517| Val Acc: 36.460\n",
            "Epoch 181: | Train Loss: 0.83127 | Val Loss: 77.82663 | Train Acc: 60.987| Val Acc: 36.344\n",
            "Epoch 182: | Train Loss: 0.83671 | Val Loss: 37.98298 | Train Acc: 60.579| Val Acc: 36.221\n",
            "Epoch 183: | Train Loss: 0.82852 | Val Loss: 51.25410 | Train Acc: 61.028| Val Acc: 36.424\n",
            "Epoch 184: | Train Loss: 0.82652 | Val Loss: 48.26266 | Train Acc: 61.196| Val Acc: 36.372\n",
            "Epoch 185: | Train Loss: 0.83206 | Val Loss: 56.82527 | Train Acc: 60.879| Val Acc: 36.169\n",
            "Epoch 186: | Train Loss: 0.82996 | Val Loss: 48.34464 | Train Acc: 60.903| Val Acc: 36.213\n",
            "Epoch 187: | Train Loss: 0.82605 | Val Loss: 41.21401 | Train Acc: 61.087| Val Acc: 36.344\n",
            "Epoch 188: | Train Loss: 0.82225 | Val Loss: 60.16166 | Train Acc: 61.396| Val Acc: 36.113\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-5748e27f82c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m           \u001b[0mX_val_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_val_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m           \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m           \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-5d63d3fdec13>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# APPENDIX"
      ],
      "metadata": {
        "id": "CdPrjLX4u2u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_df = pd.DataFrame(full_targets, columns=[\"FuturePrice\"])"
      ],
      "metadata": {
        "id": "kO0RlwtEvavG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_df[\"FuturePrice\"].value_counts().plot(kind = 'bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "o4DstDh7v61B",
        "outputId": "9fb82a04-9a72-4e9f-acc0-e71b745dfc7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74d1325d10>"
            ]
          },
          "metadata": {},
          "execution_count": 338
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildTargets_VolOnly(full_df = full, train_observations = train.shape[0], \n",
        "                         val_observations = val.shape[0], \n",
        "                         test_observations = test.shape[0], \n",
        "                         alph = 0.55, volity_int = 10):\n",
        "\n",
        "  \"\"\" \n",
        "  This function will take a complete set of train, val, and test data and return the targets.\n",
        "  Volitility will be calculated over the 252 5min incriments \n",
        "  The Target shift is looking at 2 hours shift from current time\n",
        "  \"\"\"\n",
        "\n",
        "  returns = np.log(full_df['Close']/(full_df['Close'].shift(1)))\n",
        "  returns.fillna(0, inplace=True)\n",
        "  #volatility = returns.std()*np.sqrt(volity_int)\n",
        "  volatility = returns.rolling(window=volity_int).std()*np.sqrt(volity_int)\n",
        "\n",
        "\n",
        "\n",
        "  return volatility\n",
        "  #return train_targets, val_targets, test_targets, full_targets\n",
        "\n",
        "volatility = buildTargets_VolOnly()\n",
        "\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "ax1 = fig.add_subplot(1, 1, 1)\n",
        "volatility.plot(ax=ax1, color = \"red\")\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Volatility', color = \"red\")\n",
        "ax1.set_title(f'Annualized volatility for {ticker}')\n",
        "ax2 = ax1.twinx()\n",
        "full.Close.plot(ax=ax2, color = \"blue\")\n",
        "ax2.set_ylabel('Close', color = \"blue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "qUSks6bebTnk",
        "outputId": "95096d69-9fee-4d57-cdf8-870bbf0b9abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y=data.data,data.target\n",
        "# Since the default in the file is 0=malignant 1=benign we want to reverse these\n",
        "y=(y==0).astype(int)\n",
        "X,y= np.array(X),np.array(y)\n",
        "\n",
        "# Let's set aside a test set and use the remainder for training and cross-validation\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0,test_size=0.2)\n",
        "\n",
        "# Let's scale our data to help the algorithm converge faster\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "UViHHQXtEB7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full.drop(columns=['Time', ])"
      ],
      "metadata": {
        "id": "DxdD_w9pRfO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ],
      "metadata": {
        "id": "TKu0iaKZSnyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=load_breast_cancer(as_frame=True)"
      ],
      "metadata": {
        "id": "K23hvV9cWb96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuBc_eiVWedQ",
        "outputId": "fda35b37-d263-4822-e472-46c94d9d2a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "564    0\n",
              "565    0\n",
              "566    0\n",
              "567    0\n",
              "568    1\n",
              "Name: target, Length: 569, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rCar6GOuWe6f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}