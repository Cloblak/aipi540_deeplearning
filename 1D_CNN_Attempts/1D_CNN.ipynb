{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBdogLili6qUeUxfBXy6/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cloblak/aipi540_deeplearning/blob/main/1D_CNN_Attempts/1D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install alpaca_trade_api"
      ],
      "metadata": {
        "id": "Xj0pR3efRVrc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "trkpODYLDmLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import alpaca_trade_api as tradeapi\n",
        "from datetime import datetime, timedelta, tzinfo, timezone, time\n",
        "import os.path\n",
        "import ast\n",
        "import threading\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plta"
      ],
      "metadata": {
        "id": "J1fWNRnTQZX-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAPER_API_KEY = \"PKE39LILN9SL1FMJMFV7\"\n",
        "PAPER_SECRET_KEY = \"TkU7fXH6WhP15MewgWlSnQG5RUoHGOPQ7yqlD6xq\"\n",
        "PAPER_BASE_URL = 'https://paper-api.alpaca.markets'"
      ],
      "metadata": {
        "id": "IXnO8ykgRIuv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api = tradeapi.REST(PAPER_API_KEY, PAPER_SECRET_KEY, PAPER_BASE_URL, api_version='v2')"
      ],
      "metadata": {
        "id": "_3XShkLcRQMs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_validate_offset_data(api, ticker, interval, train_days=180, test_days=60, validate_days=30, offset_days = 0):\n",
        "    ticker_data_dict = None\n",
        "    ticker_data_dict = {}\n",
        "    monthly_data_dict = None\n",
        "    monthly_data_dict = {}\n",
        "    interval_loop_data = None\n",
        "    interval_loop_data = pd.DataFrame()\n",
        "    stock_data = None\n",
        "    \n",
        "    days_to_collect = train_days + test_days + validate_days + offset_days\n",
        "\n",
        "    TZ = 'US/Eastern'\n",
        "\n",
        "    start = pd.to_datetime((datetime.now() - timedelta(days=days_to_collect)).strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "    end = pd.to_datetime(datetime.now().strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "\n",
        "    stock_data = api.get_bars(ticker, interval, start = start.isoformat(), end=end.isoformat(), adjustment=\"raw\").df\n",
        "    \n",
        "    interval_loop_data = interval_loop_data.append(stock_data)\n",
        "    df_start_ref = interval_loop_data.index[0]\n",
        "    start_str_ref = pd.to_datetime(start, utc=True)\n",
        "\n",
        "    while start_str_ref.value < ( pd.to_datetime(df_start_ref, utc=True) - pd.Timedelta(days=2.5)).value:\n",
        "        end_new = pd.to_datetime(interval_loop_data.index.iloc[0].strftime(\"%Y-%m-%d %H:%M\"), utc=True).isoformat()\n",
        "        stock_data_new = None\n",
        "        stock_data_new = api.get_bars(ticker, interval, start=start, end=end_new, adjustment=\"raw\").df\n",
        "        #stock_data_new = stock_data_new.reset_index()\n",
        "        interval_loop_data = interval_loop_data.append(stock_data_new).sort_values(by=['index'], ascending=True)\n",
        "        df_start_ref = interval_loop_data.index[0]\n",
        "        \n",
        "    stock_yr_min_df = interval_loop_data.copy()\n",
        "    stock_yr_min_df[\"Open\"] = stock_yr_min_df['open']\n",
        "    stock_yr_min_df[\"High\"]= stock_yr_min_df[\"high\"]\n",
        "    stock_yr_min_df[\"Low\"] = stock_yr_min_df[\"low\"]\n",
        "    stock_yr_min_df[\"Close\"] = stock_yr_min_df[\"close\"]\n",
        "    stock_yr_min_df[\"Volume\"] = stock_yr_min_df[\"volume\"]\n",
        "    stock_yr_min_df[\"VolumeWeightedAvgPrice\"] = stock_yr_min_df[\"vwap\"]\n",
        "    stock_yr_min_df[\"Time\"] = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    stock_yr_min_df.index = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    final_df = stock_yr_min_df.filter([\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"VolumeWeightedAvgPrice\"], axis = 1)\n",
        "    \n",
        "    first_day = final_df.index[0]\n",
        "    traintest_day = final_df.index[-1] - pd.Timedelta(days= test_days+validate_days+offset_days)\n",
        "    testval_day = final_df.index[-1] - pd.Timedelta(days= validate_days+offset_days)\n",
        "    last_day = final_df.index[-1] - pd.Timedelta(days= offset_days)\n",
        "    training_df =  final_df.loc[first_day:traintest_day] #(data_split - pd.Timedelta(days=1))]\n",
        "    testing_df =  final_df.loc[traintest_day:testval_day]\n",
        "    validate_df = final_df.loc[testval_day:last_day]\n",
        "    full_train = final_df.loc[first_day:last_day]\n",
        "    offset_df =  final_df.loc[last_day:]\n",
        "\n",
        "    return training_df, testing_df, validate_df, full_train, offset_df, final_df, traintest_day, testval_day"
      ],
      "metadata": {
        "id": "tINNlljbRaDs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = \"TQQQ\"\n",
        "interval = \"5Min\"\n",
        "train_day_int = 365\n",
        "test_day_int = 180\n",
        "val_day_int = 180\n",
        "offset_day_int = 365\n",
        "train, test, val, full, offset, complete, traintest_day, testval_day = train_test_validate_offset_data(api, ticker, \n",
        "                                                                                     interval, \n",
        "                                                                                     train_days=train_day_int, \n",
        "                                                                                     test_days=test_day_int, \n",
        "                                                                                     validate_days=val_day_int,\n",
        "                                                                                     offset_days = offset_day_int)"
      ],
      "metadata": {
        "id": "rRFxnqAiRcnE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Preparing The Data"
      ],
      "metadata": {
        "id": "IMY3MYh4D7sR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create target from OHLC and Volume Data\n",
        "\n"
      ],
      "metadata": {
        "id": "NmTD5JViEFMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y=data.data,data.target\n",
        "# Since the default in the file is 0=malignant 1=benign we want to reverse these\n",
        "y=(y==0).astype(int)\n",
        "X,y= np.array(X),np.array(y)\n",
        "\n",
        "# Let's set aside a test set and use the remainder for training and cross-validation\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0,test_size=0.2)\n",
        "\n",
        "# Let's scale our data to help the algorithm converge faster\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "UViHHQXtEB7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full.drop(columns=['Time', ])"
      ],
      "metadata": {
        "id": "DxdD_w9pRfO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ],
      "metadata": {
        "id": "TKu0iaKZSnyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=load_breast_cancer(as_frame=True)"
      ],
      "metadata": {
        "id": "K23hvV9cWb96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuBc_eiVWedQ",
        "outputId": "fda35b37-d263-4822-e472-46c94d9d2a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "564    0\n",
              "565    0\n",
              "566    0\n",
              "567    0\n",
              "568    1\n",
              "Name: target, Length: 569, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rCar6GOuWe6f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}