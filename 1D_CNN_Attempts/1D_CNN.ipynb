{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "35b0c6a641f74b7a8a5a17696c771999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5435c22875e1449bba6f514dc362fb86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2174b8eaf379476aa207a7d3553a23cb",
              "IPY_MODEL_d2eea602e1f44679b9dca81d02cef6a9",
              "IPY_MODEL_4c4ee8d44be44753b86d2334ed5201d9"
            ]
          }
        },
        "5435c22875e1449bba6f514dc362fb86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2174b8eaf379476aa207a7d3553a23cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d07aa40726741bba6d08a741f239b2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 63%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae9e58658d6e45a0ae4f071d65facbd8"
          }
        },
        "d2eea602e1f44679b9dca81d02cef6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39c656c52a3b41f4912ae2f141bf1291",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 188,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_101532c20c604f9cbddaae38f83cb611"
          }
        },
        "4c4ee8d44be44753b86d2334ed5201d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a809155bf81340c88a359f8e8b52b1a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 188/300 [1:25:16&lt;50:49, 27.23s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a927038a7cb49a6a64673ce556a0c8e"
          }
        },
        "2d07aa40726741bba6d08a741f239b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae9e58658d6e45a0ae4f071d65facbd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39c656c52a3b41f4912ae2f141bf1291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "101532c20c604f9cbddaae38f83cb611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a809155bf81340c88a359f8e8b52b1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a927038a7cb49a6a64673ce556a0c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cloblak/aipi540_deeplearning/blob/main/1D_CNN_Attempts/1D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alpaca_trade_api"
      ],
      "metadata": {
        "id": "Xj0pR3efRVrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede7ded3-d52c-4251-e23c-349526865440"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alpaca_trade_api\n",
            "  Downloading alpaca_trade_api-1.5.0-py3-none-any.whl (45 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▏                        | 10 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 20 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 45 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.24.3)\n",
            "Collecting aiohttp==3.7.4\n",
            "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 13.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>2 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (2.23.0)\n",
            "Collecting msgpack==1.0.2\n",
            "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
            "\u001b[K     |████████████████████████████████| 273 kB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.1.5)\n",
            "Collecting websocket-client<2,>=0.56.0\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 800 kB/s \n",
            "\u001b[?25hCollecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting websockets<10,>=8.0\n",
            "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api) (1.19.5)\n",
            "Collecting PyYAML==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 10.9 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (3.0.4)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (3.10.0.2)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api) (21.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation==2.1.0->alpaca_trade_api) (21.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.1->alpaca_trade_api) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->alpaca_trade_api) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->alpaca_trade_api) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation==2.1.0->alpaca_trade_api) (3.0.7)\n",
            "Installing collected packages: multidict, yarl, async-timeout, websockets, websocket-client, PyYAML, msgpack, deprecation, aiohttp, alpaca-trade-api\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.3\n",
            "    Uninstalling msgpack-1.0.3:\n",
            "      Successfully uninstalled msgpack-1.0.3\n",
            "Successfully installed PyYAML-5.4.1 aiohttp-3.7.4 alpaca-trade-api-1.5.0 async-timeout-3.0.1 deprecation-2.1.0 msgpack-1.0.2 multidict-6.0.2 websocket-client-1.2.3 websockets-9.1 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features To Consider\n",
        " - Targets are only predicting sell within market hours, i.e. at 1530, target is prediciting price for 1100 the next day.  Data from pre and post market is taken into consideration, and a sell or buy will be indicated if the price will flucuate after close."
      ],
      "metadata": {
        "id": "hdKRKIogGAu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "import alpaca_trade_api as tradeapi\n",
        "from datetime import datetime, timedelta, tzinfo, timezone, time\n",
        "import os.path\n",
        "import ast\n",
        "import threading\n",
        "import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "metadata": {
        "id": "J1fWNRnTQZX-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 101\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrI_WR501Iis",
        "outputId": "216f2636-9679-4503-f4d2-57833f93cc42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3e70228710>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAPER_API_KEY = \"PKE39LILN9SL1FMJMFV7\"\n",
        "PAPER_SECRET_KEY = \"TkU7fXH6WhP15MewgWlSnQG5RUoHGOPQ7yqlD6xq\"\n",
        "PAPER_BASE_URL = 'https://paper-api.alpaca.markets'"
      ],
      "metadata": {
        "id": "IXnO8ykgRIuv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api = tradeapi.REST(PAPER_API_KEY, PAPER_SECRET_KEY, PAPER_BASE_URL, api_version='v2')"
      ],
      "metadata": {
        "id": "_3XShkLcRQMs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepost_train_test_validate_offset_data(api, ticker, interval, train_days=180, test_days=60, validate_days=30, offset_days = 0):\n",
        "    ticker_data_dict = None\n",
        "    ticker_data_dict = {}\n",
        "    monthly_data_dict = None\n",
        "    monthly_data_dict = {}\n",
        "    interval_loop_data = None\n",
        "    interval_loop_data = pd.DataFrame()\n",
        "    stock_data = None\n",
        "    \n",
        "    days_to_collect = train_days + test_days + validate_days + offset_days\n",
        "\n",
        "    TZ = 'US/Eastern'\n",
        "\n",
        "    start = pd.to_datetime((datetime.now() - timedelta(days=days_to_collect)).strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "    end = pd.to_datetime(datetime.now().strftime(\"%Y-%m-%d %H:%M\"), utc=True)\n",
        "\n",
        "    stock_data = api.get_bars(ticker, interval, start = start.isoformat(), end=end.isoformat(), adjustment=\"raw\").df\n",
        "    \n",
        "    interval_loop_data = interval_loop_data.append(stock_data)\n",
        "    df_start_ref = interval_loop_data.index[0]\n",
        "    start_str_ref = pd.to_datetime(start, utc=True)\n",
        "\n",
        "    while start_str_ref.value < ( pd.to_datetime(df_start_ref, utc=True) - pd.Timedelta(days=2.5)).value:\n",
        "        end_new = pd.to_datetime(interval_loop_data.index[0].strftime(\"%Y-%m-%d %H:%M\"), utc=True).isoformat()\n",
        "        stock_data_new = None\n",
        "        stock_data_new = api.get_bars(ticker, interval, start=start, end=end_new, adjustment=\"raw\").df\n",
        "        #stock_data_new = stock_data_new.reset_index()\n",
        "        interval_loop_data = interval_loop_data.append(stock_data_new).sort_values(by=['index'], ascending=True)\n",
        "        df_start_ref = interval_loop_data.index[0]\n",
        "        \n",
        "    stock_yr_min_df = interval_loop_data.copy()\n",
        "    stock_yr_min_df[\"Open\"] = stock_yr_min_df['open']\n",
        "    stock_yr_min_df[\"High\"]= stock_yr_min_df[\"high\"]\n",
        "    stock_yr_min_df[\"Low\"] = stock_yr_min_df[\"low\"]\n",
        "    stock_yr_min_df[\"Close\"] = stock_yr_min_df[\"close\"]\n",
        "    stock_yr_min_df[\"Volume\"] = stock_yr_min_df[\"volume\"]\n",
        "    stock_yr_min_df[\"VolumeWeightedAvgPrice\"] = stock_yr_min_df[\"vwap\"]\n",
        "    stock_yr_min_df[\"Time\"] = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    stock_yr_min_df.index = stock_yr_min_df.index.tz_convert(TZ)\n",
        "    final_df = stock_yr_min_df.filter([\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"VolumeWeightedAvgPrice\"], axis = 1)\n",
        "    \n",
        "    first_day = final_df.index[0]\n",
        "    traintest_day = final_df.index[-1] - pd.Timedelta(days= test_days+validate_days+offset_days)\n",
        "    valtest_day = final_df.index[-1] - pd.Timedelta(days= test_days+offset_days)\n",
        "    last_day = final_df.index[-1] - pd.Timedelta(days= offset_days)\n",
        "    training_df =  final_df.loc[first_day:traintest_day] #(data_split - pd.Timedelta(days=1))]\n",
        "    validate_df = final_df.loc[traintest_day:valtest_day]\n",
        "    testing_df =  final_df.loc[valtest_day:last_day]\n",
        "    full_train = final_df.loc[first_day:last_day]\n",
        "    offset_df =  final_df.loc[last_day:]\n",
        "\n",
        "    return training_df, validate_df, testing_df, full_train, offset_df, final_df, traintest_day, valtest_day\n"
      ],
      "metadata": {
        "id": "tINNlljbRaDs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "\n",
        "train_start = date(2017, 1, 1)\n",
        "train_end = date(2019, 10, 31)\n",
        "train_delta = train_end - train_start\n",
        "print(f'Number of days of Training Data {train_delta.days}')\n",
        "\n",
        "val_day_num = 400\n",
        "print(f'Number of days of Validation Data {val_day_num}')\n",
        "\n",
        "test_start = train_end + timedelta(val_day_num)\n",
        "test_end = date.today()\n",
        "test_delta = (test_end - test_start)\n",
        "print(f'Number of days of Holdout Test Data {test_delta.days}')\n",
        "\n",
        "ticker = \"USO\" # Ticker Symbol to Test\n",
        "interval = \"5Min\" # Interval of bars\n",
        "train_day_int = train_delta.days # Size of training set (Jan 2010 - Oct 2017)\n",
        "val_day_int = val_day_num # Size of validation set\n",
        "test_day_int = test_delta.days # Size of test set\n",
        "offset_day_int = 0 # Number of days to off set the training data\n",
        "train, val, test, full, offset, complete, traintest_day, testval_day = prepost_train_test_validate_offset_data(api, ticker, \n",
        "                                                                                     interval, \n",
        "                                                                                     train_days=train_day_int, \n",
        "                                                                                     test_days=test_day_int, \n",
        "                                                                                     validate_days=val_day_int,\n",
        "                                                                                     offset_days = offset_day_int)"
      ],
      "metadata": {
        "id": "rRFxnqAiRcnE",
        "outputId": "10655657-a5cc-4030-95c9-1fd1708db415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of days of Training Data 1033\n",
            "Number of days of Validation Data 400\n",
            "Number of days of Holdout Test Data 423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def timeFilterAndBackfill(df):\n",
        "  \"\"\" \n",
        "  Prep df to be filled out for each trading day:\n",
        "  Time Frame: 0730-1730\n",
        "  Backfilling NaNs\n",
        "  Adjusting Volume to Zero if no Trading data is present\n",
        "     - Assumption is that there were no trades duing that time  \n",
        "  \"\"\"\n",
        "  \n",
        "  df = df.between_time('07:29','17:26')\n",
        "\n",
        "  TZ = 'US/Eastern'\n",
        "\n",
        "  start_dateTime = pd.Timestamp(year = df.index[0].year, \n",
        "                                month = df.index[0].month, \n",
        "                                day = df.index[0].day, \n",
        "                                hour = 7, minute = 25, tz = TZ)\n",
        "\n",
        "  end_dateTime = pd.Timestamp(year = df.index[-1].year, \n",
        "                              month = df.index[-1].month, \n",
        "                              day = df.index[-1].day, \n",
        "                              hour = 17, minute = 35, tz = TZ)\n",
        "\n",
        "  dateTime_index = pd.date_range(start_dateTime,\n",
        "                                end_dateTime, \n",
        "                                freq='5min').tolist()\n",
        "\n",
        "  dateTime_index_df = pd.DataFrame()\n",
        "  dateTime_index_df[\"Time\"] = dateTime_index \n",
        "  filtered_df = pd.merge_asof(dateTime_index_df, df,  \n",
        "                              on='Time', \n",
        "                              direction='backward').set_index(\"Time\").between_time('08:29','16:29')\n",
        "\n",
        "  volumeset_list = []\n",
        "  prev_v = None\n",
        "\n",
        "  for v in filtered_df[\"Volume\"]:\n",
        "    \n",
        "    if prev_v == None:\n",
        "      if math.isnan(v):\n",
        "        prev_v = 0\n",
        "        volumeset_list.append(0)\n",
        "      else:\n",
        "        prev_v = v\n",
        "        volumeset_list.append(v)\n",
        "\n",
        "    elif prev_v != None:\n",
        "      if v == prev_v:\n",
        "        volumeset_list.append(0)\n",
        "        prev_v = v\n",
        "      elif math.isnan(v):\n",
        "        volumeset_list.append(0)\n",
        "        prev_v = 0\n",
        "      else:\n",
        "        volumeset_list.append(v)\n",
        "        prev_v = v\n",
        "\n",
        "\n",
        "  filtered_df[\"Volume\"] = volumeset_list\n",
        "  adjvolumeset_list = []\n",
        "\n",
        "  prev_v = None\n",
        "\n",
        "  for v in filtered_df[\"VolumeWeightedAvgPrice\"]:\n",
        "    if prev_v == None:\n",
        "      if math.isnan(v):\n",
        "        prev_v = 0\n",
        "        adjvolumeset_list.append(0)\n",
        "      else:\n",
        "        prev_v = v\n",
        "        adjvolumeset_list.append(v)\n",
        "    elif prev_v != None:\n",
        "      if v == prev_v:\n",
        "        adjvolumeset_list.append(0)\n",
        "        prev_v = v\n",
        "      elif math.isnan(v):\n",
        "        adjvolumeset_list.append(0)\n",
        "        prev_v = 0\n",
        "      else:\n",
        "        adjvolumeset_list.append(v)\n",
        "        prev_v = v\n",
        "\n",
        "  filtered_df[\"VolumeWeightedAvgPrice\"] = adjvolumeset_list\n",
        "\n",
        "  preped_df = filtered_df.backfill()\n",
        "\n",
        "  return preped_df\n",
        "\n",
        "def blockshaped(arr, nrows, ncols):\n",
        "    \"\"\"\n",
        "    Return an array of shape (n, nrows, ncols) where\n",
        "    n * nrows * ncols = arr.size\n",
        "\n",
        "    If arr is a 2D array, the returned array should look like n subblocks with\n",
        "    each subblock preserving the \"physical\" layout of arr.\n",
        "    \"\"\"\n",
        "    h, w = arr.shape\n",
        "    assert h % nrows == 0, f\"{h} rows is not evenly divisible by {nrows}\"\n",
        "    assert w % ncols == 0, f\"{w} cols is not evenly divisible by {ncols}\"\n",
        "    return np.flip(np.rot90((arr.reshape(h//nrows, nrows, -1, ncols)\n",
        "               .swapaxes(1,2)\n",
        "               .reshape(-1, nrows, ncols)), axes = (1, 2)), axis = 1)\n",
        "  \n",
        "\n",
        "def buildOutData_TorchPrep(train_df = train, val_df = val, test_df = test):\n",
        "  pass"
      ],
      "metadata": {
        "id": "bbrVHNazd27v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = timeFilterAndBackfill(train)\n",
        "val = timeFilterAndBackfill(val)\n",
        "test = timeFilterAndBackfill(test)"
      ],
      "metadata": {
        "id": "wW4vHhnfgne4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tonp = train[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "val_tonp = val[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "test_tonp = test[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "train_array = train_tonp.to_numpy()\n",
        "val_array = val_tonp.to_numpy()\n",
        "test_array = test_tonp.to_numpy()\n",
        "X_train = blockshaped(train_array, 24, 5)\n",
        "X_val = blockshaped(val_array, 24, 5)\n",
        "X_test = blockshaped(test_array, 24, 5)"
      ],
      "metadata": {
        "id": "eYe9V9P9iFyn"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create target from OHLC and Volume Data\n",
        "def buildTargets(obs_array,  \n",
        "                 alph = .25, \n",
        "                 volity_int = 8):\n",
        "\n",
        "  \"\"\" \n",
        "  This function will take a complete set of train, val, and test \n",
        "  data and return the targets. Volitility will be calculated over \n",
        "  the 24 5min incriments. The Target shift is looking at 2 hours \n",
        "  shift from current time\n",
        "\n",
        "  shift_2hour = The amount of time the data interval take to equal 2 hours \n",
        "                (i.e. 5 min data interval is equal to 24)\n",
        "  alph = The alpha value for calculating the shift in price\n",
        "  volity_int = the number of incriments used to calculate volitility \n",
        "  \"\"\"\n",
        "\n",
        "  target_close_list =[]\n",
        "\n",
        "  for arr in obs_array:\n",
        "    target_close_list.append(arr[3][-1])\n",
        "  \n",
        "  target_close_df = pd.DataFrame()\n",
        "  target_close_df[\"Close\"] = target_close_list\n",
        "\n",
        "  returns = np.log(target_close_df['Close']/(target_close_df['Close'].shift(1)))\n",
        "  returns.fillna(0, inplace=True)\n",
        "  volatility = returns.rolling(window=volity_int).std()*np.sqrt(volity_int)\n",
        "  \n",
        "  targets = [2] * len(target_close_df.Close)\n",
        "\n",
        "  targets = np.where(target_close_df.Close.shift(-1) >= (target_close_df.Close * (1 + alph * volatility)), \n",
        "           1, targets)\n",
        "  \n",
        "  targets = np.where(target_close_df.Close.shift(-1) <= (target_close_df.Close * (1 - alph * volatility)), \n",
        "           0, targets)\n",
        "\n",
        "  return targets"
      ],
      "metadata": {
        "id": "Pe89LdnsLltO"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "volity_val = 2\n",
        "y_train = buildTargets(X_train, volity_int = volity_val)\n",
        "y_val = buildTargets(X_val, volity_int = volity_val)\n",
        "y_test = buildTargets(X_test, volity_int = volity_val)"
      ],
      "metadata": {
        "id": "4aYPOa7INyAl"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# Code fro scaling at a later date\n",
        "######\n",
        "\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# scalers = {}\n",
        "# for i in range(X_train.shape[1]):\n",
        "#     scalers[i] = MinMaxScaler()\n",
        "#     X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :]) \n",
        "\n",
        "# for i in range(X_val.shape[1]):\n",
        "#     X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) \n",
        "\n",
        "# for i in range(X_test.shape[1]):\n",
        "#     X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) "
      ],
      "metadata": {
        "id": "iSXapYOwjsnF"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 1,\n",
        "                          X_train.shape[1], \n",
        "                          X_train.shape[2])\n",
        "X_val = X_val.reshape(X_val.shape[0], 1,\n",
        "                          X_val.shape[1], \n",
        "                          X_val.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1,\n",
        "                          X_test.shape[1], \n",
        "                          X_test.shape[2])"
      ],
      "metadata": {
        "id": "SxB_AzoBf4Xe"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X Train Length {X_train.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test.shape}, y Test Label Length {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIYp1XKJPCNL",
        "outputId": "711c4718-934c-4533-f017-4845f56f4be7"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4128, 1, 5, 24), y Train Label Length (4128,)\n",
            "X Val Length (1604, 1, 5, 24), y Val Label Length (1604,)\n",
            "X Test Length (1696, 1, 5, 24), y Test Label Length (1696,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[100:150]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYHL1ekIYzDV",
        "outputId": "94bbeaca-609b-4f28-9c59-bd65d77df485"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 1, 0, 2, 1, 0,\n",
              "       1, 1, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       1, 2, 2, 1, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_distribution(obj):\n",
        "    count_dict = {\n",
        "        \"up\": 0,\n",
        "        \"flat\": 0,\n",
        "        \"down\": 0,\n",
        "    }\n",
        "    \n",
        "    for i in obj:\n",
        "        if i == 1: \n",
        "            count_dict['up'] += 1\n",
        "        elif i == 0: \n",
        "            count_dict['down'] += 1\n",
        "        elif i == 2: \n",
        "            count_dict['flat'] += 1             \n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "            \n",
        "    return count_dict"
      ],
      "metadata": {
        "id": "vWIY2rwEYCfM"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25,7))\n",
        "# Train\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_train)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')\n",
        "# Validation\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_val)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
        "# Test\n",
        "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_test)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[2]).set_title('Class Distribution in Test Set')"
      ],
      "metadata": {
        "id": "-BsVCfr8YCiX",
        "outputId": "718e9ef6-21a5-4a8a-8e7d-d0acc51000c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution in Test Set')"
            ]
          },
          "metadata": {},
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x504 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8ragjY1i-0F",
        "outputId": "c39a54f5-4862-44f3-d831-e1e9f8b5bfe6"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4128, 1, 5, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X Train Length {X_train.shape}, y Train Label Length {y_train.shape}')\n",
        "print(f'X Val Length {X_val.shape}, y Val Label Length {y_val.shape}')\n",
        "print(f'X Test Length {X_test.shape}, y Test Label Length {y_test.shape}')\n",
        "print(\"\")\n",
        "print('Training data window: ', len(X_train))\n",
        "print('Val data windows: ', len(X_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ThCmAdYCX9",
        "outputId": "973e6a9a-f602-4d58-b361-c854984d5c95"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Length (4128, 1, 5, 24), y Train Label Length (4128,)\n",
            "X Val Length (1604, 1, 5, 24), y Val Label Length (1604,)\n",
            "X Test Length (1696, 1, 5, 24), y Test Label Length (1696,)\n",
            "\n",
            "Training data window:  4128\n",
            "Val data windows:  1604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0].dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAdhr0KLy-72",
        "outputId": "030d3b94-8ef2-4091-a87f-9da392191c2a"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = TensorDataset(torch.from_numpy(X_train).float(), \n",
        "                         torch.from_numpy(y_train).long())\n",
        "testset = TensorDataset(torch.from_numpy(X_test).float(), \n",
        "                        torch.from_numpy(y_test).long())"
      ],
      "metadata": {
        "id": "Z8LYXJfqSLxN"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset = TensorDataset(torch.from_numpy(X_train_scaled).float(), \n",
        "#                          torch.from_numpy(y_train).long())\n",
        "# testset = TensorDataset(torch.from_numpy(X_test_scaled).float(), \n",
        "#                         torch.from_numpy(y_test).long())\n"
      ],
      "metadata": {
        "id": "PyhgFtaBR7nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 0\n",
        "\n",
        "# train_data = []\n",
        "# for i in range(len(X_train)):\n",
        "#    train_data.append([X_train[i].astype('float'), y_train[i]])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset, shuffle=False)\n",
        "i1, l1 = next(iter(train_loader))\n",
        "print(i1.shape)\n",
        "\n",
        "# val_data = []\n",
        "# for i in range(len(X_val)):\n",
        "#    val_data.append([X_val[i].astype('float'), y_val[i]])\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(testset, shuffle=False)\n",
        "i1, l1 = next(iter(val_loader))\n",
        "print(i1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zun8GwOiBlW",
        "outputId": "f6bd50fe-4df3-4748-82b8-50b073c2453f"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 5, 24])\n",
            "torch.Size([1, 1, 5, 24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get next batch of training images\n",
        "windows, labels = iter(train_loader).next()\n",
        "print(windows.shape)\n",
        "windows = windows.numpy()\n",
        "\n",
        "# plot the windows in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "for idx in range(batch_size):\n",
        "    print(labels[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "BaDGe3DSpg6f",
        "outputId": "8a7d8fa0-d352-4591-ced6-7681dbd5573d"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 5, 24])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change "
      ],
      "metadata": {
        "id": "9PL-e2mAMV6x"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockShiftClassification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(StockShiftClassification, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool1 = nn.MaxPool2d(4,4)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool2 = nn.MaxPool2d(3,3)  \n",
        "\n",
        "    self.conv3 = nn.Conv2d(64, 128, kernel_size = (1,3), stride=1, padding = 1)\n",
        "    self.pool3 = nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.fc1 = nn.Linear(128,1000) #calculate this\n",
        "    self.fc2 = nn.Linear(1000, 500)\n",
        "    self.fc3 = nn.Linear(500, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool2(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.pool3(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    # Linear layer\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    output = x #F.log_softmax(x, dim=1)\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "YSLUlwla8BSU"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "net = StockShiftClassification().float()\n",
        "\n",
        "# Display a summary of the layers of the model and output shape after each layer\n",
        "summary(net,(windows.shape[1:]),batch_size=batch_size,device=\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAw7OiPS8BNu",
        "outputId": "79a82437-483e-472a-994c-94eb40e12b0e"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1             [0, 32, 7, 24]             128\n",
            "         MaxPool2d-2              [0, 32, 1, 6]               0\n",
            "            Conv2d-3              [0, 64, 3, 6]           6,208\n",
            "         MaxPool2d-4              [0, 64, 1, 2]               0\n",
            "            Conv2d-5             [0, 128, 3, 2]          24,704\n",
            "         MaxPool2d-6             [0, 128, 1, 1]               0\n",
            "            Linear-7                  [0, 1000]         129,000\n",
            "            Linear-8                   [0, 500]         500,500\n",
            "            Linear-9                     [0, 3]           1,503\n",
            "================================================================\n",
            "Total params: 662,043\n",
            "Trainable params: 662,043\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 2.53\n",
            "Estimated Total Size (MB): 2.53\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross entropy loss combines softmax and nn.NLLLoss() in one single class.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "rZGSLKkq8BIu"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,criterion,optimizer,train_loader,n_epochs,device):\n",
        "    \n",
        "    loss_over_time = [] # to track the loss as the network trains\n",
        "    \n",
        "    model = model.to(device) # Send model to GPU if available\n",
        "    model.train() # Set the model to training mode\n",
        "    \n",
        "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            \n",
        "            # Get the input images and labels, and send to GPU if available\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # Zero the weight gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass to get outputs\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backpropagation to get the gradients with respect to each weight\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Convert loss into a scalar and add it to running_loss\n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            if i % 1000 == 999:    # print every 1000 batches\n",
        "                avg_loss = running_loss/1000\n",
        "                # record and print the avg loss over the 1000 batches\n",
        "                loss_over_time.append(avg_loss)\n",
        "                print('Epoch: {}, Batch: {}, Avg. Loss: {:.4f}'.format(epoch + 1, i+1, avg_loss))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    return loss_over_time"
      ],
      "metadata": {
        "id": "lAgQIWqA8BEW"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_epochs = 100\n",
        "cost_path = train_model(net.float(),criterion,optimizer,train_loader,n_epochs,device)\n",
        "\n",
        "# visualize the loss as the network trained\n",
        "plt.plot(cost_path)\n",
        "plt.xlabel('Batch (1000s)')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mx3XtDf_8A_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aaf87282-6a2c-4735-d4fd-fd24a112539d"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch: 1000, Avg. Loss: 1.0725\n",
            "Epoch: 1, Batch: 2000, Avg. Loss: 1.0908\n",
            "Epoch: 1, Batch: 3000, Avg. Loss: 1.0724\n",
            "Epoch: 1, Batch: 4000, Avg. Loss: 1.0833\n",
            "Epoch: 2, Batch: 1000, Avg. Loss: 1.0733\n",
            "Epoch: 2, Batch: 2000, Avg. Loss: 1.0848\n",
            "Epoch: 2, Batch: 3000, Avg. Loss: 1.0692\n",
            "Epoch: 2, Batch: 4000, Avg. Loss: 1.0819\n",
            "Epoch: 3, Batch: 1000, Avg. Loss: 1.0747\n",
            "Epoch: 3, Batch: 2000, Avg. Loss: 1.0845\n",
            "Epoch: 3, Batch: 3000, Avg. Loss: 1.0689\n",
            "Epoch: 3, Batch: 4000, Avg. Loss: 1.0815\n",
            "Epoch: 4, Batch: 1000, Avg. Loss: 1.0765\n",
            "Epoch: 4, Batch: 2000, Avg. Loss: 1.0848\n",
            "Epoch: 4, Batch: 3000, Avg. Loss: 1.0685\n",
            "Epoch: 4, Batch: 4000, Avg. Loss: 1.0814\n",
            "Epoch: 5, Batch: 1000, Avg. Loss: 1.0773\n",
            "Epoch: 5, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 5, Batch: 3000, Avg. Loss: 1.0685\n",
            "Epoch: 5, Batch: 4000, Avg. Loss: 1.0813\n",
            "Epoch: 6, Batch: 1000, Avg. Loss: 1.0774\n",
            "Epoch: 6, Batch: 2000, Avg. Loss: 1.0845\n",
            "Epoch: 6, Batch: 3000, Avg. Loss: 1.0682\n",
            "Epoch: 6, Batch: 4000, Avg. Loss: 1.0812\n",
            "Epoch: 7, Batch: 1000, Avg. Loss: 1.0782\n",
            "Epoch: 7, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 7, Batch: 3000, Avg. Loss: 1.0679\n",
            "Epoch: 7, Batch: 4000, Avg. Loss: 1.0807\n",
            "Epoch: 8, Batch: 1000, Avg. Loss: 1.0787\n",
            "Epoch: 8, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 8, Batch: 3000, Avg. Loss: 1.0680\n",
            "Epoch: 8, Batch: 4000, Avg. Loss: 1.0806\n",
            "Epoch: 9, Batch: 1000, Avg. Loss: 1.0787\n",
            "Epoch: 9, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 9, Batch: 3000, Avg. Loss: 1.0680\n",
            "Epoch: 9, Batch: 4000, Avg. Loss: 1.0805\n",
            "Epoch: 10, Batch: 1000, Avg. Loss: 1.0790\n",
            "Epoch: 10, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 10, Batch: 3000, Avg. Loss: 1.0679\n",
            "Epoch: 10, Batch: 4000, Avg. Loss: 1.0803\n",
            "Epoch: 11, Batch: 1000, Avg. Loss: 1.0793\n",
            "Epoch: 11, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 11, Batch: 3000, Avg. Loss: 1.0678\n",
            "Epoch: 11, Batch: 4000, Avg. Loss: 1.0801\n",
            "Epoch: 12, Batch: 1000, Avg. Loss: 1.0797\n",
            "Epoch: 12, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 12, Batch: 3000, Avg. Loss: 1.0677\n",
            "Epoch: 12, Batch: 4000, Avg. Loss: 1.0801\n",
            "Epoch: 13, Batch: 1000, Avg. Loss: 1.0798\n",
            "Epoch: 13, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 13, Batch: 3000, Avg. Loss: 1.0675\n",
            "Epoch: 13, Batch: 4000, Avg. Loss: 1.0798\n",
            "Epoch: 14, Batch: 1000, Avg. Loss: 1.0801\n",
            "Epoch: 14, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 14, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 14, Batch: 4000, Avg. Loss: 1.0797\n",
            "Epoch: 15, Batch: 1000, Avg. Loss: 1.0801\n",
            "Epoch: 15, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 15, Batch: 3000, Avg. Loss: 1.0676\n",
            "Epoch: 15, Batch: 4000, Avg. Loss: 1.0799\n",
            "Epoch: 16, Batch: 1000, Avg. Loss: 1.0800\n",
            "Epoch: 16, Batch: 2000, Avg. Loss: 1.0839\n",
            "Epoch: 16, Batch: 3000, Avg. Loss: 1.0675\n",
            "Epoch: 16, Batch: 4000, Avg. Loss: 1.0798\n",
            "Epoch: 17, Batch: 1000, Avg. Loss: 1.0801\n",
            "Epoch: 17, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 17, Batch: 3000, Avg. Loss: 1.0675\n",
            "Epoch: 17, Batch: 4000, Avg. Loss: 1.0796\n",
            "Epoch: 18, Batch: 1000, Avg. Loss: 1.0802\n",
            "Epoch: 18, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 18, Batch: 3000, Avg. Loss: 1.0675\n",
            "Epoch: 18, Batch: 4000, Avg. Loss: 1.0796\n",
            "Epoch: 19, Batch: 1000, Avg. Loss: 1.0803\n",
            "Epoch: 19, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 19, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 19, Batch: 4000, Avg. Loss: 1.0795\n",
            "Epoch: 20, Batch: 1000, Avg. Loss: 1.0804\n",
            "Epoch: 20, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 20, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 20, Batch: 4000, Avg. Loss: 1.0795\n",
            "Epoch: 21, Batch: 1000, Avg. Loss: 1.0804\n",
            "Epoch: 21, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 21, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 21, Batch: 4000, Avg. Loss: 1.0795\n",
            "Epoch: 22, Batch: 1000, Avg. Loss: 1.0805\n",
            "Epoch: 22, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 22, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 22, Batch: 4000, Avg. Loss: 1.0795\n",
            "Epoch: 23, Batch: 1000, Avg. Loss: 1.0805\n",
            "Epoch: 23, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 23, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 23, Batch: 4000, Avg. Loss: 1.0795\n",
            "Epoch: 24, Batch: 1000, Avg. Loss: 1.0805\n",
            "Epoch: 24, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 24, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 24, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 25, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 25, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 25, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 25, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 26, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 26, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 26, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 26, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 27, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 27, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 27, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 27, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 28, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 28, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 28, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 28, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 29, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 29, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 29, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 29, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 30, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 30, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 30, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 30, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 31, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 31, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 31, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 31, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 32, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 32, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 32, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 32, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 33, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 33, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 33, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 33, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 34, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 34, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 34, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 34, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 35, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 35, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 35, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 35, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 36, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 36, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 36, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 36, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 37, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 37, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 37, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 37, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 38, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 38, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 38, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 38, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 39, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 39, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 39, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 39, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 40, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 40, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 40, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 40, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 41, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 41, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 41, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 41, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 42, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 42, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 42, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 42, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 43, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 43, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 43, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 43, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 44, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 44, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 44, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 44, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 45, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 45, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 45, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 45, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 46, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 46, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 46, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 46, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 47, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 47, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 47, Batch: 3000, Avg. Loss: 1.0675\n",
            "Epoch: 47, Batch: 4000, Avg. Loss: 1.0796\n",
            "Epoch: 48, Batch: 1000, Avg. Loss: 1.0803\n",
            "Epoch: 48, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 48, Batch: 3000, Avg. Loss: 1.0675\n",
            "Epoch: 48, Batch: 4000, Avg. Loss: 1.0796\n",
            "Epoch: 49, Batch: 1000, Avg. Loss: 1.0805\n",
            "Epoch: 49, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 49, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 49, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 50, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 50, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 50, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 50, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 51, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 51, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 51, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 51, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 52, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 52, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 52, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 52, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 53, Batch: 1000, Avg. Loss: 1.0808\n",
            "Epoch: 53, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 53, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 53, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 54, Batch: 1000, Avg. Loss: 1.0808\n",
            "Epoch: 54, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 54, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 54, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 55, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 55, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 55, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 55, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 56, Batch: 1000, Avg. Loss: 1.0805\n",
            "Epoch: 56, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 56, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 56, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 57, Batch: 1000, Avg. Loss: 1.0805\n",
            "Epoch: 57, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 57, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 57, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 58, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 58, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 58, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 58, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 59, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 59, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 59, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 59, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 60, Batch: 1000, Avg. Loss: 1.0808\n",
            "Epoch: 60, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 60, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 60, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 61, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 61, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 61, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 61, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 62, Batch: 1000, Avg. Loss: 1.0808\n",
            "Epoch: 62, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 62, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 62, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 63, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 63, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 63, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 63, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 64, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 64, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 64, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 64, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 65, Batch: 1000, Avg. Loss: 1.0806\n",
            "Epoch: 65, Batch: 2000, Avg. Loss: 1.0840\n",
            "Epoch: 65, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 65, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 66, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 66, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 66, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 66, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 67, Batch: 1000, Avg. Loss: 1.0805\n",
            "Epoch: 67, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 67, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 67, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 68, Batch: 1000, Avg. Loss: 1.0805\n",
            "Epoch: 68, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 68, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 68, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 69, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 69, Batch: 2000, Avg. Loss: 1.0841\n",
            "Epoch: 69, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 69, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 70, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 70, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 70, Batch: 3000, Avg. Loss: 1.0674\n",
            "Epoch: 70, Batch: 4000, Avg. Loss: 1.0794\n",
            "Epoch: 71, Batch: 1000, Avg. Loss: 1.0807\n",
            "Epoch: 71, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 71, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 71, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 72, Batch: 1000, Avg. Loss: 1.0808\n",
            "Epoch: 72, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 72, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 72, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 73, Batch: 1000, Avg. Loss: 1.0808\n",
            "Epoch: 73, Batch: 2000, Avg. Loss: 1.0843\n",
            "Epoch: 73, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 73, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 74, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 74, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 74, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 74, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 75, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 75, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 75, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 75, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 76, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 76, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 76, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 76, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 77, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 77, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 77, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 77, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 78, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 78, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 78, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 78, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 79, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 79, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 79, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 79, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 80, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 80, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 80, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 80, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 81, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 81, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 81, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 81, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 82, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 82, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 82, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 82, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 83, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 83, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 83, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 83, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 84, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 84, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 84, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 84, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 85, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 85, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 85, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 85, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 86, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 86, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 86, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 86, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 87, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 87, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 87, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 87, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 88, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 88, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 88, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 88, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 89, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 89, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 89, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 89, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 90, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 90, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 90, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 90, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 91, Batch: 1000, Avg. Loss: 1.0808\n",
            "Epoch: 91, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 91, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 91, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 92, Batch: 1000, Avg. Loss: 1.0808\n",
            "Epoch: 92, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 92, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 92, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 93, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 93, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 93, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 93, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 94, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 94, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 94, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 94, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 95, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 95, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 95, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 95, Batch: 4000, Avg. Loss: 1.0792\n",
            "Epoch: 96, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 96, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 96, Batch: 3000, Avg. Loss: 1.0673\n",
            "Epoch: 96, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 97, Batch: 1000, Avg. Loss: 1.0808\n",
            "Epoch: 97, Batch: 2000, Avg. Loss: 1.0843\n",
            "Epoch: 97, Batch: 3000, Avg. Loss: 1.0671\n",
            "Epoch: 97, Batch: 4000, Avg. Loss: 1.0791\n",
            "Epoch: 98, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 98, Batch: 2000, Avg. Loss: 1.0843\n",
            "Epoch: 98, Batch: 3000, Avg. Loss: 1.0671\n",
            "Epoch: 98, Batch: 4000, Avg. Loss: 1.0791\n",
            "Epoch: 99, Batch: 1000, Avg. Loss: 1.0810\n",
            "Epoch: 99, Batch: 2000, Avg. Loss: 1.0842\n",
            "Epoch: 99, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 99, Batch: 4000, Avg. Loss: 1.0793\n",
            "Epoch: 100, Batch: 1000, Avg. Loss: 1.0809\n",
            "Epoch: 100, Batch: 2000, Avg. Loss: 1.0843\n",
            "Epoch: 100, Batch: 3000, Avg. Loss: 1.0672\n",
            "Epoch: 100, Batch: 4000, Avg. Loss: 1.0792\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model,test_loader,device):\n",
        "    # Turn autograd off\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Set the model to evaluation mode\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        # Set up lists to store true and predicted values\n",
        "        y_true = []\n",
        "        test_preds = []\n",
        "\n",
        "        # Calculate the predictions on the test set and add to list\n",
        "        for data in test_loader:\n",
        "            print(data)\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            # Feed inputs through model to get raw scores\n",
        "            logits = model.forward(inputs)\n",
        "\n",
        "            print(f'Logits: {logits}')\n",
        "            # Convert raw scores to probabilities (not necessary since we just care about discrete probs in this case)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            print(f'Probs after LogSoft: {probs}')\n",
        "            # Get discrete predictions using argmax\n",
        "            preds = np.argmax(probs.cpu().numpy(),axis=1)\n",
        "            # Add predictions and actuals to lists\n",
        "            test_preds.extend(preds)\n",
        "            y_true.extend(labels)\n",
        "\n",
        "        # Calculate the accuracy\n",
        "        test_preds = np.array(test_preds)\n",
        "        y_true = np.array(y_true)\n",
        "        test_acc = np.sum(test_preds == y_true)/y_true.shape[0]\n",
        "        \n",
        "        # Recall for each class\n",
        "        recall_vals = []\n",
        "        for i in range(3):\n",
        "            class_idx = np.argwhere(y_true==i)\n",
        "            total = len(class_idx)\n",
        "            correct = np.sum(test_preds[class_idx]==i)\n",
        "            recall = correct / total\n",
        "            recall_vals.append(recall)\n",
        "    \n",
        "    return test_acc,recall_vals"
      ],
      "metadata": {
        "id": "Sg6m09eT8A4W"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [0,1,2]"
      ],
      "metadata": {
        "id": "pGIu_p7XCACy"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the test set accuracy and recall for each class\n",
        "acc,recall_vals = test_model(net,val_loader,device)\n",
        "print('Test set accuracy is {:.3f}'.format(acc))\n",
        "for i in range(3):\n",
        "    print('For class {}, recall is {}'.format(classes[i],recall_vals[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvnTKH0fBzo2",
        "outputId": "3eae073e-f0be-441b-d8ce-dba713e63186"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "          [51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900],\n",
            "          [51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4728, 2.3641, 0.1815]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1194, 0.7914, 0.0892]], device='cuda:0')\n",
            "[tensor([[[[51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900,\n",
            "           51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900,\n",
            "           51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900,\n",
            "           51.8900, 51.8900, 51.8900],\n",
            "          [51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900,\n",
            "           51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900,\n",
            "           51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900, 51.8900,\n",
            "           51.8900, 51.8900, 51.8900],\n",
            "          [51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900],\n",
            "          [51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900, 51.7900,\n",
            "           51.7900, 51.7900, 51.7900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4728, 2.3641, 0.1815]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1194, 0.7914, 0.0892]], device='cuda:0')\n",
            "[tensor([[[[5.1590e+01, 5.1620e+01, 5.1750e+01, 5.1810e+01, 5.1810e+01,\n",
            "           5.1750e+01, 5.1750e+01, 5.1740e+01, 5.1620e+01, 5.1650e+01,\n",
            "           5.1590e+01, 5.1530e+01, 5.1550e+01, 5.1430e+01, 5.1430e+01,\n",
            "           5.1440e+01, 5.1270e+01, 5.1340e+01, 5.1580e+01, 5.1580e+01,\n",
            "           5.1540e+01, 5.1650e+01, 5.1610e+01, 5.1511e+01],\n",
            "          [5.1590e+01, 5.1650e+01, 5.1820e+01, 5.1810e+01, 5.1810e+01,\n",
            "           5.1840e+01, 5.1840e+01, 5.1740e+01, 5.1620e+01, 5.1650e+01,\n",
            "           5.1590e+01, 5.1580e+01, 5.1620e+01, 5.1530e+01, 5.1570e+01,\n",
            "           5.1450e+01, 5.1360e+01, 5.1590e+01, 5.1680e+01, 5.1690e+01,\n",
            "           5.1650e+01, 5.1660e+01, 5.1640e+01, 5.1511e+01],\n",
            "          [5.1590e+01, 5.1620e+01, 5.1720e+01, 5.1750e+01, 5.1750e+01,\n",
            "           5.1750e+01, 5.1750e+01, 5.1690e+01, 5.1620e+01, 5.1520e+01,\n",
            "           5.1540e+01, 5.1530e+01, 5.1450e+01, 5.1380e+01, 5.1430e+01,\n",
            "           5.1201e+01, 5.1250e+01, 5.1320e+01, 5.1520e+01, 5.1510e+01,\n",
            "           5.1510e+01, 5.1540e+01, 5.1497e+01, 5.1320e+01],\n",
            "          [5.1590e+01, 5.1650e+01, 5.1820e+01, 5.1810e+01, 5.1810e+01,\n",
            "           5.1830e+01, 5.1830e+01, 5.1700e+01, 5.1620e+01, 5.1520e+01,\n",
            "           5.1540e+01, 5.1580e+01, 5.1450e+01, 5.1440e+01, 5.1450e+01,\n",
            "           5.1300e+01, 5.1300e+01, 5.1580e+01, 5.1570e+01, 5.1540e+01,\n",
            "           5.1620e+01, 5.1590e+01, 5.1511e+01, 5.1370e+01],\n",
            "          [1.0000e+03, 1.3000e+03, 1.9265e+04, 9.0000e+02, 0.0000e+00,\n",
            "           9.8000e+02, 0.0000e+00, 1.0000e+03, 1.0000e+02, 1.4800e+03,\n",
            "           2.5200e+02, 1.0123e+04, 6.7330e+04, 7.6449e+04, 8.5701e+04,\n",
            "           1.7311e+05, 1.4396e+05, 1.6442e+05, 8.3696e+04, 1.2031e+05,\n",
            "           4.1209e+04, 2.6338e+04, 3.0427e+04, 1.0005e+05]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4716, 2.3556, 0.1834]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1200, 0.7900, 0.0900]], device='cuda:0')\n",
            "[tensor([[[[5.1370e+01, 5.1470e+01, 5.1940e+01, 5.1910e+01, 5.1980e+01,\n",
            "           5.1810e+01, 5.1810e+01, 5.1780e+01, 5.1770e+01, 5.1790e+01,\n",
            "           5.1810e+01, 5.1770e+01, 5.1620e+01, 5.1710e+01, 5.1570e+01,\n",
            "           5.1605e+01, 5.1660e+01, 5.1680e+01, 5.1730e+01, 5.1650e+01,\n",
            "           5.1780e+01, 5.1840e+01, 5.1810e+01, 5.1860e+01],\n",
            "          [5.1490e+01, 5.1990e+01, 5.2100e+01, 5.2050e+01, 5.2010e+01,\n",
            "           5.1875e+01, 5.1890e+01, 5.1920e+01, 5.1800e+01, 5.1910e+01,\n",
            "           5.1860e+01, 5.1830e+01, 5.1780e+01, 5.1730e+01, 5.1670e+01,\n",
            "           5.1680e+01, 5.1670e+01, 5.1740e+01, 5.1738e+01, 5.1810e+01,\n",
            "           5.1860e+01, 5.1880e+01, 5.1890e+01, 5.1940e+01],\n",
            "          [5.1320e+01, 5.1460e+01, 5.1830e+01, 5.1900e+01, 5.1770e+01,\n",
            "           5.1770e+01, 5.1730e+01, 5.1720e+01, 5.1650e+01, 5.1700e+01,\n",
            "           5.1750e+01, 5.1580e+01, 5.1600e+01, 5.1530e+01, 5.1550e+01,\n",
            "           5.1595e+01, 5.1600e+01, 5.1640e+01, 5.1650e+01, 5.1650e+01,\n",
            "           5.1760e+01, 5.1790e+01, 5.1770e+01, 5.1860e+01],\n",
            "          [5.1450e+01, 5.1950e+01, 5.1900e+01, 5.1960e+01, 5.1800e+01,\n",
            "           5.1818e+01, 5.1775e+01, 5.1770e+01, 5.1800e+01, 5.1780e+01,\n",
            "           5.1760e+01, 5.1630e+01, 5.1720e+01, 5.1560e+01, 5.1610e+01,\n",
            "           5.1677e+01, 5.1670e+01, 5.1740e+01, 5.1650e+01, 5.1770e+01,\n",
            "           5.1830e+01, 5.1795e+01, 5.1860e+01, 5.1890e+01],\n",
            "          [1.1540e+05, 1.8018e+05, 3.8082e+05, 1.8542e+05, 8.4231e+04,\n",
            "           3.3859e+04, 6.5981e+04, 1.4096e+05, 1.2847e+05, 1.2318e+05,\n",
            "           2.6530e+04, 9.4900e+04, 6.8004e+04, 1.4576e+05, 2.8678e+04,\n",
            "           1.4831e+04, 3.3889e+04, 3.8557e+04, 1.5783e+05, 2.1640e+05,\n",
            "           1.6668e+05, 5.2881e+04, 6.1678e+04, 1.2822e+05]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4720, 2.3650, 0.1828]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1192, 0.7915, 0.0893]], device='cuda:0')\n",
            "[tensor([[[[5.1900e+01, 5.1920e+01, 5.1890e+01, 5.1830e+01, 5.1840e+01,\n",
            "           5.1810e+01, 5.1850e+01, 5.1860e+01, 5.1810e+01, 5.1770e+01,\n",
            "           5.1780e+01, 5.1770e+01, 5.1650e+01, 5.1510e+01, 5.1500e+01,\n",
            "           5.1545e+01, 5.1510e+01, 5.1505e+01, 5.1500e+01, 5.1560e+01,\n",
            "           5.1540e+01, 5.1560e+01, 5.1460e+01, 5.1580e+01],\n",
            "          [5.1940e+01, 5.1980e+01, 5.1890e+01, 5.1890e+01, 5.1885e+01,\n",
            "           5.1865e+01, 5.1870e+01, 5.1860e+01, 5.1815e+01, 5.1800e+01,\n",
            "           5.1800e+01, 5.1770e+01, 5.1660e+01, 5.1560e+01, 5.1590e+01,\n",
            "           5.1590e+01, 5.1535e+01, 5.1535e+01, 5.1570e+01, 5.1620e+01,\n",
            "           5.1580e+01, 5.1560e+01, 5.1570e+01, 5.1680e+01],\n",
            "          [5.1890e+01, 5.1890e+01, 5.1810e+01, 5.1830e+01, 5.1820e+01,\n",
            "           5.1810e+01, 5.1805e+01, 5.1780e+01, 5.1765e+01, 5.1750e+01,\n",
            "           5.1725e+01, 5.1630e+01, 5.1510e+01, 5.1485e+01, 5.1495e+01,\n",
            "           5.1495e+01, 5.1485e+01, 5.1485e+01, 5.1500e+01, 5.1555e+01,\n",
            "           5.1525e+01, 5.1420e+01, 5.1460e+01, 5.1470e+01],\n",
            "          [5.1930e+01, 5.1890e+01, 5.1840e+01, 5.1840e+01, 5.1820e+01,\n",
            "           5.1860e+01, 5.1870e+01, 5.1790e+01, 5.1770e+01, 5.1780e+01,\n",
            "           5.1780e+01, 5.1660e+01, 5.1520e+01, 5.1505e+01, 5.1550e+01,\n",
            "           5.1505e+01, 5.1520e+01, 5.1495e+01, 5.1560e+01, 5.1555e+01,\n",
            "           5.1550e+01, 5.1460e+01, 5.1550e+01, 5.1490e+01],\n",
            "          [3.1191e+04, 8.2231e+04, 4.9840e+04, 2.5979e+04, 1.9821e+04,\n",
            "           1.0244e+04, 2.2235e+04, 1.5369e+04, 1.3272e+04, 2.1907e+04,\n",
            "           2.5978e+04, 3.6251e+04, 5.1198e+04, 3.7447e+04, 5.1053e+04,\n",
            "           6.5496e+04, 2.3224e+04, 2.3121e+04, 3.6863e+04, 2.6562e+04,\n",
            "           1.1679e+04, 5.8016e+04, 2.6502e+04, 7.9353e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4727, 2.3547, 0.1838]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1203, 0.7897, 0.0901]], device='cuda:0')\n",
            "[tensor([[[[5.1510e+01, 5.1440e+01, 5.1480e+01, 5.1450e+01, 5.1490e+01,\n",
            "           5.1570e+01, 5.1600e+01, 5.1610e+01, 5.1580e+01, 5.1619e+01,\n",
            "           5.1600e+01, 5.1600e+01, 5.1574e+01, 5.1565e+01, 5.1565e+01,\n",
            "           5.1550e+01, 5.1550e+01, 5.1490e+01, 5.1440e+01, 5.1460e+01,\n",
            "           5.1500e+01, 5.1500e+01, 5.1500e+01, 5.1500e+01],\n",
            "          [5.1510e+01, 5.1480e+01, 5.1490e+01, 5.1515e+01, 5.1590e+01,\n",
            "           5.1610e+01, 5.1630e+01, 5.1615e+01, 5.1610e+01, 5.1630e+01,\n",
            "           5.1620e+01, 5.1600e+01, 5.1595e+01, 5.1590e+01, 5.1580e+01,\n",
            "           5.1590e+01, 5.1560e+01, 5.1490e+01, 5.1440e+01, 5.1490e+01,\n",
            "           5.1500e+01, 5.1500e+01, 5.1500e+01, 5.1500e+01],\n",
            "          [5.1440e+01, 5.1430e+01, 5.1450e+01, 5.1450e+01, 5.1490e+01,\n",
            "           5.1540e+01, 5.1600e+01, 5.1600e+01, 5.1580e+01, 5.1580e+01,\n",
            "           5.1580e+01, 5.1570e+01, 5.1570e+01, 5.1545e+01, 5.1540e+01,\n",
            "           5.1550e+01, 5.1475e+01, 5.1435e+01, 5.1440e+01, 5.1460e+01,\n",
            "           5.1490e+01, 5.1490e+01, 5.1490e+01, 5.1490e+01],\n",
            "          [5.1450e+01, 5.1480e+01, 5.1455e+01, 5.1500e+01, 5.1580e+01,\n",
            "           5.1600e+01, 5.1600e+01, 5.1610e+01, 5.1600e+01, 5.1590e+01,\n",
            "           5.1590e+01, 5.1575e+01, 5.1570e+01, 5.1560e+01, 5.1548e+01,\n",
            "           5.1550e+01, 5.1490e+01, 5.1440e+01, 5.1440e+01, 5.1490e+01,\n",
            "           5.1490e+01, 5.1490e+01, 5.1490e+01, 5.1490e+01],\n",
            "          [2.3323e+04, 2.2391e+04, 8.1860e+03, 2.0185e+04, 1.8655e+04,\n",
            "           1.0573e+04, 8.7300e+03, 8.3240e+03, 1.0541e+04, 1.8516e+04,\n",
            "           1.0493e+04, 4.4020e+03, 3.4076e+04, 3.1460e+04, 4.5068e+04,\n",
            "           1.0381e+05, 2.5095e+05, 7.5104e+05, 2.9922e+05, 6.0900e+02,\n",
            "           1.1100e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4703, 2.3479, 0.1810]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1207, 0.7890, 0.0904]], device='cuda:0')\n",
            "[tensor([[[[5.0970e+01, 5.0900e+01, 5.0950e+01, 5.0940e+01, 5.0970e+01,\n",
            "           5.0760e+01, 5.0830e+01, 5.0930e+01, 5.0870e+01, 5.0950e+01,\n",
            "           5.0840e+01, 5.0820e+01, 5.0780e+01, 5.0860e+01, 5.0990e+01,\n",
            "           5.1020e+01, 5.0970e+01, 5.1000e+01, 5.0949e+01, 5.0960e+01,\n",
            "           5.1010e+01, 5.0820e+01, 5.0780e+01, 5.0940e+01],\n",
            "          [5.0970e+01, 5.0990e+01, 5.0980e+01, 5.0990e+01, 5.0970e+01,\n",
            "           5.0830e+01, 5.0880e+01, 5.0980e+01, 5.0940e+01, 5.0950e+01,\n",
            "           5.0840e+01, 5.0820e+01, 5.1000e+01, 5.1050e+01, 5.1090e+01,\n",
            "           5.1090e+01, 5.1027e+01, 5.1100e+01, 5.1110e+01, 5.1070e+01,\n",
            "           5.1020e+01, 5.0850e+01, 5.0950e+01, 5.1050e+01],\n",
            "          [5.0860e+01, 5.0900e+01, 5.0860e+01, 5.0920e+01, 5.0770e+01,\n",
            "           5.0760e+01, 5.0500e+01, 5.0810e+01, 5.0870e+01, 5.0950e+01,\n",
            "           5.0750e+01, 5.0760e+01, 5.0740e+01, 5.0800e+01, 5.0940e+01,\n",
            "           5.0920e+01, 5.0900e+01, 5.0900e+01, 5.0949e+01, 5.0940e+01,\n",
            "           5.0800e+01, 5.0770e+01, 5.0740e+01, 5.0940e+01],\n",
            "          [5.0880e+01, 5.0910e+01, 5.0920e+01, 5.0980e+01, 5.0780e+01,\n",
            "           5.0830e+01, 5.0880e+01, 5.0810e+01, 5.0940e+01, 5.0950e+01,\n",
            "           5.0750e+01, 5.0760e+01, 5.0870e+01, 5.0970e+01, 5.1010e+01,\n",
            "           5.0950e+01, 5.1000e+01, 5.0960e+01, 5.0980e+01, 5.1030e+01,\n",
            "           5.0840e+01, 5.0790e+01, 5.0940e+01, 5.0980e+01],\n",
            "          [2.0510e+03, 5.3600e+03, 2.0241e+04, 2.6530e+03, 2.3320e+03,\n",
            "           7.4500e+02, 1.4092e+04, 3.4120e+03, 7.7640e+03, 3.0000e+02,\n",
            "           0.0000e+00, 7.0100e+02, 1.7523e+05, 9.4475e+04, 9.6808e+04,\n",
            "           8.5554e+04, 8.6618e+04, 8.0472e+04, 1.6623e+05, 4.2617e+04,\n",
            "           1.5062e+05, 2.4410e+05, 8.6030e+04, 4.4155e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4661, 2.3267, 0.1782]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1223, 0.7860, 0.0917]], device='cuda:0')\n",
            "[tensor([[[[5.0980e+01, 5.1000e+01, 5.1000e+01, 5.0990e+01, 5.0870e+01,\n",
            "           5.0750e+01, 5.0850e+01, 5.0850e+01, 5.0860e+01, 5.0860e+01,\n",
            "           5.1020e+01, 5.0990e+01, 5.1050e+01, 5.0860e+01, 5.0860e+01,\n",
            "           5.0760e+01, 5.0700e+01, 5.0650e+01, 5.0360e+01, 5.0360e+01,\n",
            "           5.0500e+01, 5.0540e+01, 5.0580e+01, 5.0630e+01],\n",
            "          [5.1070e+01, 5.1070e+01, 5.1060e+01, 5.1000e+01, 5.0890e+01,\n",
            "           5.0900e+01, 5.0920e+01, 5.0940e+01, 5.0900e+01, 5.1060e+01,\n",
            "           5.1060e+01, 5.1100e+01, 5.1070e+01, 5.0900e+01, 5.0890e+01,\n",
            "           5.0810e+01, 5.0700e+01, 5.0680e+01, 5.0460e+01, 5.0520e+01,\n",
            "           5.0560e+01, 5.0580e+01, 5.0660e+01, 5.0654e+01],\n",
            "          [5.0980e+01, 5.0970e+01, 5.0980e+01, 5.0810e+01, 5.0730e+01,\n",
            "           5.0740e+01, 5.0810e+01, 5.0850e+01, 5.0790e+01, 5.0860e+01,\n",
            "           5.0960e+01, 5.0990e+01, 5.0830e+01, 5.0830e+01, 5.0750e+01,\n",
            "           5.0662e+01, 5.0610e+01, 5.0330e+01, 5.0319e+01, 5.0360e+01,\n",
            "           5.0500e+01, 5.0450e+01, 5.0580e+01, 5.0580e+01],\n",
            "          [5.1010e+01, 5.1010e+01, 5.0980e+01, 5.0860e+01, 5.0790e+01,\n",
            "           5.0870e+01, 5.0860e+01, 5.0870e+01, 5.0860e+01, 5.1040e+01,\n",
            "           5.0970e+01, 5.1040e+01, 5.0870e+01, 5.0862e+01, 5.0760e+01,\n",
            "           5.0690e+01, 5.0660e+01, 5.0345e+01, 5.0350e+01, 5.0491e+01,\n",
            "           5.0540e+01, 5.0580e+01, 5.0630e+01, 5.0620e+01],\n",
            "          [5.1566e+04, 3.3088e+04, 4.9828e+04, 6.7732e+04, 1.2097e+05,\n",
            "           6.9787e+04, 1.4980e+05, 3.2367e+04, 1.3907e+05, 7.8456e+04,\n",
            "           3.3753e+04, 5.3369e+04, 4.6986e+04, 2.2153e+04, 2.4534e+04,\n",
            "           4.7667e+04, 7.0941e+04, 2.0082e+05, 5.8025e+04, 4.2329e+04,\n",
            "           3.4614e+04, 3.4061e+04, 1.9682e+04, 2.3034e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4647, 2.3157, 0.1811]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1232, 0.7841, 0.0928]], device='cuda:0')\n",
            "[tensor([[[[5.0617e+01, 5.0570e+01, 5.0610e+01, 5.0530e+01, 5.0500e+01,\n",
            "           5.0580e+01, 5.0600e+01, 5.0690e+01, 5.0770e+01, 5.0890e+01,\n",
            "           5.0980e+01, 5.0890e+01, 5.0930e+01, 5.0890e+01, 5.0840e+01,\n",
            "           5.0930e+01, 5.1084e+01, 5.1030e+01, 5.0970e+01, 5.1045e+01,\n",
            "           5.1060e+01, 5.1040e+01, 5.1030e+01, 5.1120e+01],\n",
            "          [5.0620e+01, 5.0590e+01, 5.0610e+01, 5.0580e+01, 5.0570e+01,\n",
            "           5.0620e+01, 5.0700e+01, 5.0800e+01, 5.0950e+01, 5.1010e+01,\n",
            "           5.0990e+01, 5.0920e+01, 5.0940e+01, 5.0920e+01, 5.0920e+01,\n",
            "           5.1120e+01, 5.1090e+01, 5.1030e+01, 5.1080e+01, 5.1070e+01,\n",
            "           5.1095e+01, 5.1120e+01, 5.1130e+01, 5.1230e+01],\n",
            "          [5.0500e+01, 5.0535e+01, 5.0530e+01, 5.0490e+01, 5.0500e+01,\n",
            "           5.0530e+01, 5.0600e+01, 5.0690e+01, 5.0770e+01, 5.0890e+01,\n",
            "           5.0910e+01, 5.0870e+01, 5.0820e+01, 5.0850e+01, 5.0840e+01,\n",
            "           5.0920e+01, 5.1000e+01, 5.0980e+01, 5.0950e+01, 5.0970e+01,\n",
            "           5.1010e+01, 5.1000e+01, 5.0990e+01, 5.1015e+01],\n",
            "          [5.0570e+01, 5.0590e+01, 5.0530e+01, 5.0510e+01, 5.0560e+01,\n",
            "           5.0600e+01, 5.0690e+01, 5.0780e+01, 5.0880e+01, 5.0970e+01,\n",
            "           5.0910e+01, 5.0920e+01, 5.0880e+01, 5.0860e+01, 5.0910e+01,\n",
            "           5.1090e+01, 5.1040e+01, 5.0980e+01, 5.1060e+01, 5.1070e+01,\n",
            "           5.1030e+01, 5.1032e+01, 5.1120e+01, 5.1015e+01],\n",
            "          [2.2747e+04, 1.6709e+04, 2.5530e+04, 2.6541e+04, 8.1840e+03,\n",
            "           1.0953e+04, 3.3089e+04, 1.7478e+04, 7.7095e+04, 4.5473e+04,\n",
            "           2.3765e+04, 2.0668e+04, 2.4424e+04, 3.8112e+04, 1.7903e+04,\n",
            "           7.4018e+04, 1.8070e+04, 1.4429e+04, 8.1408e+04, 3.6881e+04,\n",
            "           2.9898e+04, 3.0936e+04, 2.7314e+04, 8.0787e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4634, 2.3238, 0.1731]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1223, 0.7862, 0.0915]], device='cuda:0')\n",
            "[tensor([[[[5.1030e+01, 5.1060e+01, 5.1060e+01, 5.1080e+01, 5.1020e+01,\n",
            "           5.0940e+01, 5.0920e+01, 5.0996e+01, 5.0980e+01, 5.0950e+01,\n",
            "           5.0990e+01, 5.0980e+01, 5.1020e+01, 5.0980e+01, 5.0920e+01,\n",
            "           5.0900e+01, 5.0895e+01, 5.0890e+01, 5.0920e+01, 5.0870e+01,\n",
            "           5.0870e+01, 5.0870e+01, 5.0820e+01, 5.0820e+01],\n",
            "          [5.1090e+01, 5.1090e+01, 5.1090e+01, 5.1100e+01, 5.1020e+01,\n",
            "           5.0960e+01, 5.1010e+01, 5.1010e+01, 5.0990e+01, 5.1000e+01,\n",
            "           5.1020e+01, 5.1010e+01, 5.1020e+01, 5.0985e+01, 5.0925e+01,\n",
            "           5.0930e+01, 5.0930e+01, 5.0920e+01, 5.0920e+01, 5.0870e+01,\n",
            "           5.0870e+01, 5.0870e+01, 5.0820e+01, 5.0820e+01],\n",
            "          [5.1000e+01, 5.1020e+01, 5.1045e+01, 5.1030e+01, 5.0930e+01,\n",
            "           5.0900e+01, 5.0920e+01, 5.0970e+01, 5.0942e+01, 5.0950e+01,\n",
            "           5.0980e+01, 5.0971e+01, 5.0980e+01, 5.0915e+01, 5.0870e+01,\n",
            "           5.0885e+01, 5.0885e+01, 5.0845e+01, 5.0830e+01, 5.0870e+01,\n",
            "           5.0870e+01, 5.0870e+01, 5.0820e+01, 5.0820e+01],\n",
            "          [5.1080e+01, 5.1045e+01, 5.1080e+01, 5.1030e+01, 5.0940e+01,\n",
            "           5.0920e+01, 5.1000e+01, 5.0970e+01, 5.0943e+01, 5.0990e+01,\n",
            "           5.0980e+01, 5.1010e+01, 5.0980e+01, 5.0920e+01, 5.0910e+01,\n",
            "           5.0900e+01, 5.0890e+01, 5.0920e+01, 5.0840e+01, 5.0870e+01,\n",
            "           5.0870e+01, 5.0870e+01, 5.0820e+01, 5.0820e+01],\n",
            "          [2.2395e+04, 1.4536e+04, 1.4676e+04, 1.9080e+04, 2.2172e+04,\n",
            "           2.4955e+04, 2.0391e+04, 6.9042e+04, 8.8258e+04, 2.4746e+04,\n",
            "           9.4080e+03, 1.7127e+04, 3.5677e+04, 1.1362e+05, 7.3616e+04,\n",
            "           3.7241e+04, 1.0356e+05, 1.6724e+05, 1.5521e+05, 2.0000e+03,\n",
            "           0.0000e+00, 0.0000e+00, 1.0200e+02, 0.0000e+00]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4657, 2.3215, 0.1802]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1227, 0.7850, 0.0922]], device='cuda:0')\n",
            "[tensor([[[[5.0550e+01, 5.0550e+01, 5.0550e+01, 5.0678e+01, 5.0678e+01,\n",
            "           5.0670e+01, 5.0680e+01, 5.0680e+01, 5.0750e+01, 5.0720e+01,\n",
            "           5.0690e+01, 5.0650e+01, 5.0640e+01, 5.0550e+01, 5.0500e+01,\n",
            "           5.0490e+01, 5.0470e+01, 5.0530e+01, 5.0410e+01, 5.0420e+01,\n",
            "           5.0360e+01, 5.0300e+01, 5.0310e+01, 5.0300e+01],\n",
            "          [5.0550e+01, 5.0600e+01, 5.0600e+01, 5.0678e+01, 5.0678e+01,\n",
            "           5.0670e+01, 5.0760e+01, 5.0760e+01, 5.0750e+01, 5.0730e+01,\n",
            "           5.0690e+01, 5.0670e+01, 5.0680e+01, 5.0590e+01, 5.0520e+01,\n",
            "           5.0550e+01, 5.0520e+01, 5.0540e+01, 5.0540e+01, 5.0500e+01,\n",
            "           5.0400e+01, 5.0360e+01, 5.0360e+01, 5.0410e+01],\n",
            "          [5.0540e+01, 5.0550e+01, 5.0550e+01, 5.0678e+01, 5.0678e+01,\n",
            "           5.0670e+01, 5.0680e+01, 5.0680e+01, 5.0750e+01, 5.0720e+01,\n",
            "           5.0640e+01, 5.0650e+01, 5.0570e+01, 5.0490e+01, 5.0480e+01,\n",
            "           5.0460e+01, 5.0390e+01, 5.0420e+01, 5.0400e+01, 5.0360e+01,\n",
            "           5.0290e+01, 5.0278e+01, 5.0240e+01, 5.0260e+01],\n",
            "          [5.0540e+01, 5.0600e+01, 5.0600e+01, 5.0678e+01, 5.0678e+01,\n",
            "           5.0670e+01, 5.0760e+01, 5.0760e+01, 5.0750e+01, 5.0730e+01,\n",
            "           5.0640e+01, 5.0670e+01, 5.0570e+01, 5.0540e+01, 5.0500e+01,\n",
            "           5.0490e+01, 5.0520e+01, 5.0420e+01, 5.0430e+01, 5.0360e+01,\n",
            "           5.0290e+01, 5.0330e+01, 5.0320e+01, 5.0390e+01],\n",
            "          [1.6010e+03, 4.0000e+02, 0.0000e+00, 1.5000e+02, 0.0000e+00,\n",
            "           5.0700e+02, 3.2110e+03, 0.0000e+00, 3.0000e+04, 3.1400e+03,\n",
            "           1.5161e+04, 5.4000e+02, 6.4220e+04, 6.9924e+04, 4.3736e+04,\n",
            "           2.5429e+05, 8.9929e+04, 6.2492e+04, 4.3977e+04, 4.9709e+04,\n",
            "           2.4898e+04, 3.6913e+05, 4.6223e+04, 9.2885e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4631, 2.3029, 0.1800]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1242, 0.7821, 0.0936]], device='cuda:0')\n",
            "[tensor([[[[5.0410e+01, 5.0550e+01, 5.0660e+01, 5.0635e+01, 5.0640e+01,\n",
            "           5.0490e+01, 5.0640e+01, 5.0760e+01, 5.0720e+01, 5.0720e+01,\n",
            "           5.0655e+01, 5.0600e+01, 5.0460e+01, 5.0480e+01, 5.0430e+01,\n",
            "           5.0390e+01, 5.0460e+01, 5.0500e+01, 5.0590e+01, 5.0850e+01,\n",
            "           5.0865e+01, 5.0900e+01, 5.0830e+01, 5.0830e+01],\n",
            "          [5.0660e+01, 5.0670e+01, 5.0720e+01, 5.0670e+01, 5.0670e+01,\n",
            "           5.0610e+01, 5.0830e+01, 5.0810e+01, 5.0770e+01, 5.0745e+01,\n",
            "           5.0710e+01, 5.0660e+01, 5.0520e+01, 5.0480e+01, 5.0440e+01,\n",
            "           5.0470e+01, 5.0520e+01, 5.0600e+01, 5.0840e+01, 5.0870e+01,\n",
            "           5.0920e+01, 5.0900e+01, 5.0860e+01, 5.0920e+01],\n",
            "          [5.0410e+01, 5.0530e+01, 5.0560e+01, 5.0550e+01, 5.0430e+01,\n",
            "           5.0480e+01, 5.0600e+01, 5.0720e+01, 5.0640e+01, 5.0670e+01,\n",
            "           5.0610e+01, 5.0430e+01, 5.0350e+01, 5.0410e+01, 5.0370e+01,\n",
            "           5.0380e+01, 5.0450e+01, 5.0500e+01, 5.0590e+01, 5.0780e+01,\n",
            "           5.0820e+01, 5.0800e+01, 5.0790e+01, 5.0810e+01],\n",
            "          [5.0560e+01, 5.0670e+01, 5.0650e+01, 5.0640e+01, 5.0490e+01,\n",
            "           5.0600e+01, 5.0760e+01, 5.0730e+01, 5.0720e+01, 5.0670e+01,\n",
            "           5.0610e+01, 5.0450e+01, 5.0490e+01, 5.0425e+01, 5.0400e+01,\n",
            "           5.0455e+01, 5.0505e+01, 5.0590e+01, 5.0840e+01, 5.0850e+01,\n",
            "           5.0905e+01, 5.0835e+01, 5.0830e+01, 5.0905e+01],\n",
            "          [2.5044e+05, 6.4725e+04, 1.1517e+05, 1.2936e+05, 1.0527e+05,\n",
            "           3.2894e+04, 9.4411e+04, 8.6958e+04, 5.9044e+04, 2.1374e+04,\n",
            "           3.6195e+04, 1.1245e+05, 9.6580e+04, 3.5768e+04, 3.3495e+04,\n",
            "           3.2105e+04, 2.1545e+04, 5.7692e+04, 9.0591e+04, 4.8119e+04,\n",
            "           3.1113e+04, 4.2466e+04, 2.7555e+04, 8.6497e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4633, 2.3160, 0.1761]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1230, 0.7846, 0.0923]], device='cuda:0')\n",
            "[tensor([[[[5.0900e+01, 5.0930e+01, 5.0880e+01, 5.0900e+01, 5.0900e+01,\n",
            "           5.0900e+01, 5.1010e+01, 5.0970e+01, 5.0990e+01, 5.1000e+01,\n",
            "           5.0850e+01, 5.0850e+01, 5.0860e+01, 5.0850e+01, 5.0840e+01,\n",
            "           5.0880e+01, 5.0870e+01, 5.0910e+01, 5.0880e+01, 5.1030e+01,\n",
            "           5.1030e+01, 5.1320e+01, 5.1230e+01, 5.1120e+01],\n",
            "          [5.0930e+01, 5.0950e+01, 5.0900e+01, 5.0920e+01, 5.0930e+01,\n",
            "           5.1005e+01, 5.1020e+01, 5.1010e+01, 5.1030e+01, 5.1000e+01,\n",
            "           5.0890e+01, 5.0880e+01, 5.0860e+01, 5.0890e+01, 5.0910e+01,\n",
            "           5.0890e+01, 5.0930e+01, 5.0930e+01, 5.1040e+01, 5.1090e+01,\n",
            "           5.1340e+01, 5.1320e+01, 5.1240e+01, 5.1190e+01],\n",
            "          [5.0860e+01, 5.0890e+01, 5.0850e+01, 5.0850e+01, 5.0865e+01,\n",
            "           5.0900e+01, 5.0972e+01, 5.0940e+01, 5.0980e+01, 5.0860e+01,\n",
            "           5.0840e+01, 5.0820e+01, 5.0800e+01, 5.0830e+01, 5.0830e+01,\n",
            "           5.0860e+01, 5.0870e+01, 5.0900e+01, 5.0790e+01, 5.0920e+01,\n",
            "           5.1020e+01, 5.1210e+01, 5.1080e+01, 5.1010e+01],\n",
            "          [5.0920e+01, 5.0911e+01, 5.0900e+01, 5.0900e+01, 5.0890e+01,\n",
            "           5.0980e+01, 5.0980e+01, 5.0970e+01, 5.1000e+01, 5.0860e+01,\n",
            "           5.0850e+01, 5.0820e+01, 5.0850e+01, 5.0860e+01, 5.0880e+01,\n",
            "           5.0860e+01, 5.0890e+01, 5.0915e+01, 5.1030e+01, 5.1030e+01,\n",
            "           5.1320e+01, 5.1239e+01, 5.1120e+01, 5.1165e+01],\n",
            "          [1.4880e+05, 4.8794e+04, 2.5453e+04, 4.0574e+04, 1.7259e+04,\n",
            "           4.8666e+04, 1.8751e+04, 1.2350e+04, 2.3528e+04, 3.8114e+04,\n",
            "           3.4912e+04, 1.5763e+04, 1.4390e+04, 1.4511e+04, 1.6671e+04,\n",
            "           9.3700e+03, 1.8111e+04, 2.0479e+04, 5.0466e+04, 4.9599e+04,\n",
            "           1.0953e+05, 5.0587e+04, 9.7602e+04, 1.4129e+05]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4657, 2.3297, 0.1757]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1220, 0.7867, 0.0913]], device='cuda:0')\n",
            "[tensor([[[[5.1170e+01, 5.1310e+01, 5.1250e+01, 5.1200e+01, 5.1215e+01,\n",
            "           5.1270e+01, 5.1265e+01, 5.1340e+01, 5.1500e+01, 5.1510e+01,\n",
            "           5.1620e+01, 5.1610e+01, 5.1635e+01, 5.1610e+01, 5.1610e+01,\n",
            "           5.1580e+01, 5.1560e+01, 5.1645e+01, 5.1620e+01, 5.1620e+01,\n",
            "           5.1600e+01, 5.1600e+01, 5.1600e+01, 5.1580e+01],\n",
            "          [5.1330e+01, 5.1330e+01, 5.1290e+01, 5.1255e+01, 5.1290e+01,\n",
            "           5.1280e+01, 5.1320e+01, 5.1510e+01, 5.1535e+01, 5.1640e+01,\n",
            "           5.1660e+01, 5.1630e+01, 5.1640e+01, 5.1692e+01, 5.1625e+01,\n",
            "           5.1610e+01, 5.1660e+01, 5.1645e+01, 5.1620e+01, 5.1620e+01,\n",
            "           5.1620e+01, 5.1620e+01, 5.1620e+01, 5.1580e+01],\n",
            "          [5.1120e+01, 5.1250e+01, 5.1200e+01, 5.1190e+01, 5.1190e+01,\n",
            "           5.1220e+01, 5.1260e+01, 5.1315e+01, 5.1465e+01, 5.1510e+01,\n",
            "           5.1590e+01, 5.1580e+01, 5.1590e+01, 5.1580e+01, 5.1553e+01,\n",
            "           5.1510e+01, 5.1560e+01, 5.1600e+01, 5.1620e+01, 5.1620e+01,\n",
            "           5.1600e+01, 5.1600e+01, 5.1600e+01, 5.1580e+01],\n",
            "          [5.1305e+01, 5.1270e+01, 5.1200e+01, 5.1220e+01, 5.1280e+01,\n",
            "           5.1250e+01, 5.1315e+01, 5.1510e+01, 5.1520e+01, 5.1610e+01,\n",
            "           5.1600e+01, 5.1625e+01, 5.1610e+01, 5.1605e+01, 5.1570e+01,\n",
            "           5.1530e+01, 5.1645e+01, 5.1610e+01, 5.1620e+01, 5.1620e+01,\n",
            "           5.1600e+01, 5.1600e+01, 5.1600e+01, 5.1580e+01],\n",
            "          [1.4740e+05, 4.4256e+04, 3.5561e+04, 2.6054e+04, 4.4801e+04,\n",
            "           5.4306e+04, 2.5514e+04, 6.2910e+04, 3.0708e+04, 3.7453e+04,\n",
            "           5.2746e+04, 4.7111e+04, 8.6083e+04, 4.8807e+04, 6.2401e+04,\n",
            "           5.9126e+04, 7.4560e+04, 2.0256e+05, 1.1540e+05, 0.0000e+00,\n",
            "           1.0000e+03, 0.0000e+00, 0.0000e+00, 6.8800e+02]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4685, 2.3500, 0.1776]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1203, 0.7897, 0.0900]], device='cuda:0')\n",
            "[tensor([[[[5.1460e+01, 5.1460e+01, 5.1550e+01, 5.1500e+01, 5.1500e+01,\n",
            "           5.1520e+01, 5.1600e+01, 5.1600e+01, 5.1640e+01, 5.1640e+01,\n",
            "           5.1630e+01, 5.1560e+01, 5.1570e+01, 5.1450e+01, 5.1470e+01,\n",
            "           5.1450e+01, 5.1630e+01, 5.1640e+01, 5.1520e+01, 5.1440e+01,\n",
            "           5.1370e+01, 5.1490e+01, 5.1631e+01, 5.1670e+01],\n",
            "          [5.1460e+01, 5.1460e+01, 5.1550e+01, 5.1500e+01, 5.1500e+01,\n",
            "           5.1520e+01, 5.1730e+01, 5.1730e+01, 5.1710e+01, 5.1710e+01,\n",
            "           5.1630e+01, 5.1570e+01, 5.1630e+01, 5.1545e+01, 5.1480e+01,\n",
            "           5.1610e+01, 5.1630e+01, 5.1650e+01, 5.1580e+01, 5.1450e+01,\n",
            "           5.1490e+01, 5.1645e+01, 5.1680e+01, 5.1715e+01],\n",
            "          [5.1460e+01, 5.1460e+01, 5.1550e+01, 5.1460e+01, 5.1500e+01,\n",
            "           5.1520e+01, 5.1460e+01, 5.1460e+01, 5.1640e+01, 5.1640e+01,\n",
            "           5.1570e+01, 5.1540e+01, 5.1420e+01, 5.1446e+01, 5.1380e+01,\n",
            "           5.1430e+01, 5.1500e+01, 5.1470e+01, 5.1430e+01, 5.1290e+01,\n",
            "           5.1370e+01, 5.1470e+01, 5.1610e+01, 5.1650e+01],\n",
            "          [5.1460e+01, 5.1460e+01, 5.1550e+01, 5.1460e+01, 5.1500e+01,\n",
            "           5.1520e+01, 5.1730e+01, 5.1730e+01, 5.1710e+01, 5.1710e+01,\n",
            "           5.1570e+01, 5.1570e+01, 5.1420e+01, 5.1475e+01, 5.1380e+01,\n",
            "           5.1610e+01, 5.1620e+01, 5.1500e+01, 5.1450e+01, 5.1380e+01,\n",
            "           5.1479e+01, 5.1630e+01, 5.1660e+01, 5.1680e+01],\n",
            "          [1.5000e+02, 0.0000e+00, 1.1000e+03, 1.2500e+03, 1.0000e+02,\n",
            "           1.0100e+02, 1.9730e+03, 0.0000e+00, 1.4510e+03, 0.0000e+00,\n",
            "           2.1060e+03, 1.4350e+03, 6.5786e+04, 3.2955e+04, 3.4022e+04,\n",
            "           3.1926e+04, 3.7595e+04, 8.8207e+04, 3.2235e+04, 6.6239e+04,\n",
            "           3.9725e+04, 3.8969e+04, 8.8279e+04, 1.1814e+05]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4703, 2.3514, 0.1801]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1204, 0.7896, 0.0900]], device='cuda:0')\n",
            "[tensor([[[[5.1700e+01, 5.1650e+01, 5.1635e+01, 5.1800e+01, 5.2100e+01,\n",
            "           5.2095e+01, 5.1990e+01, 5.1890e+01, 5.1940e+01, 5.2000e+01,\n",
            "           5.2160e+01, 5.2210e+01, 5.2250e+01, 5.2230e+01, 5.2320e+01,\n",
            "           5.2380e+01, 5.2390e+01, 5.2410e+01, 5.2320e+01, 5.2370e+01,\n",
            "           5.2320e+01, 5.2400e+01, 5.2300e+01, 5.2220e+01],\n",
            "          [5.1705e+01, 5.1665e+01, 5.1810e+01, 5.2180e+01, 5.2185e+01,\n",
            "           5.2100e+01, 5.2020e+01, 5.1940e+01, 5.2070e+01, 5.2180e+01,\n",
            "           5.2240e+01, 5.2300e+01, 5.2310e+01, 5.2350e+01, 5.2460e+01,\n",
            "           5.2410e+01, 5.2440e+01, 5.2440e+01, 5.2395e+01, 5.2370e+01,\n",
            "           5.2410e+01, 5.2430e+01, 5.2310e+01, 5.2270e+01],\n",
            "          [5.1620e+01, 5.1600e+01, 5.1635e+01, 5.1800e+01, 5.2080e+01,\n",
            "           5.1950e+01, 5.1880e+01, 5.1860e+01, 5.1940e+01, 5.2000e+01,\n",
            "           5.2120e+01, 5.2210e+01, 5.2220e+01, 5.2220e+01, 5.2320e+01,\n",
            "           5.2330e+01, 5.2380e+01, 5.2305e+01, 5.2315e+01, 5.2270e+01,\n",
            "           5.2310e+01, 5.2275e+01, 5.2215e+01, 5.2170e+01],\n",
            "          [5.1660e+01, 5.1630e+01, 5.1790e+01, 5.2110e+01, 5.2085e+01,\n",
            "           5.1990e+01, 5.1900e+01, 5.1940e+01, 5.2000e+01, 5.2140e+01,\n",
            "           5.2200e+01, 5.2250e+01, 5.2230e+01, 5.2320e+01, 5.2380e+01,\n",
            "           5.2380e+01, 5.2390e+01, 5.2320e+01, 5.2360e+01, 5.2320e+01,\n",
            "           5.2410e+01, 5.2295e+01, 5.2220e+01, 5.2210e+01],\n",
            "          [4.8995e+04, 4.1915e+04, 4.5410e+04, 1.5291e+05, 5.2846e+04,\n",
            "           5.6520e+04, 8.2356e+04, 9.8193e+04, 1.1996e+05, 5.3147e+04,\n",
            "           1.0406e+05, 1.6463e+05, 5.7476e+04, 4.8938e+04, 6.7799e+04,\n",
            "           5.6488e+04, 5.5534e+04, 6.3272e+04, 8.0457e+04, 5.3547e+04,\n",
            "           8.8024e+04, 4.0736e+04, 6.8711e+04, 9.7550e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4730, 2.3858, 0.1789]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1174, 0.7951, 0.0875]], device='cuda:0')\n",
            "[tensor([[[[5.2210e+01, 5.2210e+01, 5.2130e+01, 5.2130e+01, 5.2140e+01,\n",
            "           5.2110e+01, 5.2080e+01, 5.2140e+01, 5.2175e+01, 5.2200e+01,\n",
            "           5.2210e+01, 5.2150e+01, 5.2145e+01, 5.2080e+01, 5.2090e+01,\n",
            "           5.2140e+01, 5.2200e+01, 5.2220e+01, 5.2230e+01, 5.2240e+01,\n",
            "           5.2190e+01, 5.2140e+01, 5.2130e+01, 5.2110e+01],\n",
            "          [5.2250e+01, 5.2210e+01, 5.2160e+01, 5.2200e+01, 5.2160e+01,\n",
            "           5.2110e+01, 5.2180e+01, 5.2190e+01, 5.2220e+01, 5.2220e+01,\n",
            "           5.2225e+01, 5.2180e+01, 5.2175e+01, 5.2130e+01, 5.2120e+01,\n",
            "           5.2240e+01, 5.2250e+01, 5.2230e+01, 5.2278e+01, 5.2240e+01,\n",
            "           5.2190e+01, 5.2145e+01, 5.2160e+01, 5.2120e+01],\n",
            "          [5.2190e+01, 5.2100e+01, 5.2100e+01, 5.2120e+01, 5.2075e+01,\n",
            "           5.2040e+01, 5.2070e+01, 5.2110e+01, 5.2160e+01, 5.2160e+01,\n",
            "           5.2140e+01, 5.2130e+01, 5.2080e+01, 5.2080e+01, 5.2065e+01,\n",
            "           5.2135e+01, 5.2195e+01, 5.2185e+01, 5.2210e+01, 5.2140e+01,\n",
            "           5.2130e+01, 5.2090e+01, 5.2060e+01, 5.1980e+01],\n",
            "          [5.2220e+01, 5.2120e+01, 5.2140e+01, 5.2150e+01, 5.2100e+01,\n",
            "           5.2070e+01, 5.2140e+01, 5.2180e+01, 5.2200e+01, 5.2205e+01,\n",
            "           5.2140e+01, 5.2140e+01, 5.2100e+01, 5.2100e+01, 5.2110e+01,\n",
            "           5.2210e+01, 5.2220e+01, 5.2225e+01, 5.2240e+01, 5.2180e+01,\n",
            "           5.2140e+01, 5.2125e+01, 5.2080e+01, 5.2070e+01],\n",
            "          [9.0383e+04, 7.6092e+04, 1.4480e+05, 7.9896e+04, 4.0920e+04,\n",
            "           1.2227e+05, 5.9729e+04, 3.8926e+04, 4.0838e+04, 2.1874e+04,\n",
            "           2.4537e+04, 2.6653e+04, 4.4954e+04, 1.6648e+04, 3.7603e+04,\n",
            "           4.5065e+04, 3.0852e+04, 2.4082e+04, 2.4966e+04, 5.3873e+04,\n",
            "           3.4590e+04, 4.3657e+04, 3.8899e+04, 1.3864e+05]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4754, 2.3801, 0.1829]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1181, 0.7937, 0.0882]], device='cuda:0')\n",
            "[tensor([[[[5.2060e+01, 5.1950e+01, 5.2000e+01, 5.1940e+01, 5.1830e+01,\n",
            "           5.1770e+01, 5.1810e+01, 5.1780e+01, 5.1720e+01, 5.1780e+01,\n",
            "           5.1820e+01, 5.1870e+01, 5.1910e+01, 5.1930e+01, 5.1900e+01,\n",
            "           5.1870e+01, 5.1815e+01, 5.1840e+01, 5.1870e+01, 5.1870e+01,\n",
            "           5.1810e+01, 5.1810e+01, 5.1810e+01, 5.1810e+01],\n",
            "          [5.2070e+01, 5.2020e+01, 5.2000e+01, 5.1940e+01, 5.1860e+01,\n",
            "           5.1820e+01, 5.1810e+01, 5.1790e+01, 5.1780e+01, 5.1830e+01,\n",
            "           5.1870e+01, 5.1920e+01, 5.1940e+01, 5.1960e+01, 5.1910e+01,\n",
            "           5.1875e+01, 5.1890e+01, 5.1880e+01, 5.1870e+01, 5.1870e+01,\n",
            "           5.1830e+01, 5.1830e+01, 5.1830e+01, 5.1830e+01],\n",
            "          [5.1940e+01, 5.1915e+01, 5.1920e+01, 5.1815e+01, 5.1760e+01,\n",
            "           5.1770e+01, 5.1740e+01, 5.1720e+01, 5.1715e+01, 5.1763e+01,\n",
            "           5.1810e+01, 5.1855e+01, 5.1880e+01, 5.1895e+01, 5.1865e+01,\n",
            "           5.1810e+01, 5.1815e+01, 5.1835e+01, 5.1850e+01, 5.1850e+01,\n",
            "           5.1810e+01, 5.1810e+01, 5.1810e+01, 5.1810e+01],\n",
            "          [5.1950e+01, 5.2000e+01, 5.1931e+01, 5.1830e+01, 5.1770e+01,\n",
            "           5.1820e+01, 5.1780e+01, 5.1730e+01, 5.1780e+01, 5.1810e+01,\n",
            "           5.1870e+01, 5.1900e+01, 5.1930e+01, 5.1920e+01, 5.1870e+01,\n",
            "           5.1810e+01, 5.1840e+01, 5.1869e+01, 5.1850e+01, 5.1850e+01,\n",
            "           5.1820e+01, 5.1820e+01, 5.1820e+01, 5.1820e+01],\n",
            "          [7.9172e+04, 4.5776e+04, 1.6229e+04, 3.7871e+04, 7.9720e+04,\n",
            "           1.3562e+04, 3.7756e+04, 2.5413e+04, 5.4496e+04, 5.0739e+04,\n",
            "           3.3886e+04, 3.7010e+04, 4.1252e+04, 1.1621e+05, 4.8318e+04,\n",
            "           6.5414e+04, 8.7168e+04, 8.9854e+04, 3.6812e+04, 0.0000e+00,\n",
            "           1.0500e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4732, 2.3654, 0.1821]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1193, 0.7915, 0.0892]], device='cuda:0')\n",
            "[tensor([[[[5.1440e+01, 5.1440e+01, 5.1160e+01, 5.1180e+01, 5.1160e+01,\n",
            "           5.1210e+01, 5.1300e+01, 5.1250e+01, 5.1250e+01, 5.1260e+01,\n",
            "           5.1240e+01, 5.1240e+01, 5.1290e+01, 5.1375e+01, 5.1240e+01,\n",
            "           5.1119e+01, 5.1190e+01, 5.1070e+01, 5.1035e+01, 5.1090e+01,\n",
            "           5.1000e+01, 5.0770e+01, 5.0630e+01, 5.0420e+01],\n",
            "          [5.1440e+01, 5.1440e+01, 5.1160e+01, 5.1180e+01, 5.1160e+01,\n",
            "           5.1340e+01, 5.1300e+01, 5.1250e+01, 5.1250e+01, 5.1260e+01,\n",
            "           5.1270e+01, 5.1270e+01, 5.1430e+01, 5.1380e+01, 5.1250e+01,\n",
            "           5.1180e+01, 5.1200e+01, 5.1121e+01, 5.1130e+01, 5.1107e+01,\n",
            "           5.1045e+01, 5.0770e+01, 5.0680e+01, 5.0550e+01],\n",
            "          [5.1440e+01, 5.1440e+01, 5.1160e+01, 5.1180e+01, 5.1160e+01,\n",
            "           5.1210e+01, 5.1250e+01, 5.1250e+01, 5.1250e+01, 5.1240e+01,\n",
            "           5.1240e+01, 5.1240e+01, 5.1280e+01, 5.1160e+01, 5.1110e+01,\n",
            "           5.1050e+01, 5.1050e+01, 5.0970e+01, 5.0980e+01, 5.0980e+01,\n",
            "           5.0750e+01, 5.0520e+01, 5.0365e+01, 5.0410e+01],\n",
            "          [5.1440e+01, 5.1440e+01, 5.1160e+01, 5.1180e+01, 5.1160e+01,\n",
            "           5.1340e+01, 5.1250e+01, 5.1250e+01, 5.1250e+01, 5.1240e+01,\n",
            "           5.1270e+01, 5.1270e+01, 5.1370e+01, 5.1235e+01, 5.1120e+01,\n",
            "           5.1180e+01, 5.1075e+01, 5.1045e+01, 5.1090e+01, 5.0990e+01,\n",
            "           5.0760e+01, 5.0630e+01, 5.0410e+01, 5.0550e+01],\n",
            "          [3.5000e+02, 0.0000e+00, 1.0000e+02, 5.0000e+02, 3.8400e+02,\n",
            "           1.5250e+03, 1.1300e+03, 3.0250e+03, 0.0000e+00, 2.7000e+02,\n",
            "           6.7300e+02, 0.0000e+00, 9.7583e+04, 1.2370e+05, 1.2620e+05,\n",
            "           5.6758e+04, 9.4376e+04, 9.0686e+04, 1.1325e+05, 4.1001e+04,\n",
            "           1.0866e+05, 1.7978e+05, 2.0489e+05, 1.1158e+05]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4685, 2.3301, 0.1838]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1222, 0.7860, 0.0919]], device='cuda:0')\n",
            "[tensor([[[[5.0530e+01, 5.0710e+01, 5.0750e+01, 5.0870e+01, 5.0980e+01,\n",
            "           5.1130e+01, 5.1140e+01, 5.1070e+01, 5.1080e+01, 5.1250e+01,\n",
            "           5.1245e+01, 5.1130e+01, 5.1210e+01, 5.1080e+01, 5.1130e+01,\n",
            "           5.1040e+01, 5.1060e+01, 5.0980e+01, 5.1040e+01, 5.1070e+01,\n",
            "           5.1060e+01, 5.1190e+01, 5.1160e+01, 5.1170e+01],\n",
            "          [5.0740e+01, 5.0870e+01, 5.0900e+01, 5.0980e+01, 5.1143e+01,\n",
            "           5.1130e+01, 5.1200e+01, 5.1120e+01, 5.1280e+01, 5.1280e+01,\n",
            "           5.1260e+01, 5.1250e+01, 5.1310e+01, 5.1140e+01, 5.1160e+01,\n",
            "           5.1100e+01, 5.1090e+01, 5.1055e+01, 5.1055e+01, 5.1079e+01,\n",
            "           5.1190e+01, 5.1190e+01, 5.1245e+01, 5.1200e+01],\n",
            "          [5.0500e+01, 5.0685e+01, 5.0700e+01, 5.0848e+01, 5.0975e+01,\n",
            "           5.1020e+01, 5.1065e+01, 5.1030e+01, 5.1065e+01, 5.1180e+01,\n",
            "           5.1110e+01, 5.1130e+01, 5.1080e+01, 5.1040e+01, 5.0990e+01,\n",
            "           5.0970e+01, 5.0980e+01, 5.0960e+01, 5.1010e+01, 5.0980e+01,\n",
            "           5.1050e+01, 5.1120e+01, 5.1155e+01, 5.1150e+01],\n",
            "          [5.0705e+01, 5.0750e+01, 5.0854e+01, 5.0980e+01, 5.1110e+01,\n",
            "           5.1120e+01, 5.1070e+01, 5.1090e+01, 5.1230e+01, 5.1240e+01,\n",
            "           5.1125e+01, 5.1220e+01, 5.1080e+01, 5.1130e+01, 5.1020e+01,\n",
            "           5.1060e+01, 5.0980e+01, 5.1040e+01, 5.1030e+01, 5.1051e+01,\n",
            "           5.1190e+01, 5.1150e+01, 5.1170e+01, 5.1196e+01],\n",
            "          [1.6160e+05, 1.9646e+05, 1.3676e+05, 9.7913e+04, 1.3992e+05,\n",
            "           7.0063e+04, 7.2395e+04, 5.5334e+04, 1.2178e+05, 1.0908e+05,\n",
            "           5.9086e+04, 1.2464e+05, 6.6675e+04, 9.0334e+04, 4.1811e+04,\n",
            "           9.7460e+04, 4.6549e+04, 4.7407e+04, 2.5018e+04, 4.7517e+04,\n",
            "           3.4659e+04, 5.3204e+04, 2.1975e+04, 1.8585e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4657, 2.3291, 0.1782]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1220, 0.7865, 0.0915]], device='cuda:0')\n",
            "[tensor([[[[5.1200e+01, 5.1230e+01, 5.1140e+01, 5.1100e+01, 5.1120e+01,\n",
            "           5.1070e+01, 5.1080e+01, 5.1110e+01, 5.1020e+01, 5.1020e+01,\n",
            "           5.0940e+01, 5.0850e+01, 5.0800e+01, 5.0770e+01, 5.0850e+01,\n",
            "           5.0870e+01, 5.0910e+01, 5.0880e+01, 5.0920e+01, 5.0910e+01,\n",
            "           5.0850e+01, 5.0870e+01, 5.0870e+01, 5.1030e+01],\n",
            "          [5.1260e+01, 5.1240e+01, 5.1180e+01, 5.1135e+01, 5.1150e+01,\n",
            "           5.1150e+01, 5.1130e+01, 5.1115e+01, 5.1040e+01, 5.1060e+01,\n",
            "           5.0950e+01, 5.0870e+01, 5.0860e+01, 5.0850e+01, 5.0905e+01,\n",
            "           5.0940e+01, 5.0925e+01, 5.0930e+01, 5.0950e+01, 5.0910e+01,\n",
            "           5.0875e+01, 5.0945e+01, 5.1040e+01, 5.1050e+01],\n",
            "          [5.1170e+01, 5.1120e+01, 5.1090e+01, 5.1100e+01, 5.1030e+01,\n",
            "           5.1050e+01, 5.1050e+01, 5.1010e+01, 5.0990e+01, 5.0920e+01,\n",
            "           5.0810e+01, 5.0690e+01, 5.0720e+01, 5.0749e+01, 5.0800e+01,\n",
            "           5.0870e+01, 5.0870e+01, 5.0880e+01, 5.0890e+01, 5.0805e+01,\n",
            "           5.0830e+01, 5.0850e+01, 5.0850e+01, 5.0990e+01],\n",
            "          [5.1220e+01, 5.1140e+01, 5.1090e+01, 5.1120e+01, 5.1050e+01,\n",
            "           5.1090e+01, 5.1120e+01, 5.1040e+01, 5.1020e+01, 5.0930e+01,\n",
            "           5.0850e+01, 5.0810e+01, 5.0750e+01, 5.0850e+01, 5.0860e+01,\n",
            "           5.0890e+01, 5.0870e+01, 5.0910e+01, 5.0910e+01, 5.0850e+01,\n",
            "           5.0860e+01, 5.0855e+01, 5.1035e+01, 5.1030e+01],\n",
            "          [4.0824e+04, 1.0872e+05, 5.3418e+04, 1.1239e+04, 1.7541e+04,\n",
            "           3.2142e+04, 1.6406e+04, 3.5272e+04, 1.8384e+04, 3.0881e+04,\n",
            "           3.8559e+04, 7.5217e+04, 3.2473e+04, 3.1974e+04, 5.2139e+04,\n",
            "           1.1081e+04, 1.5278e+04, 1.6780e+04, 4.3989e+04, 2.3650e+04,\n",
            "           1.2738e+04, 3.3551e+04, 2.9646e+04, 1.9846e+05]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4667, 2.3246, 0.1803]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1225, 0.7854, 0.0920]], device='cuda:0')\n",
            "[tensor([[[[5.1020e+01, 5.0955e+01, 5.0980e+01, 5.1020e+01, 5.1025e+01,\n",
            "           5.1000e+01, 5.1000e+01, 5.1030e+01, 5.1025e+01, 5.0990e+01,\n",
            "           5.0965e+01, 5.0970e+01, 5.0920e+01, 5.0860e+01, 5.0890e+01,\n",
            "           5.0900e+01, 5.0780e+01, 5.0750e+01, 5.0780e+01, 5.0740e+01,\n",
            "           5.0740e+01, 5.0740e+01, 5.0740e+01, 5.0730e+01],\n",
            "          [5.1050e+01, 5.0970e+01, 5.1020e+01, 5.1060e+01, 5.1040e+01,\n",
            "           5.1045e+01, 5.1080e+01, 5.1060e+01, 5.1040e+01, 5.1000e+01,\n",
            "           5.1005e+01, 5.0975e+01, 5.0920e+01, 5.0900e+01, 5.0940e+01,\n",
            "           5.0900e+01, 5.0783e+01, 5.0810e+01, 5.0780e+01, 5.0740e+01,\n",
            "           5.0740e+01, 5.0750e+01, 5.0750e+01, 5.0730e+01],\n",
            "          [5.0950e+01, 5.0910e+01, 5.0965e+01, 5.1020e+01, 5.0970e+01,\n",
            "           5.0990e+01, 5.0995e+01, 5.1020e+01, 5.0970e+01, 5.0930e+01,\n",
            "           5.0965e+01, 5.0905e+01, 5.0830e+01, 5.0840e+01, 5.0880e+01,\n",
            "           5.0770e+01, 5.0700e+01, 5.0730e+01, 5.0740e+01, 5.0740e+01,\n",
            "           5.0740e+01, 5.0730e+01, 5.0730e+01, 5.0720e+01],\n",
            "          [5.0950e+01, 5.0965e+01, 5.1015e+01, 5.1025e+01, 5.1000e+01,\n",
            "           5.0995e+01, 5.1030e+01, 5.1030e+01, 5.0980e+01, 5.0950e+01,\n",
            "           5.0975e+01, 5.0915e+01, 5.0860e+01, 5.0890e+01, 5.0910e+01,\n",
            "           5.0770e+01, 5.0760e+01, 5.0760e+01, 5.0750e+01, 5.0740e+01,\n",
            "           5.0740e+01, 5.0750e+01, 5.0750e+01, 5.0720e+01],\n",
            "          [3.7242e+04, 3.8760e+04, 1.3339e+04, 2.0964e+04, 2.6712e+04,\n",
            "           3.8451e+04, 5.9469e+04, 2.0322e+04, 2.3531e+04, 3.3725e+04,\n",
            "           5.4142e+04, 3.6819e+04, 4.9943e+04, 5.5259e+04, 8.2782e+04,\n",
            "           9.7893e+04, 1.6882e+05, 3.7521e+05, 2.5074e+05, 1.7000e+03,\n",
            "           0.0000e+00, 3.2300e+03, 0.0000e+00, 4.5200e+02]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4658, 2.3181, 0.1812]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1230, 0.7844, 0.0926]], device='cuda:0')\n",
            "[tensor([[[[  50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500],\n",
            "          [  50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500],\n",
            "          [  50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500],\n",
            "          [  50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500,\n",
            "             50.5500,   50.5500,   50.5500,   50.5500,   50.5500,   50.5500],\n",
            "          [2900.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "              0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "              0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "              0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4620, 2.3028, 0.1767]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1242, 0.7825, 0.0934]], device='cuda:0')\n",
            "[tensor([[[[50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4620, 2.3028, 0.1767]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1242, 0.7825, 0.0934]], device='cuda:0')\n",
            "[tensor([[[[50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4620, 2.3028, 0.1767]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1242, 0.7825, 0.0934]], device='cuda:0')\n",
            "[tensor([[[[50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4620, 2.3028, 0.1767]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1242, 0.7825, 0.0934]], device='cuda:0')\n",
            "[tensor([[[[50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4620, 2.3028, 0.1767]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1242, 0.7825, 0.0934]], device='cuda:0')\n",
            "[tensor([[[[50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4620, 2.3028, 0.1767]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1242, 0.7825, 0.0934]], device='cuda:0')\n",
            "[tensor([[[[50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4620, 2.3028, 0.1767]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1242, 0.7825, 0.0934]], device='cuda:0')\n",
            "[tensor([[[[50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500, 50.5500,\n",
            "           50.5500, 50.5500, 50.5500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4620, 2.3028, 0.1767]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1242, 0.7825, 0.0934]], device='cuda:0')\n",
            "[tensor([[[[4.8950e+01, 4.8950e+01, 4.9060e+01, 4.9120e+01, 4.9110e+01,\n",
            "           4.9050e+01, 4.9120e+01, 4.9110e+01, 4.9130e+01, 4.9180e+01,\n",
            "           4.9130e+01, 4.9090e+01, 4.9030e+01, 4.8910e+01, 4.8770e+01,\n",
            "           4.8670e+01, 4.8590e+01, 4.8510e+01, 4.8690e+01, 4.8790e+01,\n",
            "           4.8750e+01, 4.8650e+01, 4.8762e+01, 4.8540e+01],\n",
            "          [4.8950e+01, 4.8950e+01, 4.9100e+01, 4.9200e+01, 4.9120e+01,\n",
            "           4.9100e+01, 4.9120e+01, 4.9120e+01, 4.9260e+01, 4.9180e+01,\n",
            "           4.9130e+01, 4.9110e+01, 4.9070e+01, 4.8990e+01, 4.8770e+01,\n",
            "           4.8690e+01, 4.8630e+01, 4.8740e+01, 4.8860e+01, 4.8790e+01,\n",
            "           4.8810e+01, 4.8810e+01, 4.8790e+01, 4.8610e+01],\n",
            "          [4.8900e+01, 4.8900e+01, 4.9060e+01, 4.9120e+01, 4.9030e+01,\n",
            "           4.9020e+01, 4.8990e+01, 4.9110e+01, 4.9130e+01, 4.9060e+01,\n",
            "           4.9130e+01, 4.9050e+01, 4.8910e+01, 4.8780e+01, 4.8630e+01,\n",
            "           4.8570e+01, 4.8425e+01, 4.8400e+01, 4.8630e+01, 4.8680e+01,\n",
            "           4.8560e+01, 4.8600e+01, 4.8510e+01, 4.8490e+01],\n",
            "          [4.8900e+01, 4.8900e+01, 4.9100e+01, 4.9120e+01, 4.9030e+01,\n",
            "           4.9100e+01, 4.9050e+01, 4.9120e+01, 4.9260e+01, 4.9090e+01,\n",
            "           4.9130e+01, 4.9050e+01, 4.8920e+01, 4.8790e+01, 4.8670e+01,\n",
            "           4.8590e+01, 4.8520e+01, 4.8690e+01, 4.8786e+01, 4.8735e+01,\n",
            "           4.8628e+01, 4.8760e+01, 4.8550e+01, 4.8580e+01],\n",
            "          [2.1600e+03, 0.0000e+00, 3.1320e+03, 3.4000e+03, 3.0100e+03,\n",
            "           6.0310e+03, 7.2160e+03, 1.2020e+03, 2.3720e+03, 1.4760e+03,\n",
            "           6.7900e+02, 1.2464e+04, 1.9281e+05, 1.6481e+05, 1.7804e+05,\n",
            "           9.4612e+04, 1.5943e+05, 1.5264e+05, 1.1422e+05, 9.7647e+04,\n",
            "           7.2894e+04, 5.3575e+04, 1.0351e+05, 6.1030e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4493, 2.2275, 0.1758]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1302, 0.7707, 0.0990]], device='cuda:0')\n",
            "[tensor([[[[4.8490e+01, 4.8480e+01, 4.8430e+01, 4.8370e+01, 4.8200e+01,\n",
            "           4.8180e+01, 4.8215e+01, 4.8160e+01, 4.8170e+01, 4.8230e+01,\n",
            "           4.8310e+01, 4.8340e+01, 4.8360e+01, 4.8260e+01, 4.8000e+01,\n",
            "           4.8110e+01, 4.8240e+01, 4.8460e+01, 4.8440e+01, 4.8410e+01,\n",
            "           4.8420e+01, 4.8435e+01, 4.8610e+01, 4.8650e+01],\n",
            "          [4.8560e+01, 4.8560e+01, 4.8440e+01, 4.8370e+01, 4.8250e+01,\n",
            "           4.8310e+01, 4.8230e+01, 4.8190e+01, 4.8299e+01, 4.8310e+01,\n",
            "           4.8360e+01, 4.8380e+01, 4.8380e+01, 4.8290e+01, 4.8130e+01,\n",
            "           4.8240e+01, 4.8460e+01, 4.8470e+01, 4.8450e+01, 4.8499e+01,\n",
            "           4.8490e+01, 4.8630e+01, 4.8690e+01, 4.8730e+01],\n",
            "          [4.8450e+01, 4.8350e+01, 4.8290e+01, 4.8150e+01, 4.8130e+01,\n",
            "           4.8180e+01, 4.8091e+01, 4.8107e+01, 4.8120e+01, 4.8110e+01,\n",
            "           4.8265e+01, 4.8277e+01, 4.8260e+01, 4.7970e+01, 4.7960e+01,\n",
            "           4.8045e+01, 4.8230e+01, 4.8370e+01, 4.8400e+01, 4.8390e+01,\n",
            "           4.8390e+01, 4.8430e+01, 4.8600e+01, 4.8610e+01],\n",
            "          [4.8490e+01, 4.8410e+01, 4.8370e+01, 4.8220e+01, 4.8200e+01,\n",
            "           4.8200e+01, 4.8160e+01, 4.8170e+01, 4.8240e+01, 4.8310e+01,\n",
            "           4.8340e+01, 4.8380e+01, 4.8260e+01, 4.8013e+01, 4.8110e+01,\n",
            "           4.8240e+01, 4.8460e+01, 4.8430e+01, 4.8440e+01, 4.8410e+01,\n",
            "           4.8436e+01, 4.8600e+01, 4.8660e+01, 4.8700e+01],\n",
            "          [9.4649e+04, 9.4681e+04, 1.6900e+05, 1.4032e+05, 1.1751e+05,\n",
            "           1.6799e+05, 1.0618e+05, 6.5089e+04, 5.8318e+04, 7.8242e+04,\n",
            "           1.1267e+05, 6.0099e+04, 1.1482e+05, 1.9620e+05, 1.2735e+05,\n",
            "           1.1907e+05, 9.5355e+04, 8.5843e+04, 4.7445e+04, 3.5684e+05,\n",
            "           6.1453e+04, 7.8821e+04, 5.7143e+04, 7.1299e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4441, 2.2110, 0.1663]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1314, 0.7691, 0.0995]], device='cuda:0')\n",
            "[tensor([[[[4.8700e+01, 4.8670e+01, 4.8760e+01, 4.8740e+01, 4.8824e+01,\n",
            "           4.8910e+01, 4.8940e+01, 4.8980e+01, 4.9010e+01, 4.9080e+01,\n",
            "           4.9035e+01, 4.9040e+01, 4.9120e+01, 4.9150e+01, 4.9200e+01,\n",
            "           4.9190e+01, 4.9210e+01, 4.9160e+01, 4.9120e+01, 4.9280e+01,\n",
            "           4.9360e+01, 4.9350e+01, 4.9410e+01, 4.9435e+01],\n",
            "          [4.8710e+01, 4.8760e+01, 4.8800e+01, 4.8840e+01, 4.8930e+01,\n",
            "           4.8970e+01, 4.8998e+01, 4.9020e+01, 4.9070e+01, 4.9130e+01,\n",
            "           4.9070e+01, 4.9150e+01, 4.9150e+01, 4.9210e+01, 4.9260e+01,\n",
            "           4.9230e+01, 4.9220e+01, 4.9200e+01, 4.9440e+01, 4.9360e+01,\n",
            "           4.9390e+01, 4.9430e+01, 4.9530e+01, 4.9730e+01],\n",
            "          [4.8620e+01, 4.8650e+01, 4.8720e+01, 4.8740e+01, 4.8800e+01,\n",
            "           4.8885e+01, 4.8900e+01, 4.8900e+01, 4.8970e+01, 4.9022e+01,\n",
            "           4.9000e+01, 4.9030e+01, 4.9090e+01, 4.9120e+01, 4.9180e+01,\n",
            "           4.9160e+01, 4.9090e+01, 4.9125e+01, 4.9110e+01, 4.9260e+01,\n",
            "           4.9310e+01, 4.9340e+01, 4.9400e+01, 4.9375e+01],\n",
            "          [4.8660e+01, 4.8760e+01, 4.8740e+01, 4.8832e+01, 4.8910e+01,\n",
            "           4.8940e+01, 4.8960e+01, 4.9020e+01, 4.9070e+01, 4.9030e+01,\n",
            "           4.9040e+01, 4.9140e+01, 4.9150e+01, 4.9200e+01, 4.9190e+01,\n",
            "           4.9200e+01, 4.9145e+01, 4.9125e+01, 4.9290e+01, 4.9350e+01,\n",
            "           4.9370e+01, 4.9400e+01, 4.9430e+01, 4.9730e+01],\n",
            "          [4.8291e+04, 5.0100e+04, 5.3536e+04, 7.0352e+04, 2.9876e+04,\n",
            "           6.6165e+04, 4.0825e+04, 7.2054e+04, 4.6812e+04, 7.9683e+04,\n",
            "           3.1953e+04, 5.8713e+04, 3.0946e+04, 4.0996e+04, 9.4591e+04,\n",
            "           3.0397e+04, 4.6186e+04, 3.6985e+04, 1.6797e+05, 5.6825e+04,\n",
            "           3.7301e+04, 8.8893e+04, 1.1421e+05, 5.6417e+05]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4497, 2.2472, 0.1648]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1284, 0.7750, 0.0966]], device='cuda:0')\n",
            "[tensor([[[[4.9710e+01, 4.9741e+01, 4.9840e+01, 4.9870e+01, 4.9830e+01,\n",
            "           4.9930e+01, 4.9905e+01, 4.9892e+01, 4.9920e+01, 4.9890e+01,\n",
            "           4.9920e+01, 4.9900e+01, 4.9910e+01, 4.9890e+01, 4.9900e+01,\n",
            "           4.9900e+01, 4.9920e+01, 4.9910e+01, 4.9900e+01, 4.9900e+01,\n",
            "           5.0000e+01, 5.0000e+01, 5.0040e+01, 5.0000e+01],\n",
            "          [4.9790e+01, 4.9840e+01, 4.9875e+01, 4.9874e+01, 4.9965e+01,\n",
            "           4.9980e+01, 4.9950e+01, 4.9940e+01, 4.9940e+01, 4.9935e+01,\n",
            "           4.9970e+01, 4.9920e+01, 4.9930e+01, 4.9915e+01, 4.9920e+01,\n",
            "           4.9915e+01, 4.9970e+01, 4.9950e+01, 4.9910e+01, 4.9910e+01,\n",
            "           5.0000e+01, 5.0000e+01, 5.0040e+01, 5.0000e+01],\n",
            "          [4.9660e+01, 4.9710e+01, 4.9800e+01, 4.9810e+01, 4.9830e+01,\n",
            "           4.9880e+01, 4.9890e+01, 4.9890e+01, 4.9886e+01, 4.9873e+01,\n",
            "           4.9900e+01, 4.9890e+01, 4.9890e+01, 4.9870e+01, 4.9885e+01,\n",
            "           4.9840e+01, 4.9900e+01, 4.9890e+01, 4.9900e+01, 4.9900e+01,\n",
            "           4.9990e+01, 4.9990e+01, 5.0040e+01, 4.9990e+01],\n",
            "          [4.9750e+01, 4.9816e+01, 4.9871e+01, 4.9830e+01, 4.9931e+01,\n",
            "           4.9900e+01, 4.9890e+01, 4.9910e+01, 4.9890e+01, 4.9910e+01,\n",
            "           4.9900e+01, 4.9910e+01, 4.9895e+01, 4.9890e+01, 4.9905e+01,\n",
            "           4.9910e+01, 4.9910e+01, 4.9920e+01, 4.9910e+01, 4.9910e+01,\n",
            "           5.0000e+01, 5.0000e+01, 5.0040e+01, 4.9990e+01],\n",
            "          [1.0120e+05, 5.7993e+04, 2.5936e+04, 1.5497e+04, 6.9064e+04,\n",
            "           9.3677e+04, 8.2138e+04, 2.6846e+04, 3.8330e+04, 8.8271e+04,\n",
            "           7.7170e+04, 4.7891e+04, 7.2292e+04, 5.1612e+04, 1.4358e+05,\n",
            "           1.0466e+05, 1.6836e+05, 1.7358e+05, 6.0460e+05, 0.0000e+00,\n",
            "           7.2000e+02, 0.0000e+00, 1.0500e+02, 4.0180e+03]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4568, 2.2758, 0.1740]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1263, 0.7786, 0.0952]], device='cuda:0')\n",
            "[tensor([[[[5.0500e+01, 5.0390e+01, 5.0500e+01, 5.0460e+01, 5.0310e+01,\n",
            "           5.0310e+01, 5.0230e+01, 5.0530e+01, 5.0700e+01, 5.0750e+01,\n",
            "           5.0850e+01, 5.0900e+01, 5.0900e+01, 5.0840e+01, 5.0850e+01,\n",
            "           5.0730e+01, 5.0760e+01, 5.0730e+01, 5.0730e+01, 5.0810e+01,\n",
            "           5.0860e+01, 5.0840e+01, 5.0730e+01, 5.0750e+01],\n",
            "          [5.0500e+01, 5.0390e+01, 5.0500e+01, 5.0460e+01, 5.0310e+01,\n",
            "           5.0310e+01, 5.0390e+01, 5.0640e+01, 5.0860e+01, 5.0800e+01,\n",
            "           5.0920e+01, 5.1000e+01, 5.0980e+01, 5.0901e+01, 5.0890e+01,\n",
            "           5.0820e+01, 5.0790e+01, 5.0780e+01, 5.0870e+01, 5.0910e+01,\n",
            "           5.0900e+01, 5.0880e+01, 5.0840e+01, 5.0750e+01],\n",
            "          [5.0500e+01, 5.0370e+01, 5.0500e+01, 5.0240e+01, 5.0310e+01,\n",
            "           5.0310e+01, 5.0220e+01, 5.0530e+01, 5.0700e+01, 5.0720e+01,\n",
            "           5.0850e+01, 5.0900e+01, 5.0810e+01, 5.0790e+01, 5.0680e+01,\n",
            "           5.0640e+01, 5.0680e+01, 5.0650e+01, 5.0730e+01, 5.0795e+01,\n",
            "           5.0770e+01, 5.0720e+01, 5.0715e+01, 5.0590e+01],\n",
            "          [5.0500e+01, 5.0370e+01, 5.0500e+01, 5.0240e+01, 5.0310e+01,\n",
            "           5.0310e+01, 5.0390e+01, 5.0640e+01, 5.0740e+01, 5.0800e+01,\n",
            "           5.0910e+01, 5.0942e+01, 5.0850e+01, 5.0850e+01, 5.0720e+01,\n",
            "           5.0780e+01, 5.0746e+01, 5.0720e+01, 5.0795e+01, 5.0860e+01,\n",
            "           5.0840e+01, 5.0720e+01, 5.0755e+01, 5.0660e+01],\n",
            "          [1.1500e+02, 4.0000e+02, 1.2000e+02, 4.6100e+02, 4.3100e+02,\n",
            "           0.0000e+00, 1.0160e+03, 1.3222e+04, 7.5170e+03, 2.3510e+03,\n",
            "           5.7773e+04, 5.4469e+04, 1.5869e+05, 8.1743e+04, 1.0139e+05,\n",
            "           5.8380e+04, 5.4322e+04, 2.9361e+04, 7.1471e+04, 3.5317e+04,\n",
            "           6.8502e+04, 4.2954e+04, 5.9194e+04, 9.4729e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4617, 2.3147, 0.1734]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1230, 0.7848, 0.0922]], device='cuda:0')\n",
            "[tensor([[[[5.0650e+01, 5.0620e+01, 5.0730e+01, 5.0820e+01, 5.0890e+01,\n",
            "           5.0810e+01, 5.0770e+01, 5.0790e+01, 5.1040e+01, 5.1020e+01,\n",
            "           5.1035e+01, 5.1125e+01, 5.1030e+01, 5.1030e+01, 5.1160e+01,\n",
            "           5.1190e+01, 5.1150e+01, 5.1160e+01, 5.1130e+01, 5.1160e+01,\n",
            "           5.1180e+01, 5.1210e+01, 5.1330e+01, 5.1310e+01],\n",
            "          [5.0780e+01, 5.0730e+01, 5.0850e+01, 5.0974e+01, 5.0980e+01,\n",
            "           5.0850e+01, 5.0800e+01, 5.1060e+01, 5.1060e+01, 5.1090e+01,\n",
            "           5.1190e+01, 5.1125e+01, 5.1090e+01, 5.1260e+01, 5.1180e+01,\n",
            "           5.1190e+01, 5.1180e+01, 5.1160e+01, 5.1220e+01, 5.1190e+01,\n",
            "           5.1240e+01, 5.1370e+01, 5.1330e+01, 5.1460e+01],\n",
            "          [5.0620e+01, 5.0600e+01, 5.0700e+01, 5.0820e+01, 5.0810e+01,\n",
            "           5.0760e+01, 5.0700e+01, 5.0785e+01, 5.1000e+01, 5.0990e+01,\n",
            "           5.1030e+01, 5.1000e+01, 5.1020e+01, 5.1025e+01, 5.1120e+01,\n",
            "           5.1110e+01, 5.1140e+01, 5.1080e+01, 5.1130e+01, 5.1140e+01,\n",
            "           5.1170e+01, 5.1200e+01, 5.1250e+01, 5.1310e+01],\n",
            "          [5.0620e+01, 5.0730e+01, 5.0820e+01, 5.0920e+01, 5.0820e+01,\n",
            "           5.0780e+01, 5.0790e+01, 5.1045e+01, 5.1020e+01, 5.1040e+01,\n",
            "           5.1120e+01, 5.1030e+01, 5.1020e+01, 5.1150e+01, 5.1160e+01,\n",
            "           5.1110e+01, 5.1170e+01, 5.1130e+01, 5.1180e+01, 5.1160e+01,\n",
            "           5.1210e+01, 5.1340e+01, 5.1320e+01, 5.1420e+01],\n",
            "          [6.2992e+04, 6.4931e+04, 6.2004e+04, 7.8809e+04, 3.7947e+04,\n",
            "           6.9178e+04, 4.2079e+04, 6.2750e+04, 3.0130e+04, 4.8383e+04,\n",
            "           6.0750e+04, 1.0442e+05, 4.3314e+04, 7.5084e+04, 6.5318e+04,\n",
            "           2.1609e+04, 2.5123e+04, 3.7735e+04, 8.9544e+04, 6.0567e+04,\n",
            "           1.0414e+05, 5.8655e+04, 3.7886e+04, 6.2739e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4640, 2.3329, 0.1741]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1215, 0.7876, 0.0909]], device='cuda:0')\n",
            "[tensor([[[[5.1420e+01, 5.1440e+01, 5.1405e+01, 5.1430e+01, 5.1430e+01,\n",
            "           5.1470e+01, 5.1480e+01, 5.1500e+01, 5.1490e+01, 5.1530e+01,\n",
            "           5.1545e+01, 5.1420e+01, 5.1450e+01, 5.1490e+01, 5.1490e+01,\n",
            "           5.1480e+01, 5.1550e+01, 5.1410e+01, 5.1420e+01, 5.1400e+01,\n",
            "           5.1390e+01, 5.1460e+01, 5.1450e+01, 5.1450e+01],\n",
            "          [5.1460e+01, 5.1440e+01, 5.1430e+01, 5.1450e+01, 5.1490e+01,\n",
            "           5.1500e+01, 5.1530e+01, 5.1500e+01, 5.1550e+01, 5.1555e+01,\n",
            "           5.1570e+01, 5.1460e+01, 5.1515e+01, 5.1530e+01, 5.1510e+01,\n",
            "           5.1565e+01, 5.1550e+01, 5.1460e+01, 5.1460e+01, 5.1400e+01,\n",
            "           5.1470e+01, 5.1474e+01, 5.1500e+01, 5.1480e+01],\n",
            "          [5.1400e+01, 5.1380e+01, 5.1390e+01, 5.1410e+01, 5.1410e+01,\n",
            "           5.1430e+01, 5.1470e+01, 5.1440e+01, 5.1490e+01, 5.1510e+01,\n",
            "           5.1410e+01, 5.1400e+01, 5.1440e+01, 5.1470e+01, 5.1460e+01,\n",
            "           5.1470e+01, 5.1410e+01, 5.1410e+01, 5.1380e+01, 5.1344e+01,\n",
            "           5.1390e+01, 5.1430e+01, 5.1410e+01, 5.1350e+01],\n",
            "          [5.1450e+01, 5.1410e+01, 5.1420e+01, 5.1430e+01, 5.1470e+01,\n",
            "           5.1490e+01, 5.1495e+01, 5.1490e+01, 5.1540e+01, 5.1545e+01,\n",
            "           5.1410e+01, 5.1450e+01, 5.1480e+01, 5.1500e+01, 5.1480e+01,\n",
            "           5.1560e+01, 5.1410e+01, 5.1415e+01, 5.1390e+01, 5.1390e+01,\n",
            "           5.1460e+01, 5.1450e+01, 5.1440e+01, 5.1370e+01],\n",
            "          [2.1710e+04, 3.8576e+04, 3.0825e+04, 2.2121e+04, 3.8013e+04,\n",
            "           4.1610e+04, 2.5680e+04, 1.8284e+04, 3.1776e+04, 2.6176e+04,\n",
            "           5.0136e+04, 2.9127e+04, 4.0333e+04, 2.7748e+04, 2.1421e+04,\n",
            "           2.5701e+04, 3.2493e+04, 1.4639e+04, 2.8926e+04, 2.6767e+05,\n",
            "           3.0710e+04, 2.0770e+04, 4.5737e+04, 1.4762e+05]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4697, 2.3467, 0.1804]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1207, 0.7889, 0.0904]], device='cuda:0')\n",
            "[tensor([[[[5.1370e+01, 5.1415e+01, 5.1415e+01, 5.1410e+01, 5.1460e+01,\n",
            "           5.1470e+01, 5.1530e+01, 5.1560e+01, 5.1545e+01, 5.1560e+01,\n",
            "           5.1560e+01, 5.1560e+01, 5.1550e+01, 5.1580e+01, 5.1550e+01,\n",
            "           5.1540e+01, 5.1550e+01, 5.1580e+01, 5.1570e+01, 5.1570e+01,\n",
            "           5.1570e+01, 5.1570e+01, 5.1570e+01, 5.1570e+01],\n",
            "          [5.1430e+01, 5.1430e+01, 5.1450e+01, 5.1455e+01, 5.1479e+01,\n",
            "           5.1540e+01, 5.1590e+01, 5.1565e+01, 5.1570e+01, 5.1565e+01,\n",
            "           5.1570e+01, 5.1560e+01, 5.1580e+01, 5.1580e+01, 5.1550e+01,\n",
            "           5.1555e+01, 5.1590e+01, 5.1610e+01, 5.1570e+01, 5.1570e+01,\n",
            "           5.1570e+01, 5.1570e+01, 5.1570e+01, 5.1570e+01],\n",
            "          [5.1360e+01, 5.1410e+01, 5.1410e+01, 5.1410e+01, 5.1445e+01,\n",
            "           5.1450e+01, 5.1515e+01, 5.1530e+01, 5.1530e+01, 5.1550e+01,\n",
            "           5.1545e+01, 5.1540e+01, 5.1545e+01, 5.1535e+01, 5.1525e+01,\n",
            "           5.1525e+01, 5.1540e+01, 5.1570e+01, 5.1570e+01, 5.1570e+01,\n",
            "           5.1570e+01, 5.1570e+01, 5.1570e+01, 5.1570e+01],\n",
            "          [5.1420e+01, 5.1420e+01, 5.1420e+01, 5.1455e+01, 5.1479e+01,\n",
            "           5.1530e+01, 5.1565e+01, 5.1550e+01, 5.1550e+01, 5.1563e+01,\n",
            "           5.1550e+01, 5.1555e+01, 5.1580e+01, 5.1550e+01, 5.1545e+01,\n",
            "           5.1550e+01, 5.1584e+01, 5.1580e+01, 5.1570e+01, 5.1570e+01,\n",
            "           5.1570e+01, 5.1570e+01, 5.1570e+01, 5.1570e+01],\n",
            "          [3.4212e+04, 1.0566e+04, 1.1765e+04, 1.2016e+04, 1.5253e+04,\n",
            "           6.5210e+04, 8.0813e+04, 1.1169e+04, 1.5259e+04, 8.3710e+03,\n",
            "           1.4325e+04, 1.0799e+04, 2.4465e+04, 2.1838e+04, 5.8998e+04,\n",
            "           2.4574e+05, 2.8747e+05, 2.3306e+05, 1.2356e+05, 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00, 2.0000e+03, 0.0000e+00]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4699, 2.3491, 0.1798]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1205, 0.7893, 0.0902]], device='cuda:0')\n",
            "[tensor([[[[5.1320e+01, 5.1320e+01, 5.1320e+01, 5.1210e+01, 5.1380e+01,\n",
            "           5.1340e+01, 5.1300e+01, 5.1300e+01, 5.1260e+01, 5.1260e+01,\n",
            "           5.1260e+01, 5.1330e+01, 5.1420e+01, 5.1380e+01, 5.1390e+01,\n",
            "           5.1360e+01, 5.1275e+01, 5.1290e+01, 5.1380e+01, 5.1460e+01,\n",
            "           5.1440e+01, 5.1465e+01, 5.1576e+01, 5.1570e+01],\n",
            "          [5.1320e+01, 5.1320e+01, 5.1320e+01, 5.1210e+01, 5.1400e+01,\n",
            "           5.1440e+01, 5.1310e+01, 5.1300e+01, 5.1260e+01, 5.1260e+01,\n",
            "           5.1260e+01, 5.1330e+01, 5.1440e+01, 5.1410e+01, 5.1405e+01,\n",
            "           5.1410e+01, 5.1330e+01, 5.1390e+01, 5.1490e+01, 5.1500e+01,\n",
            "           5.1485e+01, 5.1580e+01, 5.1620e+01, 5.1590e+01],\n",
            "          [5.1320e+01, 5.1320e+01, 5.1320e+01, 5.1110e+01, 5.1360e+01,\n",
            "           5.1340e+01, 5.1300e+01, 5.1300e+01, 5.1260e+01, 5.1260e+01,\n",
            "           5.1260e+01, 5.1330e+01, 5.1350e+01, 5.1320e+01, 5.1270e+01,\n",
            "           5.1280e+01, 5.1250e+01, 5.1260e+01, 5.1360e+01, 5.1385e+01,\n",
            "           5.1390e+01, 5.1430e+01, 5.1510e+01, 5.1490e+01],\n",
            "          [5.1320e+01, 5.1320e+01, 5.1320e+01, 5.1150e+01, 5.1360e+01,\n",
            "           5.1440e+01, 5.1310e+01, 5.1300e+01, 5.1260e+01, 5.1260e+01,\n",
            "           5.1260e+01, 5.1330e+01, 5.1370e+01, 5.1400e+01, 5.1370e+01,\n",
            "           5.1280e+01, 5.1290e+01, 5.1390e+01, 5.1460e+01, 5.1425e+01,\n",
            "           5.1473e+01, 5.1570e+01, 5.1600e+01, 5.1490e+01],\n",
            "          [1.5000e+03, 0.0000e+00, 0.0000e+00, 2.5700e+03, 1.0581e+04,\n",
            "           9.3100e+02, 8.0100e+02, 1.0000e+02, 2.0000e+02, 0.0000e+00,\n",
            "           0.0000e+00, 3.8000e+03, 1.3303e+05, 1.4022e+05, 1.3915e+05,\n",
            "           6.6715e+04, 8.7853e+04, 7.2580e+04, 1.6081e+05, 5.4742e+04,\n",
            "           4.0165e+04, 5.1555e+04, 4.2717e+04, 3.5994e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4686, 2.3446, 0.1771]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1209, 0.7889, 0.0903]], device='cuda:0')\n",
            "[tensor([[[[5.1580e+01, 5.1425e+01, 5.1760e+01, 5.1630e+01, 5.1720e+01,\n",
            "           5.1745e+01, 5.1593e+01, 5.1580e+01, 5.1510e+01, 5.1620e+01,\n",
            "           5.1634e+01, 5.1710e+01, 5.1750e+01, 5.1860e+01, 5.1781e+01,\n",
            "           5.1730e+01, 5.1770e+01, 5.1780e+01, 5.1820e+01, 5.1930e+01,\n",
            "           5.1990e+01, 5.1990e+01, 5.1940e+01, 5.1950e+01],\n",
            "          [5.1580e+01, 5.1820e+01, 5.1800e+01, 5.1720e+01, 5.1746e+01,\n",
            "           5.1745e+01, 5.1670e+01, 5.1590e+01, 5.1643e+01, 5.1660e+01,\n",
            "           5.1720e+01, 5.1760e+01, 5.1860e+01, 5.1915e+01, 5.1790e+01,\n",
            "           5.1775e+01, 5.1790e+01, 5.1820e+01, 5.1955e+01, 5.2020e+01,\n",
            "           5.2040e+01, 5.1990e+01, 5.1952e+01, 5.2020e+01],\n",
            "          [5.1400e+01, 5.1400e+01, 5.1615e+01, 5.1630e+01, 5.1690e+01,\n",
            "           5.1560e+01, 5.1565e+01, 5.1470e+01, 5.1510e+01, 5.1610e+01,\n",
            "           5.1600e+01, 5.1650e+01, 5.1730e+01, 5.1770e+01, 5.1720e+01,\n",
            "           5.1680e+01, 5.1730e+01, 5.1770e+01, 5.1780e+01, 5.1890e+01,\n",
            "           5.1940e+01, 5.1910e+01, 5.1910e+01, 5.1950e+01],\n",
            "          [5.1410e+01, 5.1740e+01, 5.1640e+01, 5.1720e+01, 5.1720e+01,\n",
            "           5.1600e+01, 5.1565e+01, 5.1510e+01, 5.1640e+01, 5.1630e+01,\n",
            "           5.1710e+01, 5.1750e+01, 5.1850e+01, 5.1790e+01, 5.1730e+01,\n",
            "           5.1770e+01, 5.1780e+01, 5.1810e+01, 5.1940e+01, 5.2000e+01,\n",
            "           5.1980e+01, 5.1920e+01, 5.1950e+01, 5.2000e+01],\n",
            "          [9.4669e+04, 3.2061e+05, 1.2532e+05, 1.9722e+05, 6.8123e+04,\n",
            "           4.4901e+04, 3.0419e+04, 4.7835e+04, 5.9522e+04, 1.2393e+04,\n",
            "           4.8459e+04, 2.8442e+04, 6.0368e+04, 2.4748e+05, 4.9412e+04,\n",
            "           4.8984e+04, 3.6014e+04, 5.5321e+04, 8.2519e+04, 4.1486e+04,\n",
            "           4.0675e+04, 3.5309e+04, 1.5482e+04, 3.1600e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4716, 2.3676, 0.1780]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1190, 0.7923, 0.0887]], device='cuda:0')\n",
            "[tensor([[[[5.1980e+01, 5.1990e+01, 5.2010e+01, 5.1970e+01, 5.1970e+01,\n",
            "           5.1990e+01, 5.1960e+01, 5.1980e+01, 5.2030e+01, 5.1965e+01,\n",
            "           5.1985e+01, 5.2060e+01, 5.2070e+01, 5.2050e+01, 5.2060e+01,\n",
            "           5.1990e+01, 5.2070e+01, 5.2150e+01, 5.2160e+01, 5.2100e+01,\n",
            "           5.2050e+01, 5.2120e+01, 5.2220e+01, 5.2310e+01],\n",
            "          [5.2020e+01, 5.2020e+01, 5.2040e+01, 5.1990e+01, 5.2010e+01,\n",
            "           5.2000e+01, 5.2010e+01, 5.2040e+01, 5.2030e+01, 5.2010e+01,\n",
            "           5.2095e+01, 5.2080e+01, 5.2080e+01, 5.2090e+01, 5.2060e+01,\n",
            "           5.2110e+01, 5.2190e+01, 5.2200e+01, 5.2160e+01, 5.2130e+01,\n",
            "           5.2130e+01, 5.2230e+01, 5.2340e+01, 5.2380e+01],\n",
            "          [5.1960e+01, 5.1960e+01, 5.1980e+01, 5.1940e+01, 5.1970e+01,\n",
            "           5.1940e+01, 5.1940e+01, 5.1970e+01, 5.1960e+01, 5.1960e+01,\n",
            "           5.1975e+01, 5.2025e+01, 5.2035e+01, 5.2040e+01, 5.1980e+01,\n",
            "           5.1990e+01, 5.2060e+01, 5.2150e+01, 5.2090e+01, 5.2040e+01,\n",
            "           5.2050e+01, 5.2110e+01, 5.2210e+01, 5.2310e+01],\n",
            "          [5.2000e+01, 5.2010e+01, 5.1980e+01, 5.1960e+01, 5.2000e+01,\n",
            "           5.1960e+01, 5.1990e+01, 5.2040e+01, 5.1960e+01, 5.1995e+01,\n",
            "           5.2075e+01, 5.2070e+01, 5.2060e+01, 5.2070e+01, 5.1980e+01,\n",
            "           5.2080e+01, 5.2150e+01, 5.2160e+01, 5.2100e+01, 5.2050e+01,\n",
            "           5.2120e+01, 5.2230e+01, 5.2319e+01, 5.2340e+01],\n",
            "          [2.3088e+04, 3.4628e+04, 2.5780e+04, 4.1709e+04, 1.9389e+04,\n",
            "           2.5641e+04, 1.9353e+04, 1.3418e+05, 2.4488e+04, 1.0631e+04,\n",
            "           3.1430e+04, 1.8235e+04, 1.7013e+04, 6.4474e+04, 4.6140e+05,\n",
            "           7.1546e+04, 6.7603e+04, 3.9117e+04, 1.1592e+05, 2.0268e+05,\n",
            "           3.5277e+04, 4.0625e+04, 4.0586e+04, 7.3556e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4738, 2.3772, 0.1788]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1183, 0.7936, 0.0881]], device='cuda:0')\n",
            "[tensor([[[[5.2350e+01, 5.2420e+01, 5.2500e+01, 5.2435e+01, 5.2470e+01,\n",
            "           5.2450e+01, 5.2425e+01, 5.2385e+01, 5.2400e+01, 5.2420e+01,\n",
            "           5.2375e+01, 5.2375e+01, 5.2375e+01, 5.2400e+01, 5.2410e+01,\n",
            "           5.2415e+01, 5.2460e+01, 5.2472e+01, 5.2480e+01, 5.2470e+01,\n",
            "           5.2470e+01, 5.2470e+01, 5.2470e+01, 5.2480e+01],\n",
            "          [5.2406e+01, 5.2515e+01, 5.2508e+01, 5.2480e+01, 5.2485e+01,\n",
            "           5.2450e+01, 5.2425e+01, 5.2417e+01, 5.2420e+01, 5.2440e+01,\n",
            "           5.2390e+01, 5.2390e+01, 5.2410e+01, 5.2420e+01, 5.2420e+01,\n",
            "           5.2460e+01, 5.2480e+01, 5.2495e+01, 5.2480e+01, 5.2470e+01,\n",
            "           5.2470e+01, 5.2470e+01, 5.2470e+01, 5.2480e+01],\n",
            "          [5.2330e+01, 5.2400e+01, 5.2420e+01, 5.2410e+01, 5.2460e+01,\n",
            "           5.2410e+01, 5.2375e+01, 5.2385e+01, 5.2395e+01, 5.2370e+01,\n",
            "           5.2350e+01, 5.2375e+01, 5.2375e+01, 5.2390e+01, 5.2380e+01,\n",
            "           5.2400e+01, 5.2445e+01, 5.2440e+01, 5.2440e+01, 5.2430e+01,\n",
            "           5.2430e+01, 5.2430e+01, 5.2430e+01, 5.2480e+01],\n",
            "          [5.2400e+01, 5.2500e+01, 5.2425e+01, 5.2470e+01, 5.2460e+01,\n",
            "           5.2425e+01, 5.2390e+01, 5.2410e+01, 5.2420e+01, 5.2370e+01,\n",
            "           5.2380e+01, 5.2380e+01, 5.2410e+01, 5.2405e+01, 5.2420e+01,\n",
            "           5.2460e+01, 5.2470e+01, 5.2480e+01, 5.2440e+01, 5.2430e+01,\n",
            "           5.2430e+01, 5.2430e+01, 5.2430e+01, 5.2480e+01],\n",
            "          [2.9609e+05, 1.2395e+05, 9.4432e+04, 4.0632e+04, 2.8308e+04,\n",
            "           1.2553e+04, 3.1002e+04, 3.0997e+04, 1.2146e+04, 3.5847e+04,\n",
            "           2.5743e+04, 1.6591e+04, 3.0538e+04, 3.1563e+04, 2.7802e+04,\n",
            "           1.3143e+05, 5.5030e+04, 2.0106e+05, 1.2339e+05, 6.3000e+02,\n",
            "           0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+02]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4773, 2.3916, 0.1837]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1173, 0.7953, 0.0874]], device='cuda:0')\n",
            "[tensor([[[[5.2550e+01, 5.2550e+01, 5.2480e+01, 5.2480e+01, 5.2510e+01,\n",
            "           5.2530e+01, 5.2640e+01, 5.2540e+01, 5.2510e+01, 5.2400e+01,\n",
            "           5.2420e+01, 5.2410e+01, 5.2480e+01, 5.2540e+01, 5.2560e+01,\n",
            "           5.2554e+01, 5.2490e+01, 5.2530e+01, 5.2500e+01, 5.2380e+01,\n",
            "           5.2360e+01, 5.2470e+01, 5.2531e+01, 5.2480e+01],\n",
            "          [5.2550e+01, 5.2550e+01, 5.2480e+01, 5.2480e+01, 5.2510e+01,\n",
            "           5.2540e+01, 5.2640e+01, 5.2570e+01, 5.2510e+01, 5.2400e+01,\n",
            "           5.2450e+01, 5.2410e+01, 5.2550e+01, 5.2640e+01, 5.2570e+01,\n",
            "           5.2580e+01, 5.2550e+01, 5.2530e+01, 5.2520e+01, 5.2470e+01,\n",
            "           5.2488e+01, 5.2570e+01, 5.2550e+01, 5.2530e+01],\n",
            "          [5.2550e+01, 5.2550e+01, 5.2480e+01, 5.2480e+01, 5.2510e+01,\n",
            "           5.2510e+01, 5.2630e+01, 5.2540e+01, 5.2510e+01, 5.2400e+01,\n",
            "           5.2420e+01, 5.2410e+01, 5.2360e+01, 5.2510e+01, 5.2460e+01,\n",
            "           5.2420e+01, 5.2450e+01, 5.2470e+01, 5.2360e+01, 5.2350e+01,\n",
            "           5.2360e+01, 5.2460e+01, 5.2480e+01, 5.2420e+01],\n",
            "          [5.2550e+01, 5.2550e+01, 5.2480e+01, 5.2480e+01, 5.2510e+01,\n",
            "           5.2540e+01, 5.2630e+01, 5.2570e+01, 5.2510e+01, 5.2400e+01,\n",
            "           5.2440e+01, 5.2410e+01, 5.2550e+01, 5.2560e+01, 5.2560e+01,\n",
            "           5.2490e+01, 5.2530e+01, 5.2490e+01, 5.2370e+01, 5.2370e+01,\n",
            "           5.2460e+01, 5.2530e+01, 5.2480e+01, 5.2430e+01],\n",
            "          [2.0000e+02, 1.0000e+03, 2.9300e+02, 0.0000e+00, 1.0000e+03,\n",
            "           1.4400e+03, 1.5550e+03, 4.4030e+03, 1.0010e+03, 1.0000e+03,\n",
            "           1.2100e+03, 1.2500e+02, 8.2044e+04, 7.4457e+04, 4.4196e+04,\n",
            "           8.6182e+04, 3.5755e+04, 5.6034e+04, 6.5847e+04, 4.9465e+04,\n",
            "           2.7241e+04, 8.5386e+04, 1.0013e+04, 1.1434e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4784, 2.3942, 0.1846]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1171, 0.7956, 0.0873]], device='cuda:0')\n",
            "[tensor([[[[5.2450e+01, 5.2380e+01, 5.2500e+01, 5.2520e+01, 5.2500e+01,\n",
            "           5.2570e+01, 5.2570e+01, 5.2550e+01, 5.2490e+01, 5.2520e+01,\n",
            "           5.2750e+01, 5.2800e+01, 5.2920e+01, 5.2890e+01, 5.2790e+01,\n",
            "           5.2880e+01, 5.2940e+01, 5.2920e+01, 5.2960e+01, 5.3000e+01,\n",
            "           5.2930e+01, 5.2951e+01, 5.2950e+01, 5.3010e+01],\n",
            "          [5.2450e+01, 5.2510e+01, 5.2540e+01, 5.2538e+01, 5.2590e+01,\n",
            "           5.2580e+01, 5.2580e+01, 5.2570e+01, 5.2510e+01, 5.2730e+01,\n",
            "           5.2860e+01, 5.3010e+01, 5.2960e+01, 5.2910e+01, 5.2880e+01,\n",
            "           5.2990e+01, 5.2965e+01, 5.2970e+01, 5.3075e+01, 5.3000e+01,\n",
            "           5.2960e+01, 5.2970e+01, 5.3030e+01, 5.3075e+01],\n",
            "          [5.2370e+01, 5.2380e+01, 5.2480e+01, 5.2490e+01, 5.2490e+01,\n",
            "           5.2520e+01, 5.2530e+01, 5.2470e+01, 5.2450e+01, 5.2520e+01,\n",
            "           5.2680e+01, 5.2800e+01, 5.2860e+01, 5.2760e+01, 5.2770e+01,\n",
            "           5.2880e+01, 5.2890e+01, 5.2910e+01, 5.2950e+01, 5.2910e+01,\n",
            "           5.2890e+01, 5.2910e+01, 5.2950e+01, 5.3010e+01],\n",
            "          [5.2404e+01, 5.2500e+01, 5.2540e+01, 5.2520e+01, 5.2570e+01,\n",
            "           5.2580e+01, 5.2550e+01, 5.2500e+01, 5.2510e+01, 5.2720e+01,\n",
            "           5.2815e+01, 5.2910e+01, 5.2880e+01, 5.2770e+01, 5.2875e+01,\n",
            "           5.2935e+01, 5.2910e+01, 5.2960e+01, 5.2982e+01, 5.2950e+01,\n",
            "           5.2940e+01, 5.2930e+01, 5.3010e+01, 5.3010e+01],\n",
            "          [4.1000e+04, 4.4992e+04, 1.6230e+04, 2.6511e+04, 2.8257e+04,\n",
            "           2.5205e+04, 2.8338e+04, 2.7741e+04, 3.1766e+04, 2.4386e+05,\n",
            "           9.4042e+04, 1.7678e+05, 8.8524e+04, 7.9096e+04, 4.0299e+04,\n",
            "           5.1391e+04, 3.6079e+04, 4.6520e+04, 1.1224e+05, 2.5408e+04,\n",
            "           4.0020e+04, 1.6697e+04, 2.8554e+04, 6.4631e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4780, 2.4124, 0.1782]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1155, 0.7990, 0.0855]], device='cuda:0')\n",
            "[tensor([[[[5.3001e+01, 5.2970e+01, 5.2960e+01, 5.3000e+01, 5.2960e+01,\n",
            "           5.3000e+01, 5.2970e+01, 5.3000e+01, 5.3024e+01, 5.2890e+01,\n",
            "           5.2880e+01, 5.2910e+01, 5.2940e+01, 5.2980e+01, 5.2960e+01,\n",
            "           5.2980e+01, 5.2970e+01, 5.2980e+01, 5.2990e+01, 5.2975e+01,\n",
            "           5.2945e+01, 5.2945e+01, 5.2960e+01, 5.3020e+01],\n",
            "          [5.3032e+01, 5.2985e+01, 5.3005e+01, 5.3000e+01, 5.3010e+01,\n",
            "           5.3020e+01, 5.3000e+01, 5.3040e+01, 5.3024e+01, 5.2920e+01,\n",
            "           5.2920e+01, 5.3000e+01, 5.3000e+01, 5.3030e+01, 5.2985e+01,\n",
            "           5.2980e+01, 5.3005e+01, 5.3005e+01, 5.3010e+01, 5.2978e+01,\n",
            "           5.2955e+01, 5.3020e+01, 5.3040e+01, 5.3150e+01],\n",
            "          [5.2960e+01, 5.2940e+01, 5.2950e+01, 5.2950e+01, 5.2952e+01,\n",
            "           5.2960e+01, 5.2950e+01, 5.2990e+01, 5.2880e+01, 5.2860e+01,\n",
            "           5.2860e+01, 5.2910e+01, 5.2925e+01, 5.2960e+01, 5.2940e+01,\n",
            "           5.2950e+01, 5.2960e+01, 5.2960e+01, 5.2970e+01, 5.2940e+01,\n",
            "           5.2930e+01, 5.2940e+01, 5.2960e+01, 5.2940e+01],\n",
            "          [5.2980e+01, 5.2970e+01, 5.2990e+01, 5.2960e+01, 5.2990e+01,\n",
            "           5.2980e+01, 5.3000e+01, 5.3025e+01, 5.2895e+01, 5.2880e+01,\n",
            "           5.2910e+01, 5.2940e+01, 5.2985e+01, 5.2970e+01, 5.2980e+01,\n",
            "           5.2970e+01, 5.2980e+01, 5.2990e+01, 5.2970e+01, 5.2940e+01,\n",
            "           5.2950e+01, 5.2960e+01, 5.3020e+01, 5.3140e+01],\n",
            "          [2.2530e+04, 2.8109e+04, 1.4018e+04, 1.4593e+04, 2.0489e+04,\n",
            "           2.7038e+04, 1.1134e+04, 1.7495e+04, 5.2273e+04, 4.3587e+04,\n",
            "           2.7838e+04, 2.1931e+04, 1.5077e+04, 2.4049e+04, 1.4300e+04,\n",
            "           1.0229e+04, 2.5739e+04, 1.6519e+04, 1.8280e+04, 1.7064e+04,\n",
            "           2.3687e+04, 2.2078e+04, 3.1957e+04, 1.4916e+05]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4820, 2.4160, 0.1850]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1155, 0.7987, 0.0858]], device='cuda:0')\n",
            "[tensor([[[[5.3145e+01, 5.3030e+01, 5.2995e+01, 5.3100e+01, 5.3120e+01,\n",
            "           5.3120e+01, 5.3115e+01, 5.3080e+01, 5.3100e+01, 5.3130e+01,\n",
            "           5.3080e+01, 5.3220e+01, 5.3180e+01, 5.3170e+01, 5.3190e+01,\n",
            "           5.3170e+01, 5.3190e+01, 5.3205e+01, 5.3130e+01, 5.3120e+01,\n",
            "           5.3120e+01, 5.3100e+01, 5.3160e+01, 5.3160e+01],\n",
            "          [5.3145e+01, 5.3040e+01, 5.3105e+01, 5.3120e+01, 5.3130e+01,\n",
            "           5.3125e+01, 5.3120e+01, 5.3115e+01, 5.3130e+01, 5.3130e+01,\n",
            "           5.3220e+01, 5.3220e+01, 5.3190e+01, 5.3200e+01, 5.3220e+01,\n",
            "           5.3225e+01, 5.3235e+01, 5.3210e+01, 5.3130e+01, 5.3120e+01,\n",
            "           5.3120e+01, 5.3100e+01, 5.3160e+01, 5.3160e+01],\n",
            "          [5.2980e+01, 5.2960e+01, 5.2994e+01, 5.3090e+01, 5.3100e+01,\n",
            "           5.3100e+01, 5.3090e+01, 5.3080e+01, 5.3100e+01, 5.3070e+01,\n",
            "           5.3080e+01, 5.3180e+01, 5.3160e+01, 5.3160e+01, 5.3170e+01,\n",
            "           5.3170e+01, 5.3180e+01, 5.3105e+01, 5.3130e+01, 5.3110e+01,\n",
            "           5.3110e+01, 5.3100e+01, 5.3110e+01, 5.3110e+01],\n",
            "          [5.3040e+01, 5.2990e+01, 5.3105e+01, 5.3120e+01, 5.3120e+01,\n",
            "           5.3120e+01, 5.3090e+01, 5.3110e+01, 5.3120e+01, 5.3080e+01,\n",
            "           5.3201e+01, 5.3185e+01, 5.3165e+01, 5.3190e+01, 5.3180e+01,\n",
            "           5.3190e+01, 5.3200e+01, 5.3130e+01, 5.3130e+01, 5.3110e+01,\n",
            "           5.3110e+01, 5.3100e+01, 5.3130e+01, 5.3130e+01],\n",
            "          [3.5233e+04, 1.8350e+04, 3.8875e+04, 2.5350e+04, 1.0129e+04,\n",
            "           1.1548e+04, 2.0699e+04, 1.6411e+04, 9.9820e+03, 2.2099e+04,\n",
            "           1.1608e+05, 2.0816e+04, 3.4987e+04, 1.6132e+04, 3.6849e+04,\n",
            "           7.5049e+04, 1.8619e+05, 1.9768e+05, 1.7325e+04, 3.0000e+02,\n",
            "           0.0000e+00, 2.2480e+03, 7.3700e+02, 0.0000e+00]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4831, 2.4241, 0.1852]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1148, 0.7999, 0.0853]], device='cuda:0')\n",
            "[tensor([[[[ 53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900],\n",
            "          [ 53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900],\n",
            "          [ 53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900],\n",
            "          [ 53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,  53.0900,\n",
            "            53.0900,  53.0900,  53.0900],\n",
            "          [400.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "             0.0000,   0.0000,   0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900, 53.0900,\n",
            "           53.0900, 53.0900, 53.0900],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4825, 2.4190, 0.1857]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1152, 0.7991, 0.0856]], device='cuda:0')\n",
            "[tensor([[[[5.2600e+01, 5.2610e+01, 5.2680e+01, 5.2840e+01, 5.2840e+01,\n",
            "           5.2850e+01, 5.2990e+01, 5.2930e+01, 5.2950e+01, 5.2960e+01,\n",
            "           5.2900e+01, 5.2920e+01, 5.2980e+01, 5.2880e+01, 5.2830e+01,\n",
            "           5.2970e+01, 5.3100e+01, 5.2960e+01, 5.2957e+01, 5.3130e+01,\n",
            "           5.3190e+01, 5.3180e+01, 5.3410e+01, 5.3660e+01],\n",
            "          [5.2600e+01, 5.2610e+01, 5.2810e+01, 5.2840e+01, 5.2880e+01,\n",
            "           5.2850e+01, 5.2990e+01, 5.2930e+01, 5.2960e+01, 5.3000e+01,\n",
            "           5.2920e+01, 5.2980e+01, 5.3040e+01, 5.2880e+01, 5.2970e+01,\n",
            "           5.3139e+01, 5.3100e+01, 5.2990e+01, 5.3130e+01, 5.3200e+01,\n",
            "           5.3190e+01, 5.3410e+01, 5.3650e+01, 5.3760e+01],\n",
            "          [5.2600e+01, 5.2610e+01, 5.2680e+01, 5.2820e+01, 5.2840e+01,\n",
            "           5.2850e+01, 5.2970e+01, 5.2930e+01, 5.2950e+01, 5.2960e+01,\n",
            "           5.2900e+01, 5.2920e+01, 5.2860e+01, 5.2805e+01, 5.2830e+01,\n",
            "           5.2970e+01, 5.2900e+01, 5.2910e+01, 5.2950e+01, 5.3110e+01,\n",
            "           5.3100e+01, 5.3145e+01, 5.3410e+01, 5.3615e+01],\n",
            "          [5.2600e+01, 5.2610e+01, 5.2810e+01, 5.2820e+01, 5.2880e+01,\n",
            "           5.2850e+01, 5.2970e+01, 5.2930e+01, 5.2960e+01, 5.2960e+01,\n",
            "           5.2920e+01, 5.2980e+01, 5.2870e+01, 5.2830e+01, 5.2950e+01,\n",
            "           5.3091e+01, 5.2950e+01, 5.2950e+01, 5.3130e+01, 5.3190e+01,\n",
            "           5.3170e+01, 5.3410e+01, 5.3650e+01, 5.3760e+01],\n",
            "          [1.0000e+03, 7.0000e+02, 8.2350e+03, 3.0000e+02, 1.4250e+03,\n",
            "           1.0900e+02, 4.5200e+02, 2.0000e+02, 1.1620e+03, 4.1000e+03,\n",
            "           5.6500e+02, 5.0100e+02, 5.5343e+04, 5.1161e+04, 3.0952e+04,\n",
            "           3.6532e+04, 4.4356e+04, 3.2358e+04, 2.4212e+04, 3.6268e+04,\n",
            "           2.8010e+04, 8.5533e+04, 5.4894e+04, 4.2749e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4800, 2.4227, 0.1780]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1147, 0.8005, 0.0848]], device='cuda:0')\n",
            "[tensor([[[[5.3750e+01, 5.3980e+01, 5.4060e+01, 5.4140e+01, 5.4180e+01,\n",
            "           5.4330e+01, 5.4540e+01, 5.4512e+01, 5.4490e+01, 5.4540e+01,\n",
            "           5.4560e+01, 5.4570e+01, 5.4600e+01, 5.4510e+01, 5.4535e+01,\n",
            "           5.4560e+01, 5.4600e+01, 5.4620e+01, 5.4580e+01, 5.4580e+01,\n",
            "           5.4570e+01, 5.4540e+01, 5.4520e+01, 5.4490e+01],\n",
            "          [5.4020e+01, 5.4080e+01, 5.4190e+01, 5.4190e+01, 5.4460e+01,\n",
            "           5.4550e+01, 5.4563e+01, 5.4590e+01, 5.4565e+01, 5.4600e+01,\n",
            "           5.4590e+01, 5.4645e+01, 5.4600e+01, 5.4545e+01, 5.4600e+01,\n",
            "           5.4595e+01, 5.4632e+01, 5.4629e+01, 5.4590e+01, 5.4590e+01,\n",
            "           5.4570e+01, 5.4560e+01, 5.4520e+01, 5.4500e+01],\n",
            "          [5.3750e+01, 5.3850e+01, 5.4024e+01, 5.4130e+01, 5.4180e+01,\n",
            "           5.4300e+01, 5.4460e+01, 5.4430e+01, 5.4470e+01, 5.4480e+01,\n",
            "           5.4517e+01, 5.4560e+01, 5.4490e+01, 5.4430e+01, 5.4515e+01,\n",
            "           5.4520e+01, 5.4592e+01, 5.4560e+01, 5.4540e+01, 5.4530e+01,\n",
            "           5.4500e+01, 5.4500e+01, 5.4470e+01, 5.4432e+01],\n",
            "          [5.3971e+01, 5.4070e+01, 5.4086e+01, 5.4170e+01, 5.4310e+01,\n",
            "           5.4540e+01, 5.4501e+01, 5.4480e+01, 5.4530e+01, 5.4560e+01,\n",
            "           5.4570e+01, 5.4600e+01, 5.4490e+01, 5.4535e+01, 5.4560e+01,\n",
            "           5.4590e+01, 5.4630e+01, 5.4580e+01, 5.4580e+01, 5.4580e+01,\n",
            "           5.4540e+01, 5.4520e+01, 5.4480e+01, 5.4470e+01],\n",
            "          [1.5766e+05, 4.8531e+04, 9.7176e+04, 1.4117e+05, 1.7309e+05,\n",
            "           6.3783e+04, 6.6564e+04, 2.0003e+05, 3.4546e+04, 3.7322e+04,\n",
            "           2.6096e+04, 3.1236e+04, 6.8000e+04, 6.1945e+04, 3.2318e+04,\n",
            "           1.5547e+04, 1.6838e+04, 3.5452e+04, 2.5651e+04, 3.0245e+04,\n",
            "           2.7621e+04, 1.4230e+04, 1.7605e+04, 1.7461e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4930, 2.4851, 0.1892]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1103, 0.8084, 0.0814]], device='cuda:0')\n",
            "[tensor([[[[5.4470e+01, 5.4400e+01, 5.4430e+01, 5.4430e+01, 5.4425e+01,\n",
            "           5.4385e+01, 5.4400e+01, 5.4439e+01, 5.4460e+01, 5.4450e+01,\n",
            "           5.4390e+01, 5.4440e+01, 5.4460e+01, 5.4460e+01, 5.4500e+01,\n",
            "           5.4520e+01, 5.4510e+01, 5.4470e+01, 5.4440e+01, 5.4440e+01,\n",
            "           5.4430e+01, 5.4420e+01, 5.4390e+01, 5.4520e+01],\n",
            "          [5.4480e+01, 5.4460e+01, 5.4448e+01, 5.4470e+01, 5.4440e+01,\n",
            "           5.4405e+01, 5.4470e+01, 5.4480e+01, 5.4468e+01, 5.4450e+01,\n",
            "           5.4420e+01, 5.4480e+01, 5.4478e+01, 5.4510e+01, 5.4520e+01,\n",
            "           5.4545e+01, 5.4520e+01, 5.4480e+01, 5.4450e+01, 5.4450e+01,\n",
            "           5.4445e+01, 5.4443e+01, 5.4540e+01, 5.4640e+01],\n",
            "          [5.4400e+01, 5.4374e+01, 5.4390e+01, 5.4430e+01, 5.4360e+01,\n",
            "           5.4350e+01, 5.4400e+01, 5.4430e+01, 5.4410e+01, 5.4380e+01,\n",
            "           5.4350e+01, 5.4430e+01, 5.4440e+01, 5.4440e+01, 5.4490e+01,\n",
            "           5.4490e+01, 5.4455e+01, 5.4410e+01, 5.4410e+01, 5.4400e+01,\n",
            "           5.4394e+01, 5.4385e+01, 5.4370e+01, 5.4310e+01],\n",
            "          [5.4400e+01, 5.4440e+01, 5.4390e+01, 5.4433e+01, 5.4380e+01,\n",
            "           5.4390e+01, 5.4440e+01, 5.4470e+01, 5.4445e+01, 5.4400e+01,\n",
            "           5.4395e+01, 5.4470e+01, 5.4458e+01, 5.4500e+01, 5.4515e+01,\n",
            "           5.4500e+01, 5.4470e+01, 5.4440e+01, 5.4440e+01, 5.4430e+01,\n",
            "           5.4430e+01, 5.4385e+01, 5.4530e+01, 5.4360e+01],\n",
            "          [4.1859e+04, 3.3028e+05, 1.0060e+04, 2.9432e+04, 1.3449e+05,\n",
            "           2.9545e+04, 3.4302e+04, 2.5904e+04, 9.7100e+03, 9.2880e+03,\n",
            "           1.6337e+04, 1.3357e+04, 1.8699e+04, 1.4455e+04, 2.2366e+04,\n",
            "           6.7571e+04, 3.3443e+04, 3.0958e+04, 2.3914e+04, 2.0007e+04,\n",
            "           1.5530e+04, 1.2139e+04, 4.2853e+04, 1.9324e+05]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4938, 2.4843, 0.1894]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1104, 0.8081, 0.0814]], device='cuda:0')\n",
            "[tensor([[[[5.4350e+01, 5.4350e+01, 5.4320e+01, 5.4330e+01, 5.4300e+01,\n",
            "           5.4290e+01, 5.4330e+01, 5.4335e+01, 5.4370e+01, 5.4420e+01,\n",
            "           5.4420e+01, 5.4410e+01, 5.4410e+01, 5.4440e+01, 5.4410e+01,\n",
            "           5.4430e+01, 5.4445e+01, 5.4485e+01, 5.4520e+01, 5.4510e+01,\n",
            "           5.4510e+01, 5.4520e+01, 5.4520e+01, 5.4520e+01],\n",
            "          [5.4405e+01, 5.4353e+01, 5.4340e+01, 5.4330e+01, 5.4330e+01,\n",
            "           5.4345e+01, 5.4340e+01, 5.4380e+01, 5.4434e+01, 5.4450e+01,\n",
            "           5.4430e+01, 5.4425e+01, 5.4460e+01, 5.4440e+01, 5.4450e+01,\n",
            "           5.4475e+01, 5.4490e+01, 5.4540e+01, 5.4540e+01, 5.4510e+01,\n",
            "           5.4510e+01, 5.4520e+01, 5.4520e+01, 5.4520e+01],\n",
            "          [5.4330e+01, 5.4290e+01, 5.4301e+01, 5.4300e+01, 5.4280e+01,\n",
            "           5.4290e+01, 5.4320e+01, 5.4333e+01, 5.4360e+01, 5.4400e+01,\n",
            "           5.4400e+01, 5.4410e+01, 5.4410e+01, 5.4400e+01, 5.4390e+01,\n",
            "           5.4430e+01, 5.4430e+01, 5.4475e+01, 5.4490e+01, 5.4510e+01,\n",
            "           5.4510e+01, 5.4520e+01, 5.4520e+01, 5.4520e+01],\n",
            "          [5.4370e+01, 5.4330e+01, 5.4330e+01, 5.4300e+01, 5.4280e+01,\n",
            "           5.4340e+01, 5.4330e+01, 5.4373e+01, 5.4430e+01, 5.4425e+01,\n",
            "           5.4411e+01, 5.4410e+01, 5.4440e+01, 5.4400e+01, 5.4430e+01,\n",
            "           5.4435e+01, 5.4490e+01, 5.4520e+01, 5.4490e+01, 5.4510e+01,\n",
            "           5.4510e+01, 5.4520e+01, 5.4520e+01, 5.4520e+01],\n",
            "          [3.8730e+04, 5.0912e+04, 3.9355e+04, 1.0737e+05, 1.6328e+04,\n",
            "           8.4150e+03, 1.2886e+04, 2.1887e+04, 2.4431e+04, 3.1933e+04,\n",
            "           3.0846e+04, 1.3874e+04, 1.7108e+04, 8.3445e+04, 6.8807e+04,\n",
            "           1.7853e+05, 7.7844e+04, 2.8602e+05, 2.8471e+04, 4.5000e+02,\n",
            "           0.0000e+00, 1.8600e+02, 0.0000e+00, 0.0000e+00]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4931, 2.4833, 0.1889]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1104, 0.8081, 0.0815]], device='cuda:0')\n",
            "[tensor([[[[5.5080e+01, 5.5080e+01, 5.5020e+01, 5.4970e+01, 5.4900e+01,\n",
            "           5.4890e+01, 5.4980e+01, 5.4970e+01, 5.4970e+01, 5.4890e+01,\n",
            "           5.4900e+01, 5.4780e+01, 5.4830e+01, 5.4760e+01, 5.4730e+01,\n",
            "           5.4700e+01, 5.4620e+01, 5.4830e+01, 5.4800e+01, 5.4960e+01,\n",
            "           5.4810e+01, 5.4830e+01, 5.4830e+01, 5.4920e+01],\n",
            "          [5.5080e+01, 5.5080e+01, 5.5020e+01, 5.4970e+01, 5.4900e+01,\n",
            "           5.4900e+01, 5.4980e+01, 5.4970e+01, 5.4970e+01, 5.4890e+01,\n",
            "           5.4900e+01, 5.4780e+01, 5.4850e+01, 5.4790e+01, 5.4839e+01,\n",
            "           5.4740e+01, 5.4870e+01, 5.4900e+01, 5.4960e+01, 5.4980e+01,\n",
            "           5.4900e+01, 5.4880e+01, 5.4970e+01, 5.5005e+01],\n",
            "          [5.5080e+01, 5.5080e+01, 5.5020e+01, 5.4900e+01, 5.4850e+01,\n",
            "           5.4860e+01, 5.4980e+01, 5.4840e+01, 5.4840e+01, 5.4890e+01,\n",
            "           5.4830e+01, 5.4780e+01, 5.4620e+01, 5.4640e+01, 5.4715e+01,\n",
            "           5.4590e+01, 5.4620e+01, 5.4800e+01, 5.4780e+01, 5.4820e+01,\n",
            "           5.4810e+01, 5.4780e+01, 5.4810e+01, 5.4910e+01],\n",
            "          [5.5080e+01, 5.5080e+01, 5.5020e+01, 5.4900e+01, 5.4880e+01,\n",
            "           5.4860e+01, 5.4980e+01, 5.4840e+01, 5.4840e+01, 5.4890e+01,\n",
            "           5.4830e+01, 5.4780e+01, 5.4730e+01, 5.4720e+01, 5.4720e+01,\n",
            "           5.4620e+01, 5.4860e+01, 5.4800e+01, 5.4960e+01, 5.4840e+01,\n",
            "           5.4840e+01, 5.4820e+01, 5.4925e+01, 5.4960e+01],\n",
            "          [1.0000e+03, 0.0000e+00, 1.4400e+03, 2.8400e+02, 2.3380e+03,\n",
            "           1.4070e+03, 2.2400e+03, 1.5390e+03, 0.0000e+00, 1.0000e+02,\n",
            "           7.0600e+02, 1.0100e+02, 6.4501e+04, 3.5132e+04, 2.9196e+04,\n",
            "           5.0724e+04, 3.6765e+04, 2.4439e+04, 3.4813e+04, 4.3744e+04,\n",
            "           1.7459e+04, 1.0182e+05, 5.6790e+04, 5.6354e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4978, 2.5061, 0.1926]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1088, 0.8109, 0.0802]], device='cuda:0')\n",
            "[tensor([[[[5.4970e+01, 5.5070e+01, 5.4920e+01, 5.4800e+01, 5.4720e+01,\n",
            "           5.4710e+01, 5.4700e+01, 5.4670e+01, 5.4760e+01, 5.4680e+01,\n",
            "           5.4615e+01, 5.4750e+01, 5.4760e+01, 5.4770e+01, 5.4740e+01,\n",
            "           5.4650e+01, 5.4710e+01, 5.4790e+01, 5.4760e+01, 5.4819e+01,\n",
            "           5.4710e+01, 5.4755e+01, 5.4750e+01, 5.4800e+01],\n",
            "          [5.5140e+01, 5.5080e+01, 5.4920e+01, 5.4800e+01, 5.4790e+01,\n",
            "           5.4740e+01, 5.4710e+01, 5.4790e+01, 5.4790e+01, 5.4680e+01,\n",
            "           5.4750e+01, 5.4750e+01, 5.4790e+01, 5.4810e+01, 5.4760e+01,\n",
            "           5.4730e+01, 5.4800e+01, 5.4820e+01, 5.4820e+01, 5.4819e+01,\n",
            "           5.4770e+01, 5.4810e+01, 5.4820e+01, 5.4800e+01],\n",
            "          [5.4940e+01, 5.4900e+01, 5.4770e+01, 5.4710e+01, 5.4680e+01,\n",
            "           5.4640e+01, 5.4630e+01, 5.4550e+01, 5.4690e+01, 5.4540e+01,\n",
            "           5.4610e+01, 5.4695e+01, 5.4690e+01, 5.4740e+01, 5.4615e+01,\n",
            "           5.4630e+01, 5.4690e+01, 5.4755e+01, 5.4760e+01, 5.4700e+01,\n",
            "           5.4680e+01, 5.4750e+01, 5.4750e+01, 5.4730e+01],\n",
            "          [5.5080e+01, 5.4920e+01, 5.4810e+01, 5.4710e+01, 5.4720e+01,\n",
            "           5.4704e+01, 5.4680e+01, 5.4770e+01, 5.4691e+01, 5.4620e+01,\n",
            "           5.4750e+01, 5.4750e+01, 5.4790e+01, 5.4760e+01, 5.4650e+01,\n",
            "           5.4710e+01, 5.4790e+01, 5.4760e+01, 5.4820e+01, 5.4700e+01,\n",
            "           5.4750e+01, 5.4810e+01, 5.4800e+01, 5.4730e+01],\n",
            "          [6.5680e+04, 2.0687e+04, 3.8782e+04, 4.2551e+04, 2.3484e+04,\n",
            "           3.1120e+04, 3.7447e+04, 6.3668e+04, 2.5078e+04, 3.1523e+04,\n",
            "           2.7463e+04, 1.5192e+04, 2.8153e+04, 2.8013e+04, 1.7722e+04,\n",
            "           2.4378e+04, 2.8730e+04, 1.2123e+04, 9.5490e+03, 1.6835e+04,\n",
            "           1.7033e+04, 1.7780e+04, 1.0997e+04, 2.2468e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4973, 2.5013, 0.1931]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1092, 0.8102, 0.0806]], device='cuda:0')\n",
            "[tensor([[[[5.4735e+01, 5.4570e+01, 5.4640e+01, 5.4660e+01, 5.4670e+01,\n",
            "           5.4700e+01, 5.4650e+01, 5.4600e+01, 5.4595e+01, 5.4630e+01,\n",
            "           5.4630e+01, 5.4650e+01, 5.4660e+01, 5.4670e+01, 5.4630e+01,\n",
            "           5.4660e+01, 5.4640e+01, 5.4640e+01, 5.4675e+01, 5.4690e+01,\n",
            "           5.4680e+01, 5.4720e+01, 5.4800e+01, 5.4830e+01],\n",
            "          [5.4735e+01, 5.4675e+01, 5.4680e+01, 5.4680e+01, 5.4710e+01,\n",
            "           5.4720e+01, 5.4655e+01, 5.4605e+01, 5.4640e+01, 5.4650e+01,\n",
            "           5.4640e+01, 5.4690e+01, 5.4670e+01, 5.4700e+01, 5.4670e+01,\n",
            "           5.4665e+01, 5.4650e+01, 5.4677e+01, 5.4705e+01, 5.4730e+01,\n",
            "           5.4730e+01, 5.4800e+01, 5.4820e+01, 5.4830e+01],\n",
            "          [5.4560e+01, 5.4570e+01, 5.4610e+01, 5.4600e+01, 5.4670e+01,\n",
            "           5.4660e+01, 5.4590e+01, 5.4555e+01, 5.4580e+01, 5.4590e+01,\n",
            "           5.4610e+01, 5.4640e+01, 5.4640e+01, 5.4640e+01, 5.4600e+01,\n",
            "           5.4630e+01, 5.4630e+01, 5.4630e+01, 5.4640e+01, 5.4655e+01,\n",
            "           5.4670e+01, 5.4720e+01, 5.4770e+01, 5.4610e+01],\n",
            "          [5.4580e+01, 5.4630e+01, 5.4670e+01, 5.4650e+01, 5.4710e+01,\n",
            "           5.4660e+01, 5.4610e+01, 5.4600e+01, 5.4630e+01, 5.4610e+01,\n",
            "           5.4640e+01, 5.4660e+01, 5.4670e+01, 5.4640e+01, 5.4655e+01,\n",
            "           5.4635e+01, 5.4635e+01, 5.4670e+01, 5.4680e+01, 5.4670e+01,\n",
            "           5.4720e+01, 5.4800e+01, 5.4820e+01, 5.4700e+01],\n",
            "          [7.2086e+04, 1.9265e+04, 2.6505e+04, 1.5789e+04, 1.3682e+04,\n",
            "           8.1860e+03, 2.1853e+04, 1.2164e+04, 1.8635e+04, 1.6746e+04,\n",
            "           6.4570e+03, 7.5900e+03, 7.9690e+03, 1.3167e+05, 9.8570e+03,\n",
            "           3.9450e+03, 1.4210e+04, 1.3013e+04, 3.3933e+04, 1.1310e+04,\n",
            "           1.2265e+04, 3.5932e+04, 1.6462e+04, 8.3348e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4958, 2.4940, 0.1901]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1097, 0.8094, 0.0808]], device='cuda:0')\n",
            "[tensor([[[[5.4700e+01, 5.4710e+01, 5.4630e+01, 5.4622e+01, 5.4600e+01,\n",
            "           5.4630e+01, 5.4630e+01, 5.4670e+01, 5.4690e+01, 5.4660e+01,\n",
            "           5.4690e+01, 5.4685e+01, 5.4700e+01, 5.4700e+01, 5.4710e+01,\n",
            "           5.4735e+01, 5.4750e+01, 5.4690e+01, 5.4670e+01, 5.4670e+01,\n",
            "           5.4670e+01, 5.4670e+01, 5.4720e+01, 5.4720e+01],\n",
            "          [5.4750e+01, 5.4710e+01, 5.4640e+01, 5.4622e+01, 5.4630e+01,\n",
            "           5.4645e+01, 5.4690e+01, 5.4695e+01, 5.4695e+01, 5.4690e+01,\n",
            "           5.4700e+01, 5.4700e+01, 5.4745e+01, 5.4730e+01, 5.4740e+01,\n",
            "           5.4760e+01, 5.4750e+01, 5.4700e+01, 5.4670e+01, 5.4670e+01,\n",
            "           5.4670e+01, 5.4670e+01, 5.4720e+01, 5.4720e+01],\n",
            "          [5.4660e+01, 5.4610e+01, 5.4610e+01, 5.4590e+01, 5.4590e+01,\n",
            "           5.4630e+01, 5.4630e+01, 5.4670e+01, 5.4660e+01, 5.4660e+01,\n",
            "           5.4680e+01, 5.4680e+01, 5.4690e+01, 5.4700e+01, 5.4710e+01,\n",
            "           5.4730e+01, 5.4680e+01, 5.4645e+01, 5.4650e+01, 5.4650e+01,\n",
            "           5.4650e+01, 5.4650e+01, 5.4720e+01, 5.4720e+01],\n",
            "          [5.4720e+01, 5.4640e+01, 5.4620e+01, 5.4600e+01, 5.4620e+01,\n",
            "           5.4630e+01, 5.4680e+01, 5.4690e+01, 5.4660e+01, 5.4690e+01,\n",
            "           5.4695e+01, 5.4695e+01, 5.4700e+01, 5.4716e+01, 5.4735e+01,\n",
            "           5.4760e+01, 5.4685e+01, 5.4660e+01, 5.4670e+01, 5.4670e+01,\n",
            "           5.4670e+01, 5.4670e+01, 5.4720e+01, 5.4720e+01],\n",
            "          [4.4717e+04, 5.4113e+04, 7.5170e+03, 1.4802e+04, 1.6741e+04,\n",
            "           1.2971e+04, 3.0580e+04, 4.5290e+03, 1.9648e+04, 5.0420e+03,\n",
            "           9.3480e+03, 2.5248e+04, 2.5290e+04, 6.5690e+03, 1.2541e+04,\n",
            "           1.6982e+05, 7.1866e+04, 1.7146e+05, 3.0822e+05, 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00, 1.0000e+02, 0.0000e+00]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4957, 2.4938, 0.1911]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1097, 0.8093, 0.0809]], device='cuda:0')\n",
            "[tensor([[[[5.4440e+01, 5.4440e+01, 5.4520e+01, 5.4520e+01, 5.4440e+01,\n",
            "           5.4510e+01, 5.4510e+01, 5.4510e+01, 5.4530e+01, 5.4530e+01,\n",
            "           5.4420e+01, 5.4420e+01, 5.4480e+01, 5.4520e+01, 5.4540e+01,\n",
            "           5.4490e+01, 5.4460e+01, 5.4540e+01, 5.4620e+01, 5.4590e+01,\n",
            "           5.4670e+01, 5.4590e+01, 5.4630e+01, 5.4790e+01],\n",
            "          [5.4440e+01, 5.4440e+01, 5.4520e+01, 5.4520e+01, 5.4440e+01,\n",
            "           5.4510e+01, 5.4510e+01, 5.4510e+01, 5.4530e+01, 5.4530e+01,\n",
            "           5.4470e+01, 5.4470e+01, 5.4570e+01, 5.4600e+01, 5.4570e+01,\n",
            "           5.4520e+01, 5.4580e+01, 5.4630e+01, 5.4620e+01, 5.4670e+01,\n",
            "           5.4670e+01, 5.4640e+01, 5.4800e+01, 5.4850e+01],\n",
            "          [5.4440e+01, 5.4440e+01, 5.4520e+01, 5.4520e+01, 5.4440e+01,\n",
            "           5.4510e+01, 5.4510e+01, 5.4510e+01, 5.4530e+01, 5.4530e+01,\n",
            "           5.4420e+01, 5.4420e+01, 5.4460e+01, 5.4500e+01, 5.4460e+01,\n",
            "           5.4405e+01, 5.4440e+01, 5.4540e+01, 5.4580e+01, 5.4570e+01,\n",
            "           5.4520e+01, 5.4480e+01, 5.4620e+01, 5.4730e+01],\n",
            "          [5.4440e+01, 5.4440e+01, 5.4520e+01, 5.4520e+01, 5.4440e+01,\n",
            "           5.4510e+01, 5.4510e+01, 5.4510e+01, 5.4530e+01, 5.4530e+01,\n",
            "           5.4470e+01, 5.4470e+01, 5.4530e+01, 5.4530e+01, 5.4490e+01,\n",
            "           5.4480e+01, 5.4550e+01, 5.4610e+01, 5.4600e+01, 5.4650e+01,\n",
            "           5.4580e+01, 5.4630e+01, 5.4795e+01, 5.4730e+01],\n",
            "          [3.6000e+02, 0.0000e+00, 6.0000e+02, 0.0000e+00, 5.2500e+02,\n",
            "           1.0200e+02, 0.0000e+00, 0.0000e+00, 1.8700e+02, 0.0000e+00,\n",
            "           7.8300e+02, 0.0000e+00, 6.0781e+04, 3.5363e+04, 1.0766e+05,\n",
            "           5.3452e+04, 3.5688e+04, 3.4024e+04, 1.1897e+04, 3.2921e+04,\n",
            "           3.8818e+04, 1.0966e+05, 4.2639e+04, 2.9910e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4939, 2.4907, 0.1880]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1099, 0.8092, 0.0809]], device='cuda:0')\n",
            "[tensor([[[[5.4770e+01, 5.5220e+01, 5.5230e+01, 5.5451e+01, 5.5610e+01,\n",
            "           5.5550e+01, 5.5460e+01, 5.5445e+01, 5.5290e+01, 5.5010e+01,\n",
            "           5.4995e+01, 5.4870e+01, 5.4489e+01, 5.4420e+01, 5.4410e+01,\n",
            "           5.4541e+01, 5.4560e+01, 5.4500e+01, 5.4550e+01, 5.4470e+01,\n",
            "           5.4500e+01, 5.4470e+01, 5.4470e+01, 5.4490e+01],\n",
            "          [5.5220e+01, 5.5290e+01, 5.5485e+01, 5.5670e+01, 5.5610e+01,\n",
            "           5.5600e+01, 5.5470e+01, 5.5480e+01, 5.5330e+01, 5.5070e+01,\n",
            "           5.4995e+01, 5.4910e+01, 5.4620e+01, 5.4550e+01, 5.4580e+01,\n",
            "           5.4650e+01, 5.4600e+01, 5.4570e+01, 5.4565e+01, 5.4530e+01,\n",
            "           5.4550e+01, 5.4485e+01, 5.4550e+01, 5.4560e+01],\n",
            "          [5.4770e+01, 5.5090e+01, 5.5230e+01, 5.5451e+01, 5.5450e+01,\n",
            "           5.5350e+01, 5.5290e+01, 5.5280e+01, 5.4970e+01, 5.4920e+01,\n",
            "           5.4810e+01, 5.4430e+01, 5.4410e+01, 5.4360e+01, 5.4400e+01,\n",
            "           5.4540e+01, 5.4490e+01, 5.4486e+01, 5.4430e+01, 5.4450e+01,\n",
            "           5.4465e+01, 5.4430e+01, 5.4470e+01, 5.4460e+01],\n",
            "          [5.5210e+01, 5.5244e+01, 5.5485e+01, 5.5610e+01, 5.5540e+01,\n",
            "           5.5460e+01, 5.5430e+01, 5.5280e+01, 5.5010e+01, 5.4970e+01,\n",
            "           5.4900e+01, 5.4490e+01, 5.4420e+01, 5.4430e+01, 5.4530e+01,\n",
            "           5.4560e+01, 5.4510e+01, 5.4530e+01, 5.4470e+01, 5.4515e+01,\n",
            "           5.4480e+01, 5.4465e+01, 5.4490e+01, 5.4560e+01],\n",
            "          [9.8881e+04, 1.6106e+05, 9.6955e+04, 1.1529e+05, 9.3214e+04,\n",
            "           8.7677e+04, 7.7330e+04, 5.0758e+04, 1.2176e+05, 5.9471e+04,\n",
            "           7.7941e+04, 1.6483e+05, 1.5132e+05, 1.2170e+05, 1.2103e+05,\n",
            "           7.3989e+04, 2.5009e+04, 4.5388e+04, 5.5466e+04, 4.3571e+04,\n",
            "           1.2483e+05, 2.8725e+04, 3.7407e+04, 1.4183e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5003, 2.4990, 0.2041]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1096, 0.8089, 0.0815]], device='cuda:0')\n",
            "[tensor([[[[5.4550e+01, 5.4620e+01, 5.4820e+01, 5.4870e+01, 5.4850e+01,\n",
            "           5.4860e+01, 5.4930e+01, 5.4920e+01, 5.4930e+01, 5.4930e+01,\n",
            "           5.5040e+01, 5.5035e+01, 5.5025e+01, 5.5020e+01, 5.5030e+01,\n",
            "           5.5140e+01, 5.5140e+01, 5.5070e+01, 5.5060e+01, 5.5030e+01,\n",
            "           5.5025e+01, 5.5060e+01, 5.5060e+01, 5.4990e+01],\n",
            "          [5.4630e+01, 5.4850e+01, 5.4880e+01, 5.4890e+01, 5.4850e+01,\n",
            "           5.4930e+01, 5.4980e+01, 5.4950e+01, 5.4970e+01, 5.5040e+01,\n",
            "           5.5040e+01, 5.5060e+01, 5.5035e+01, 5.5050e+01, 5.5135e+01,\n",
            "           5.5215e+01, 5.5140e+01, 5.5070e+01, 5.5080e+01, 5.5070e+01,\n",
            "           5.5110e+01, 5.5090e+01, 5.5060e+01, 5.5150e+01],\n",
            "          [5.4521e+01, 5.4620e+01, 5.4790e+01, 5.4830e+01, 5.4810e+01,\n",
            "           5.4860e+01, 5.4880e+01, 5.4880e+01, 5.4900e+01, 5.4930e+01,\n",
            "           5.4990e+01, 5.4980e+01, 5.4980e+01, 5.5000e+01, 5.5030e+01,\n",
            "           5.5130e+01, 5.5060e+01, 5.5000e+01, 5.5010e+01, 5.5000e+01,\n",
            "           5.4980e+01, 5.5040e+01, 5.4930e+01, 5.4970e+01],\n",
            "          [5.4620e+01, 5.4800e+01, 5.4870e+01, 5.4840e+01, 5.4850e+01,\n",
            "           5.4930e+01, 5.4920e+01, 5.4940e+01, 5.4935e+01, 5.5035e+01,\n",
            "           5.5035e+01, 5.5020e+01, 5.5010e+01, 5.5020e+01, 5.5135e+01,\n",
            "           5.5140e+01, 5.5080e+01, 5.5050e+01, 5.5030e+01, 5.5030e+01,\n",
            "           5.5055e+01, 5.5075e+01, 5.4980e+01, 5.5130e+01],\n",
            "          [1.6485e+04, 7.5711e+04, 1.5999e+04, 2.1376e+04, 9.4140e+03,\n",
            "           1.4461e+04, 4.1924e+04, 2.2346e+04, 1.2968e+04, 4.3548e+04,\n",
            "           5.1533e+04, 3.0932e+04, 3.9738e+04, 4.3630e+04, 1.7368e+04,\n",
            "           1.9838e+04, 1.2186e+04, 1.3834e+04, 2.2745e+04, 2.6003e+04,\n",
            "           3.0923e+04, 1.2678e+04, 4.6807e+04, 6.5361e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4968, 2.5106, 0.1907]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1084, 0.8118, 0.0798]], device='cuda:0')\n",
            "[tensor([[[[5.5130e+01, 5.4990e+01, 5.5020e+01, 5.5065e+01, 5.5040e+01,\n",
            "           5.5030e+01, 5.5030e+01, 5.5070e+01, 5.5075e+01, 5.5050e+01,\n",
            "           5.5050e+01, 5.5050e+01, 5.5025e+01, 5.5060e+01, 5.5060e+01,\n",
            "           5.5095e+01, 5.5070e+01, 5.5080e+01, 5.5080e+01, 5.5070e+01,\n",
            "           5.5070e+01, 5.5090e+01, 5.5091e+01, 5.5110e+01],\n",
            "          [5.5130e+01, 5.5020e+01, 5.5080e+01, 5.5075e+01, 5.5060e+01,\n",
            "           5.5050e+01, 5.5080e+01, 5.5070e+01, 5.5080e+01, 5.5060e+01,\n",
            "           5.5060e+01, 5.5050e+01, 5.5070e+01, 5.5065e+01, 5.5090e+01,\n",
            "           5.5095e+01, 5.5100e+01, 5.5090e+01, 5.5090e+01, 5.5080e+01,\n",
            "           5.5080e+01, 5.5090e+01, 5.5091e+01, 5.5110e+01],\n",
            "          [5.4990e+01, 5.4970e+01, 5.5010e+01, 5.5035e+01, 5.5020e+01,\n",
            "           5.5030e+01, 5.5030e+01, 5.5050e+01, 5.5030e+01, 5.5045e+01,\n",
            "           5.5030e+01, 5.5025e+01, 5.5025e+01, 5.5030e+01, 5.5055e+01,\n",
            "           5.5050e+01, 5.5060e+01, 5.5060e+01, 5.5080e+01, 5.5070e+01,\n",
            "           5.5070e+01, 5.5080e+01, 5.5070e+01, 5.5100e+01],\n",
            "          [5.4990e+01, 5.5020e+01, 5.5070e+01, 5.5040e+01, 5.5030e+01,\n",
            "           5.5035e+01, 5.5070e+01, 5.5070e+01, 5.5040e+01, 5.5055e+01,\n",
            "           5.5055e+01, 5.5025e+01, 5.5065e+01, 5.5055e+01, 5.5090e+01,\n",
            "           5.5065e+01, 5.5075e+01, 5.5080e+01, 5.5090e+01, 5.5080e+01,\n",
            "           5.5080e+01, 5.5090e+01, 5.5090e+01, 5.5100e+01],\n",
            "          [2.3869e+04, 1.4868e+04, 1.3649e+04, 5.9110e+03, 5.3650e+03,\n",
            "           1.2862e+04, 1.0208e+04, 5.9410e+03, 1.1757e+04, 7.4580e+03,\n",
            "           1.1247e+04, 1.2358e+04, 2.1420e+04, 4.9699e+04, 9.9981e+04,\n",
            "           7.4540e+04, 5.2763e+04, 9.4285e+04, 2.8528e+04, 3.5590e+03,\n",
            "           0.0000e+00, 2.1730e+03, 1.6900e+03, 3.1800e+02]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4988, 2.5108, 0.1924]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1085, 0.8116, 0.0799]], device='cuda:0')\n",
            "[tensor([[[[5.4950e+01, 5.5070e+01, 5.5040e+01, 5.4980e+01, 5.4980e+01,\n",
            "           5.4990e+01, 5.4900e+01, 5.5220e+01, 5.5190e+01, 5.5310e+01,\n",
            "           5.5300e+01, 5.5250e+01, 5.5320e+01, 5.5440e+01, 5.5350e+01,\n",
            "           5.5330e+01, 5.5455e+01, 5.5410e+01, 5.5485e+01, 5.5490e+01,\n",
            "           5.5510e+01, 5.5520e+01, 5.5620e+01, 5.5590e+01],\n",
            "          [5.5090e+01, 5.5070e+01, 5.5050e+01, 5.4980e+01, 5.4980e+01,\n",
            "           5.4990e+01, 5.5150e+01, 5.5220e+01, 5.5290e+01, 5.5350e+01,\n",
            "           5.5300e+01, 5.5250e+01, 5.5450e+01, 5.5450e+01, 5.5385e+01,\n",
            "           5.5450e+01, 5.5455e+01, 5.5504e+01, 5.5555e+01, 5.5553e+01,\n",
            "           5.5610e+01, 5.5635e+01, 5.5730e+01, 5.5650e+01],\n",
            "          [5.4950e+01, 5.5070e+01, 5.5000e+01, 5.4980e+01, 5.4980e+01,\n",
            "           5.4990e+01, 5.4900e+01, 5.5220e+01, 5.5190e+01, 5.5300e+01,\n",
            "           5.5300e+01, 5.5250e+01, 5.5300e+01, 5.5350e+01, 5.5301e+01,\n",
            "           5.5310e+01, 5.5390e+01, 5.5410e+01, 5.5460e+01, 5.5440e+01,\n",
            "           5.5510e+01, 5.5520e+01, 5.5600e+01, 5.5580e+01],\n",
            "          [5.5010e+01, 5.5070e+01, 5.5000e+01, 5.4980e+01, 5.4980e+01,\n",
            "           5.4990e+01, 5.5110e+01, 5.5220e+01, 5.5290e+01, 5.5300e+01,\n",
            "           5.5300e+01, 5.5250e+01, 5.5440e+01, 5.5350e+01, 5.5360e+01,\n",
            "           5.5424e+01, 5.5400e+01, 5.5485e+01, 5.5484e+01, 5.5520e+01,\n",
            "           5.5530e+01, 5.5620e+01, 5.5600e+01, 5.5627e+01],\n",
            "          [2.2700e+03, 3.0000e+02, 1.4000e+03, 2.0000e+02, 1.1550e+03,\n",
            "           2.8450e+03, 9.9600e+02, 1.0080e+04, 1.8800e+03, 4.1530e+03,\n",
            "           7.6000e+02, 5.7500e+02, 6.1927e+04, 3.6563e+04, 4.2123e+04,\n",
            "           3.6683e+04, 3.0468e+04, 4.0309e+04, 4.9053e+04, 2.4964e+04,\n",
            "           4.6013e+04, 5.3394e+04, 1.1073e+05, 4.3948e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4994, 2.5288, 0.1884]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1070, 0.8145, 0.0784]], device='cuda:0')\n",
            "[tensor([[[[5.5660e+01, 5.5630e+01, 5.5660e+01, 5.5600e+01, 5.5460e+01,\n",
            "           5.5357e+01, 5.5390e+01, 5.5345e+01, 5.5320e+01, 5.5380e+01,\n",
            "           5.5201e+01, 5.5214e+01, 5.5180e+01, 5.5280e+01, 5.5330e+01,\n",
            "           5.5257e+01, 5.5310e+01, 5.5370e+01, 5.5410e+01, 5.5380e+01,\n",
            "           5.5420e+01, 5.5350e+01, 5.5320e+01, 5.5390e+01],\n",
            "          [5.5660e+01, 5.5685e+01, 5.5695e+01, 5.5620e+01, 5.5460e+01,\n",
            "           5.5410e+01, 5.5390e+01, 5.5350e+01, 5.5410e+01, 5.5384e+01,\n",
            "           5.5230e+01, 5.5280e+01, 5.5285e+01, 5.5360e+01, 5.5330e+01,\n",
            "           5.5330e+01, 5.5390e+01, 5.5420e+01, 5.5428e+01, 5.5450e+01,\n",
            "           5.5425e+01, 5.5360e+01, 5.5390e+01, 5.5390e+01],\n",
            "          [5.5590e+01, 5.5610e+01, 5.5580e+01, 5.5460e+01, 5.5280e+01,\n",
            "           5.5280e+01, 5.5310e+01, 5.5280e+01, 5.5320e+01, 5.5130e+01,\n",
            "           5.5140e+01, 5.5090e+01, 5.5150e+01, 5.5260e+01, 5.5205e+01,\n",
            "           5.5240e+01, 5.5310e+01, 5.5360e+01, 5.5360e+01, 5.5380e+01,\n",
            "           5.5350e+01, 5.5300e+01, 5.5320e+01, 5.5325e+01],\n",
            "          [5.5620e+01, 5.5665e+01, 5.5580e+01, 5.5460e+01, 5.5350e+01,\n",
            "           5.5400e+01, 5.5340e+01, 5.5320e+01, 5.5390e+01, 5.5190e+01,\n",
            "           5.5210e+01, 5.5180e+01, 5.5270e+01, 5.5320e+01, 5.5250e+01,\n",
            "           5.5301e+01, 5.5370e+01, 5.5396e+01, 5.5380e+01, 5.5420e+01,\n",
            "           5.5350e+01, 5.5310e+01, 5.5382e+01, 5.5345e+01],\n",
            "          [3.8767e+04, 2.3648e+04, 2.1365e+04, 5.4974e+04, 5.7817e+04,\n",
            "           5.9269e+04, 2.7042e+04, 2.2737e+04, 2.0432e+04, 4.8882e+04,\n",
            "           5.3250e+04, 6.2056e+04, 7.7637e+04, 2.7537e+04, 3.1424e+04,\n",
            "           1.5982e+04, 2.6179e+04, 3.4082e+04, 1.0910e+04, 7.5170e+03,\n",
            "           1.4200e+04, 1.6214e+04, 1.6193e+04, 1.4414e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5022, 2.5291, 0.1960]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1072, 0.8138, 0.0789]], device='cuda:0')\n",
            "[tensor([[[[5.5355e+01, 5.5340e+01, 5.5370e+01, 5.5340e+01, 5.5320e+01,\n",
            "           5.5335e+01, 5.5385e+01, 5.5320e+01, 5.5345e+01, 5.5340e+01,\n",
            "           5.5390e+01, 5.5420e+01, 5.5450e+01, 5.5480e+01, 5.5465e+01,\n",
            "           5.5460e+01, 5.5440e+01, 5.5330e+01, 5.5370e+01, 5.5280e+01,\n",
            "           5.5250e+01, 5.5330e+01, 5.5330e+01, 5.5380e+01],\n",
            "          [5.5380e+01, 5.5365e+01, 5.5370e+01, 5.5360e+01, 5.5342e+01,\n",
            "           5.5382e+01, 5.5390e+01, 5.5360e+01, 5.5370e+01, 5.5365e+01,\n",
            "           5.5410e+01, 5.5460e+01, 5.5490e+01, 5.5480e+01, 5.5490e+01,\n",
            "           5.5480e+01, 5.5440e+01, 5.5360e+01, 5.5370e+01, 5.5280e+01,\n",
            "           5.5330e+01, 5.5360e+01, 5.5365e+01, 5.5510e+01],\n",
            "          [5.5340e+01, 5.5330e+01, 5.5330e+01, 5.5320e+01, 5.5305e+01,\n",
            "           5.5335e+01, 5.5310e+01, 5.5305e+01, 5.5340e+01, 5.5335e+01,\n",
            "           5.5380e+01, 5.5390e+01, 5.5425e+01, 5.5440e+01, 5.5445e+01,\n",
            "           5.5440e+01, 5.5350e+01, 5.5280e+01, 5.5260e+01, 5.5190e+01,\n",
            "           5.5235e+01, 5.5310e+01, 5.5305e+01, 5.5310e+01],\n",
            "          [5.5345e+01, 5.5360e+01, 5.5330e+01, 5.5325e+01, 5.5330e+01,\n",
            "           5.5382e+01, 5.5310e+01, 5.5345e+01, 5.5340e+01, 5.5360e+01,\n",
            "           5.5410e+01, 5.5450e+01, 5.5480e+01, 5.5454e+01, 5.5470e+01,\n",
            "           5.5440e+01, 5.5350e+01, 5.5360e+01, 5.5265e+01, 5.5260e+01,\n",
            "           5.5320e+01, 5.5335e+01, 5.5365e+01, 5.5320e+01],\n",
            "          [1.6848e+04, 2.0907e+04, 1.7773e+04, 1.9098e+04, 1.1653e+04,\n",
            "           4.5060e+03, 1.7728e+04, 2.4902e+04, 1.4378e+04, 1.3806e+04,\n",
            "           3.4444e+04, 2.4484e+04, 2.2113e+04, 1.1543e+04, 1.0300e+04,\n",
            "           1.0212e+04, 2.2088e+04, 3.1059e+04, 4.2458e+04, 2.5438e+04,\n",
            "           2.5763e+04, 2.6092e+04, 1.2650e+04, 8.6046e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5011, 2.5259, 0.1927]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1074, 0.8137, 0.0789]], device='cuda:0')\n",
            "[tensor([[[[5.5325e+01, 5.5230e+01, 5.5210e+01, 5.5240e+01, 5.5230e+01,\n",
            "           5.5180e+01, 5.5200e+01, 5.5160e+01, 5.5150e+01, 5.5155e+01,\n",
            "           5.5160e+01, 5.5130e+01, 5.5120e+01, 5.5150e+01, 5.5155e+01,\n",
            "           5.5110e+01, 5.5090e+01, 5.5110e+01, 5.5100e+01, 5.5080e+01,\n",
            "           5.5080e+01, 5.5070e+01, 5.5070e+01, 5.5070e+01],\n",
            "          [5.5325e+01, 5.5240e+01, 5.5240e+01, 5.5255e+01, 5.5240e+01,\n",
            "           5.5210e+01, 5.5210e+01, 5.5167e+01, 5.5160e+01, 5.5169e+01,\n",
            "           5.5200e+01, 5.5140e+01, 5.5155e+01, 5.5170e+01, 5.5169e+01,\n",
            "           5.5125e+01, 5.5125e+01, 5.5110e+01, 5.5130e+01, 5.5100e+01,\n",
            "           5.5100e+01, 5.5070e+01, 5.5070e+01, 5.5070e+01],\n",
            "          [5.5194e+01, 5.5200e+01, 5.5210e+01, 5.5230e+01, 5.5150e+01,\n",
            "           5.5170e+01, 5.5170e+01, 5.5130e+01, 5.5130e+01, 5.5130e+01,\n",
            "           5.5130e+01, 5.5095e+01, 5.5110e+01, 5.5130e+01, 5.5110e+01,\n",
            "           5.5080e+01, 5.5060e+01, 5.5030e+01, 5.5080e+01, 5.5080e+01,\n",
            "           5.5080e+01, 5.5060e+01, 5.5060e+01, 5.5060e+01],\n",
            "          [5.5230e+01, 5.5200e+01, 5.5240e+01, 5.5235e+01, 5.5170e+01,\n",
            "           5.5209e+01, 5.5170e+01, 5.5149e+01, 5.5160e+01, 5.5155e+01,\n",
            "           5.5130e+01, 5.5120e+01, 5.5155e+01, 5.5155e+01, 5.5120e+01,\n",
            "           5.5090e+01, 5.5115e+01, 5.5080e+01, 5.5100e+01, 5.5100e+01,\n",
            "           5.5100e+01, 5.5060e+01, 5.5060e+01, 5.5060e+01],\n",
            "          [3.7002e+04, 1.5014e+04, 2.2550e+04, 1.2605e+04, 1.3385e+04,\n",
            "           1.3779e+04, 1.3189e+04, 2.5432e+04, 2.3853e+04, 3.0795e+04,\n",
            "           1.9446e+05, 4.5366e+04, 1.7451e+04, 2.9387e+04, 4.1818e+04,\n",
            "           5.2025e+04, 7.7724e+04, 4.2899e+05, 5.9582e+05, 6.3400e+02,\n",
            "           0.0000e+00, 1.3210e+03, 0.0000e+00, 0.0000e+00]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5001, 2.5135, 0.1948]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1084, 0.8117, 0.0799]], device='cuda:0')\n",
            "[tensor([[[[5.4500e+01, 5.4500e+01, 5.4430e+01, 5.4430e+01, 5.4460e+01,\n",
            "           5.4460e+01, 5.4450e+01, 5.4730e+01, 5.4680e+01, 5.4850e+01,\n",
            "           5.4880e+01, 5.4920e+01, 5.4890e+01, 5.5010e+01, 5.4860e+01,\n",
            "           5.4780e+01, 5.4770e+01, 5.4930e+01, 5.4880e+01, 5.4820e+01,\n",
            "           5.4970e+01, 5.4910e+01, 5.5000e+01, 5.4840e+01],\n",
            "          [5.4500e+01, 5.4560e+01, 5.4480e+01, 5.4480e+01, 5.4500e+01,\n",
            "           5.4500e+01, 5.4720e+01, 5.4730e+01, 5.4800e+01, 5.4910e+01,\n",
            "           5.4900e+01, 5.4920e+01, 5.5010e+01, 5.5040e+01, 5.4891e+01,\n",
            "           5.4840e+01, 5.4950e+01, 5.4930e+01, 5.4910e+01, 5.5010e+01,\n",
            "           5.5000e+01, 5.5010e+01, 5.5000e+01, 5.4840e+01],\n",
            "          [5.4500e+01, 5.4490e+01, 5.4430e+01, 5.4430e+01, 5.4460e+01,\n",
            "           5.4460e+01, 5.4400e+01, 5.4650e+01, 5.4660e+01, 5.4840e+01,\n",
            "           5.4880e+01, 5.4890e+01, 5.4880e+01, 5.4800e+01, 5.4750e+01,\n",
            "           5.4760e+01, 5.4760e+01, 5.4830e+01, 5.4810e+01, 5.4820e+01,\n",
            "           5.4880e+01, 5.4890e+01, 5.4875e+01, 5.4730e+01],\n",
            "          [5.4500e+01, 5.4490e+01, 5.4480e+01, 5.4480e+01, 5.4500e+01,\n",
            "           5.4500e+01, 5.4720e+01, 5.4650e+01, 5.4800e+01, 5.4880e+01,\n",
            "           5.4900e+01, 5.4890e+01, 5.5010e+01, 5.4900e+01, 5.4760e+01,\n",
            "           5.4780e+01, 5.4930e+01, 5.4910e+01, 5.4810e+01, 5.4970e+01,\n",
            "           5.4910e+01, 5.5000e+01, 5.4875e+01, 5.4760e+01],\n",
            "          [2.0300e+02, 4.9890e+03, 2.0000e+02, 0.0000e+00, 9.3300e+02,\n",
            "           0.0000e+00, 3.8100e+03, 2.1530e+03, 1.7180e+03, 1.4410e+03,\n",
            "           2.3340e+03, 1.4900e+03, 6.5329e+04, 7.3076e+04, 6.2899e+04,\n",
            "           4.4270e+04, 9.4807e+04, 7.5608e+04, 3.5031e+04, 4.7434e+04,\n",
            "           2.5944e+04, 5.7395e+04, 1.0787e+04, 2.8950e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4952, 2.5010, 0.1882]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1091, 0.8107, 0.0802]], device='cuda:0')\n",
            "[tensor([[[[   54.7450,    54.8300,    54.8000,    54.8700,    54.8500,\n",
            "              54.8700,    54.9500,    54.8800,    54.8700,    54.9500,\n",
            "              55.0700,    55.1300,    54.9800,    54.8200,    54.6200,\n",
            "              54.5799,    54.5700,    54.5250,    54.5300,    54.5698,\n",
            "              54.4700,    54.4900,    54.4500,    54.4200],\n",
            "          [   54.8300,    54.8300,    54.8800,    54.8800,    54.9100,\n",
            "              54.9550,    54.9600,    54.9100,    54.9600,    55.0800,\n",
            "              55.1300,    55.1700,    54.9900,    54.8495,    54.6900,\n",
            "              54.6100,    54.5900,    54.6100,    54.5700,    54.5800,\n",
            "              54.5200,    54.4900,    54.4600,    54.4600],\n",
            "          [   54.7300,    54.7500,    54.7500,    54.8200,    54.8400,\n",
            "              54.8650,    54.8400,    54.8700,    54.8700,    54.9500,\n",
            "              55.0700,    54.9850,    54.8000,    54.6100,    54.5462,\n",
            "              54.5409,    54.4500,    54.5000,    54.4700,    54.4800,\n",
            "              54.4100,    54.4000,    54.4200,    54.4100],\n",
            "          [   54.8300,    54.8100,    54.8800,    54.8300,    54.8800,\n",
            "              54.9250,    54.8700,    54.9000,    54.9500,    55.0750,\n",
            "              55.1300,    54.9850,    54.8000,    54.6500,    54.5700,\n",
            "              54.5985,    54.5100,    54.5300,    54.5600,    54.4800,\n",
            "              54.4900,    54.4350,    54.4200,    54.4200],\n",
            "          [25911.0000, 14840.0000, 30968.0000, 13952.0000, 19470.0000,\n",
            "           21542.0000, 18965.0000, 26318.0000, 18517.0000, 44406.0000,\n",
            "           17592.0000, 40848.0000, 49118.0000, 31835.0000, 24691.0000,\n",
            "           18487.0000, 17998.0000, 37635.0000, 26641.0000, 11728.0000,\n",
            "           14374.0000, 11350.0000, 11772.0000,  9437.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4962, 2.4915, 0.1956]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1100, 0.8086, 0.0814]], device='cuda:0')\n",
            "[tensor([[[[5.4420e+01, 5.4380e+01, 5.4495e+01, 5.4440e+01, 5.4340e+01,\n",
            "           5.4361e+01, 5.4470e+01, 5.4400e+01, 5.4380e+01, 5.4390e+01,\n",
            "           5.4350e+01, 5.4290e+01, 5.4320e+01, 5.4270e+01, 5.4230e+01,\n",
            "           5.4260e+01, 5.4230e+01, 5.4190e+01, 5.4220e+01, 5.4240e+01,\n",
            "           5.4120e+01, 5.4170e+01, 5.4140e+01, 5.4120e+01],\n",
            "          [5.4420e+01, 5.4494e+01, 5.4495e+01, 5.4440e+01, 5.4390e+01,\n",
            "           5.4460e+01, 5.4470e+01, 5.4423e+01, 5.4400e+01, 5.4400e+01,\n",
            "           5.4360e+01, 5.4320e+01, 5.4320e+01, 5.4290e+01, 5.4290e+01,\n",
            "           5.4260e+01, 5.4260e+01, 5.4250e+01, 5.4310e+01, 5.4240e+01,\n",
            "           5.4190e+01, 5.4180e+01, 5.4180e+01, 5.4260e+01],\n",
            "          [5.4360e+01, 5.4375e+01, 5.4420e+01, 5.4312e+01, 5.4340e+01,\n",
            "           5.4320e+01, 5.4390e+01, 5.4364e+01, 5.4350e+01, 5.4320e+01,\n",
            "           5.4190e+01, 5.4260e+01, 5.4210e+01, 5.4235e+01, 5.4200e+01,\n",
            "           5.4190e+01, 5.4170e+01, 5.4170e+01, 5.4120e+01, 5.4120e+01,\n",
            "           5.4050e+01, 5.4070e+01, 5.4100e+01, 5.4040e+01],\n",
            "          [5.4370e+01, 5.4490e+01, 5.4430e+01, 5.4350e+01, 5.4390e+01,\n",
            "           5.4460e+01, 5.4410e+01, 5.4390e+01, 5.4395e+01, 5.4400e+01,\n",
            "           5.4270e+01, 5.4320e+01, 5.4280e+01, 5.4235e+01, 5.4260e+01,\n",
            "           5.4230e+01, 5.4192e+01, 5.4250e+01, 5.4240e+01, 5.4120e+01,\n",
            "           5.4160e+01, 5.4140e+01, 5.4130e+01, 5.4180e+01],\n",
            "          [1.8700e+04, 1.9394e+04, 6.9070e+03, 2.0780e+04, 7.9060e+03,\n",
            "           1.4534e+04, 1.2779e+04, 1.6130e+04, 2.0053e+04, 1.5000e+04,\n",
            "           4.4416e+04, 1.6141e+04, 1.5930e+04, 1.2616e+04, 2.6087e+04,\n",
            "           1.6746e+04, 2.3385e+04, 3.3460e+04, 5.0431e+04, 1.4203e+04,\n",
            "           4.2815e+04, 2.9738e+04, 3.0308e+04, 9.9655e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4933, 2.4758, 0.1925]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1111, 0.8067, 0.0822]], device='cuda:0')\n",
            "[tensor([[[[5.4180e+01, 5.4200e+01, 5.4254e+01, 5.4250e+01, 5.4275e+01,\n",
            "           5.4232e+01, 5.4305e+01, 5.4360e+01, 5.4310e+01, 5.4310e+01,\n",
            "           5.4385e+01, 5.4385e+01, 5.4355e+01, 5.4365e+01, 5.4415e+01,\n",
            "           5.4420e+01, 5.4390e+01, 5.4365e+01, 5.4360e+01, 5.4360e+01,\n",
            "           5.4350e+01, 5.4350e+01, 5.4350e+01, 5.4350e+01],\n",
            "          [5.4240e+01, 5.4270e+01, 5.4270e+01, 5.4275e+01, 5.4290e+01,\n",
            "           5.4300e+01, 5.4380e+01, 5.4370e+01, 5.4340e+01, 5.4380e+01,\n",
            "           5.4390e+01, 5.4390e+01, 5.4375e+01, 5.4410e+01, 5.4450e+01,\n",
            "           5.4420e+01, 5.4390e+01, 5.4400e+01, 5.4400e+01, 5.4400e+01,\n",
            "           5.4350e+01, 5.4350e+01, 5.4350e+01, 5.4350e+01],\n",
            "          [5.4160e+01, 5.4187e+01, 5.4230e+01, 5.4230e+01, 5.4230e+01,\n",
            "           5.4210e+01, 5.4297e+01, 5.4300e+01, 5.4310e+01, 5.4310e+01,\n",
            "           5.4365e+01, 5.4360e+01, 5.4330e+01, 5.4365e+01, 5.4415e+01,\n",
            "           5.4390e+01, 5.4330e+01, 5.4335e+01, 5.4360e+01, 5.4360e+01,\n",
            "           5.4350e+01, 5.4350e+01, 5.4350e+01, 5.4350e+01],\n",
            "          [5.4210e+01, 5.4255e+01, 5.4255e+01, 5.4272e+01, 5.4230e+01,\n",
            "           5.4300e+01, 5.4370e+01, 5.4305e+01, 5.4310e+01, 5.4380e+01,\n",
            "           5.4390e+01, 5.4360e+01, 5.4365e+01, 5.4410e+01, 5.4420e+01,\n",
            "           5.4396e+01, 5.4365e+01, 5.4350e+01, 5.4400e+01, 5.4400e+01,\n",
            "           5.4350e+01, 5.4350e+01, 5.4350e+01, 5.4350e+01],\n",
            "          [3.9805e+04, 2.9885e+04, 2.3482e+04, 8.6850e+03, 8.6580e+03,\n",
            "           1.7705e+04, 2.5220e+04, 2.0098e+04, 1.1845e+04, 2.4022e+04,\n",
            "           4.7940e+03, 1.1503e+04, 2.9995e+04, 4.4156e+04, 2.5453e+04,\n",
            "           6.1766e+04, 9.7568e+04, 1.2584e+05, 3.4594e+04, 0.0000e+00,\n",
            "           8.0000e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4925, 2.4776, 0.1899]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1109, 0.8072, 0.0819]], device='cuda:0')\n",
            "[tensor([[[[54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4927, 2.4766, 0.1901]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1110, 0.8070, 0.0820]], device='cuda:0')\n",
            "[tensor([[[[54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4927, 2.4766, 0.1901]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1110, 0.8070, 0.0820]], device='cuda:0')\n",
            "[tensor([[[[54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4927, 2.4766, 0.1901]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1110, 0.8070, 0.0820]], device='cuda:0')\n",
            "[tensor([[[[54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4927, 2.4766, 0.1901]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1110, 0.8070, 0.0820]], device='cuda:0')\n",
            "[tensor([[[[54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4927, 2.4766, 0.1901]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1110, 0.8070, 0.0820]], device='cuda:0')\n",
            "[tensor([[[[54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4927, 2.4766, 0.1901]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1110, 0.8070, 0.0820]], device='cuda:0')\n",
            "[tensor([[[[54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4927, 2.4766, 0.1901]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1110, 0.8070, 0.0820]], device='cuda:0')\n",
            "[tensor([[[[54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500, 54.3500,\n",
            "           54.3500, 54.3500, 54.3500],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4927, 2.4766, 0.1901]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1110, 0.8070, 0.0820]], device='cuda:0')\n",
            "[tensor([[[[5.4040e+01, 5.4100e+01, 5.3970e+01, 5.3900e+01, 5.3890e+01,\n",
            "           5.3820e+01, 5.3810e+01, 5.3830e+01, 5.3990e+01, 5.3710e+01,\n",
            "           5.3710e+01, 5.3940e+01, 5.3970e+01, 5.4400e+01, 5.4320e+01,\n",
            "           5.4440e+01, 5.4110e+01, 5.4210e+01, 5.4350e+01, 5.4320e+01,\n",
            "           5.4250e+01, 5.4360e+01, 5.4350e+01, 5.4520e+01],\n",
            "          [5.4040e+01, 5.4100e+01, 5.3970e+01, 5.3910e+01, 5.3890e+01,\n",
            "           5.3880e+01, 5.3890e+01, 5.3990e+01, 5.3990e+01, 5.3780e+01,\n",
            "           5.3750e+01, 5.3980e+01, 5.4400e+01, 5.4440e+01, 5.4430e+01,\n",
            "           5.4440e+01, 5.4280e+01, 5.4370e+01, 5.4440e+01, 5.4360e+01,\n",
            "           5.4380e+01, 5.4360e+01, 5.4560e+01, 5.4590e+01],\n",
            "          [5.3950e+01, 5.3930e+01, 5.3900e+01, 5.3810e+01, 5.3830e+01,\n",
            "           5.3790e+01, 5.3770e+01, 5.3830e+01, 5.3650e+01, 5.3620e+01,\n",
            "           5.3710e+01, 5.3940e+01, 5.3940e+01, 5.4290e+01, 5.4290e+01,\n",
            "           5.4080e+01, 5.4060e+01, 5.4180e+01, 5.4290e+01, 5.4180e+01,\n",
            "           5.4250e+01, 5.4280e+01, 5.4330e+01, 5.4480e+01],\n",
            "          [5.3990e+01, 5.3930e+01, 5.3900e+01, 5.3900e+01, 5.3830e+01,\n",
            "           5.3880e+01, 5.3890e+01, 5.3880e+01, 5.3800e+01, 5.3620e+01,\n",
            "           5.3750e+01, 5.3980e+01, 5.4390e+01, 5.4300e+01, 5.4430e+01,\n",
            "           5.4120e+01, 5.4235e+01, 5.4325e+01, 5.4320e+01, 5.4230e+01,\n",
            "           5.4360e+01, 5.4350e+01, 5.4500e+01, 5.4540e+01],\n",
            "          [3.0390e+03, 1.8980e+03, 2.3000e+03, 1.0899e+04, 1.3050e+03,\n",
            "           6.0740e+03, 9.0970e+03, 8.7400e+02, 2.2410e+03, 7.0000e+02,\n",
            "           6.0000e+02, 1.1000e+03, 2.5205e+05, 2.0279e+05, 1.5128e+05,\n",
            "           1.0587e+05, 1.1542e+05, 1.1242e+05, 6.2382e+04, 5.3473e+04,\n",
            "           5.7155e+04, 5.3509e+04, 1.1787e+05, 7.0216e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4911, 2.4782, 0.1837]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1108, 0.8078, 0.0814]], device='cuda:0')\n",
            "[tensor([[[[5.4550e+01, 5.4590e+01, 5.4650e+01, 5.4620e+01, 5.4640e+01,\n",
            "           5.4550e+01, 5.4630e+01, 5.4630e+01, 5.4685e+01, 5.4800e+01,\n",
            "           5.4810e+01, 5.4780e+01, 5.4810e+01, 5.4760e+01, 5.4737e+01,\n",
            "           5.4808e+01, 5.4920e+01, 5.4900e+01, 5.4930e+01, 5.5060e+01,\n",
            "           5.5000e+01, 5.4960e+01, 5.4980e+01, 5.5050e+01],\n",
            "          [5.4590e+01, 5.4667e+01, 5.4670e+01, 5.4626e+01, 5.4660e+01,\n",
            "           5.4720e+01, 5.4650e+01, 5.4740e+01, 5.4820e+01, 5.4860e+01,\n",
            "           5.4850e+01, 5.4810e+01, 5.4810e+01, 5.4820e+01, 5.4820e+01,\n",
            "           5.4960e+01, 5.4970e+01, 5.4970e+01, 5.5060e+01, 5.5120e+01,\n",
            "           5.5000e+01, 5.4990e+01, 5.5040e+01, 5.5160e+01],\n",
            "          [5.4500e+01, 5.4590e+01, 5.4590e+01, 5.4545e+01, 5.4510e+01,\n",
            "           5.4531e+01, 5.4500e+01, 5.4628e+01, 5.4680e+01, 5.4780e+01,\n",
            "           5.4760e+01, 5.4700e+01, 5.4710e+01, 5.4710e+01, 5.4737e+01,\n",
            "           5.4808e+01, 5.4830e+01, 5.4900e+01, 5.4925e+01, 5.4980e+01,\n",
            "           5.4900e+01, 5.4960e+01, 5.4965e+01, 5.5045e+01],\n",
            "          [5.4585e+01, 5.4650e+01, 5.4630e+01, 5.4626e+01, 5.4550e+01,\n",
            "           5.4630e+01, 5.4640e+01, 5.4680e+01, 5.4790e+01, 5.4810e+01,\n",
            "           5.4770e+01, 5.4800e+01, 5.4750e+01, 5.4730e+01, 5.4780e+01,\n",
            "           5.4930e+01, 5.4880e+01, 5.4940e+01, 5.5050e+01, 5.4980e+01,\n",
            "           5.4940e+01, 5.4980e+01, 5.5040e+01, 5.5130e+01],\n",
            "          [6.3953e+04, 8.1283e+04, 1.0538e+05, 4.5505e+04, 1.1007e+05,\n",
            "           6.6000e+04, 6.0974e+04, 4.8120e+04, 1.4400e+05, 5.1764e+04,\n",
            "           8.9769e+04, 5.2266e+04, 4.2141e+04, 6.3932e+04, 2.1881e+04,\n",
            "           5.8977e+04, 1.8612e+04, 1.5877e+04, 4.6018e+04, 8.6275e+04,\n",
            "           1.4733e+04, 6.0905e+04, 3.1236e+04, 5.7991e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.4957, 2.5055, 0.1876]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1087, 0.8114, 0.0799]], device='cuda:0')\n",
            "[tensor([[[[5.5130e+01, 5.5120e+01, 5.5081e+01, 5.5130e+01, 5.5110e+01,\n",
            "           5.5120e+01, 5.5090e+01, 5.5020e+01, 5.4990e+01, 5.4960e+01,\n",
            "           5.4945e+01, 5.4800e+01, 5.4870e+01, 5.4840e+01, 5.4844e+01,\n",
            "           5.4860e+01, 5.4860e+01, 5.4740e+01, 5.4740e+01, 5.4740e+01,\n",
            "           5.4850e+01, 5.4810e+01, 5.4850e+01, 5.4990e+01],\n",
            "          [5.5140e+01, 5.5125e+01, 5.5133e+01, 5.5130e+01, 5.5120e+01,\n",
            "           5.5120e+01, 5.5100e+01, 5.5040e+01, 5.5040e+01, 5.4970e+01,\n",
            "           5.4955e+01, 5.4900e+01, 5.4890e+01, 5.4860e+01, 5.4850e+01,\n",
            "           5.4899e+01, 5.4860e+01, 5.4780e+01, 5.4780e+01, 5.4890e+01,\n",
            "           5.4860e+01, 5.4890e+01, 5.4990e+01, 5.5030e+01],\n",
            "          [5.5090e+01, 5.5040e+01, 5.5058e+01, 5.5090e+01, 5.5070e+01,\n",
            "           5.5030e+01, 5.5020e+01, 5.4940e+01, 5.4965e+01, 5.4920e+01,\n",
            "           5.4820e+01, 5.4770e+01, 5.4790e+01, 5.4810e+01, 5.4780e+01,\n",
            "           5.4850e+01, 5.4760e+01, 5.4740e+01, 5.4710e+01, 5.4710e+01,\n",
            "           5.4790e+01, 5.4780e+01, 5.4830e+01, 5.4890e+01],\n",
            "          [5.5120e+01, 5.5080e+01, 5.5133e+01, 5.5110e+01, 5.5110e+01,\n",
            "           5.5070e+01, 5.5030e+01, 5.4995e+01, 5.4970e+01, 5.4940e+01,\n",
            "           5.4820e+01, 5.4880e+01, 5.4850e+01, 5.4854e+01, 5.4845e+01,\n",
            "           5.4870e+01, 5.4760e+01, 5.4770e+01, 5.4740e+01, 5.4860e+01,\n",
            "           5.4820e+01, 5.4850e+01, 5.4990e+01, 5.4890e+01],\n",
            "          [3.6247e+04, 1.6692e+04, 2.3788e+04, 3.0020e+04, 1.7817e+04,\n",
            "           1.4973e+04, 1.6182e+04, 2.9742e+04, 1.8491e+04, 2.1891e+04,\n",
            "           6.5737e+04, 4.7785e+04, 2.1128e+04, 2.8686e+04, 1.8611e+04,\n",
            "           1.3861e+04, 1.1836e+04, 9.8500e+03, 1.0907e+04, 3.4014e+04,\n",
            "           7.2348e+04, 8.2245e+04, 8.1108e+04, 1.8464e+05]]]]), tensor([2])]\n",
            "Logits: tensor([[0.4987, 2.5035, 0.1939]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1092, 0.8104, 0.0805]], device='cuda:0')\n",
            "[tensor([[[[5.4890e+01, 5.4940e+01, 5.4900e+01, 5.4960e+01, 5.4940e+01,\n",
            "           5.4920e+01, 5.4955e+01, 5.4950e+01, 5.4960e+01, 5.4925e+01,\n",
            "           5.4890e+01, 5.4890e+01, 5.4880e+01, 5.4910e+01, 5.4870e+01,\n",
            "           5.4875e+01, 5.4890e+01, 5.4900e+01, 5.4830e+01, 5.4910e+01,\n",
            "           5.4890e+01, 5.4900e+01, 5.4890e+01, 5.4890e+01],\n",
            "          [5.4940e+01, 5.4960e+01, 5.4970e+01, 5.4970e+01, 5.4940e+01,\n",
            "           5.4960e+01, 5.4960e+01, 5.4960e+01, 5.4970e+01, 5.4950e+01,\n",
            "           5.4910e+01, 5.4910e+01, 5.4915e+01, 5.4910e+01, 5.4875e+01,\n",
            "           5.4905e+01, 5.4905e+01, 5.4905e+01, 5.4890e+01, 5.4910e+01,\n",
            "           5.4900e+01, 5.4900e+01, 5.4890e+01, 5.4890e+01],\n",
            "          [5.4880e+01, 5.4845e+01, 5.4890e+01, 5.4930e+01, 5.4915e+01,\n",
            "           5.4920e+01, 5.4940e+01, 5.4930e+01, 5.4925e+01, 5.4860e+01,\n",
            "           5.4860e+01, 5.4865e+01, 5.4880e+01, 5.4860e+01, 5.4850e+01,\n",
            "           5.4870e+01, 5.4870e+01, 5.4840e+01, 5.4830e+01, 5.4910e+01,\n",
            "           5.4890e+01, 5.4900e+01, 5.4890e+01, 5.4890e+01],\n",
            "          [5.4935e+01, 5.4900e+01, 5.4965e+01, 5.4940e+01, 5.4930e+01,\n",
            "           5.4950e+01, 5.4950e+01, 5.4950e+01, 5.4925e+01, 5.4880e+01,\n",
            "           5.4885e+01, 5.4875e+01, 5.4915e+01, 5.4870e+01, 5.4870e+01,\n",
            "           5.4895e+01, 5.4900e+01, 5.4860e+01, 5.4890e+01, 5.4910e+01,\n",
            "           5.4900e+01, 5.4900e+01, 5.4890e+01, 5.4890e+01],\n",
            "          [6.7335e+04, 9.5628e+04, 9.5545e+04, 1.0671e+05, 9.8260e+03,\n",
            "           1.2008e+04, 2.1773e+04, 1.1723e+04, 1.8218e+04, 9.2122e+04,\n",
            "           1.2180e+04, 2.0058e+04, 5.9221e+04, 2.5184e+04, 2.3507e+04,\n",
            "           7.3289e+04, 8.6947e+04, 2.0612e+05, 7.2255e+05, 1.3000e+02,\n",
            "           8.2500e+02, 1.2000e+02, 3.1200e+02, 0.0000e+00]]]]), tensor([1])]\n",
            "Logits: tensor([[0.4975, 2.5030, 0.1929]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1091, 0.8105, 0.0804]], device='cuda:0')\n",
            "[tensor([[[[5.5500e+01, 5.5500e+01, 5.5450e+01, 5.5450e+01, 5.5550e+01,\n",
            "           5.5570e+01, 5.5500e+01, 5.5260e+01, 5.5160e+01, 5.5320e+01,\n",
            "           5.5250e+01, 5.5220e+01, 5.5310e+01, 5.5470e+01, 5.5560e+01,\n",
            "           5.5505e+01, 5.5830e+01, 5.5970e+01, 5.5880e+01, 5.5790e+01,\n",
            "           5.5780e+01, 5.5800e+01, 5.5780e+01, 5.5820e+01],\n",
            "          [5.5500e+01, 5.5500e+01, 5.5450e+01, 5.5450e+01, 5.5610e+01,\n",
            "           5.5570e+01, 5.5500e+01, 5.5270e+01, 5.5270e+01, 5.5320e+01,\n",
            "           5.5250e+01, 5.5300e+01, 5.5540e+01, 5.5590e+01, 5.5600e+01,\n",
            "           5.5820e+01, 5.6020e+01, 5.6050e+01, 5.5920e+01, 5.5840e+01,\n",
            "           5.5865e+01, 5.5860e+01, 5.5850e+01, 5.5860e+01],\n",
            "          [5.5490e+01, 5.5490e+01, 5.5450e+01, 5.5450e+01, 5.5550e+01,\n",
            "           5.5490e+01, 5.5210e+01, 5.5210e+01, 5.5160e+01, 5.5290e+01,\n",
            "           5.5250e+01, 5.5220e+01, 5.5250e+01, 5.5430e+01, 5.5500e+01,\n",
            "           5.5505e+01, 5.5804e+01, 5.5870e+01, 5.5770e+01, 5.5680e+01,\n",
            "           5.5760e+01, 5.5710e+01, 5.5740e+01, 5.5755e+01],\n",
            "          [5.5490e+01, 5.5490e+01, 5.5450e+01, 5.5450e+01, 5.5580e+01,\n",
            "           5.5490e+01, 5.5250e+01, 5.5210e+01, 5.5260e+01, 5.5290e+01,\n",
            "           5.5250e+01, 5.5270e+01, 5.5480e+01, 5.5560e+01, 5.5500e+01,\n",
            "           5.5810e+01, 5.5970e+01, 5.5880e+01, 5.5785e+01, 5.5795e+01,\n",
            "           5.5795e+01, 5.5770e+01, 5.5830e+01, 5.5770e+01],\n",
            "          [4.4000e+02, 0.0000e+00, 7.2000e+02, 4.8490e+03, 2.7470e+03,\n",
            "           1.3450e+03, 7.2930e+03, 5.2100e+02, 4.1920e+03, 1.4750e+03,\n",
            "           8.0000e+02, 1.3161e+04, 1.1090e+05, 5.7971e+04, 1.0666e+05,\n",
            "           1.9872e+05, 2.3624e+05, 1.2989e+05, 6.9490e+04, 1.2058e+05,\n",
            "           4.4841e+04, 4.8060e+04, 5.9473e+04, 5.7150e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5036, 2.5462, 0.1914]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1059, 0.8166, 0.0775]], device='cuda:0')\n",
            "[tensor([[[[5.5780e+01, 5.5710e+01, 5.5750e+01, 5.5740e+01, 5.5800e+01,\n",
            "           5.5810e+01, 5.5715e+01, 5.5380e+01, 5.5520e+01, 5.5630e+01,\n",
            "           5.5520e+01, 5.5380e+01, 5.5430e+01, 5.5470e+01, 5.5550e+01,\n",
            "           5.5600e+01, 5.5650e+01, 5.5650e+01, 5.5730e+01, 5.5770e+01,\n",
            "           5.5690e+01, 5.5760e+01, 5.5770e+01, 5.5760e+01],\n",
            "          [5.5940e+01, 5.5785e+01, 5.5830e+01, 5.5850e+01, 5.5860e+01,\n",
            "           5.5820e+01, 5.5715e+01, 5.5540e+01, 5.5640e+01, 5.5670e+01,\n",
            "           5.5535e+01, 5.5460e+01, 5.5480e+01, 5.5590e+01, 5.5625e+01,\n",
            "           5.5670e+01, 5.5690e+01, 5.5760e+01, 5.5800e+01, 5.5780e+01,\n",
            "           5.5740e+01, 5.5830e+01, 5.5800e+01, 5.5810e+01],\n",
            "          [5.5700e+01, 5.5710e+01, 5.5730e+01, 5.5710e+01, 5.5800e+01,\n",
            "           5.5700e+01, 5.5295e+01, 5.5380e+01, 5.5510e+01, 5.5520e+01,\n",
            "           5.5350e+01, 5.5295e+01, 5.5380e+01, 5.5430e+01, 5.5544e+01,\n",
            "           5.5590e+01, 5.5620e+01, 5.5650e+01, 5.5720e+01, 5.5670e+01,\n",
            "           5.5670e+01, 5.5760e+01, 5.5735e+01, 5.5760e+01],\n",
            "          [5.5720e+01, 5.5760e+01, 5.5740e+01, 5.5780e+01, 5.5830e+01,\n",
            "           5.5710e+01, 5.5380e+01, 5.5530e+01, 5.5640e+01, 5.5530e+01,\n",
            "           5.5390e+01, 5.5430e+01, 5.5480e+01, 5.5558e+01, 5.5610e+01,\n",
            "           5.5635e+01, 5.5660e+01, 5.5720e+01, 5.5770e+01, 5.5690e+01,\n",
            "           5.5740e+01, 5.5780e+01, 5.5760e+01, 5.5790e+01],\n",
            "          [1.0749e+05, 5.7423e+04, 4.2934e+04, 5.9651e+04, 5.1712e+04,\n",
            "           8.0310e+04, 1.9063e+05, 1.1006e+05, 6.5026e+04, 3.5494e+04,\n",
            "           5.5409e+04, 1.2646e+05, 7.6337e+04, 8.5717e+04, 3.1874e+04,\n",
            "           2.2459e+04, 3.2519e+04, 3.4158e+04, 5.0749e+04, 7.1774e+04,\n",
            "           1.1697e+04, 3.4140e+04, 1.3014e+04, 2.1777e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5049, 2.5429, 0.1957]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1063, 0.8157, 0.0780]], device='cuda:0')\n",
            "[tensor([[[[5.5790e+01, 5.5770e+01, 5.5740e+01, 5.5702e+01, 5.5680e+01,\n",
            "           5.5700e+01, 5.5680e+01, 5.5590e+01, 5.5740e+01, 5.5710e+01,\n",
            "           5.5760e+01, 5.5750e+01, 5.5750e+01, 5.5670e+01, 5.5690e+01,\n",
            "           5.5700e+01, 5.5720e+01, 5.5710e+01, 5.5730e+01, 5.5680e+01,\n",
            "           5.5660e+01, 5.5660e+01, 5.5640e+01, 5.5650e+01],\n",
            "          [5.5805e+01, 5.5780e+01, 5.5750e+01, 5.5710e+01, 5.5700e+01,\n",
            "           5.5710e+01, 5.5680e+01, 5.5750e+01, 5.5742e+01, 5.5800e+01,\n",
            "           5.5840e+01, 5.5780e+01, 5.5750e+01, 5.5700e+01, 5.5720e+01,\n",
            "           5.5760e+01, 5.5720e+01, 5.5750e+01, 5.5770e+01, 5.5730e+01,\n",
            "           5.5710e+01, 5.5670e+01, 5.5690e+01, 5.5680e+01],\n",
            "          [5.5730e+01, 5.5700e+01, 5.5690e+01, 5.5660e+01, 5.5660e+01,\n",
            "           5.5660e+01, 5.5575e+01, 5.5580e+01, 5.5670e+01, 5.5700e+01,\n",
            "           5.5710e+01, 5.5710e+01, 5.5650e+01, 5.5630e+01, 5.5680e+01,\n",
            "           5.5700e+01, 5.5670e+01, 5.5680e+01, 5.5680e+01, 5.5660e+01,\n",
            "           5.5640e+01, 5.5610e+01, 5.5610e+01, 5.5580e+01],\n",
            "          [5.5760e+01, 5.5730e+01, 5.5690e+01, 5.5670e+01, 5.5695e+01,\n",
            "           5.5680e+01, 5.5590e+01, 5.5750e+01, 5.5700e+01, 5.5755e+01,\n",
            "           5.5750e+01, 5.5715e+01, 5.5670e+01, 5.5690e+01, 5.5700e+01,\n",
            "           5.5730e+01, 5.5710e+01, 5.5735e+01, 5.5690e+01, 5.5660e+01,\n",
            "           5.5660e+01, 5.5640e+01, 5.5620e+01, 5.5630e+01],\n",
            "          [6.2257e+04, 1.8651e+04, 1.3818e+04, 1.2935e+04, 2.3733e+04,\n",
            "           1.5286e+04, 6.5091e+04, 4.5511e+04, 1.9215e+04, 2.6123e+04,\n",
            "           2.9292e+05, 2.7345e+04, 3.7498e+04, 3.1560e+04, 3.1475e+04,\n",
            "           1.1042e+04, 1.3677e+04, 3.3288e+04, 2.5407e+04, 1.9354e+04,\n",
            "           1.6397e+04, 2.8787e+04, 3.0993e+04, 5.0913e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5037, 2.5412, 0.1956]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1063, 0.8156, 0.0781]], device='cuda:0')\n",
            "[tensor([[[[5.5640e+01, 5.5660e+01, 5.5600e+01, 5.5630e+01, 5.5610e+01,\n",
            "           5.5600e+01, 5.5590e+01, 5.5660e+01, 5.5700e+01, 5.5710e+01,\n",
            "           5.5735e+01, 5.5745e+01, 5.5695e+01, 5.5660e+01, 5.5641e+01,\n",
            "           5.5655e+01, 5.5640e+01, 5.5625e+01, 5.5590e+01, 5.5590e+01,\n",
            "           5.5590e+01, 5.5590e+01, 5.5620e+01, 5.5620e+01],\n",
            "          [5.5700e+01, 5.5660e+01, 5.5630e+01, 5.5630e+01, 5.5640e+01,\n",
            "           5.5625e+01, 5.5668e+01, 5.5715e+01, 5.5715e+01, 5.5770e+01,\n",
            "           5.5750e+01, 5.5745e+01, 5.5695e+01, 5.5680e+01, 5.5655e+01,\n",
            "           5.5660e+01, 5.5650e+01, 5.5625e+01, 5.5590e+01, 5.5590e+01,\n",
            "           5.5590e+01, 5.5590e+01, 5.5620e+01, 5.5620e+01],\n",
            "          [5.5630e+01, 5.5580e+01, 5.5590e+01, 5.5600e+01, 5.5600e+01,\n",
            "           5.5590e+01, 5.5580e+01, 5.5660e+01, 5.5690e+01, 5.5700e+01,\n",
            "           5.5710e+01, 5.5680e+01, 5.5650e+01, 5.5630e+01, 5.5614e+01,\n",
            "           5.5635e+01, 5.5620e+01, 5.5560e+01, 5.5560e+01, 5.5560e+01,\n",
            "           5.5560e+01, 5.5560e+01, 5.5620e+01, 5.5620e+01],\n",
            "          [5.5660e+01, 5.5600e+01, 5.5629e+01, 5.5610e+01, 5.5600e+01,\n",
            "           5.5595e+01, 5.5650e+01, 5.5690e+01, 5.5710e+01, 5.5735e+01,\n",
            "           5.5745e+01, 5.5690e+01, 5.5660e+01, 5.5645e+01, 5.5650e+01,\n",
            "           5.5645e+01, 5.5630e+01, 5.5580e+01, 5.5580e+01, 5.5580e+01,\n",
            "           5.5580e+01, 5.5580e+01, 5.5620e+01, 5.5620e+01],\n",
            "          [3.3645e+04, 1.9545e+04, 1.3387e+04, 8.3690e+03, 1.6232e+04,\n",
            "           1.2330e+04, 2.0214e+04, 1.5323e+04, 1.1926e+04, 3.2437e+04,\n",
            "           1.6653e+04, 2.3211e+04, 6.7519e+04, 9.0877e+04, 2.2161e+04,\n",
            "           2.9184e+04, 1.1261e+05, 3.6191e+05, 7.6019e+04, 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00, 5.3700e+02, 1.0000e+03]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5034, 2.5361, 0.1952]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1067, 0.8149, 0.0784]], device='cuda:0')\n",
            "[tensor([[[[5.6000e+01, 5.5990e+01, 5.6000e+01, 5.6100e+01, 5.6050e+01,\n",
            "           5.6130e+01, 5.6210e+01, 5.6010e+01, 5.5970e+01, 5.6040e+01,\n",
            "           5.6110e+01, 5.6110e+01, 5.6160e+01, 5.6140e+01, 5.6210e+01,\n",
            "           5.6250e+01, 5.6210e+01, 5.6200e+01, 5.6260e+01, 5.6260e+01,\n",
            "           5.6300e+01, 5.6420e+01, 5.6340e+01, 5.6380e+01],\n",
            "          [5.6000e+01, 5.5990e+01, 5.6000e+01, 5.6100e+01, 5.6100e+01,\n",
            "           5.6200e+01, 5.6210e+01, 5.6020e+01, 5.6040e+01, 5.6040e+01,\n",
            "           5.6110e+01, 5.6110e+01, 5.6220e+01, 5.6240e+01, 5.6290e+01,\n",
            "           5.6340e+01, 5.6300e+01, 5.6270e+01, 5.6320e+01, 5.6320e+01,\n",
            "           5.6430e+01, 5.6450e+01, 5.6410e+01, 5.6430e+01],\n",
            "          [5.6000e+01, 5.5990e+01, 5.6000e+01, 5.6030e+01, 5.6040e+01,\n",
            "           5.6130e+01, 5.6030e+01, 5.5940e+01, 5.5970e+01, 5.6040e+01,\n",
            "           5.6100e+01, 5.6100e+01, 5.6110e+01, 5.6100e+01, 5.6165e+01,\n",
            "           5.6180e+01, 5.6170e+01, 5.6170e+01, 5.6230e+01, 5.6210e+01,\n",
            "           5.6300e+01, 5.6330e+01, 5.6330e+01, 5.6300e+01],\n",
            "          [5.6000e+01, 5.5990e+01, 5.6000e+01, 5.6030e+01, 5.6100e+01,\n",
            "           5.6200e+01, 5.6030e+01, 5.5950e+01, 5.6040e+01, 5.6040e+01,\n",
            "           5.6100e+01, 5.6100e+01, 5.6150e+01, 5.6220e+01, 5.6250e+01,\n",
            "           5.6220e+01, 5.6220e+01, 5.6235e+01, 5.6250e+01, 5.6300e+01,\n",
            "           5.6424e+01, 5.6340e+01, 5.6380e+01, 5.6360e+01],\n",
            "          [1.5200e+02, 1.0000e+02, 1.1000e+02, 1.1363e+04, 7.0000e+02,\n",
            "           2.6930e+03, 1.4660e+03, 1.9970e+03, 2.5830e+03, 1.6300e+02,\n",
            "           1.8840e+03, 0.0000e+00, 7.6566e+04, 6.1033e+04, 1.0944e+05,\n",
            "           1.2231e+05, 4.9211e+04, 1.9039e+05, 1.1224e+05, 8.4794e+04,\n",
            "           1.0864e+05, 3.9211e+04, 4.0131e+04, 7.0100e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5071, 2.5665, 0.1937]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1045, 0.8192, 0.0764]], device='cuda:0')\n",
            "[tensor([[[[5.6350e+01, 5.6120e+01, 5.6041e+01, 5.6180e+01, 5.6400e+01,\n",
            "           5.6430e+01, 5.6330e+01, 5.6275e+01, 5.6320e+01, 5.6350e+01,\n",
            "           5.6320e+01, 5.6320e+01, 5.6350e+01, 5.6260e+01, 5.6280e+01,\n",
            "           5.6290e+01, 5.6280e+01, 5.6280e+01, 5.6340e+01, 5.6440e+01,\n",
            "           5.6380e+01, 5.6440e+01, 5.6430e+01, 5.6380e+01],\n",
            "          [5.6350e+01, 5.6230e+01, 5.6190e+01, 5.6395e+01, 5.6450e+01,\n",
            "           5.6470e+01, 5.6380e+01, 5.6370e+01, 5.6350e+01, 5.6355e+01,\n",
            "           5.6370e+01, 5.6350e+01, 5.6400e+01, 5.6300e+01, 5.6300e+01,\n",
            "           5.6320e+01, 5.6320e+01, 5.6341e+01, 5.6440e+01, 5.6440e+01,\n",
            "           5.6440e+01, 5.6440e+01, 5.6435e+01, 5.6390e+01],\n",
            "          [5.6030e+01, 5.6040e+01, 5.6020e+01, 5.6180e+01, 5.6320e+01,\n",
            "           5.6300e+01, 5.6250e+01, 5.6275e+01, 5.6310e+01, 5.6260e+01,\n",
            "           5.6255e+01, 5.6265e+01, 5.6260e+01, 5.6240e+01, 5.6200e+01,\n",
            "           5.6270e+01, 5.6270e+01, 5.6275e+01, 5.6335e+01, 5.6370e+01,\n",
            "           5.6360e+01, 5.6405e+01, 5.6380e+01, 5.6360e+01],\n",
            "          [5.6119e+01, 5.6040e+01, 5.6180e+01, 5.6395e+01, 5.6430e+01,\n",
            "           5.6330e+01, 5.6250e+01, 5.6320e+01, 5.6340e+01, 5.6320e+01,\n",
            "           5.6320e+01, 5.6350e+01, 5.6260e+01, 5.6280e+01, 5.6290e+01,\n",
            "           5.6280e+01, 5.6280e+01, 5.6340e+01, 5.6430e+01, 5.6380e+01,\n",
            "           5.6430e+01, 5.6415e+01, 5.6390e+01, 5.6380e+01],\n",
            "          [1.8520e+05, 1.3479e+05, 1.2459e+05, 8.3215e+04, 4.9924e+04,\n",
            "           6.4128e+04, 5.9944e+04, 5.4668e+04, 6.0639e+04, 8.3870e+04,\n",
            "           7.2839e+04, 5.5991e+04, 3.8555e+04, 5.4827e+04, 5.6673e+04,\n",
            "           2.1336e+04, 3.9911e+04, 2.3020e+04, 4.8904e+04, 5.1465e+04,\n",
            "           4.5742e+04, 2.7755e+04, 2.0413e+04, 1.8438e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5093, 2.5719, 0.1971]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1042, 0.8196, 0.0762]], device='cuda:0')\n",
            "[tensor([[[[5.6380e+01, 5.6370e+01, 5.6370e+01, 5.6380e+01, 5.6310e+01,\n",
            "           5.6350e+01, 5.6390e+01, 5.6430e+01, 5.6405e+01, 5.6380e+01,\n",
            "           5.6390e+01, 5.6350e+01, 5.6400e+01, 5.6390e+01, 5.6360e+01,\n",
            "           5.6360e+01, 5.6370e+01, 5.6370e+01, 5.6350e+01, 5.6264e+01,\n",
            "           5.6270e+01, 5.6240e+01, 5.6080e+01, 5.6000e+01],\n",
            "          [5.6395e+01, 5.6370e+01, 5.6395e+01, 5.6380e+01, 5.6368e+01,\n",
            "           5.6400e+01, 5.6440e+01, 5.6480e+01, 5.6410e+01, 5.6400e+01,\n",
            "           5.6395e+01, 5.6400e+01, 5.6430e+01, 5.6420e+01, 5.6370e+01,\n",
            "           5.6380e+01, 5.6380e+01, 5.6371e+01, 5.6380e+01, 5.6330e+01,\n",
            "           5.6300e+01, 5.6255e+01, 5.6080e+01, 5.6070e+01],\n",
            "          [5.6360e+01, 5.6310e+01, 5.6350e+01, 5.6290e+01, 5.6305e+01,\n",
            "           5.6350e+01, 5.6385e+01, 5.6401e+01, 5.6350e+01, 5.6360e+01,\n",
            "           5.6340e+01, 5.6350e+01, 5.6380e+01, 5.6370e+01, 5.6325e+01,\n",
            "           5.6360e+01, 5.6340e+01, 5.6330e+01, 5.6260e+01, 5.6260e+01,\n",
            "           5.6240e+01, 5.6080e+01, 5.5990e+01, 5.5955e+01],\n",
            "          [5.6365e+01, 5.6360e+01, 5.6380e+01, 5.6310e+01, 5.6365e+01,\n",
            "           5.6400e+01, 5.6430e+01, 5.6401e+01, 5.6370e+01, 5.6375e+01,\n",
            "           5.6340e+01, 5.6400e+01, 5.6380e+01, 5.6370e+01, 5.6355e+01,\n",
            "           5.6370e+01, 5.6365e+01, 5.6340e+01, 5.6270e+01, 5.6280e+01,\n",
            "           5.6240e+01, 5.6090e+01, 5.6010e+01, 5.6020e+01],\n",
            "          [2.3941e+04, 1.9641e+04, 2.1645e+04, 4.1899e+04, 2.1934e+04,\n",
            "           1.7221e+04, 3.3042e+04, 2.9426e+04, 3.5663e+04, 1.2280e+04,\n",
            "           1.7519e+04, 1.1416e+05, 3.6201e+04, 4.2453e+04, 1.9980e+04,\n",
            "           1.0221e+04, 1.1389e+04, 2.0307e+04, 4.9742e+04, 3.6922e+04,\n",
            "           8.1262e+04, 9.4265e+04, 9.8151e+04, 1.2324e+05]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5093, 2.5681, 0.1991]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1045, 0.8189, 0.0766]], device='cuda:0')\n",
            "[tensor([[[[5.6000e+01, 5.5900e+01, 5.5895e+01, 5.5839e+01, 5.5910e+01,\n",
            "           5.5870e+01, 5.5870e+01, 5.5780e+01, 5.5690e+01, 5.5700e+01,\n",
            "           5.5600e+01, 5.5631e+01, 5.5650e+01, 5.5625e+01, 5.5605e+01,\n",
            "           5.5560e+01, 5.5470e+01, 5.5495e+01, 5.5440e+01, 5.5450e+01,\n",
            "           5.5470e+01, 5.5510e+01, 5.5510e+01, 5.5510e+01],\n",
            "          [5.6037e+01, 5.5950e+01, 5.5920e+01, 5.5910e+01, 5.5940e+01,\n",
            "           5.5900e+01, 5.5870e+01, 5.5780e+01, 5.5735e+01, 5.5700e+01,\n",
            "           5.5660e+01, 5.5720e+01, 5.5659e+01, 5.5660e+01, 5.5615e+01,\n",
            "           5.5560e+01, 5.5520e+01, 5.5505e+01, 5.5470e+01, 5.5470e+01,\n",
            "           5.5490e+01, 5.5510e+01, 5.5510e+01, 5.5510e+01],\n",
            "          [5.5900e+01, 5.5880e+01, 5.5830e+01, 5.5830e+01, 5.5860e+01,\n",
            "           5.5860e+01, 5.5780e+01, 5.5675e+01, 5.5660e+01, 5.5600e+01,\n",
            "           5.5590e+01, 5.5620e+01, 5.5610e+01, 5.5600e+01, 5.5520e+01,\n",
            "           5.5475e+01, 5.5440e+01, 5.5430e+01, 5.5430e+01, 5.5450e+01,\n",
            "           5.5470e+01, 5.5510e+01, 5.5510e+01, 5.5510e+01],\n",
            "          [5.5910e+01, 5.5910e+01, 5.5840e+01, 5.5901e+01, 5.5870e+01,\n",
            "           5.5880e+01, 5.5790e+01, 5.5690e+01, 5.5700e+01, 5.5600e+01,\n",
            "           5.5630e+01, 5.5660e+01, 5.5625e+01, 5.5600e+01, 5.5570e+01,\n",
            "           5.5475e+01, 5.5490e+01, 5.5440e+01, 5.5470e+01, 5.5470e+01,\n",
            "           5.5490e+01, 5.5510e+01, 5.5510e+01, 5.5510e+01],\n",
            "          [8.7559e+04, 4.5792e+04, 4.0894e+04, 4.2797e+04, 4.7635e+04,\n",
            "           1.5154e+04, 2.0584e+04, 8.0585e+04, 1.2683e+05, 3.2529e+04,\n",
            "           3.4601e+04, 8.3011e+04, 3.6696e+04, 1.0776e+05, 7.7382e+04,\n",
            "           5.0675e+04, 9.3478e+04, 2.8719e+05, 1.5000e+03, 1.9807e+04,\n",
            "           2.5002e+04, 4.1210e+03, 0.0000e+00, 2.5800e+02]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5053, 2.5354, 0.1995]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1069, 0.8143, 0.0788]], device='cuda:0')\n",
            "[tensor([[[[5.6840e+01, 5.6850e+01, 5.6950e+01, 5.7100e+01, 5.7000e+01,\n",
            "           5.6970e+01, 5.7190e+01, 5.7280e+01, 5.7290e+01, 5.7170e+01,\n",
            "           5.7190e+01, 5.7080e+01, 5.7100e+01, 5.7150e+01, 5.7190e+01,\n",
            "           5.7200e+01, 5.7080e+01, 5.7020e+01, 5.7020e+01, 5.6780e+01,\n",
            "           5.6740e+01, 5.6760e+01, 5.6725e+01, 5.6820e+01],\n",
            "          [5.6840e+01, 5.7020e+01, 5.7130e+01, 5.7100e+01, 5.7000e+01,\n",
            "           5.7140e+01, 5.7350e+01, 5.7320e+01, 5.7330e+01, 5.7250e+01,\n",
            "           5.7230e+01, 5.7110e+01, 5.7160e+01, 5.7280e+01, 5.7310e+01,\n",
            "           5.7220e+01, 5.7125e+01, 5.7105e+01, 5.7090e+01, 5.6840e+01,\n",
            "           5.6810e+01, 5.6780e+01, 5.6820e+01, 5.6960e+01],\n",
            "          [5.6780e+01, 5.6840e+01, 5.6950e+01, 5.6950e+01, 5.6940e+01,\n",
            "           5.6970e+01, 5.7180e+01, 5.7280e+01, 5.7230e+01, 5.7140e+01,\n",
            "           5.7190e+01, 5.7050e+01, 5.6970e+01, 5.7040e+01, 5.7170e+01,\n",
            "           5.7005e+01, 5.6990e+01, 5.6960e+01, 5.6800e+01, 5.6710e+01,\n",
            "           5.6680e+01, 5.6650e+01, 5.6680e+01, 5.6810e+01],\n",
            "          [5.6820e+01, 5.7020e+01, 5.7130e+01, 5.7010e+01, 5.7000e+01,\n",
            "           5.7140e+01, 5.7290e+01, 5.7320e+01, 5.7230e+01, 5.7250e+01,\n",
            "           5.7190e+01, 5.7110e+01, 5.7120e+01, 5.7184e+01, 5.7195e+01,\n",
            "           5.7065e+01, 5.7000e+01, 5.6995e+01, 5.6810e+01, 5.6760e+01,\n",
            "           5.6750e+01, 5.6720e+01, 5.6820e+01, 5.6950e+01],\n",
            "          [9.2800e+02, 1.5979e+04, 8.4360e+03, 8.7040e+03, 1.5250e+03,\n",
            "           1.4420e+03, 7.1130e+03, 1.9110e+03, 1.5170e+03, 2.8140e+03,\n",
            "           2.2210e+03, 5.0910e+03, 1.9037e+05, 1.7615e+05, 1.6582e+05,\n",
            "           1.1036e+05, 1.3297e+05, 6.3775e+04, 1.7605e+05, 6.9897e+04,\n",
            "           8.4682e+04, 5.9087e+04, 1.0435e+05, 7.1725e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5152, 2.6037, 0.2037]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1020, 0.8233, 0.0747]], device='cuda:0')\n",
            "[tensor([[[[5.6950e+01, 5.7020e+01, 5.7060e+01, 5.6910e+01, 5.6990e+01,\n",
            "           5.6960e+01, 5.6910e+01, 5.6840e+01, 5.6940e+01, 5.7020e+01,\n",
            "           5.6980e+01, 5.7020e+01, 5.7060e+01, 5.7130e+01, 5.7080e+01,\n",
            "           5.7140e+01, 5.7210e+01, 5.7270e+01, 5.7200e+01, 5.7210e+01,\n",
            "           5.7210e+01, 5.7125e+01, 5.7140e+01, 5.7020e+01],\n",
            "          [5.7040e+01, 5.7090e+01, 5.7080e+01, 5.7020e+01, 5.6990e+01,\n",
            "           5.7030e+01, 5.6960e+01, 5.6985e+01, 5.7050e+01, 5.7090e+01,\n",
            "           5.7060e+01, 5.7120e+01, 5.7140e+01, 5.7140e+01, 5.7150e+01,\n",
            "           5.7230e+01, 5.7290e+01, 5.7270e+01, 5.7220e+01, 5.7240e+01,\n",
            "           5.7210e+01, 5.7180e+01, 5.7160e+01, 5.7100e+01],\n",
            "          [5.6950e+01, 5.7000e+01, 5.6900e+01, 5.6910e+01, 5.6900e+01,\n",
            "           5.6820e+01, 5.6790e+01, 5.6820e+01, 5.6890e+01, 5.6980e+01,\n",
            "           5.6960e+01, 5.7000e+01, 5.7020e+01, 5.7050e+01, 5.7045e+01,\n",
            "           5.7113e+01, 5.7170e+01, 5.7190e+01, 5.7140e+01, 5.7180e+01,\n",
            "           5.7120e+01, 5.7125e+01, 5.6990e+01, 5.7000e+01],\n",
            "          [5.7020e+01, 5.7040e+01, 5.6910e+01, 5.6970e+01, 5.6960e+01,\n",
            "           5.6910e+01, 5.6840e+01, 5.6930e+01, 5.7015e+01, 5.7000e+01,\n",
            "           5.7030e+01, 5.7060e+01, 5.7120e+01, 5.7090e+01, 5.7120e+01,\n",
            "           5.7200e+01, 5.7280e+01, 5.7217e+01, 5.7220e+01, 5.7205e+01,\n",
            "           5.7120e+01, 5.7140e+01, 5.7015e+01, 5.7080e+01],\n",
            "          [5.9612e+04, 4.2742e+04, 4.7829e+04, 4.0589e+04, 4.3092e+04,\n",
            "           7.1516e+04, 5.8895e+04, 5.8505e+04, 4.1226e+04, 6.4230e+04,\n",
            "           3.9055e+04, 5.6694e+04, 8.5165e+04, 5.1629e+04, 3.8900e+04,\n",
            "           4.3797e+04, 5.3330e+04, 2.1591e+04, 4.0072e+04, 2.9473e+04,\n",
            "           2.7739e+04, 3.3802e+04, 4.9626e+04, 4.1249e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5142, 2.6079, 0.1982]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1016, 0.8244, 0.0741]], device='cuda:0')\n",
            "[tensor([[[[5.7085e+01, 5.6994e+01, 5.6930e+01, 5.6910e+01, 5.6900e+01,\n",
            "           5.6800e+01, 5.6835e+01, 5.6850e+01, 5.6800e+01, 5.6750e+01,\n",
            "           5.6800e+01, 5.6770e+01, 5.6720e+01, 5.6728e+01, 5.6690e+01,\n",
            "           5.6730e+01, 5.6725e+01, 5.6740e+01, 5.6770e+01, 5.6790e+01,\n",
            "           5.6800e+01, 5.6810e+01, 5.6850e+01, 5.6860e+01],\n",
            "          [5.7110e+01, 5.7000e+01, 5.6950e+01, 5.6920e+01, 5.6920e+01,\n",
            "           5.6850e+01, 5.6860e+01, 5.6860e+01, 5.6810e+01, 5.6810e+01,\n",
            "           5.6800e+01, 5.6770e+01, 5.6755e+01, 5.6770e+01, 5.6760e+01,\n",
            "           5.6750e+01, 5.6780e+01, 5.6780e+01, 5.6850e+01, 5.6814e+01,\n",
            "           5.6850e+01, 5.6860e+01, 5.6893e+01, 5.7010e+01],\n",
            "          [5.7010e+01, 5.6900e+01, 5.6900e+01, 5.6820e+01, 5.6810e+01,\n",
            "           5.6785e+01, 5.6770e+01, 5.6755e+01, 5.6730e+01, 5.6720e+01,\n",
            "           5.6740e+01, 5.6670e+01, 5.6710e+01, 5.6700e+01, 5.6685e+01,\n",
            "           5.6680e+01, 5.6690e+01, 5.6700e+01, 5.6770e+01, 5.6690e+01,\n",
            "           5.6771e+01, 5.6790e+01, 5.6775e+01, 5.6830e+01],\n",
            "          [5.7020e+01, 5.6930e+01, 5.6900e+01, 5.6890e+01, 5.6810e+01,\n",
            "           5.6830e+01, 5.6850e+01, 5.6800e+01, 5.6765e+01, 5.6795e+01,\n",
            "           5.6765e+01, 5.6720e+01, 5.6730e+01, 5.6705e+01, 5.6740e+01,\n",
            "           5.6730e+01, 5.6740e+01, 5.6775e+01, 5.6780e+01, 5.6780e+01,\n",
            "           5.6820e+01, 5.6840e+01, 5.6858e+01, 5.6860e+01],\n",
            "          [2.7489e+04, 4.4612e+04, 2.1309e+04, 4.6151e+04, 3.2635e+04,\n",
            "           4.0362e+04, 4.8168e+04, 3.2788e+04, 1.5935e+04, 4.9476e+04,\n",
            "           2.2388e+04, 3.1593e+04, 2.9108e+04, 2.2852e+04, 1.9714e+04,\n",
            "           3.0832e+04, 1.9086e+04, 2.1619e+04, 2.6600e+04, 2.8674e+04,\n",
            "           2.8591e+04, 2.4206e+04, 4.2165e+04, 9.8124e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5137, 2.5937, 0.1991]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1027, 0.8223, 0.0750]], device='cuda:0')\n",
            "[tensor([[[[5.6870e+01, 5.6910e+01, 5.6890e+01, 5.7010e+01, 5.7010e+01,\n",
            "           5.7050e+01, 5.7030e+01, 5.7090e+01, 5.7030e+01, 5.7070e+01,\n",
            "           5.7060e+01, 5.7020e+01, 5.7000e+01, 5.6960e+01, 5.6930e+01,\n",
            "           5.6901e+01, 5.6850e+01, 5.6845e+01, 5.6890e+01, 5.6890e+01,\n",
            "           5.6860e+01, 5.6860e+01, 5.6890e+01, 5.6890e+01],\n",
            "          [5.6960e+01, 5.6945e+01, 5.7000e+01, 5.7055e+01, 5.7070e+01,\n",
            "           5.7090e+01, 5.7100e+01, 5.7090e+01, 5.7085e+01, 5.7070e+01,\n",
            "           5.7070e+01, 5.7050e+01, 5.7040e+01, 5.6970e+01, 5.6940e+01,\n",
            "           5.6905e+01, 5.6890e+01, 5.6900e+01, 5.6900e+01, 5.6900e+01,\n",
            "           5.6860e+01, 5.6860e+01, 5.6890e+01, 5.6890e+01],\n",
            "          [5.6860e+01, 5.6880e+01, 5.6880e+01, 5.7010e+01, 5.7010e+01,\n",
            "           5.7025e+01, 5.7015e+01, 5.7040e+01, 5.7030e+01, 5.7015e+01,\n",
            "           5.7020e+01, 5.6990e+01, 5.6945e+01, 5.6900e+01, 5.6880e+01,\n",
            "           5.6840e+01, 5.6820e+01, 5.6830e+01, 5.6890e+01, 5.6890e+01,\n",
            "           5.6860e+01, 5.6860e+01, 5.6890e+01, 5.6890e+01],\n",
            "          [5.6910e+01, 5.6885e+01, 5.7000e+01, 5.7010e+01, 5.7045e+01,\n",
            "           5.7025e+01, 5.7090e+01, 5.7040e+01, 5.7070e+01, 5.7045e+01,\n",
            "           5.7020e+01, 5.7000e+01, 5.6960e+01, 5.6935e+01, 5.6910e+01,\n",
            "           5.6840e+01, 5.6845e+01, 5.6900e+01, 5.6900e+01, 5.6900e+01,\n",
            "           5.6860e+01, 5.6860e+01, 5.6890e+01, 5.6890e+01],\n",
            "          [3.7787e+04, 2.0802e+04, 2.8573e+04, 1.8392e+04, 2.6022e+04,\n",
            "           2.4315e+04, 2.1580e+04, 1.3011e+04, 4.3828e+04, 4.0777e+04,\n",
            "           2.8586e+04, 6.1203e+04, 6.5959e+04, 3.2423e+04, 6.4481e+04,\n",
            "           2.0854e+05, 1.0932e+05, 3.8489e+05, 6.4773e+04, 0.0000e+00,\n",
            "           1.0000e+02, 0.0000e+00, 2.2600e+02, 0.0000e+00]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5143, 2.5948, 0.2013]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1027, 0.8223, 0.0751]], device='cuda:0')\n",
            "[tensor([[[[5.7340e+01, 5.7310e+01, 5.7360e+01, 5.7330e+01, 5.7280e+01,\n",
            "           5.7270e+01, 5.7110e+01, 5.7050e+01, 5.7000e+01, 5.6900e+01,\n",
            "           5.6920e+01, 5.6850e+01, 5.6900e+01, 5.6670e+01, 5.6730e+01,\n",
            "           5.6820e+01, 5.6850e+01, 5.7000e+01, 5.6960e+01, 5.6950e+01,\n",
            "           5.6860e+01, 5.6791e+01, 5.6760e+01, 5.6810e+01],\n",
            "          [5.7350e+01, 5.7310e+01, 5.7360e+01, 5.7330e+01, 5.7280e+01,\n",
            "           5.7270e+01, 5.7260e+01, 5.7050e+01, 5.7050e+01, 5.6930e+01,\n",
            "           5.6920e+01, 5.6880e+01, 5.7030e+01, 5.6780e+01, 5.6845e+01,\n",
            "           5.6900e+01, 5.7000e+01, 5.7040e+01, 5.6970e+01, 5.6960e+01,\n",
            "           5.6890e+01, 5.6870e+01, 5.6820e+01, 5.6900e+01],\n",
            "          [5.7340e+01, 5.7310e+01, 5.7330e+01, 5.7330e+01, 5.7250e+01,\n",
            "           5.7270e+01, 5.7110e+01, 5.7050e+01, 5.6980e+01, 5.6900e+01,\n",
            "           5.6850e+01, 5.6850e+01, 5.6640e+01, 5.6600e+01, 5.6679e+01,\n",
            "           5.6740e+01, 5.6820e+01, 5.6920e+01, 5.6880e+01, 5.6860e+01,\n",
            "           5.6790e+01, 5.6740e+01, 5.6730e+01, 5.6770e+01],\n",
            "          [5.7350e+01, 5.7310e+01, 5.7360e+01, 5.7330e+01, 5.7250e+01,\n",
            "           5.7270e+01, 5.7260e+01, 5.7050e+01, 5.7050e+01, 5.6930e+01,\n",
            "           5.6850e+01, 5.6880e+01, 5.6650e+01, 5.6732e+01, 5.6820e+01,\n",
            "           5.6850e+01, 5.6995e+01, 5.6960e+01, 5.6970e+01, 5.6860e+01,\n",
            "           5.6800e+01, 5.6780e+01, 5.6770e+01, 5.6780e+01],\n",
            "          [2.0000e+02, 5.6400e+02, 1.3910e+03, 1.0000e+02, 7.1300e+02,\n",
            "           5.0000e+02, 5.9520e+03, 1.0100e+02, 8.7600e+02, 4.9900e+02,\n",
            "           9.8100e+02, 1.4630e+03, 6.8422e+04, 1.9991e+04, 4.7664e+04,\n",
            "           7.7013e+04, 8.1453e+04, 3.8061e+04, 2.9773e+04, 3.8974e+04,\n",
            "           3.6969e+04, 7.0086e+04, 3.5490e+04, 6.3046e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5170, 2.6010, 0.2047]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1024, 0.8227, 0.0749]], device='cuda:0')\n",
            "[tensor([[[[5.6780e+01, 5.6790e+01, 5.6730e+01, 5.6810e+01, 5.6790e+01,\n",
            "           5.6550e+01, 5.6615e+01, 5.6560e+01, 5.6650e+01, 5.6640e+01,\n",
            "           5.6605e+01, 5.6760e+01, 5.6790e+01, 5.6825e+01, 5.6760e+01,\n",
            "           5.6650e+01, 5.6670e+01, 5.6770e+01, 5.6690e+01, 5.6500e+01,\n",
            "           5.6510e+01, 5.6620e+01, 5.6600e+01, 5.6570e+01],\n",
            "          [5.6870e+01, 5.6850e+01, 5.6830e+01, 5.6850e+01, 5.6840e+01,\n",
            "           5.6620e+01, 5.6660e+01, 5.6710e+01, 5.6665e+01, 5.6690e+01,\n",
            "           5.6775e+01, 5.6840e+01, 5.6820e+01, 5.6880e+01, 5.6770e+01,\n",
            "           5.6670e+01, 5.6770e+01, 5.6810e+01, 5.6690e+01, 5.6610e+01,\n",
            "           5.6650e+01, 5.6630e+01, 5.6610e+01, 5.6570e+01],\n",
            "          [5.6710e+01, 5.6720e+01, 5.6730e+01, 5.6740e+01, 5.6480e+01,\n",
            "           5.6520e+01, 5.6580e+01, 5.6530e+01, 5.6570e+01, 5.6561e+01,\n",
            "           5.6580e+01, 5.6730e+01, 5.6740e+01, 5.6760e+01, 5.6650e+01,\n",
            "           5.6610e+01, 5.6640e+01, 5.6675e+01, 5.6480e+01, 5.6495e+01,\n",
            "           5.6510e+01, 5.6580e+01, 5.6540e+01, 5.6505e+01],\n",
            "          [5.6790e+01, 5.6730e+01, 5.6830e+01, 5.6795e+01, 5.6540e+01,\n",
            "           5.6620e+01, 5.6590e+01, 5.6650e+01, 5.6640e+01, 5.6600e+01,\n",
            "           5.6770e+01, 5.6790e+01, 5.6810e+01, 5.6760e+01, 5.6670e+01,\n",
            "           5.6670e+01, 5.6760e+01, 5.6680e+01, 5.6500e+01, 5.6510e+01,\n",
            "           5.6620e+01, 5.6600e+01, 5.6570e+01, 5.6540e+01],\n",
            "          [6.7063e+04, 2.2439e+04, 4.4457e+04, 3.7052e+04, 1.2405e+05,\n",
            "           4.3682e+04, 3.8809e+04, 5.8756e+04, 7.4433e+04, 3.8235e+04,\n",
            "           9.8550e+04, 7.4796e+04, 4.9915e+04, 6.8772e+04, 2.8146e+04,\n",
            "           9.5835e+04, 6.6813e+04, 5.4915e+04, 1.6358e+05, 4.4930e+04,\n",
            "           5.8505e+04, 4.1133e+04, 2.4209e+04, 5.3541e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5124, 2.5877, 0.2000]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1031, 0.8215, 0.0754]], device='cuda:0')\n",
            "[tensor([[[[5.6540e+01, 5.6520e+01, 5.6535e+01, 5.6550e+01, 5.6460e+01,\n",
            "           5.6557e+01, 5.6510e+01, 5.6590e+01, 5.6520e+01, 5.6545e+01,\n",
            "           5.6460e+01, 5.6520e+01, 5.6475e+01, 5.6470e+01, 5.6560e+01,\n",
            "           5.6580e+01, 5.6550e+01, 5.6545e+01, 5.6495e+01, 5.6490e+01,\n",
            "           5.6510e+01, 5.6485e+01, 5.6469e+01, 5.6500e+01],\n",
            "          [5.6570e+01, 5.6560e+01, 5.6580e+01, 5.6550e+01, 5.6560e+01,\n",
            "           5.6560e+01, 5.6590e+01, 5.6590e+01, 5.6570e+01, 5.6570e+01,\n",
            "           5.6560e+01, 5.6550e+01, 5.6480e+01, 5.6570e+01, 5.6630e+01,\n",
            "           5.6580e+01, 5.6570e+01, 5.6550e+01, 5.6520e+01, 5.6540e+01,\n",
            "           5.6520e+01, 5.6515e+01, 5.6500e+01, 5.6660e+01],\n",
            "          [5.6502e+01, 5.6495e+01, 5.6525e+01, 5.6420e+01, 5.6460e+01,\n",
            "           5.6500e+01, 5.6490e+01, 5.6515e+01, 5.6465e+01, 5.6455e+01,\n",
            "           5.6460e+01, 5.6460e+01, 5.6365e+01, 5.6465e+01, 5.6555e+01,\n",
            "           5.6515e+01, 5.6530e+01, 5.6490e+01, 5.6490e+01, 5.6480e+01,\n",
            "           5.6475e+01, 5.6460e+01, 5.6435e+01, 5.6470e+01],\n",
            "          [5.6517e+01, 5.6550e+01, 5.6560e+01, 5.6455e+01, 5.6550e+01,\n",
            "           5.6500e+01, 5.6580e+01, 5.6515e+01, 5.6550e+01, 5.6460e+01,\n",
            "           5.6520e+01, 5.6470e+01, 5.6470e+01, 5.6570e+01, 5.6580e+01,\n",
            "           5.6570e+01, 5.6540e+01, 5.6510e+01, 5.6490e+01, 5.6515e+01,\n",
            "           5.6480e+01, 5.6480e+01, 5.6490e+01, 5.6620e+01],\n",
            "          [1.8628e+04, 2.8970e+04, 2.8188e+04, 1.3890e+05, 1.8965e+04,\n",
            "           1.7953e+04, 5.7324e+04, 1.3380e+04, 3.3792e+04, 2.6319e+04,\n",
            "           4.8313e+04, 2.9452e+04, 1.1600e+05, 7.1719e+04, 1.4576e+04,\n",
            "           1.5935e+04, 1.1609e+04, 1.6188e+04, 1.5981e+04, 2.1132e+04,\n",
            "           1.5250e+04, 2.0569e+04, 2.9651e+04, 1.2059e+05]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5109, 2.5787, 0.1979]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1038, 0.8204, 0.0759]], device='cuda:0')\n",
            "[tensor([[[[5.6630e+01, 5.6730e+01, 5.6750e+01, 5.6755e+01, 5.6670e+01,\n",
            "           5.6580e+01, 5.6480e+01, 5.6575e+01, 5.6565e+01, 5.6535e+01,\n",
            "           5.6580e+01, 5.6600e+01, 5.6615e+01, 5.6630e+01, 5.6690e+01,\n",
            "           5.6660e+01, 5.6685e+01, 5.6655e+01, 5.6670e+01, 5.6650e+01,\n",
            "           5.6650e+01, 5.6650e+01, 5.6650e+01, 5.6650e+01],\n",
            "          [5.6750e+01, 5.6755e+01, 5.6790e+01, 5.6770e+01, 5.6670e+01,\n",
            "           5.6595e+01, 5.6570e+01, 5.6595e+01, 5.6580e+01, 5.6585e+01,\n",
            "           5.6615e+01, 5.6610e+01, 5.6650e+01, 5.6690e+01, 5.6700e+01,\n",
            "           5.6690e+01, 5.6710e+01, 5.6700e+01, 5.6670e+01, 5.6650e+01,\n",
            "           5.6650e+01, 5.6650e+01, 5.6650e+01, 5.6650e+01],\n",
            "          [5.6620e+01, 5.6710e+01, 5.6730e+01, 5.6630e+01, 5.6590e+01,\n",
            "           5.6480e+01, 5.6430e+01, 5.6565e+01, 5.6530e+01, 5.6535e+01,\n",
            "           5.6580e+01, 5.6585e+01, 5.6610e+01, 5.6620e+01, 5.6650e+01,\n",
            "           5.6660e+01, 5.6640e+01, 5.6650e+01, 5.6660e+01, 5.6640e+01,\n",
            "           5.6640e+01, 5.6640e+01, 5.6640e+01, 5.6640e+01],\n",
            "          [5.6718e+01, 5.6750e+01, 5.6740e+01, 5.6660e+01, 5.6595e+01,\n",
            "           5.6480e+01, 5.6570e+01, 5.6569e+01, 5.6540e+01, 5.6580e+01,\n",
            "           5.6610e+01, 5.6610e+01, 5.6635e+01, 5.6690e+01, 5.6650e+01,\n",
            "           5.6680e+01, 5.6650e+01, 5.6650e+01, 5.6660e+01, 5.6640e+01,\n",
            "           5.6640e+01, 5.6640e+01, 5.6640e+01, 5.6640e+01],\n",
            "          [1.3916e+05, 3.0926e+04, 5.1817e+04, 2.8081e+04, 1.7073e+04,\n",
            "           3.2160e+04, 5.7363e+04, 2.3660e+04, 1.7841e+04, 9.7740e+03,\n",
            "           2.5005e+04, 3.1520e+04, 5.6657e+04, 6.0478e+04, 3.9702e+04,\n",
            "           4.6466e+04, 3.0877e+05, 4.1663e+05, 1.1515e+06, 2.0020e+03,\n",
            "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5118, 2.5849, 0.1991]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1033, 0.8212, 0.0756]], device='cuda:0')\n",
            "[tensor([[[[  56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200],\n",
            "          [  56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200],\n",
            "          [  56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200],\n",
            "          [  56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200,\n",
            "             56.4200,   56.4200,   56.4200,   56.4200,   56.4200,   56.4200],\n",
            "          [1127.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "              0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "              0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "              0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5095, 2.5712, 0.1974]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1043, 0.8194, 0.0763]], device='cuda:0')\n",
            "[tensor([[[[56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5095, 2.5712, 0.1974]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1043, 0.8194, 0.0763]], device='cuda:0')\n",
            "[tensor([[[[56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5095, 2.5712, 0.1974]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1043, 0.8194, 0.0763]], device='cuda:0')\n",
            "[tensor([[[[56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5095, 2.5712, 0.1974]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1043, 0.8194, 0.0763]], device='cuda:0')\n",
            "[tensor([[[[56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5095, 2.5712, 0.1974]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1043, 0.8194, 0.0763]], device='cuda:0')\n",
            "[tensor([[[[56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5095, 2.5712, 0.1974]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1043, 0.8194, 0.0763]], device='cuda:0')\n",
            "[tensor([[[[56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5095, 2.5712, 0.1974]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1043, 0.8194, 0.0763]], device='cuda:0')\n",
            "[tensor([[[[56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200, 56.4200,\n",
            "           56.4200, 56.4200, 56.4200],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5095, 2.5712, 0.1974]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1043, 0.8194, 0.0763]], device='cuda:0')\n",
            "[tensor([[[[5.6450e+01, 5.6470e+01, 5.6480e+01, 5.6510e+01, 5.6510e+01,\n",
            "           5.6560e+01, 5.6460e+01, 5.6480e+01, 5.6480e+01, 5.6480e+01,\n",
            "           5.6530e+01, 5.6580e+01, 5.6570e+01, 5.6572e+01, 5.6530e+01,\n",
            "           5.6580e+01, 5.6370e+01, 5.6370e+01, 5.6340e+01, 5.5950e+01,\n",
            "           5.6210e+01, 5.6080e+01, 5.6160e+01, 5.6150e+01],\n",
            "          [5.6480e+01, 5.6470e+01, 5.6480e+01, 5.6510e+01, 5.6610e+01,\n",
            "           5.6580e+01, 5.6470e+01, 5.6480e+01, 5.6480e+01, 5.6480e+01,\n",
            "           5.6530e+01, 5.6600e+01, 5.6778e+01, 5.6572e+01, 5.6630e+01,\n",
            "           5.6580e+01, 5.6410e+01, 5.6390e+01, 5.6360e+01, 5.6260e+01,\n",
            "           5.6210e+01, 5.6180e+01, 5.6205e+01, 5.6230e+01],\n",
            "          [5.6440e+01, 5.6470e+01, 5.6480e+01, 5.6490e+01, 5.6510e+01,\n",
            "           5.6560e+01, 5.6460e+01, 5.6480e+01, 5.6480e+01, 5.6480e+01,\n",
            "           5.6530e+01, 5.6580e+01, 5.6560e+01, 5.6450e+01, 5.6490e+01,\n",
            "           5.6344e+01, 5.6310e+01, 5.6330e+01, 5.5920e+01, 5.5950e+01,\n",
            "           5.5940e+01, 5.6070e+01, 5.6110e+01, 5.6120e+01],\n",
            "          [5.6470e+01, 5.6470e+01, 5.6480e+01, 5.6490e+01, 5.6610e+01,\n",
            "           5.6580e+01, 5.6470e+01, 5.6480e+01, 5.6480e+01, 5.6480e+01,\n",
            "           5.6530e+01, 5.6600e+01, 5.6570e+01, 5.6530e+01, 5.6560e+01,\n",
            "           5.6370e+01, 5.6370e+01, 5.6360e+01, 5.5950e+01, 5.6230e+01,\n",
            "           5.6080e+01, 5.6115e+01, 5.6160e+01, 5.6170e+01],\n",
            "          [6.4830e+03, 1.0255e+04, 5.0000e+02, 2.5510e+03, 1.6475e+04,\n",
            "           2.0000e+02, 2.1600e+02, 1.5000e+02, 0.0000e+00, 1.0000e+03,\n",
            "           7.0000e+02, 7.2880e+03, 1.2046e+05, 6.9570e+04, 1.7754e+05,\n",
            "           6.5264e+04, 3.8544e+04, 2.5685e+04, 2.5124e+05, 6.5282e+04,\n",
            "           2.3908e+05, 3.3752e+04, 4.3982e+04, 3.9176e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5114, 2.5738, 0.2006]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1042, 0.8195, 0.0764]], device='cuda:0')\n",
            "[tensor([[[[5.6180e+01, 5.6420e+01, 5.6360e+01, 5.6400e+01, 5.6430e+01,\n",
            "           5.6420e+01, 5.6430e+01, 5.6170e+01, 5.6230e+01, 5.6310e+01,\n",
            "           5.6410e+01, 5.6400e+01, 5.6377e+01, 5.6400e+01, 5.6270e+01,\n",
            "           5.6260e+01, 5.6200e+01, 5.6230e+01, 5.6230e+01, 5.6220e+01,\n",
            "           5.6210e+01, 5.6260e+01, 5.6260e+01, 5.6330e+01],\n",
            "          [5.6510e+01, 5.6440e+01, 5.6405e+01, 5.6420e+01, 5.6430e+01,\n",
            "           5.6440e+01, 5.6470e+01, 5.6270e+01, 5.6340e+01, 5.6470e+01,\n",
            "           5.6470e+01, 5.6420e+01, 5.6450e+01, 5.6420e+01, 5.6295e+01,\n",
            "           5.6330e+01, 5.6300e+01, 5.6280e+01, 5.6295e+01, 5.6259e+01,\n",
            "           5.6310e+01, 5.6300e+01, 5.6350e+01, 5.6380e+01],\n",
            "          [5.6150e+01, 5.6300e+01, 5.6300e+01, 5.6320e+01, 5.6360e+01,\n",
            "           5.6329e+01, 5.6120e+01, 5.6150e+01, 5.6200e+01, 5.6270e+01,\n",
            "           5.6365e+01, 5.6320e+01, 5.6350e+01, 5.6250e+01, 5.6180e+01,\n",
            "           5.6190e+01, 5.6195e+01, 5.6205e+01, 5.6200e+01, 5.6190e+01,\n",
            "           5.6210e+01, 5.6240e+01, 5.6260e+01, 5.6188e+01],\n",
            "          [5.6410e+01, 5.6340e+01, 5.6405e+01, 5.6420e+01, 5.6410e+01,\n",
            "           5.6430e+01, 5.6180e+01, 5.6240e+01, 5.6300e+01, 5.6440e+01,\n",
            "           5.6415e+01, 5.6380e+01, 5.6405e+01, 5.6275e+01, 5.6255e+01,\n",
            "           5.6215e+01, 5.6230e+01, 5.6250e+01, 5.6220e+01, 5.6210e+01,\n",
            "           5.6270e+01, 5.6250e+01, 5.6330e+01, 5.6200e+01],\n",
            "          [9.4397e+04, 3.5372e+04, 1.5529e+04, 3.9935e+04, 4.9995e+04,\n",
            "           5.5919e+04, 8.0962e+04, 2.8882e+04, 4.5006e+04, 5.8596e+04,\n",
            "           3.1811e+04, 2.4459e+04, 4.6376e+04, 4.3608e+04, 3.8274e+04,\n",
            "           2.6148e+04, 1.5285e+04, 2.0130e+04, 3.1224e+04, 1.3070e+04,\n",
            "           1.3709e+04, 6.4320e+03, 1.4092e+04, 2.8795e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5090, 2.5687, 0.1983]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1044, 0.8190, 0.0765]], device='cuda:0')\n",
            "[tensor([[[[5.6210e+01, 5.6040e+01, 5.5980e+01, 5.6040e+01, 5.6130e+01,\n",
            "           5.6170e+01, 5.6140e+01, 5.6100e+01, 5.6160e+01, 5.6060e+01,\n",
            "           5.6120e+01, 5.6180e+01, 5.6100e+01, 5.6130e+01, 5.6098e+01,\n",
            "           5.6140e+01, 5.6220e+01, 5.6260e+01, 5.6270e+01, 5.6350e+01,\n",
            "           5.6370e+01, 5.6290e+01, 5.6255e+01, 5.6270e+01],\n",
            "          [5.6210e+01, 5.6040e+01, 5.6080e+01, 5.6210e+01, 5.6220e+01,\n",
            "           5.6195e+01, 5.6181e+01, 5.6170e+01, 5.6180e+01, 5.6120e+01,\n",
            "           5.6180e+01, 5.6180e+01, 5.6165e+01, 5.6145e+01, 5.6130e+01,\n",
            "           5.6210e+01, 5.6270e+01, 5.6280e+01, 5.6360e+01, 5.6420e+01,\n",
            "           5.6380e+01, 5.6310e+01, 5.6270e+01, 5.6320e+01],\n",
            "          [5.5990e+01, 5.5950e+01, 5.5970e+01, 5.6040e+01, 5.6100e+01,\n",
            "           5.6140e+01, 5.6070e+01, 5.6100e+01, 5.6070e+01, 5.6040e+01,\n",
            "           5.6060e+01, 5.6090e+01, 5.6100e+01, 5.6060e+01, 5.6080e+01,\n",
            "           5.6125e+01, 5.6220e+01, 5.6230e+01, 5.6270e+01, 5.6320e+01,\n",
            "           5.6280e+01, 5.6220e+01, 5.6180e+01, 5.6010e+01],\n",
            "          [5.6015e+01, 5.5980e+01, 5.6050e+01, 5.6120e+01, 5.6210e+01,\n",
            "           5.6140e+01, 5.6100e+01, 5.6166e+01, 5.6080e+01, 5.6120e+01,\n",
            "           5.6180e+01, 5.6090e+01, 5.6120e+01, 5.6090e+01, 5.6130e+01,\n",
            "           5.6210e+01, 5.6265e+01, 5.6275e+01, 5.6360e+01, 5.6370e+01,\n",
            "           5.6280e+01, 5.6260e+01, 5.6270e+01, 5.6010e+01],\n",
            "          [7.2491e+04, 5.2548e+04, 2.3323e+04, 2.9816e+04, 1.7760e+04,\n",
            "           1.1461e+04, 3.5918e+04, 2.4553e+04, 2.3815e+04, 1.6546e+04,\n",
            "           4.7462e+04, 3.7104e+04, 8.5850e+03, 1.9492e+04, 2.3697e+04,\n",
            "           2.7139e+04, 2.7045e+04, 2.8350e+04, 4.0362e+04, 5.2035e+04,\n",
            "           2.5107e+04, 3.9024e+04, 1.7867e+04, 9.1867e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5080, 2.5673, 0.1953]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1045, 0.8191, 0.0764]], device='cuda:0')\n",
            "[tensor([[[[5.6040e+01, 5.5970e+01, 5.5900e+01, 5.5840e+01, 5.5920e+01,\n",
            "           5.5920e+01, 5.6050e+01, 5.6010e+01, 5.6000e+01, 5.6000e+01,\n",
            "           5.6060e+01, 5.6040e+01, 5.6035e+01, 5.6060e+01, 5.6070e+01,\n",
            "           5.6080e+01, 5.6085e+01, 5.6120e+01, 5.6160e+01, 5.6130e+01,\n",
            "           5.6120e+01, 5.6120e+01, 5.6180e+01, 5.6180e+01],\n",
            "          [5.6090e+01, 5.6000e+01, 5.5910e+01, 5.5930e+01, 5.5940e+01,\n",
            "           5.6010e+01, 5.6050e+01, 5.6020e+01, 5.6010e+01, 5.6085e+01,\n",
            "           5.6070e+01, 5.6060e+01, 5.6060e+01, 5.6085e+01, 5.6095e+01,\n",
            "           5.6135e+01, 5.6135e+01, 5.6190e+01, 5.6200e+01, 5.6130e+01,\n",
            "           5.6120e+01, 5.6120e+01, 5.6180e+01, 5.6180e+01],\n",
            "          [5.5960e+01, 5.5880e+01, 5.5840e+01, 5.5830e+01, 5.5910e+01,\n",
            "           5.5900e+01, 5.5980e+01, 5.5985e+01, 5.5970e+01, 5.5980e+01,\n",
            "           5.6020e+01, 5.6040e+01, 5.6010e+01, 5.6050e+01, 5.6020e+01,\n",
            "           5.6080e+01, 5.6085e+01, 5.6115e+01, 5.6160e+01, 5.6120e+01,\n",
            "           5.6120e+01, 5.6120e+01, 5.6180e+01, 5.6180e+01],\n",
            "          [5.5980e+01, 5.5910e+01, 5.5850e+01, 5.5925e+01, 5.5920e+01,\n",
            "           5.6010e+01, 5.6010e+01, 5.6000e+01, 5.6010e+01, 5.6060e+01,\n",
            "           5.6050e+01, 5.6040e+01, 5.6050e+01, 5.6060e+01, 5.6085e+01,\n",
            "           5.6100e+01, 5.6110e+01, 5.6165e+01, 5.6200e+01, 5.6120e+01,\n",
            "           5.6120e+01, 5.6120e+01, 5.6180e+01, 5.6180e+01],\n",
            "          [5.0003e+04, 3.6538e+04, 3.1155e+04, 3.1553e+04, 3.3146e+04,\n",
            "           3.4198e+04, 8.1810e+03, 2.4919e+04, 2.2280e+04, 1.8014e+04,\n",
            "           1.5102e+04, 6.8210e+03, 3.6337e+04, 4.1814e+04, 8.7537e+04,\n",
            "           7.8088e+04, 4.7050e+04, 1.1934e+05, 6.0717e+04, 2.0000e+02,\n",
            "           5.9800e+02, 0.0000e+00, 1.0000e+02, 0.0000e+00]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5063, 2.5587, 0.1945]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1051, 0.8180, 0.0769]], device='cuda:0')\n",
            "[tensor([[[[5.6740e+01, 5.6740e+01, 5.6740e+01, 5.6740e+01, 5.6700e+01,\n",
            "           5.6780e+01, 5.6900e+01, 5.7240e+01, 5.7270e+01, 5.7230e+01,\n",
            "           5.7130e+01, 5.6980e+01, 5.6950e+01, 5.6790e+01, 5.6720e+01,\n",
            "           5.6590e+01, 5.6620e+01, 5.6625e+01, 5.6690e+01, 5.6810e+01,\n",
            "           5.6929e+01, 5.6990e+01, 5.6960e+01, 5.6915e+01],\n",
            "          [5.6740e+01, 5.6740e+01, 5.6740e+01, 5.6740e+01, 5.6700e+01,\n",
            "           5.6850e+01, 5.7190e+01, 5.7270e+01, 5.7300e+01, 5.7230e+01,\n",
            "           5.7130e+01, 5.6980e+01, 5.6980e+01, 5.6860e+01, 5.6720e+01,\n",
            "           5.6650e+01, 5.6715e+01, 5.6690e+01, 5.6810e+01, 5.6930e+01,\n",
            "           5.7030e+01, 5.7030e+01, 5.6980e+01, 5.7010e+01],\n",
            "          [5.6740e+01, 5.6740e+01, 5.6740e+01, 5.6740e+01, 5.6700e+01,\n",
            "           5.6780e+01, 5.6900e+01, 5.7210e+01, 5.7240e+01, 5.7140e+01,\n",
            "           5.7030e+01, 5.6980e+01, 5.6800e+01, 5.6660e+01, 5.6540e+01,\n",
            "           5.6560e+01, 5.6580e+01, 5.6580e+01, 5.6640e+01, 5.6810e+01,\n",
            "           5.6900e+01, 5.6900e+01, 5.6900e+01, 5.6900e+01],\n",
            "          [5.6740e+01, 5.6740e+01, 5.6740e+01, 5.6740e+01, 5.6700e+01,\n",
            "           5.6850e+01, 5.7180e+01, 5.7220e+01, 5.7290e+01, 5.7140e+01,\n",
            "           5.7030e+01, 5.6980e+01, 5.6800e+01, 5.6730e+01, 5.6640e+01,\n",
            "           5.6620e+01, 5.6640e+01, 5.6640e+01, 5.6810e+01, 5.6920e+01,\n",
            "           5.6989e+01, 5.6950e+01, 5.6920e+01, 5.6950e+01],\n",
            "          [4.3000e+02, 1.0000e+02, 0.0000e+00, 0.0000e+00, 3.0000e+02,\n",
            "           3.6050e+03, 3.5050e+03, 1.2540e+03, 2.5820e+03, 2.8642e+04,\n",
            "           1.2310e+03, 1.5000e+02, 9.1010e+04, 1.3248e+05, 1.1851e+05,\n",
            "           1.2097e+05, 7.8232e+04, 7.3993e+04, 3.0438e+04, 6.5464e+04,\n",
            "           4.6508e+04, 8.4084e+04, 8.0906e+04, 5.3156e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5137, 2.5922, 0.2000]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.1029, 0.8220, 0.0752]], device='cuda:0')\n",
            "[tensor([[[[5.6980e+01, 5.7010e+01, 5.7060e+01, 5.6990e+01, 5.7035e+01,\n",
            "           5.7130e+01, 5.7210e+01, 5.7290e+01, 5.7670e+01, 5.7820e+01,\n",
            "           5.7800e+01, 5.7730e+01, 5.7868e+01, 5.7980e+01, 5.8000e+01,\n",
            "           5.7950e+01, 5.7890e+01, 5.7910e+01, 5.7940e+01, 5.7950e+01,\n",
            "           5.7970e+01, 5.7960e+01, 5.7990e+01, 5.8030e+01],\n",
            "          [5.7030e+01, 5.7050e+01, 5.7080e+01, 5.7070e+01, 5.7130e+01,\n",
            "           5.7230e+01, 5.7325e+01, 5.7640e+01, 5.7870e+01, 5.7869e+01,\n",
            "           5.7830e+01, 5.7880e+01, 5.8030e+01, 5.8040e+01, 5.8080e+01,\n",
            "           5.7960e+01, 5.7925e+01, 5.7970e+01, 5.8030e+01, 5.7970e+01,\n",
            "           5.7970e+01, 5.8005e+01, 5.8036e+01, 5.8030e+01],\n",
            "          [5.6940e+01, 5.6960e+01, 5.6950e+01, 5.6985e+01, 5.7025e+01,\n",
            "           5.7080e+01, 5.7180e+01, 5.7290e+01, 5.7650e+01, 5.7753e+01,\n",
            "           5.7670e+01, 5.7725e+01, 5.7850e+01, 5.7950e+01, 5.7940e+01,\n",
            "           5.7845e+01, 5.7850e+01, 5.7890e+01, 5.7900e+01, 5.7910e+01,\n",
            "           5.7910e+01, 5.7920e+01, 5.7970e+01, 5.7930e+01],\n",
            "          [5.6980e+01, 5.7040e+01, 5.7000e+01, 5.7030e+01, 5.7110e+01,\n",
            "           5.7210e+01, 5.7280e+01, 5.7640e+01, 5.7800e+01, 5.7800e+01,\n",
            "           5.7710e+01, 5.7855e+01, 5.7980e+01, 5.7990e+01, 5.7950e+01,\n",
            "           5.7880e+01, 5.7918e+01, 5.7940e+01, 5.7930e+01, 5.7970e+01,\n",
            "           5.7960e+01, 5.7990e+01, 5.8000e+01, 5.7960e+01],\n",
            "          [5.3185e+04, 3.9674e+04, 7.3654e+04, 4.6341e+04, 4.1924e+04,\n",
            "           3.4482e+04, 7.4285e+04, 2.8234e+05, 3.7636e+05, 6.1442e+04,\n",
            "           9.3663e+04, 7.1991e+04, 3.3385e+05, 7.4829e+04, 5.9496e+04,\n",
            "           8.1324e+04, 5.0512e+04, 8.2272e+04, 6.9744e+04, 3.9352e+04,\n",
            "           2.9909e+04, 7.3251e+04, 5.7442e+04, 3.0342e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5179, 2.6351, 0.1951]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0997, 0.8281, 0.0722]], device='cuda:0')\n",
            "[tensor([[[[5.7985e+01, 5.7960e+01, 5.8070e+01, 5.8120e+01, 5.8140e+01,\n",
            "           5.8242e+01, 5.8140e+01, 5.8110e+01, 5.8050e+01, 5.8080e+01,\n",
            "           5.8080e+01, 5.8085e+01, 5.8050e+01, 5.8025e+01, 5.7990e+01,\n",
            "           5.8020e+01, 5.8070e+01, 5.8050e+01, 5.8000e+01, 5.7970e+01,\n",
            "           5.7935e+01, 5.8020e+01, 5.8010e+01, 5.8020e+01],\n",
            "          [5.8009e+01, 5.8179e+01, 5.8140e+01, 5.8130e+01, 5.8250e+01,\n",
            "           5.8249e+01, 5.8165e+01, 5.8110e+01, 5.8090e+01, 5.8110e+01,\n",
            "           5.8140e+01, 5.8100e+01, 5.8085e+01, 5.8070e+01, 5.8035e+01,\n",
            "           5.8100e+01, 5.8085e+01, 5.8050e+01, 5.8010e+01, 5.7980e+01,\n",
            "           5.8060e+01, 5.8075e+01, 5.8030e+01, 5.8120e+01],\n",
            "          [5.7940e+01, 5.7950e+01, 5.8060e+01, 5.8060e+01, 5.8120e+01,\n",
            "           5.8120e+01, 5.8070e+01, 5.8020e+01, 5.8020e+01, 5.8060e+01,\n",
            "           5.8080e+01, 5.8040e+01, 5.8021e+01, 5.7980e+01, 5.7980e+01,\n",
            "           5.8020e+01, 5.8050e+01, 5.7980e+01, 5.7940e+01, 5.7910e+01,\n",
            "           5.7930e+01, 5.7980e+01, 5.7950e+01, 5.8000e+01],\n",
            "          [5.7950e+01, 5.8054e+01, 5.8130e+01, 5.8130e+01, 5.8230e+01,\n",
            "           5.8140e+01, 5.8100e+01, 5.8050e+01, 5.8087e+01, 5.8085e+01,\n",
            "           5.8080e+01, 5.8042e+01, 5.8035e+01, 5.7980e+01, 5.8025e+01,\n",
            "           5.8065e+01, 5.8051e+01, 5.8000e+01, 5.7980e+01, 5.7930e+01,\n",
            "           5.8014e+01, 5.8010e+01, 5.8030e+01, 5.8090e+01],\n",
            "          [3.0152e+04, 1.0004e+05, 6.4064e+04, 1.6513e+04, 1.2344e+05,\n",
            "           4.0311e+04, 5.9681e+04, 5.3033e+04, 1.9294e+04, 2.8924e+04,\n",
            "           1.5797e+04, 1.8780e+04, 2.5412e+04, 5.5369e+04, 2.9801e+04,\n",
            "           8.6730e+03, 2.5269e+04, 2.7672e+04, 1.8406e+04, 3.5441e+05,\n",
            "           4.4783e+04, 3.7520e+04, 5.1474e+04, 7.7119e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5235, 2.6484, 0.2046]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0990, 0.8290, 0.0720]], device='cuda:0')\n",
            "[tensor([[[[5.8080e+01, 5.8110e+01, 5.8140e+01, 5.8200e+01, 5.8200e+01,\n",
            "           5.8210e+01, 5.8220e+01, 5.8250e+01, 5.8220e+01, 5.8210e+01,\n",
            "           5.8205e+01, 5.8210e+01, 5.8160e+01, 5.8110e+01, 5.8100e+01,\n",
            "           5.8120e+01, 5.8110e+01, 5.8125e+01, 5.8160e+01, 5.8175e+01,\n",
            "           5.8175e+01, 5.8175e+01, 5.8170e+01, 5.8170e+01],\n",
            "          [5.8130e+01, 5.8150e+01, 5.8200e+01, 5.8225e+01, 5.8220e+01,\n",
            "           5.8250e+01, 5.8245e+01, 5.8280e+01, 5.8220e+01, 5.8210e+01,\n",
            "           5.8235e+01, 5.8220e+01, 5.8185e+01, 5.8120e+01, 5.8125e+01,\n",
            "           5.8160e+01, 5.8150e+01, 5.8180e+01, 5.8160e+01, 5.8175e+01,\n",
            "           5.8175e+01, 5.8175e+01, 5.8170e+01, 5.8170e+01],\n",
            "          [5.8010e+01, 5.8100e+01, 5.8140e+01, 5.8190e+01, 5.8180e+01,\n",
            "           5.8200e+01, 5.8201e+01, 5.8220e+01, 5.8180e+01, 5.8175e+01,\n",
            "           5.8200e+01, 5.8170e+01, 5.8090e+01, 5.8080e+01, 5.8080e+01,\n",
            "           5.8095e+01, 5.8100e+01, 5.8125e+01, 5.8130e+01, 5.8150e+01,\n",
            "           5.8150e+01, 5.8150e+01, 5.8170e+01, 5.8170e+01],\n",
            "          [5.8130e+01, 5.8150e+01, 5.8200e+01, 5.8206e+01, 5.8210e+01,\n",
            "           5.8215e+01, 5.8245e+01, 5.8220e+01, 5.8190e+01, 5.8200e+01,\n",
            "           5.8205e+01, 5.8170e+01, 5.8100e+01, 5.8090e+01, 5.8120e+01,\n",
            "           5.8105e+01, 5.8125e+01, 5.8180e+01, 5.8130e+01, 5.8150e+01,\n",
            "           5.8150e+01, 5.8150e+01, 5.8170e+01, 5.8170e+01],\n",
            "          [3.8866e+04, 2.9585e+04, 2.0468e+04, 5.6730e+03, 1.8462e+04,\n",
            "           2.8904e+04, 1.8462e+04, 4.5515e+04, 3.8784e+04, 2.9457e+04,\n",
            "           3.8802e+04, 2.7250e+04, 5.8380e+04, 2.6367e+05, 2.2023e+05,\n",
            "           1.9195e+05, 1.1594e+05, 3.9692e+05, 2.2419e+05, 5.4400e+02,\n",
            "           0.0000e+00, 0.0000e+00, 1.0400e+02, 0.0000e+00]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5237, 2.6522, 0.2046]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0987, 0.8295, 0.0718]], device='cuda:0')\n",
            "[tensor([[[[5.8470e+01, 5.8529e+01, 5.8550e+01, 5.8570e+01, 5.8520e+01,\n",
            "           5.8570e+01, 5.8550e+01, 5.8450e+01, 5.8500e+01, 5.8480e+01,\n",
            "           5.8430e+01, 5.8470e+01, 5.8370e+01, 5.8420e+01, 5.8570e+01,\n",
            "           5.8590e+01, 5.8560e+01, 5.8590e+01, 5.8500e+01, 5.8461e+01,\n",
            "           5.8540e+01, 5.8480e+01, 5.8480e+01, 5.8507e+01],\n",
            "          [5.8530e+01, 5.8560e+01, 5.8550e+01, 5.8580e+01, 5.8530e+01,\n",
            "           5.8600e+01, 5.8550e+01, 5.8500e+01, 5.8500e+01, 5.8480e+01,\n",
            "           5.8480e+01, 5.8470e+01, 5.8528e+01, 5.8580e+01, 5.8640e+01,\n",
            "           5.8600e+01, 5.8644e+01, 5.8660e+01, 5.8570e+01, 5.8540e+01,\n",
            "           5.8630e+01, 5.8540e+01, 5.8558e+01, 5.8510e+01],\n",
            "          [5.8470e+01, 5.8520e+01, 5.8550e+01, 5.8550e+01, 5.8520e+01,\n",
            "           5.8570e+01, 5.8440e+01, 5.8450e+01, 5.8460e+01, 5.8420e+01,\n",
            "           5.8430e+01, 5.8380e+01, 5.8360e+01, 5.8380e+01, 5.8510e+01,\n",
            "           5.8420e+01, 5.8550e+01, 5.8515e+01, 5.8460e+01, 5.8400e+01,\n",
            "           5.8480e+01, 5.8410e+01, 5.8470e+01, 5.8430e+01],\n",
            "          [5.8530e+01, 5.8520e+01, 5.8550e+01, 5.8550e+01, 5.8530e+01,\n",
            "           5.8600e+01, 5.8440e+01, 5.8500e+01, 5.8490e+01, 5.8420e+01,\n",
            "           5.8450e+01, 5.8380e+01, 5.8413e+01, 5.8560e+01, 5.8580e+01,\n",
            "           5.8560e+01, 5.8590e+01, 5.8520e+01, 5.8460e+01, 5.8540e+01,\n",
            "           5.8490e+01, 5.8470e+01, 5.8515e+01, 5.8430e+01],\n",
            "          [1.7120e+03, 7.0200e+02, 3.0000e+02, 7.3000e+02, 2.0900e+02,\n",
            "           1.9800e+03, 1.4280e+03, 1.3780e+03, 7.7870e+03, 1.2800e+04,\n",
            "           6.9510e+03, 5.7080e+03, 2.6283e+05, 5.3941e+04, 1.0679e+05,\n",
            "           1.0257e+05, 7.7978e+04, 7.2742e+04, 3.0836e+04, 3.8726e+04,\n",
            "           6.8467e+04, 3.7295e+04, 2.6350e+04, 1.9693e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5273, 2.6718, 0.2053]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0974, 0.8319, 0.0706]], device='cuda:0')\n",
            "[tensor([[[[5.8460e+01, 5.8710e+01, 5.8720e+01, 5.8800e+01, 5.8720e+01,\n",
            "           5.8650e+01, 5.8680e+01, 5.8730e+01, 5.8700e+01, 5.8759e+01,\n",
            "           5.8720e+01, 5.8827e+01, 5.8850e+01, 5.8830e+01, 5.8975e+01,\n",
            "           5.8970e+01, 5.8980e+01, 5.9040e+01, 5.9040e+01, 5.9070e+01,\n",
            "           5.8980e+01, 5.9045e+01, 5.9010e+01, 5.9045e+01],\n",
            "          [5.8760e+01, 5.8810e+01, 5.8800e+01, 5.8850e+01, 5.8720e+01,\n",
            "           5.8730e+01, 5.8760e+01, 5.8750e+01, 5.8800e+01, 5.8780e+01,\n",
            "           5.8825e+01, 5.8880e+01, 5.8890e+01, 5.9000e+01, 5.9010e+01,\n",
            "           5.9010e+01, 5.9070e+01, 5.9050e+01, 5.9085e+01, 5.9080e+01,\n",
            "           5.9050e+01, 5.9070e+01, 5.9040e+01, 5.9050e+01],\n",
            "          [5.8455e+01, 5.8680e+01, 5.8640e+01, 5.8690e+01, 5.8620e+01,\n",
            "           5.8610e+01, 5.8660e+01, 5.8580e+01, 5.8690e+01, 5.8700e+01,\n",
            "           5.8717e+01, 5.8790e+01, 5.8810e+01, 5.8810e+01, 5.8960e+01,\n",
            "           5.8960e+01, 5.8980e+01, 5.8990e+01, 5.9000e+01, 5.8940e+01,\n",
            "           5.8960e+01, 5.9010e+01, 5.9000e+01, 5.8981e+01],\n",
            "          [5.8700e+01, 5.8692e+01, 5.8790e+01, 5.8710e+01, 5.8640e+01,\n",
            "           5.8700e+01, 5.8730e+01, 5.8690e+01, 5.8770e+01, 5.8745e+01,\n",
            "           5.8825e+01, 5.8850e+01, 5.8820e+01, 5.8980e+01, 5.8970e+01,\n",
            "           5.8970e+01, 5.9040e+01, 5.9030e+01, 5.9075e+01, 5.8980e+01,\n",
            "           5.9050e+01, 5.9010e+01, 5.9040e+01, 5.9010e+01],\n",
            "          [1.3934e+05, 1.0022e+05, 4.2698e+04, 6.6324e+04, 2.0347e+04,\n",
            "           7.2785e+04, 4.2797e+04, 4.5528e+04, 2.2710e+04, 2.1628e+04,\n",
            "           2.8842e+04, 3.2612e+04, 3.9475e+04, 1.0070e+05, 8.8282e+04,\n",
            "           5.0440e+04, 8.4365e+04, 3.8682e+04, 3.8319e+04, 5.1691e+04,\n",
            "           4.5823e+04, 4.7046e+04, 2.2338e+04, 2.4778e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5287, 2.6906, 0.2033]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0961, 0.8346, 0.0694]], device='cuda:0')\n",
            "[tensor([[[[5.9010e+01, 5.9075e+01, 5.9160e+01, 5.9160e+01, 5.9105e+01,\n",
            "           5.9100e+01, 5.9025e+01, 5.9050e+01, 5.9040e+01, 5.8995e+01,\n",
            "           5.9010e+01, 5.8980e+01, 5.8950e+01, 5.9000e+01, 5.8930e+01,\n",
            "           5.8965e+01, 5.8980e+01, 5.8890e+01, 5.8940e+01, 5.9000e+01,\n",
            "           5.8950e+01, 5.9035e+01, 5.9050e+01, 5.9030e+01],\n",
            "          [5.9080e+01, 5.9160e+01, 5.9170e+01, 5.9160e+01, 5.9120e+01,\n",
            "           5.9115e+01, 5.9060e+01, 5.9050e+01, 5.9045e+01, 5.9030e+01,\n",
            "           5.9010e+01, 5.8985e+01, 5.9040e+01, 5.9010e+01, 5.8980e+01,\n",
            "           5.8985e+01, 5.8980e+01, 5.8965e+01, 5.9010e+01, 5.9020e+01,\n",
            "           5.9050e+01, 5.9070e+01, 5.9050e+01, 5.9040e+01],\n",
            "          [5.8990e+01, 5.9060e+01, 5.9130e+01, 5.9100e+01, 5.9080e+01,\n",
            "           5.9020e+01, 5.9015e+01, 5.8960e+01, 5.9000e+01, 5.8710e+01,\n",
            "           5.8950e+01, 5.8910e+01, 5.8940e+01, 5.8920e+01, 5.8915e+01,\n",
            "           5.8950e+01, 5.8860e+01, 5.8890e+01, 5.8935e+01, 5.8950e+01,\n",
            "           5.8940e+01, 5.9000e+01, 5.9000e+01, 5.8780e+01],\n",
            "          [5.9078e+01, 5.9160e+01, 5.9150e+01, 5.9100e+01, 5.9100e+01,\n",
            "           5.9020e+01, 5.9045e+01, 5.9035e+01, 5.9010e+01, 5.9010e+01,\n",
            "           5.8975e+01, 5.8955e+01, 5.9015e+01, 5.8930e+01, 5.8970e+01,\n",
            "           5.8985e+01, 5.8890e+01, 5.8942e+01, 5.9010e+01, 5.8959e+01,\n",
            "           5.9050e+01, 5.9070e+01, 5.9030e+01, 5.8790e+01],\n",
            "          [2.7403e+04, 1.1658e+05, 5.9851e+04, 3.7900e+04, 2.4064e+04,\n",
            "           4.6414e+04, 2.0621e+04, 2.8781e+04, 2.9517e+04, 1.1485e+05,\n",
            "           2.4118e+04, 1.6707e+05, 2.2628e+04, 4.9058e+04, 2.6759e+04,\n",
            "           1.9610e+04, 5.5468e+04, 1.9315e+04, 5.0296e+04, 2.7455e+04,\n",
            "           4.9544e+04, 3.4716e+04, 3.6513e+05, 6.3258e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5317, 2.6922, 0.2084]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0962, 0.8342, 0.0696]], device='cuda:0')\n",
            "[tensor([[[[5.8780e+01, 5.8830e+01, 5.8800e+01, 5.8720e+01, 5.8700e+01,\n",
            "           5.8740e+01, 5.8790e+01, 5.8790e+01, 5.8810e+01, 5.8850e+01,\n",
            "           5.8830e+01, 5.8850e+01, 5.8820e+01, 5.8810e+01, 5.8775e+01,\n",
            "           5.8780e+01, 5.8775e+01, 5.8895e+01, 5.8910e+01, 5.8910e+01,\n",
            "           5.8910e+01, 5.8910e+01, 5.8910e+01, 5.8950e+01],\n",
            "          [5.8850e+01, 5.8835e+01, 5.8800e+01, 5.8740e+01, 5.8745e+01,\n",
            "           5.8790e+01, 5.8795e+01, 5.8820e+01, 5.8855e+01, 5.8865e+01,\n",
            "           5.8880e+01, 5.8850e+01, 5.8840e+01, 5.8810e+01, 5.8790e+01,\n",
            "           5.8790e+01, 5.8900e+01, 5.8930e+01, 5.8910e+01, 5.8910e+01,\n",
            "           5.8960e+01, 5.8960e+01, 5.8960e+01, 5.8950e+01],\n",
            "          [5.8760e+01, 5.8800e+01, 5.8710e+01, 5.8690e+01, 5.8685e+01,\n",
            "           5.8730e+01, 5.8750e+01, 5.8775e+01, 5.8810e+01, 5.8820e+01,\n",
            "           5.8830e+01, 5.8800e+01, 5.8800e+01, 5.8770e+01, 5.8760e+01,\n",
            "           5.8750e+01, 5.8775e+01, 5.8865e+01, 5.8880e+01, 5.8880e+01,\n",
            "           5.8910e+01, 5.8910e+01, 5.8910e+01, 5.8950e+01],\n",
            "          [5.8840e+01, 5.8810e+01, 5.8720e+01, 5.8705e+01, 5.8745e+01,\n",
            "           5.8790e+01, 5.8790e+01, 5.8815e+01, 5.8850e+01, 5.8830e+01,\n",
            "           5.8855e+01, 5.8821e+01, 5.8810e+01, 5.8770e+01, 5.8770e+01,\n",
            "           5.8775e+01, 5.8895e+01, 5.8930e+01, 5.8880e+01, 5.8880e+01,\n",
            "           5.8960e+01, 5.8960e+01, 5.8960e+01, 5.8950e+01],\n",
            "          [4.5062e+04, 1.4278e+04, 2.0160e+04, 3.3490e+04, 2.2069e+04,\n",
            "           1.5195e+04, 2.3111e+04, 1.8373e+04, 1.6261e+04, 1.8892e+04,\n",
            "           2.9708e+04, 8.0753e+04, 6.6320e+04, 2.2903e+04, 2.3019e+04,\n",
            "           2.6421e+04, 1.2331e+05, 3.8128e+05, 4.7000e+03, 0.0000e+00,\n",
            "           2.5000e+02, 0.0000e+00, 0.0000e+00, 1.0000e+02]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5290, 2.6857, 0.2047]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0965, 0.8338, 0.0698]], device='cuda:0')\n",
            "[tensor([[[[5.8610e+01, 5.8610e+01, 5.8750e+01, 5.8720e+01, 5.8680e+01,\n",
            "           5.8770e+01, 5.8770e+01, 5.8880e+01, 5.8900e+01, 5.8830e+01,\n",
            "           5.8980e+01, 5.9020e+01, 5.9020e+01, 5.8930e+01, 5.8980e+01,\n",
            "           5.9030e+01, 5.9010e+01, 5.9098e+01, 5.9010e+01, 5.8990e+01,\n",
            "           5.8900e+01, 5.8850e+01, 5.8820e+01, 5.8790e+01],\n",
            "          [5.8650e+01, 5.8650e+01, 5.8750e+01, 5.8720e+01, 5.8700e+01,\n",
            "           5.8800e+01, 5.8800e+01, 5.8950e+01, 5.8900e+01, 5.8890e+01,\n",
            "           5.9000e+01, 5.9020e+01, 5.9070e+01, 5.8970e+01, 5.9035e+01,\n",
            "           5.9030e+01, 5.9130e+01, 5.9105e+01, 5.9050e+01, 5.9000e+01,\n",
            "           5.8927e+01, 5.8860e+01, 5.8850e+01, 5.8850e+01],\n",
            "          [5.8610e+01, 5.8610e+01, 5.8750e+01, 5.8720e+01, 5.8680e+01,\n",
            "           5.8770e+01, 5.8770e+01, 5.8880e+01, 5.8900e+01, 5.8830e+01,\n",
            "           5.8970e+01, 5.9020e+01, 5.8880e+01, 5.8910e+01, 5.8920e+01,\n",
            "           5.8960e+01, 5.9010e+01, 5.8980e+01, 5.8930e+01, 5.8880e+01,\n",
            "           5.8850e+01, 5.8790e+01, 5.8780e+01, 5.8780e+01],\n",
            "          [5.8640e+01, 5.8640e+01, 5.8750e+01, 5.8720e+01, 5.8690e+01,\n",
            "           5.8800e+01, 5.8800e+01, 5.8950e+01, 5.8900e+01, 5.8890e+01,\n",
            "           5.8970e+01, 5.9020e+01, 5.8900e+01, 5.8950e+01, 5.9030e+01,\n",
            "           5.9020e+01, 5.9100e+01, 5.9010e+01, 5.8990e+01, 5.8910e+01,\n",
            "           5.8860e+01, 5.8810e+01, 5.8800e+01, 5.8820e+01],\n",
            "          [4.0000e+02, 0.0000e+00, 1.8000e+02, 2.2800e+02, 1.0735e+04,\n",
            "           4.0100e+02, 0.0000e+00, 8.5600e+02, 2.5600e+02, 3.0400e+02,\n",
            "           1.4130e+03, 3.1200e+03, 8.9723e+04, 3.5861e+04, 4.9854e+04,\n",
            "           6.1414e+04, 1.1481e+05, 5.5902e+04, 3.0760e+04, 4.1249e+04,\n",
            "           3.6533e+04, 6.2672e+04, 2.9812e+04, 4.7800e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5288, 2.6891, 0.2050]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0962, 0.8343, 0.0696]], device='cuda:0')\n",
            "[tensor([[[[5.8800e+01, 5.8710e+01, 5.8665e+01, 5.8640e+01, 5.8600e+01,\n",
            "           5.8580e+01, 5.8510e+01, 5.8510e+01, 5.8570e+01, 5.8600e+01,\n",
            "           5.8560e+01, 5.8600e+01, 5.8740e+01, 5.8830e+01, 5.8910e+01,\n",
            "           5.8960e+01, 5.9020e+01, 5.9030e+01, 5.9025e+01, 5.9030e+01,\n",
            "           5.9010e+01, 5.8980e+01, 5.8900e+01, 5.8900e+01],\n",
            "          [5.8800e+01, 5.8775e+01, 5.8685e+01, 5.8690e+01, 5.8600e+01,\n",
            "           5.8600e+01, 5.8650e+01, 5.8620e+01, 5.8620e+01, 5.8630e+01,\n",
            "           5.8650e+01, 5.8770e+01, 5.8840e+01, 5.8920e+01, 5.9040e+01,\n",
            "           5.9030e+01, 5.9060e+01, 5.9040e+01, 5.9050e+01, 5.9050e+01,\n",
            "           5.9020e+01, 5.8980e+01, 5.8910e+01, 5.8910e+01],\n",
            "          [5.8610e+01, 5.8630e+01, 5.8560e+01, 5.8610e+01, 5.8440e+01,\n",
            "           5.8480e+01, 5.8500e+01, 5.8460e+01, 5.8500e+01, 5.8550e+01,\n",
            "           5.8560e+01, 5.8600e+01, 5.8740e+01, 5.8830e+01, 5.8900e+01,\n",
            "           5.8950e+01, 5.8980e+01, 5.9000e+01, 5.8950e+01, 5.9010e+01,\n",
            "           5.8970e+01, 5.8870e+01, 5.8845e+01, 5.8810e+01],\n",
            "          [5.8719e+01, 5.8660e+01, 5.8630e+01, 5.8630e+01, 5.8550e+01,\n",
            "           5.8510e+01, 5.8545e+01, 5.8610e+01, 5.8620e+01, 5.8550e+01,\n",
            "           5.8600e+01, 5.8760e+01, 5.8830e+01, 5.8920e+01, 5.8980e+01,\n",
            "           5.9020e+01, 5.9040e+01, 5.9030e+01, 5.9010e+01, 5.9020e+01,\n",
            "           5.8970e+01, 5.8910e+01, 5.8900e+01, 5.8860e+01],\n",
            "          [8.7319e+04, 8.3820e+04, 6.1958e+04, 1.9957e+04, 5.3830e+04,\n",
            "           3.6917e+04, 4.1548e+04, 8.1713e+04, 2.9552e+04, 8.5150e+03,\n",
            "           1.8995e+04, 6.9326e+04, 3.3981e+04, 3.4493e+04, 4.4443e+04,\n",
            "           6.9335e+04, 4.5148e+04, 8.4421e+04, 1.0797e+05, 1.9105e+04,\n",
            "           3.4196e+04, 7.8864e+04, 2.3030e+04, 3.5903e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5283, 2.6886, 0.2023]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0962, 0.8344, 0.0694]], device='cuda:0')\n",
            "[tensor([[[[5.8850e+01, 5.8820e+01, 5.8810e+01, 5.8770e+01, 5.8650e+01,\n",
            "           5.8670e+01, 5.8762e+01, 5.8810e+01, 5.8820e+01, 5.8860e+01,\n",
            "           5.8850e+01, 5.8770e+01, 5.8740e+01, 5.8730e+01, 5.8810e+01,\n",
            "           5.8890e+01, 5.8920e+01, 5.8915e+01, 5.8910e+01, 5.8950e+01,\n",
            "           5.8830e+01, 5.8820e+01, 5.8780e+01, 5.8760e+01],\n",
            "          [5.8850e+01, 5.8840e+01, 5.8810e+01, 5.8770e+01, 5.8700e+01,\n",
            "           5.8780e+01, 5.8820e+01, 5.8825e+01, 5.8860e+01, 5.8880e+01,\n",
            "           5.8850e+01, 5.8770e+01, 5.8760e+01, 5.8820e+01, 5.8893e+01,\n",
            "           5.8940e+01, 5.8920e+01, 5.8915e+01, 5.8960e+01, 5.8950e+01,\n",
            "           5.8880e+01, 5.8820e+01, 5.8780e+01, 5.8800e+01],\n",
            "          [5.8805e+01, 5.8780e+01, 5.8760e+01, 5.8630e+01, 5.8640e+01,\n",
            "           5.8650e+01, 5.8760e+01, 5.8750e+01, 5.8810e+01, 5.8810e+01,\n",
            "           5.8780e+01, 5.8700e+01, 5.8710e+01, 5.8710e+01, 5.8801e+01,\n",
            "           5.8860e+01, 5.8870e+01, 5.8870e+01, 5.8870e+01, 5.8820e+01,\n",
            "           5.8810e+01, 5.8720e+01, 5.8740e+01, 5.8560e+01],\n",
            "          [5.8810e+01, 5.8813e+01, 5.8780e+01, 5.8650e+01, 5.8650e+01,\n",
            "           5.8760e+01, 5.8820e+01, 5.8790e+01, 5.8860e+01, 5.8860e+01,\n",
            "           5.8780e+01, 5.8745e+01, 5.8730e+01, 5.8810e+01, 5.8890e+01,\n",
            "           5.8920e+01, 5.8910e+01, 5.8900e+01, 5.8950e+01, 5.8830e+01,\n",
            "           5.8820e+01, 5.8780e+01, 5.8760e+01, 5.8570e+01],\n",
            "          [2.9074e+04, 1.8759e+04, 4.1454e+04, 3.5509e+04, 2.5110e+04,\n",
            "           4.1786e+04, 3.5005e+04, 4.2495e+04, 9.8250e+03, 1.3475e+04,\n",
            "           1.3362e+04, 1.8148e+04, 6.9670e+03, 1.9381e+04, 1.1443e+04,\n",
            "           3.5114e+04, 1.0464e+04, 1.7584e+04, 2.6334e+05, 2.4363e+04,\n",
            "           2.5975e+04, 3.1834e+05, 5.3135e+04, 7.8957e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5291, 2.6850, 0.2059]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0965, 0.8336, 0.0699]], device='cuda:0')\n",
            "[tensor([[[[5.8580e+01, 5.8520e+01, 5.8480e+01, 5.8460e+01, 5.8450e+01,\n",
            "           5.8420e+01, 5.8420e+01, 5.8270e+01, 5.8250e+01, 5.8273e+01,\n",
            "           5.8310e+01, 5.8300e+01, 5.8310e+01, 5.8330e+01, 5.8257e+01,\n",
            "           5.8310e+01, 5.8270e+01, 5.8230e+01, 5.8270e+01, 5.8200e+01,\n",
            "           5.8200e+01, 5.8300e+01, 5.8280e+01, 5.8280e+01],\n",
            "          [5.8620e+01, 5.8535e+01, 5.8489e+01, 5.8490e+01, 5.8490e+01,\n",
            "           5.8480e+01, 5.8420e+01, 5.8280e+01, 5.8280e+01, 5.8350e+01,\n",
            "           5.8340e+01, 5.8330e+01, 5.8330e+01, 5.8340e+01, 5.8320e+01,\n",
            "           5.8350e+01, 5.8275e+01, 5.8300e+01, 5.8270e+01, 5.8260e+01,\n",
            "           5.8260e+01, 5.8300e+01, 5.8280e+01, 5.8280e+01],\n",
            "          [5.8485e+01, 5.8440e+01, 5.8455e+01, 5.8450e+01, 5.8420e+01,\n",
            "           5.8420e+01, 5.8260e+01, 5.8210e+01, 5.8230e+01, 5.8253e+01,\n",
            "           5.8300e+01, 5.8290e+01, 5.8290e+01, 5.8230e+01, 5.8246e+01,\n",
            "           5.8245e+01, 5.8210e+01, 5.8210e+01, 5.8270e+01, 5.8200e+01,\n",
            "           5.8200e+01, 5.8300e+01, 5.8280e+01, 5.8280e+01],\n",
            "          [5.8520e+01, 5.8450e+01, 5.8460e+01, 5.8450e+01, 5.8430e+01,\n",
            "           5.8420e+01, 5.8265e+01, 5.8246e+01, 5.8250e+01, 5.8310e+01,\n",
            "           5.8306e+01, 5.8310e+01, 5.8330e+01, 5.8255e+01, 5.8310e+01,\n",
            "           5.8270e+01, 5.8225e+01, 5.8300e+01, 5.8270e+01, 5.8260e+01,\n",
            "           5.8260e+01, 5.8300e+01, 5.8280e+01, 5.8280e+01],\n",
            "          [7.1625e+04, 4.3638e+04, 2.0233e+04, 1.2523e+04, 1.6361e+04,\n",
            "           3.1420e+04, 4.0632e+04, 5.9369e+04, 3.3644e+04, 4.8673e+04,\n",
            "           4.1365e+04, 1.8053e+04, 3.6819e+04, 1.8429e+05, 5.4750e+04,\n",
            "           1.1000e+05, 1.2881e+05, 2.8461e+05, 2.0207e+05, 1.3600e+05,\n",
            "           0.0000e+00, 1.0000e+04, 4.0100e+02, 0.0000e+00]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5265, 2.6606, 0.2068]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0983, 0.8303, 0.0714]], device='cuda:0')\n",
            "[tensor([[[[5.8830e+01, 5.8830e+01, 5.8850e+01, 5.8940e+01, 5.8850e+01,\n",
            "           5.8810e+01, 5.8890e+01, 5.8960e+01, 5.9100e+01, 5.9090e+01,\n",
            "           5.9150e+01, 5.9150e+01, 5.9100e+01, 5.9200e+01, 5.9260e+01,\n",
            "           5.9255e+01, 5.9280e+01, 5.9250e+01, 5.9330e+01, 5.9270e+01,\n",
            "           5.9120e+01, 5.9220e+01, 5.9340e+01, 5.9240e+01],\n",
            "          [5.8830e+01, 5.8840e+01, 5.9000e+01, 5.8940e+01, 5.8860e+01,\n",
            "           5.8830e+01, 5.8970e+01, 5.9090e+01, 5.9120e+01, 5.9130e+01,\n",
            "           5.9250e+01, 5.9150e+01, 5.9230e+01, 5.9280e+01, 5.9280e+01,\n",
            "           5.9400e+01, 5.9360e+01, 5.9359e+01, 5.9350e+01, 5.9270e+01,\n",
            "           5.9270e+01, 5.9360e+01, 5.9340e+01, 5.9314e+01],\n",
            "          [5.8780e+01, 5.8760e+01, 5.8840e+01, 5.8880e+01, 5.8810e+01,\n",
            "           5.8810e+01, 5.8840e+01, 5.8960e+01, 5.9050e+01, 5.9090e+01,\n",
            "           5.9130e+01, 5.9090e+01, 5.9100e+01, 5.9150e+01, 5.9160e+01,\n",
            "           5.9240e+01, 5.9210e+01, 5.9240e+01, 5.9210e+01, 5.9100e+01,\n",
            "           5.9070e+01, 5.9220e+01, 5.9233e+01, 5.9220e+01],\n",
            "          [5.8780e+01, 5.8840e+01, 5.9000e+01, 5.8880e+01, 5.8860e+01,\n",
            "           5.8830e+01, 5.8960e+01, 5.9090e+01, 5.9120e+01, 5.9130e+01,\n",
            "           5.9200e+01, 5.9090e+01, 5.9164e+01, 5.9250e+01, 5.9260e+01,\n",
            "           5.9270e+01, 5.9230e+01, 5.9320e+01, 5.9265e+01, 5.9120e+01,\n",
            "           5.9210e+01, 5.9350e+01, 5.9240e+01, 5.9290e+01],\n",
            "          [9.3600e+02, 5.4000e+04, 5.6200e+04, 9.5000e+02, 2.4260e+04,\n",
            "           4.0000e+02, 2.2623e+04, 6.3150e+03, 5.0280e+03, 1.0711e+04,\n",
            "           5.3067e+04, 1.8127e+04, 8.8397e+04, 6.3733e+04, 7.3891e+04,\n",
            "           8.9245e+04, 1.0602e+05, 6.0172e+04, 5.0250e+04, 6.1156e+04,\n",
            "           9.8623e+04, 2.5015e+05, 5.4141e+04, 3.7042e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5296, 2.7028, 0.2036]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0952, 0.8361, 0.0687]], device='cuda:0')\n",
            "[tensor([[[[5.9300e+01, 5.9340e+01, 5.9280e+01, 5.9233e+01, 5.9265e+01,\n",
            "           5.9230e+01, 5.9220e+01, 5.9170e+01, 5.9160e+01, 5.9240e+01,\n",
            "           5.9210e+01, 5.9270e+01, 5.9420e+01, 5.9400e+01, 5.9300e+01,\n",
            "           5.9190e+01, 5.9160e+01, 5.9110e+01, 5.9120e+01, 5.9275e+01,\n",
            "           5.9310e+01, 5.9340e+01, 5.9360e+01, 5.9330e+01],\n",
            "          [5.9360e+01, 5.9360e+01, 5.9280e+01, 5.9270e+01, 5.9270e+01,\n",
            "           5.9255e+01, 5.9276e+01, 5.9210e+01, 5.9300e+01, 5.9280e+01,\n",
            "           5.9270e+01, 5.9420e+01, 5.9500e+01, 5.9410e+01, 5.9310e+01,\n",
            "           5.9240e+01, 5.9180e+01, 5.9160e+01, 5.9280e+01, 5.9330e+01,\n",
            "           5.9370e+01, 5.9370e+01, 5.9360e+01, 5.9400e+01],\n",
            "          [5.9280e+01, 5.9220e+01, 5.9140e+01, 5.9200e+01, 5.9180e+01,\n",
            "           5.9190e+01, 5.9140e+01, 5.9120e+01, 5.9125e+01, 5.9180e+01,\n",
            "           5.9170e+01, 5.9245e+01, 5.9350e+01, 5.9290e+01, 5.9200e+01,\n",
            "           5.9130e+01, 5.9090e+01, 5.9100e+01, 5.9100e+01, 5.9252e+01,\n",
            "           5.9310e+01, 5.9320e+01, 5.9300e+01, 5.9310e+01],\n",
            "          [5.9350e+01, 5.9280e+01, 5.9221e+01, 5.9260e+01, 5.9240e+01,\n",
            "           5.9210e+01, 5.9170e+01, 5.9150e+01, 5.9250e+01, 5.9201e+01,\n",
            "           5.9260e+01, 5.9420e+01, 5.9410e+01, 5.9290e+01, 5.9200e+01,\n",
            "           5.9160e+01, 5.9090e+01, 5.9120e+01, 5.9280e+01, 5.9310e+01,\n",
            "           5.9320e+01, 5.9353e+01, 5.9337e+01, 5.9390e+01],\n",
            "          [3.0095e+04, 3.7268e+04, 7.0848e+04, 4.1535e+04, 3.1025e+04,\n",
            "           1.7172e+04, 2.7942e+04, 1.7355e+04, 3.2741e+04, 2.0582e+04,\n",
            "           2.4423e+04, 9.1874e+04, 1.7196e+05, 5.5111e+04, 6.0607e+04,\n",
            "           6.0972e+04, 3.9129e+04, 3.4998e+04, 6.4513e+04, 3.6259e+04,\n",
            "           3.3568e+04, 2.2282e+04, 2.2189e+04, 5.2882e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5332, 2.7049, 0.2067]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0953, 0.8360, 0.0687]], device='cuda:0')\n",
            "[tensor([[[[5.9390e+01, 5.9440e+01, 5.9530e+01, 5.9635e+01, 5.9635e+01,\n",
            "           5.9760e+01, 5.9770e+01, 5.9680e+01, 5.9700e+01, 5.9665e+01,\n",
            "           5.9665e+01, 5.9680e+01, 5.9751e+01, 5.9750e+01, 5.9740e+01,\n",
            "           5.9760e+01, 5.9770e+01, 5.9776e+01, 5.9810e+01, 5.9810e+01,\n",
            "           5.9790e+01, 5.9820e+01, 5.9760e+01, 5.9760e+01],\n",
            "          [5.9455e+01, 5.9575e+01, 5.9640e+01, 5.9635e+01, 5.9750e+01,\n",
            "           5.9780e+01, 5.9830e+01, 5.9770e+01, 5.9710e+01, 5.9730e+01,\n",
            "           5.9726e+01, 5.9760e+01, 5.9840e+01, 5.9770e+01, 5.9760e+01,\n",
            "           5.9820e+01, 5.9805e+01, 5.9830e+01, 5.9835e+01, 5.9820e+01,\n",
            "           5.9840e+01, 5.9820e+01, 5.9765e+01, 5.9770e+01],\n",
            "          [5.9390e+01, 5.9410e+01, 5.9525e+01, 5.9580e+01, 5.9620e+01,\n",
            "           5.9650e+01, 5.9640e+01, 5.9670e+01, 5.9640e+01, 5.9650e+01,\n",
            "           5.9663e+01, 5.9680e+01, 5.9740e+01, 5.9720e+01, 5.9720e+01,\n",
            "           5.9740e+01, 5.9750e+01, 5.9770e+01, 5.9780e+01, 5.9760e+01,\n",
            "           5.9744e+01, 5.9760e+01, 5.9725e+01, 5.9670e+01],\n",
            "          [5.9442e+01, 5.9540e+01, 5.9630e+01, 5.9630e+01, 5.9750e+01,\n",
            "           5.9780e+01, 5.9675e+01, 5.9700e+01, 5.9690e+01, 5.9670e+01,\n",
            "           5.9690e+01, 5.9755e+01, 5.9750e+01, 5.9740e+01, 5.9760e+01,\n",
            "           5.9780e+01, 5.9759e+01, 5.9810e+01, 5.9800e+01, 5.9775e+01,\n",
            "           5.9820e+01, 5.9760e+01, 5.9760e+01, 5.9760e+01],\n",
            "          [1.5873e+04, 1.6684e+05, 7.7498e+04, 2.4637e+04, 5.9595e+04,\n",
            "           6.4864e+04, 9.1419e+04, 7.9582e+04, 3.5122e+04, 4.6842e+04,\n",
            "           5.1608e+04, 2.4739e+04, 6.2588e+04, 4.8512e+04, 3.1029e+04,\n",
            "           4.2761e+04, 3.8504e+04, 1.3538e+04, 1.5311e+04, 3.2149e+04,\n",
            "           4.0614e+04, 3.6726e+04, 6.6549e+04, 8.8128e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5360, 2.7256, 0.2084]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0939, 0.8385, 0.0677]], device='cuda:0')\n",
            "[tensor([[[[5.9770e+01, 5.9840e+01, 5.9795e+01, 5.9780e+01, 5.9830e+01,\n",
            "           5.9800e+01, 5.9740e+01, 5.9760e+01, 5.9760e+01, 5.9805e+01,\n",
            "           5.9860e+01, 5.9890e+01, 5.9925e+01, 5.9920e+01, 5.9900e+01,\n",
            "           5.9945e+01, 5.9920e+01, 5.9940e+01, 5.9970e+01, 5.9960e+01,\n",
            "           5.9970e+01, 5.9990e+01, 5.9950e+01, 5.9920e+01],\n",
            "          [5.9890e+01, 5.9840e+01, 5.9830e+01, 5.9839e+01, 5.9835e+01,\n",
            "           5.9810e+01, 5.9770e+01, 5.9775e+01, 5.9830e+01, 5.9870e+01,\n",
            "           5.9900e+01, 5.9950e+01, 5.9940e+01, 5.9930e+01, 5.9940e+01,\n",
            "           5.9980e+01, 5.9960e+01, 5.9970e+01, 5.9990e+01, 5.9960e+01,\n",
            "           5.9970e+01, 5.9990e+01, 5.9950e+01, 5.9920e+01],\n",
            "          [5.9730e+01, 5.9790e+01, 5.9760e+01, 5.9770e+01, 5.9780e+01,\n",
            "           5.9734e+01, 5.9740e+01, 5.9730e+01, 5.9760e+01, 5.9805e+01,\n",
            "           5.9840e+01, 5.9890e+01, 5.9900e+01, 5.9890e+01, 5.9890e+01,\n",
            "           5.9900e+01, 5.9910e+01, 5.9910e+01, 5.9940e+01, 5.9960e+01,\n",
            "           5.9940e+01, 5.9940e+01, 5.9930e+01, 5.9920e+01],\n",
            "          [5.9840e+01, 5.9799e+01, 5.9780e+01, 5.9830e+01, 5.9790e+01,\n",
            "           5.9735e+01, 5.9770e+01, 5.9770e+01, 5.9810e+01, 5.9850e+01,\n",
            "           5.9890e+01, 5.9925e+01, 5.9920e+01, 5.9900e+01, 5.9940e+01,\n",
            "           5.9920e+01, 5.9940e+01, 5.9950e+01, 5.9990e+01, 5.9960e+01,\n",
            "           5.9970e+01, 5.9940e+01, 5.9930e+01, 5.9920e+01],\n",
            "          [6.3850e+04, 3.2334e+05, 2.2043e+04, 3.4644e+04, 3.6711e+04,\n",
            "           3.4171e+04, 6.7526e+04, 2.1178e+04, 2.9917e+04, 3.3713e+04,\n",
            "           3.8775e+04, 4.3869e+04, 8.6432e+04, 1.9794e+05, 1.4303e+05,\n",
            "           1.0370e+05, 2.1167e+05, 3.3914e+05, 2.0822e+05, 2.3400e+02,\n",
            "           1.3000e+03, 7.1400e+02, 7.0000e+02, 1.1680e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5370, 2.7329, 0.2079]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0934, 0.8394, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[ 60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,\n",
            "            60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,\n",
            "            60.,  60.],\n",
            "          [ 60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,\n",
            "            60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,\n",
            "            60.,  60.],\n",
            "          [ 60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,\n",
            "            60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,\n",
            "            60.,  60.],\n",
            "          [ 60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,\n",
            "            60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,  60.,\n",
            "            60.,  60.],\n",
            "          [450.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
            "             0.,   0.]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60., 60.,\n",
            "           60., 60., 60., 60., 60., 60., 60., 60., 60., 60.],\n",
            "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5384, 2.7350, 0.2100]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0933, 0.8395, 0.0672]], device='cuda:0')\n",
            "[tensor([[[[6.0870e+01, 6.0900e+01, 6.0890e+01, 6.0870e+01, 6.0870e+01,\n",
            "           6.0810e+01, 6.0810e+01, 6.0600e+01, 6.0540e+01, 6.0530e+01,\n",
            "           6.0530e+01, 6.0480e+01, 6.0360e+01, 6.0390e+01, 6.0480e+01,\n",
            "           6.0470e+01, 6.0500e+01, 6.0505e+01, 6.0540e+01, 6.0490e+01,\n",
            "           6.0580e+01, 6.0630e+01, 6.0680e+01, 6.0770e+01],\n",
            "          [6.0930e+01, 6.0930e+01, 6.0900e+01, 6.0910e+01, 6.0880e+01,\n",
            "           6.0810e+01, 6.0810e+01, 6.0600e+01, 6.0540e+01, 6.0530e+01,\n",
            "           6.0530e+01, 6.0480e+01, 6.0500e+01, 6.0500e+01, 6.0550e+01,\n",
            "           6.0510e+01, 6.0540e+01, 6.0580e+01, 6.0565e+01, 6.0580e+01,\n",
            "           6.0720e+01, 6.0730e+01, 6.0770e+01, 6.0850e+01],\n",
            "          [6.0870e+01, 6.0870e+01, 6.0850e+01, 6.0870e+01, 6.0870e+01,\n",
            "           6.0810e+01, 6.0680e+01, 6.0550e+01, 6.0500e+01, 6.0460e+01,\n",
            "           6.0460e+01, 6.0350e+01, 6.0340e+01, 6.0270e+01, 6.0400e+01,\n",
            "           6.0400e+01, 6.0450e+01, 6.0475e+01, 6.0470e+01, 6.0440e+01,\n",
            "           6.0550e+01, 6.0620e+01, 6.0667e+01, 6.0740e+01],\n",
            "          [6.0870e+01, 6.0900e+01, 6.0850e+01, 6.0890e+01, 6.0880e+01,\n",
            "           6.0810e+01, 6.0680e+01, 6.0550e+01, 6.0540e+01, 6.0460e+01,\n",
            "           6.0460e+01, 6.0370e+01, 6.0390e+01, 6.0490e+01, 6.0470e+01,\n",
            "           6.0500e+01, 6.0520e+01, 6.0550e+01, 6.0500e+01, 6.0580e+01,\n",
            "           6.0630e+01, 6.0680e+01, 6.0770e+01, 6.0850e+01],\n",
            "          [1.6010e+03, 9.0310e+03, 1.3254e+04, 1.3479e+04, 1.0000e+04,\n",
            "           8.3950e+03, 4.0800e+02, 1.7050e+03, 7.3600e+02, 1.2010e+04,\n",
            "           0.0000e+00, 2.3835e+04, 3.6492e+05, 1.8133e+05, 1.1569e+05,\n",
            "           7.4294e+04, 6.7116e+04, 1.2847e+05, 7.4591e+04, 6.4686e+04,\n",
            "           7.6738e+04, 6.4921e+04, 1.0043e+05, 7.0907e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5457, 2.7682, 0.2142]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0913, 0.8431, 0.0656]], device='cuda:0')\n",
            "[tensor([[[[6.0840e+01, 6.0840e+01, 6.0730e+01, 6.0835e+01, 6.0750e+01,\n",
            "           6.0580e+01, 6.0550e+01, 6.0570e+01, 6.0550e+01, 6.0450e+01,\n",
            "           6.0450e+01, 6.0470e+01, 6.0470e+01, 6.0250e+01, 6.0380e+01,\n",
            "           6.0435e+01, 6.0560e+01, 6.0629e+01, 6.0590e+01, 6.0590e+01,\n",
            "           6.0642e+01, 6.0510e+01, 6.0490e+01, 6.0400e+01],\n",
            "          [6.0857e+01, 6.0865e+01, 6.0830e+01, 6.0900e+01, 6.0755e+01,\n",
            "           6.0632e+01, 6.0600e+01, 6.0600e+01, 6.0570e+01, 6.0550e+01,\n",
            "           6.0500e+01, 6.0550e+01, 6.0480e+01, 6.0370e+01, 6.0430e+01,\n",
            "           6.0560e+01, 6.0660e+01, 6.0640e+01, 6.0680e+01, 6.0660e+01,\n",
            "           6.0642e+01, 6.0530e+01, 6.0492e+01, 6.0400e+01],\n",
            "          [6.0780e+01, 6.0710e+01, 6.0710e+01, 6.0730e+01, 6.0592e+01,\n",
            "           6.0540e+01, 6.0500e+01, 6.0500e+01, 6.0350e+01, 6.0450e+01,\n",
            "           6.0420e+01, 6.0390e+01, 6.0200e+01, 6.0160e+01, 6.0355e+01,\n",
            "           6.0435e+01, 6.0560e+01, 6.0575e+01, 6.0585e+01, 6.0560e+01,\n",
            "           6.0510e+01, 6.0460e+01, 6.0390e+01, 6.0330e+01],\n",
            "          [6.0850e+01, 6.0720e+01, 6.0830e+01, 6.0750e+01, 6.0592e+01,\n",
            "           6.0560e+01, 6.0560e+01, 6.0555e+01, 6.0460e+01, 6.0470e+01,\n",
            "           6.0470e+01, 6.0480e+01, 6.0230e+01, 6.0360e+01, 6.0430e+01,\n",
            "           6.0560e+01, 6.0620e+01, 6.0590e+01, 6.0610e+01, 6.0650e+01,\n",
            "           6.0520e+01, 6.0530e+01, 6.0390e+01, 6.0400e+01],\n",
            "          [5.2690e+04, 8.3074e+04, 1.6326e+05, 7.1309e+04, 5.7730e+04,\n",
            "           5.5717e+04, 9.9809e+04, 5.6241e+04, 8.6554e+04, 4.3842e+04,\n",
            "           2.2880e+04, 6.9577e+04, 1.0212e+05, 6.6056e+04, 2.4722e+04,\n",
            "           5.8605e+04, 1.6391e+05, 2.8638e+04, 6.7810e+04, 1.0130e+05,\n",
            "           5.0546e+04, 1.8839e+04, 2.9975e+04, 4.3667e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5448, 2.7666, 0.2150]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0914, 0.8429, 0.0657]], device='cuda:0')\n",
            "[tensor([[[[6.0380e+01, 6.0360e+01, 6.0330e+01, 6.0320e+01, 6.0280e+01,\n",
            "           6.0340e+01, 6.0340e+01, 6.0330e+01, 6.0340e+01, 6.0480e+01,\n",
            "           6.0450e+01, 6.0360e+01, 6.0290e+01, 6.0290e+01, 6.0360e+01,\n",
            "           6.0500e+01, 6.0550e+01, 6.0630e+01, 6.0690e+01, 6.0650e+01,\n",
            "           6.0630e+01, 6.0570e+01, 6.0730e+01, 6.0570e+01],\n",
            "          [6.0380e+01, 6.0380e+01, 6.0360e+01, 6.0360e+01, 6.0390e+01,\n",
            "           6.0380e+01, 6.0370e+01, 6.0370e+01, 6.0495e+01, 6.0490e+01,\n",
            "           6.0456e+01, 6.0360e+01, 6.0315e+01, 6.0360e+01, 6.0520e+01,\n",
            "           6.0570e+01, 6.0650e+01, 6.0750e+01, 6.0720e+01, 6.0660e+01,\n",
            "           6.0630e+01, 6.0740e+01, 6.0740e+01, 6.0780e+01],\n",
            "          [6.0310e+01, 6.0270e+01, 6.0280e+01, 6.0240e+01, 6.0280e+01,\n",
            "           6.0335e+01, 6.0312e+01, 6.0275e+01, 6.0335e+01, 6.0440e+01,\n",
            "           6.0350e+01, 6.0280e+01, 6.0280e+01, 6.0280e+01, 6.0340e+01,\n",
            "           6.0500e+01, 6.0550e+01, 6.0620e+01, 6.0600e+01, 6.0610e+01,\n",
            "           6.0560e+01, 6.0540e+01, 6.0580e+01, 6.0550e+01],\n",
            "          [6.0370e+01, 6.0340e+01, 6.0320e+01, 6.0260e+01, 6.0340e+01,\n",
            "           6.0340e+01, 6.0330e+01, 6.0360e+01, 6.0480e+01, 6.0450e+01,\n",
            "           6.0360e+01, 6.0290e+01, 6.0290e+01, 6.0350e+01, 6.0500e+01,\n",
            "           6.0536e+01, 6.0600e+01, 6.0690e+01, 6.0635e+01, 6.0610e+01,\n",
            "           6.0570e+01, 6.0740e+01, 6.0580e+01, 6.0770e+01],\n",
            "          [4.3308e+04, 2.6320e+04, 5.6739e+04, 3.1378e+04, 1.9403e+04,\n",
            "           8.2990e+03, 1.1544e+04, 1.4484e+04, 6.3267e+04, 3.5651e+04,\n",
            "           2.4119e+04, 6.0299e+04, 2.0308e+04, 2.6739e+04, 9.6105e+04,\n",
            "           3.5818e+04, 2.8146e+04, 3.1442e+04, 4.8781e+04, 4.9893e+04,\n",
            "           5.6334e+04, 7.4884e+04, 1.8651e+04, 4.2380e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5420, 2.7647, 0.2083]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0913, 0.8432, 0.0654]], device='cuda:0')\n",
            "[tensor([[[[6.0770e+01, 6.0859e+01, 6.0965e+01, 6.0970e+01, 6.1020e+01,\n",
            "           6.1080e+01, 6.0980e+01, 6.0980e+01, 6.1030e+01, 6.1060e+01,\n",
            "           6.0945e+01, 6.0990e+01, 6.1020e+01, 6.0980e+01, 6.1000e+01,\n",
            "           6.0995e+01, 6.0970e+01, 6.0930e+01, 6.0970e+01, 6.1030e+01,\n",
            "           6.1180e+01, 6.1240e+01, 6.1200e+01, 6.1140e+01],\n",
            "          [6.0870e+01, 6.0990e+01, 6.0990e+01, 6.1030e+01, 6.1080e+01,\n",
            "           6.1090e+01, 6.1044e+01, 6.1050e+01, 6.1090e+01, 6.1079e+01,\n",
            "           6.1010e+01, 6.1020e+01, 6.1040e+01, 6.1005e+01, 6.1025e+01,\n",
            "           6.1010e+01, 6.1040e+01, 6.1010e+01, 6.1040e+01, 6.1040e+01,\n",
            "           6.1180e+01, 6.1240e+01, 6.1200e+01, 6.1140e+01],\n",
            "          [6.0750e+01, 6.0859e+01, 6.0940e+01, 6.0970e+01, 6.1020e+01,\n",
            "           6.0960e+01, 6.0950e+01, 6.0980e+01, 6.1030e+01, 6.0920e+01,\n",
            "           6.0940e+01, 6.0945e+01, 6.0980e+01, 6.0950e+01, 6.0965e+01,\n",
            "           6.0940e+01, 6.0920e+01, 6.0900e+01, 6.0960e+01, 6.1010e+01,\n",
            "           6.1180e+01, 6.1180e+01, 6.1160e+01, 6.1130e+01],\n",
            "          [6.0850e+01, 6.0960e+01, 6.0950e+01, 6.1010e+01, 6.1070e+01,\n",
            "           6.0980e+01, 6.0975e+01, 6.1030e+01, 6.1070e+01, 6.0933e+01,\n",
            "           6.0994e+01, 6.1020e+01, 6.0980e+01, 6.1000e+01, 6.0990e+01,\n",
            "           6.0970e+01, 6.0930e+01, 6.1010e+01, 6.1040e+01, 6.1010e+01,\n",
            "           6.1180e+01, 6.1180e+01, 6.1160e+01, 6.1130e+01],\n",
            "          [5.9402e+04, 3.7974e+04, 4.5972e+04, 6.8982e+04, 6.2898e+04,\n",
            "           1.0941e+05, 7.0725e+04, 3.7937e+04, 2.5935e+04, 3.2617e+04,\n",
            "           4.6795e+04, 5.0494e+04, 6.1108e+04, 7.2913e+04, 1.0943e+05,\n",
            "           1.3882e+05, 1.0927e+05, 4.9487e+05, 1.9561e+05, 2.0400e+03,\n",
            "           3.1000e+02, 1.0900e+03, 2.2400e+02, 3.1060e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5463, 2.7853, 0.2126]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0901, 0.8454, 0.0645]], device='cuda:0')\n",
            "[tensor([[[[6.1110e+01, 6.1060e+01, 6.1130e+01, 6.1170e+01, 6.1170e+01,\n",
            "           6.1170e+01, 6.1210e+01, 6.1142e+01, 6.1160e+01, 6.1160e+01,\n",
            "           6.1200e+01, 6.1260e+01, 6.1250e+01, 6.1390e+01, 6.1380e+01,\n",
            "           6.1340e+01, 6.1250e+01, 6.1350e+01, 6.1380e+01, 6.1420e+01,\n",
            "           6.1340e+01, 6.1330e+01, 6.1190e+01, 6.1170e+01],\n",
            "          [6.1110e+01, 6.1060e+01, 6.1140e+01, 6.1170e+01, 6.1170e+01,\n",
            "           6.1170e+01, 6.1210e+01, 6.1150e+01, 6.1240e+01, 6.1240e+01,\n",
            "           6.1200e+01, 6.1260e+01, 6.1460e+01, 6.1460e+01, 6.1380e+01,\n",
            "           6.1360e+01, 6.1390e+01, 6.1380e+01, 6.1430e+01, 6.1430e+01,\n",
            "           6.1410e+01, 6.1340e+01, 6.1230e+01, 6.1272e+01],\n",
            "          [6.1110e+01, 6.1030e+01, 6.1130e+01, 6.1150e+01, 6.1150e+01,\n",
            "           6.1150e+01, 6.1140e+01, 6.1142e+01, 6.1160e+01, 6.1160e+01,\n",
            "           6.1200e+01, 6.1230e+01, 6.1240e+01, 6.1370e+01, 6.1280e+01,\n",
            "           6.1210e+01, 6.1230e+01, 6.1310e+01, 6.1290e+01, 6.1320e+01,\n",
            "           6.1330e+01, 6.1141e+01, 6.1140e+01, 6.1150e+01],\n",
            "          [6.1110e+01, 6.1030e+01, 6.1140e+01, 6.1150e+01, 6.1150e+01,\n",
            "           6.1150e+01, 6.1140e+01, 6.1150e+01, 6.1240e+01, 6.1240e+01,\n",
            "           6.1200e+01, 6.1240e+01, 6.1380e+01, 6.1396e+01, 6.1340e+01,\n",
            "           6.1230e+01, 6.1340e+01, 6.1360e+01, 6.1410e+01, 6.1346e+01,\n",
            "           6.1330e+01, 6.1160e+01, 6.1160e+01, 6.1272e+01],\n",
            "          [1.4040e+03, 2.6000e+02, 6.0000e+02, 1.0080e+03, 0.0000e+00,\n",
            "           0.0000e+00, 2.0050e+03, 3.4300e+02, 2.6010e+03, 0.0000e+00,\n",
            "           7.5100e+02, 4.5800e+02, 1.1701e+05, 3.6424e+04, 1.5765e+05,\n",
            "           8.4797e+04, 5.5884e+04, 3.5531e+04, 1.1466e+05, 1.0897e+05,\n",
            "           5.2830e+04, 1.0339e+05, 5.9732e+04, 8.4390e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5483, 2.7969, 0.2123]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0894, 0.8468, 0.0639]], device='cuda:0')\n",
            "[tensor([[[[6.1280e+01, 6.1230e+01, 6.1360e+01, 6.1551e+01, 6.1480e+01,\n",
            "           6.1520e+01, 6.1540e+01, 6.1600e+01, 6.1560e+01, 6.1660e+01,\n",
            "           6.1640e+01, 6.1620e+01, 6.1630e+01, 6.1580e+01, 6.1690e+01,\n",
            "           6.1670e+01, 6.1820e+01, 6.1878e+01, 6.1810e+01, 6.1750e+01,\n",
            "           6.1610e+01, 6.1570e+01, 6.1600e+01, 6.1645e+01],\n",
            "          [6.1330e+01, 6.1420e+01, 6.1570e+01, 6.1570e+01, 6.1580e+01,\n",
            "           6.1580e+01, 6.1620e+01, 6.1600e+01, 6.1650e+01, 6.1700e+01,\n",
            "           6.1660e+01, 6.1690e+01, 6.1700e+01, 6.1700e+01, 6.1690e+01,\n",
            "           6.1830e+01, 6.1900e+01, 6.1890e+01, 6.1835e+01, 6.1759e+01,\n",
            "           6.1640e+01, 6.1620e+01, 6.1670e+01, 6.1710e+01],\n",
            "          [6.1230e+01, 6.1220e+01, 6.1360e+01, 6.1440e+01, 6.1470e+01,\n",
            "           6.1490e+01, 6.1540e+01, 6.1540e+01, 6.1540e+01, 6.1610e+01,\n",
            "           6.1605e+01, 6.1600e+01, 6.1480e+01, 6.1565e+01, 6.1645e+01,\n",
            "           6.1670e+01, 6.1815e+01, 6.1805e+01, 6.1730e+01, 6.1610e+01,\n",
            "           6.1542e+01, 6.1450e+01, 6.1560e+01, 6.1623e+01],\n",
            "          [6.1235e+01, 6.1340e+01, 6.1550e+01, 6.1480e+01, 6.1511e+01,\n",
            "           6.1545e+01, 6.1610e+01, 6.1570e+01, 6.1650e+01, 6.1640e+01,\n",
            "           6.1620e+01, 6.1630e+01, 6.1580e+01, 6.1700e+01, 6.1670e+01,\n",
            "           6.1810e+01, 6.1880e+01, 6.1805e+01, 6.1750e+01, 6.1610e+01,\n",
            "           6.1570e+01, 6.1600e+01, 6.1651e+01, 6.1708e+01],\n",
            "          [5.9748e+04, 1.2650e+05, 1.9404e+05, 1.3272e+05, 6.8431e+04,\n",
            "           5.9193e+04, 5.0786e+04, 4.7508e+04, 3.9903e+04, 5.8838e+04,\n",
            "           9.0791e+04, 5.6830e+04, 4.6916e+05, 4.6369e+04, 3.9985e+04,\n",
            "           9.1440e+04, 4.6005e+04, 4.7029e+04, 5.1449e+04, 8.9372e+04,\n",
            "           3.2987e+04, 6.7386e+04, 4.2677e+04, 2.0868e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5512, 2.8172, 0.2149]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0881, 0.8490, 0.0629]], device='cuda:0')\n",
            "[tensor([[[[6.1690e+01, 6.1600e+01, 6.1570e+01, 6.1520e+01, 6.1620e+01,\n",
            "           6.1545e+01, 6.1600e+01, 6.1531e+01, 6.1520e+01, 6.1280e+01,\n",
            "           6.1090e+01, 6.1140e+01, 6.1160e+01, 6.1300e+01, 6.1308e+01,\n",
            "           6.1275e+01, 6.1280e+01, 6.1280e+01, 6.1330e+01, 6.1320e+01,\n",
            "           6.1460e+01, 6.1450e+01, 6.1430e+01, 6.1310e+01],\n",
            "          [6.1690e+01, 6.1660e+01, 6.1570e+01, 6.1610e+01, 6.1670e+01,\n",
            "           6.1610e+01, 6.1610e+01, 6.1570e+01, 6.1530e+01, 6.1300e+01,\n",
            "           6.1210e+01, 6.1205e+01, 6.1330e+01, 6.1320e+01, 6.1320e+01,\n",
            "           6.1301e+01, 6.1310e+01, 6.1390e+01, 6.1340e+01, 6.1470e+01,\n",
            "           6.1480e+01, 6.1460e+01, 6.1430e+01, 6.1400e+01],\n",
            "          [6.1610e+01, 6.1525e+01, 6.1510e+01, 6.1520e+01, 6.1540e+01,\n",
            "           6.1545e+01, 6.1510e+01, 6.1490e+01, 6.1230e+01, 6.1100e+01,\n",
            "           6.0980e+01, 6.1130e+01, 6.1120e+01, 6.1260e+01, 6.1220e+01,\n",
            "           6.1260e+01, 6.1240e+01, 6.1270e+01, 6.1280e+01, 6.1260e+01,\n",
            "           6.1420e+01, 6.1405e+01, 6.1280e+01, 6.1270e+01],\n",
            "          [6.1640e+01, 6.1570e+01, 6.1530e+01, 6.1600e+01, 6.1540e+01,\n",
            "           6.1610e+01, 6.1550e+01, 6.1520e+01, 6.1290e+01, 6.1110e+01,\n",
            "           6.1135e+01, 6.1150e+01, 6.1330e+01, 6.1310e+01, 6.1270e+01,\n",
            "           6.1290e+01, 6.1295e+01, 6.1325e+01, 6.1320e+01, 6.1470e+01,\n",
            "           6.1450e+01, 6.1430e+01, 6.1290e+01, 6.1270e+01],\n",
            "          [2.9023e+04, 5.9475e+04, 2.5074e+04, 3.1959e+04, 1.5337e+04,\n",
            "           3.9223e+04, 3.3825e+04, 1.5799e+04, 7.7544e+04, 2.9791e+04,\n",
            "           8.7193e+04, 2.1330e+04, 3.2384e+04, 1.3791e+04, 2.3126e+04,\n",
            "           8.9060e+03, 9.3380e+03, 2.9184e+04, 2.4734e+04, 6.5113e+04,\n",
            "           3.1839e+04, 2.4140e+04, 2.5685e+04, 4.2835e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5510, 2.8030, 0.2178]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0891, 0.8470, 0.0639]], device='cuda:0')\n",
            "[tensor([[[[6.1260e+01, 6.1175e+01, 6.1100e+01, 6.1100e+01, 6.1030e+01,\n",
            "           6.1110e+01, 6.1160e+01, 6.1160e+01, 6.1151e+01, 6.1250e+01,\n",
            "           6.1160e+01, 6.1200e+01, 6.1220e+01, 6.1180e+01, 6.1100e+01,\n",
            "           6.1170e+01, 6.1100e+01, 6.1070e+01, 6.1050e+01, 6.1100e+01,\n",
            "           6.1120e+01, 6.1130e+01, 6.1080e+01, 6.1080e+01],\n",
            "          [6.1270e+01, 6.1210e+01, 6.1118e+01, 6.1100e+01, 6.1100e+01,\n",
            "           6.1170e+01, 6.1180e+01, 6.1160e+01, 6.1250e+01, 6.1250e+01,\n",
            "           6.1220e+01, 6.1260e+01, 6.1230e+01, 6.1180e+01, 6.1180e+01,\n",
            "           6.1175e+01, 6.1100e+01, 6.1100e+01, 6.1080e+01, 6.1100e+01,\n",
            "           6.1140e+01, 6.1130e+01, 6.1080e+01, 6.1080e+01],\n",
            "          [6.1150e+01, 6.1085e+01, 6.1055e+01, 6.1010e+01, 6.1030e+01,\n",
            "           6.1100e+01, 6.1140e+01, 6.1110e+01, 6.1150e+01, 6.1160e+01,\n",
            "           6.1155e+01, 6.1200e+01, 6.1150e+01, 6.1100e+01, 6.1100e+01,\n",
            "           6.1100e+01, 6.1020e+01, 6.1020e+01, 6.1030e+01, 6.1100e+01,\n",
            "           6.1050e+01, 6.1080e+01, 6.1070e+01, 6.1070e+01],\n",
            "          [6.1160e+01, 6.1085e+01, 6.1100e+01, 6.1040e+01, 6.1100e+01,\n",
            "           6.1170e+01, 6.1170e+01, 6.1150e+01, 6.1250e+01, 6.1160e+01,\n",
            "           6.1200e+01, 6.1230e+01, 6.1170e+01, 6.1100e+01, 6.1170e+01,\n",
            "           6.1100e+01, 6.1075e+01, 6.1080e+01, 6.1030e+01, 6.1100e+01,\n",
            "           6.1140e+01, 6.1080e+01, 6.1070e+01, 6.1070e+01],\n",
            "          [2.9228e+04, 2.7676e+04, 3.2251e+04, 3.9457e+04, 2.1117e+04,\n",
            "           3.3931e+04, 3.2790e+04, 3.7894e+04, 1.6513e+04, 2.6636e+04,\n",
            "           2.9516e+04, 3.7303e+04, 1.6901e+04, 8.7161e+04, 2.3693e+04,\n",
            "           3.3438e+04, 9.5926e+04, 3.3862e+05, 3.5131e+05, 2.2000e+02,\n",
            "           2.0300e+03, 4.0000e+02, 5.0000e+02, 0.0000e+00]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5480, 2.7877, 0.2152]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0900, 0.8454, 0.0645]], device='cuda:0')\n",
            "[tensor([[[[6.1020e+01, 6.1070e+01, 6.1070e+01, 6.1060e+01, 6.1130e+01,\n",
            "           6.1170e+01, 6.1140e+01, 6.1180e+01, 6.1180e+01, 6.1200e+01,\n",
            "           6.1120e+01, 6.1200e+01, 6.1240e+01, 6.1130e+01, 6.1120e+01,\n",
            "           6.1160e+01, 6.1250e+01, 6.1263e+01, 6.1260e+01, 6.1350e+01,\n",
            "           6.1330e+01, 6.1290e+01, 6.1440e+01, 6.1490e+01],\n",
            "          [6.1050e+01, 6.1120e+01, 6.1070e+01, 6.1080e+01, 6.1160e+01,\n",
            "           6.1180e+01, 6.1170e+01, 6.1200e+01, 6.1180e+01, 6.1200e+01,\n",
            "           6.1290e+01, 6.1220e+01, 6.1260e+01, 6.1130e+01, 6.1170e+01,\n",
            "           6.1240e+01, 6.1330e+01, 6.1350e+01, 6.1380e+01, 6.1350e+01,\n",
            "           6.1340e+01, 6.1440e+01, 6.1520e+01, 6.1518e+01],\n",
            "          [6.1020e+01, 6.1030e+01, 6.1070e+01, 6.1060e+01, 6.1130e+01,\n",
            "           6.1150e+01, 6.1140e+01, 6.1180e+01, 6.1140e+01, 6.1140e+01,\n",
            "           6.1120e+01, 6.1200e+01, 6.1110e+01, 6.1060e+01, 6.1100e+01,\n",
            "           6.1100e+01, 6.1230e+01, 6.1240e+01, 6.1210e+01, 6.1270e+01,\n",
            "           6.1210e+01, 6.1290e+01, 6.1440e+01, 6.1410e+01],\n",
            "          [6.1050e+01, 6.1030e+01, 6.1070e+01, 6.1080e+01, 6.1160e+01,\n",
            "           6.1180e+01, 6.1170e+01, 6.1200e+01, 6.1140e+01, 6.1140e+01,\n",
            "           6.1290e+01, 6.1220e+01, 6.1170e+01, 6.1120e+01, 6.1155e+01,\n",
            "           6.1240e+01, 6.1260e+01, 6.1260e+01, 6.1340e+01, 6.1330e+01,\n",
            "           6.1290e+01, 6.1430e+01, 6.1500e+01, 6.1518e+01],\n",
            "          [1.0400e+04, 6.5498e+04, 1.0000e+02, 1.0125e+04, 7.9200e+02,\n",
            "           6.1100e+02, 3.7500e+02, 6.8500e+02, 1.4180e+03, 1.6380e+03,\n",
            "           1.5720e+03, 1.3600e+03, 6.9045e+04, 3.6506e+04, 4.2652e+04,\n",
            "           3.7892e+04, 4.6483e+04, 1.7630e+05, 9.0570e+04, 5.8519e+04,\n",
            "           7.9627e+04, 6.3731e+04, 5.9874e+04, 1.6764e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5474, 2.7961, 0.2110]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0894, 0.8468, 0.0638]], device='cuda:0')\n",
            "[tensor([[[[6.1470e+01, 6.1560e+01, 6.1620e+01, 6.1645e+01, 6.1670e+01,\n",
            "           6.1650e+01, 6.1590e+01, 6.1700e+01, 6.1745e+01, 6.1750e+01,\n",
            "           6.1859e+01, 6.1890e+01, 6.1890e+01, 6.1830e+01, 6.2080e+01,\n",
            "           6.1870e+01, 6.1760e+01, 6.1770e+01, 6.1820e+01, 6.1710e+01,\n",
            "           6.1650e+01, 6.1660e+01, 6.1630e+01, 6.1710e+01],\n",
            "          [6.1590e+01, 6.1640e+01, 6.1660e+01, 6.1680e+01, 6.1700e+01,\n",
            "           6.1660e+01, 6.1750e+01, 6.1795e+01, 6.1760e+01, 6.1880e+01,\n",
            "           6.1890e+01, 6.1930e+01, 6.1910e+01, 6.2170e+01, 6.2081e+01,\n",
            "           6.1900e+01, 6.1860e+01, 6.1850e+01, 6.1820e+01, 6.1750e+01,\n",
            "           6.1680e+01, 6.1690e+01, 6.1730e+01, 6.1755e+01],\n",
            "          [6.1470e+01, 6.1530e+01, 6.1590e+01, 6.1620e+01, 6.1620e+01,\n",
            "           6.1580e+01, 6.1420e+01, 6.1680e+01, 6.1670e+01, 6.1726e+01,\n",
            "           6.1810e+01, 6.1830e+01, 6.1790e+01, 6.1790e+01, 6.1801e+01,\n",
            "           6.1754e+01, 6.1750e+01, 6.1770e+01, 6.1690e+01, 6.1605e+01,\n",
            "           6.1610e+01, 6.1610e+01, 6.1620e+01, 6.1650e+01],\n",
            "          [6.1560e+01, 6.1620e+01, 6.1650e+01, 6.1670e+01, 6.1655e+01,\n",
            "           6.1610e+01, 6.1700e+01, 6.1745e+01, 6.1747e+01, 6.1850e+01,\n",
            "           6.1870e+01, 6.1890e+01, 6.1828e+01, 6.2090e+01, 6.1880e+01,\n",
            "           6.1760e+01, 6.1760e+01, 6.1820e+01, 6.1720e+01, 6.1660e+01,\n",
            "           6.1665e+01, 6.1640e+01, 6.1710e+01, 6.1700e+01],\n",
            "          [2.1546e+04, 2.6719e+04, 2.8742e+04, 2.1110e+04, 2.6206e+04,\n",
            "           6.5423e+04, 1.7041e+05, 6.7878e+04, 7.9877e+04, 7.3431e+04,\n",
            "           3.4789e+04, 7.8089e+04, 4.4891e+04, 3.1280e+05, 6.4342e+04,\n",
            "           5.9766e+04, 3.3618e+04, 3.0562e+04, 2.1394e+04, 9.3831e+04,\n",
            "           2.8614e+04, 4.3518e+04, 4.2416e+04, 2.1685e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5526, 2.8187, 0.2161]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0881, 0.8491, 0.0629]], device='cuda:0')\n",
            "[tensor([[[[6.1720e+01, 6.1730e+01, 6.1700e+01, 6.1677e+01, 6.1660e+01,\n",
            "           6.1680e+01, 6.1730e+01, 6.1671e+01, 6.1590e+01, 6.1500e+01,\n",
            "           6.1420e+01, 6.1440e+01, 6.1500e+01, 6.1480e+01, 6.1470e+01,\n",
            "           6.1601e+01, 6.1620e+01, 6.1665e+01, 6.1640e+01, 6.1710e+01,\n",
            "           6.1650e+01, 6.1490e+01, 6.1405e+01, 6.1410e+01],\n",
            "          [6.1770e+01, 6.1730e+01, 6.1740e+01, 6.1700e+01, 6.1710e+01,\n",
            "           6.1750e+01, 6.1770e+01, 6.1690e+01, 6.1610e+01, 6.1530e+01,\n",
            "           6.1470e+01, 6.1545e+01, 6.1510e+01, 6.1500e+01, 6.1650e+01,\n",
            "           6.1650e+01, 6.1694e+01, 6.1700e+01, 6.1760e+01, 6.1730e+01,\n",
            "           6.1670e+01, 6.1500e+01, 6.1460e+01, 6.1410e+01],\n",
            "          [6.1700e+01, 6.1650e+01, 6.1668e+01, 6.1650e+01, 6.1640e+01,\n",
            "           6.1670e+01, 6.1660e+01, 6.1560e+01, 6.1490e+01, 6.1380e+01,\n",
            "           6.1400e+01, 6.1440e+01, 6.1460e+01, 6.1450e+01, 6.1470e+01,\n",
            "           6.1575e+01, 6.1620e+01, 6.1625e+01, 6.1640e+01, 6.1660e+01,\n",
            "           6.1480e+01, 6.1400e+01, 6.1390e+01, 6.1300e+01],\n",
            "          [6.1730e+01, 6.1680e+01, 6.1680e+01, 6.1670e+01, 6.1701e+01,\n",
            "           6.1730e+01, 6.1680e+01, 6.1580e+01, 6.1500e+01, 6.1420e+01,\n",
            "           6.1421e+01, 6.1500e+01, 6.1480e+01, 6.1480e+01, 6.1610e+01,\n",
            "           6.1650e+01, 6.1670e+01, 6.1630e+01, 6.1740e+01, 6.1660e+01,\n",
            "           6.1500e+01, 6.1400e+01, 6.1415e+01, 6.1335e+01],\n",
            "          [1.7591e+04, 1.6217e+04, 8.7540e+03, 1.9992e+04, 1.1493e+04,\n",
            "           1.8456e+04, 3.3018e+04, 3.0508e+04, 3.0521e+04, 4.5585e+04,\n",
            "           6.7692e+04, 4.0316e+04, 1.4734e+04, 1.3387e+04, 3.0144e+04,\n",
            "           2.5523e+04, 1.7773e+04, 2.5584e+04, 2.8054e+04, 2.3903e+04,\n",
            "           4.3220e+04, 2.7196e+04, 4.2803e+04, 7.4220e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5527, 2.8129, 0.2183]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0885, 0.8482, 0.0633]], device='cuda:0')\n",
            "[tensor([[[[6.1340e+01, 6.1280e+01, 6.1240e+01, 6.1220e+01, 6.1220e+01,\n",
            "           6.1250e+01, 6.1240e+01, 6.1130e+01, 6.1115e+01, 6.0910e+01,\n",
            "           6.1020e+01, 6.0900e+01, 6.0825e+01, 6.0795e+01, 6.0680e+01,\n",
            "           6.0700e+01, 6.0645e+01, 6.0650e+01, 6.0660e+01, 6.0570e+01,\n",
            "           6.0520e+01, 6.0500e+01, 6.0500e+01, 6.0450e+01],\n",
            "          [6.1380e+01, 6.1305e+01, 6.1290e+01, 6.1250e+01, 6.1240e+01,\n",
            "           6.1260e+01, 6.1260e+01, 6.1150e+01, 6.1140e+01, 6.1020e+01,\n",
            "           6.1030e+01, 6.0900e+01, 6.0855e+01, 6.0800e+01, 6.0790e+01,\n",
            "           6.0710e+01, 6.0690e+01, 6.0690e+01, 6.0660e+01, 6.0600e+01,\n",
            "           6.0660e+01, 6.0500e+01, 6.0500e+01, 6.0500e+01],\n",
            "          [6.1280e+01, 6.1210e+01, 6.1210e+01, 6.1180e+01, 6.1190e+01,\n",
            "           6.1212e+01, 6.1140e+01, 6.1100e+01, 6.0890e+01, 6.0910e+01,\n",
            "           6.0890e+01, 6.0815e+01, 6.0785e+01, 6.0680e+01, 6.0650e+01,\n",
            "           6.0635e+01, 6.0630e+01, 6.0605e+01, 6.0610e+01, 6.0570e+01,\n",
            "           6.0500e+01, 6.0440e+01, 6.0500e+01, 6.0450e+01],\n",
            "          [6.1280e+01, 6.1240e+01, 6.1210e+01, 6.1220e+01, 6.1240e+01,\n",
            "           6.1230e+01, 6.1140e+01, 6.1101e+01, 6.0910e+01, 6.1020e+01,\n",
            "           6.0905e+01, 6.0820e+01, 6.0785e+01, 6.0690e+01, 6.0710e+01,\n",
            "           6.0660e+01, 6.0640e+01, 6.0670e+01, 6.0610e+01, 6.0590e+01,\n",
            "           6.0520e+01, 6.0440e+01, 6.0500e+01, 6.0500e+01],\n",
            "          [3.8267e+04, 2.0503e+04, 2.7139e+04, 2.1774e+04, 2.3309e+04,\n",
            "           1.1853e+04, 1.5274e+04, 1.4667e+04, 7.8075e+04, 3.6661e+04,\n",
            "           9.2692e+04, 5.3273e+04, 9.1708e+04, 6.6702e+04, 1.0003e+05,\n",
            "           7.4746e+04, 1.2700e+05, 1.6270e+05, 4.5695e+04, 9.1600e+02,\n",
            "           1.3056e+04, 5.2650e+03, 1.0000e+03, 7.3000e+02]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5481, 2.7727, 0.2207]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0912, 0.8431, 0.0657]], device='cuda:0')\n",
            "[tensor([[[[6.0560e+01, 6.0690e+01, 6.0800e+01, 6.0900e+01, 6.0850e+01,\n",
            "           6.0920e+01, 6.0950e+01, 6.1000e+01, 6.0930e+01, 6.0930e+01,\n",
            "           6.0870e+01, 6.0980e+01, 6.0870e+01, 6.0730e+01, 6.0800e+01,\n",
            "           6.0670e+01, 6.0740e+01, 6.0480e+01, 6.0440e+01, 6.0450e+01,\n",
            "           6.0335e+01, 6.0250e+01, 6.0275e+01, 6.0280e+01],\n",
            "          [6.0640e+01, 6.0810e+01, 6.0830e+01, 6.0900e+01, 6.1000e+01,\n",
            "           6.0940e+01, 6.1020e+01, 6.1030e+01, 6.0930e+01, 6.0930e+01,\n",
            "           6.0880e+01, 6.0990e+01, 6.0870e+01, 6.0850e+01, 6.0800e+01,\n",
            "           6.0770e+01, 6.0760e+01, 6.0530e+01, 6.0450e+01, 6.0520e+01,\n",
            "           6.0335e+01, 6.0380e+01, 6.0340e+01, 6.0439e+01],\n",
            "          [6.0560e+01, 6.0670e+01, 6.0750e+01, 6.0800e+01, 6.0800e+01,\n",
            "           6.0910e+01, 6.0950e+01, 6.0960e+01, 6.0870e+01, 6.0870e+01,\n",
            "           6.0840e+01, 6.0840e+01, 6.0660e+01, 6.0670e+01, 6.0670e+01,\n",
            "           6.0590e+01, 6.0451e+01, 6.0340e+01, 6.0220e+01, 6.0340e+01,\n",
            "           6.0184e+01, 6.0230e+01, 6.0080e+01, 6.0230e+01],\n",
            "          [6.0630e+01, 6.0810e+01, 6.0830e+01, 6.0800e+01, 6.0880e+01,\n",
            "           6.0920e+01, 6.1010e+01, 6.0960e+01, 6.0870e+01, 6.0870e+01,\n",
            "           6.0850e+01, 6.0860e+01, 6.0750e+01, 6.0790e+01, 6.0670e+01,\n",
            "           6.0740e+01, 6.0510e+01, 6.0470e+01, 6.0430e+01, 6.0350e+01,\n",
            "           6.0280e+01, 6.0285e+01, 6.0290e+01, 6.0420e+01],\n",
            "          [3.4540e+03, 1.3400e+03, 2.0500e+03, 2.8290e+03, 1.0374e+04,\n",
            "           2.2560e+03, 2.9970e+03, 2.0580e+03, 2.0210e+03, 0.0000e+00,\n",
            "           1.0620e+03, 3.6270e+03, 1.3626e+05, 1.5506e+05, 1.3821e+05,\n",
            "           8.4413e+04, 4.7235e+04, 6.1421e+04, 1.3963e+05, 2.6291e+05,\n",
            "           1.3394e+05, 7.7059e+04, 9.0806e+04, 7.7567e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5457, 2.7675, 0.2183]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0914, 0.8428, 0.0659]], device='cuda:0')\n",
            "[tensor([[[[6.0420e+01, 6.0690e+01, 6.0790e+01, 6.0910e+01, 6.0995e+01,\n",
            "           6.0885e+01, 6.0955e+01, 6.0810e+01, 6.0990e+01, 6.0920e+01,\n",
            "           6.1040e+01, 6.1160e+01, 6.1190e+01, 6.0990e+01, 6.0850e+01,\n",
            "           6.0820e+01, 6.0795e+01, 6.0740e+01, 6.0830e+01, 6.0745e+01,\n",
            "           6.0760e+01, 6.0860e+01, 6.0760e+01, 6.0840e+01],\n",
            "          [6.0700e+01, 6.0840e+01, 6.0928e+01, 6.1010e+01, 6.1070e+01,\n",
            "           6.0950e+01, 6.0966e+01, 6.1000e+01, 6.1000e+01, 6.1060e+01,\n",
            "           6.1240e+01, 6.1220e+01, 6.1190e+01, 6.1040e+01, 6.0900e+01,\n",
            "           6.0865e+01, 6.0860e+01, 6.0860e+01, 6.0830e+01, 6.0850e+01,\n",
            "           6.0850e+01, 6.0870e+01, 6.0850e+01, 6.0900e+01],\n",
            "          [6.0370e+01, 6.0680e+01, 6.0750e+01, 6.0870e+01, 6.0870e+01,\n",
            "           6.0870e+01, 6.0780e+01, 6.0790e+01, 6.0870e+01, 6.0910e+01,\n",
            "           6.1040e+01, 6.1135e+01, 6.0970e+01, 6.0820e+01, 6.0812e+01,\n",
            "           6.0710e+01, 6.0723e+01, 6.0740e+01, 6.0660e+01, 6.0740e+01,\n",
            "           6.0715e+01, 6.0720e+01, 6.0690e+01, 6.0820e+01],\n",
            "          [6.0690e+01, 6.0790e+01, 6.0910e+01, 6.0980e+01, 6.0885e+01,\n",
            "           6.0940e+01, 6.0830e+01, 6.0980e+01, 6.0900e+01, 6.1050e+01,\n",
            "           6.1160e+01, 6.1190e+01, 6.0980e+01, 6.0850e+01, 6.0860e+01,\n",
            "           6.0770e+01, 6.0745e+01, 6.0830e+01, 6.0750e+01, 6.0780e+01,\n",
            "           6.0850e+01, 6.0760e+01, 6.0820e+01, 6.0850e+01],\n",
            "          [9.4996e+04, 6.7424e+04, 8.9579e+04, 6.6602e+04, 7.4928e+04,\n",
            "           5.8904e+04, 5.9315e+04, 6.4343e+04, 3.3929e+04, 4.9673e+04,\n",
            "           4.5153e+04, 4.6501e+04, 4.1948e+04, 5.1117e+04, 2.3327e+04,\n",
            "           4.4455e+04, 1.0479e+05, 2.2140e+04, 4.3335e+04, 2.0971e+04,\n",
            "           6.9431e+04, 3.0066e+04, 2.7292e+04, 3.6427e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5449, 2.7771, 0.2147]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0906, 0.8443, 0.0651]], device='cuda:0')\n",
            "[tensor([[[[6.0850e+01, 6.0920e+01, 6.0990e+01, 6.1040e+01, 6.0930e+01,\n",
            "           6.0900e+01, 6.0830e+01, 6.0760e+01, 6.0760e+01, 6.0840e+01,\n",
            "           6.0775e+01, 6.0733e+01, 6.0760e+01, 6.0840e+01, 6.0870e+01,\n",
            "           6.0890e+01, 6.0935e+01, 6.0900e+01, 6.0880e+01, 6.0920e+01,\n",
            "           6.0820e+01, 6.0930e+01, 6.0940e+01, 6.0950e+01],\n",
            "          [6.0910e+01, 6.1001e+01, 6.1050e+01, 6.1040e+01, 6.0970e+01,\n",
            "           6.0900e+01, 6.0860e+01, 6.0815e+01, 6.0880e+01, 6.0865e+01,\n",
            "           6.0785e+01, 6.0770e+01, 6.0850e+01, 6.0900e+01, 6.0910e+01,\n",
            "           6.0930e+01, 6.0945e+01, 6.0910e+01, 6.0920e+01, 6.0930e+01,\n",
            "           6.0960e+01, 6.0950e+01, 6.0970e+01, 6.0990e+01],\n",
            "          [6.0790e+01, 6.0880e+01, 6.0975e+01, 6.0910e+01, 6.0895e+01,\n",
            "           6.0830e+01, 6.0760e+01, 6.0680e+01, 6.0750e+01, 6.0771e+01,\n",
            "           6.0710e+01, 6.0720e+01, 6.0743e+01, 6.0800e+01, 6.0865e+01,\n",
            "           6.0870e+01, 6.0870e+01, 6.0840e+01, 6.0850e+01, 6.0805e+01,\n",
            "           6.0820e+01, 6.0880e+01, 6.0910e+01, 6.0880e+01],\n",
            "          [6.0910e+01, 6.1000e+01, 6.1040e+01, 6.0910e+01, 6.0895e+01,\n",
            "           6.0840e+01, 6.0760e+01, 6.0740e+01, 6.0840e+01, 6.0771e+01,\n",
            "           6.0740e+01, 6.0765e+01, 6.0830e+01, 6.0860e+01, 6.0890e+01,\n",
            "           6.0930e+01, 6.0900e+01, 6.0890e+01, 6.0910e+01, 6.0810e+01,\n",
            "           6.0930e+01, 6.0950e+01, 6.0950e+01, 6.0980e+01],\n",
            "          [2.4882e+04, 6.4020e+04, 3.3405e+04, 2.0786e+04, 1.5266e+05,\n",
            "           3.6773e+04, 4.0167e+04, 4.2394e+04, 2.2245e+04, 3.4396e+04,\n",
            "           3.3303e+04, 2.1706e+04, 1.9415e+04, 1.0970e+04, 2.8510e+04,\n",
            "           2.6617e+04, 2.1982e+04, 3.4964e+04, 2.3841e+04, 2.6306e+04,\n",
            "           1.7219e+04, 1.5350e+04, 3.7858e+04, 5.6743e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5461, 2.7796, 0.2140]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0905, 0.8446, 0.0649]], device='cuda:0')\n",
            "[tensor([[[[6.0970e+01, 6.0920e+01, 6.0960e+01, 6.0950e+01, 6.0945e+01,\n",
            "           6.0900e+01, 6.0840e+01, 6.0678e+01, 6.0560e+01, 6.0570e+01,\n",
            "           6.0630e+01, 6.0570e+01, 6.0500e+01, 6.0570e+01, 6.0610e+01,\n",
            "           6.0740e+01, 6.0790e+01, 6.0705e+01, 6.0810e+01, 6.0830e+01,\n",
            "           6.0780e+01, 6.0810e+01, 6.0810e+01, 6.0810e+01],\n",
            "          [6.0970e+01, 6.0960e+01, 6.0995e+01, 6.0960e+01, 6.0945e+01,\n",
            "           6.0900e+01, 6.0840e+01, 6.0690e+01, 6.0600e+01, 6.0650e+01,\n",
            "           6.0650e+01, 6.0590e+01, 6.0600e+01, 6.0620e+01, 6.0820e+01,\n",
            "           6.0790e+01, 6.0790e+01, 6.0800e+01, 6.0880e+01, 6.0830e+01,\n",
            "           6.0790e+01, 6.0810e+01, 6.0810e+01, 6.0810e+01],\n",
            "          [6.0880e+01, 6.0890e+01, 6.0930e+01, 6.0925e+01, 6.0890e+01,\n",
            "           6.0845e+01, 6.0660e+01, 6.0550e+01, 6.0545e+01, 6.0520e+01,\n",
            "           6.0555e+01, 6.0480e+01, 6.0500e+01, 6.0560e+01, 6.0600e+01,\n",
            "           6.0700e+01, 6.0710e+01, 6.0705e+01, 6.0810e+01, 6.0790e+01,\n",
            "           6.0780e+01, 6.0810e+01, 6.0810e+01, 6.0810e+01],\n",
            "          [6.0920e+01, 6.0960e+01, 6.0950e+01, 6.0950e+01, 6.0910e+01,\n",
            "           6.0845e+01, 6.0680e+01, 6.0580e+01, 6.0580e+01, 6.0640e+01,\n",
            "           6.0575e+01, 6.0509e+01, 6.0570e+01, 6.0610e+01, 6.0730e+01,\n",
            "           6.0790e+01, 6.0720e+01, 6.0790e+01, 6.0880e+01, 6.0790e+01,\n",
            "           6.0790e+01, 6.0810e+01, 6.0810e+01, 6.0810e+01],\n",
            "          [3.5189e+04, 3.5909e+04, 4.6194e+04, 5.2843e+04, 1.8212e+04,\n",
            "           7.0555e+04, 6.0526e+04, 1.4654e+05, 1.0333e+05, 1.2396e+05,\n",
            "           1.7014e+05, 3.0789e+04, 3.9722e+04, 3.7036e+04, 7.1568e+04,\n",
            "           4.0867e+04, 8.3415e+04, 9.5308e+04, 8.1900e+02, 3.1609e+04,\n",
            "           2.1030e+03, 7.0300e+02, 0.0000e+00, 0.0000e+00]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5470, 2.7753, 0.2152]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0909, 0.8439, 0.0652]], device='cuda:0')\n",
            "[tensor([[[[ 60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,\n",
            "            60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,\n",
            "            60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,\n",
            "            60.8000,  60.8000,  60.8000],\n",
            "          [ 60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,\n",
            "            60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,\n",
            "            60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,  60.8000,\n",
            "            60.8000,  60.8000,  60.8000],\n",
            "          [ 60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,\n",
            "            60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,\n",
            "            60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,\n",
            "            60.5700,  60.5700,  60.5700],\n",
            "          [ 60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,\n",
            "            60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,\n",
            "            60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,  60.5700,\n",
            "            60.5700,  60.5700,  60.5700],\n",
            "          [460.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "             0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "             0.0000,   0.0000,   0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5448, 2.7715, 0.2128]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0910, 0.8437, 0.0653]], device='cuda:0')\n",
            "[tensor([[[[60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5448, 2.7715, 0.2128]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0910, 0.8437, 0.0653]], device='cuda:0')\n",
            "[tensor([[[[60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5448, 2.7715, 0.2128]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0910, 0.8437, 0.0653]], device='cuda:0')\n",
            "[tensor([[[[60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5448, 2.7715, 0.2128]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0910, 0.8437, 0.0653]], device='cuda:0')\n",
            "[tensor([[[[60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5448, 2.7715, 0.2128]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0910, 0.8437, 0.0653]], device='cuda:0')\n",
            "[tensor([[[[60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5448, 2.7715, 0.2128]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0910, 0.8437, 0.0653]], device='cuda:0')\n",
            "[tensor([[[[60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5448, 2.7715, 0.2128]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0910, 0.8437, 0.0653]], device='cuda:0')\n",
            "[tensor([[[[60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000, 60.8000,\n",
            "           60.8000, 60.8000, 60.8000],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700, 60.5700,\n",
            "           60.5700, 60.5700, 60.5700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5448, 2.7715, 0.2128]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0910, 0.8437, 0.0653]], device='cuda:0')\n",
            "[tensor([[[[6.0360e+01, 6.0360e+01, 6.0330e+01, 6.0290e+01, 6.0190e+01,\n",
            "           6.0010e+01, 6.0040e+01, 6.0090e+01, 5.9990e+01, 5.9985e+01,\n",
            "           5.9910e+01, 5.9870e+01, 5.9910e+01, 6.0020e+01, 6.0155e+01,\n",
            "           6.0030e+01, 5.9840e+01, 5.9530e+01, 5.9460e+01, 5.9170e+01,\n",
            "           5.9140e+01, 5.9330e+01, 5.9290e+01, 5.9520e+01],\n",
            "          [6.0440e+01, 6.0360e+01, 6.0370e+01, 6.0300e+01, 6.0270e+01,\n",
            "           6.0100e+01, 6.0100e+01, 6.0090e+01, 6.0040e+01, 6.0140e+01,\n",
            "           5.9910e+01, 6.0000e+01, 6.0060e+01, 6.0200e+01, 6.0220e+01,\n",
            "           6.0030e+01, 5.9900e+01, 5.9800e+01, 5.9540e+01, 5.9310e+01,\n",
            "           5.9350e+01, 5.9470e+01, 5.9515e+01, 5.9700e+01],\n",
            "          [6.0360e+01, 6.0290e+01, 6.0270e+01, 6.0290e+01, 6.0110e+01,\n",
            "           6.0000e+01, 6.0000e+01, 5.9650e+01, 5.9950e+01, 5.9985e+01,\n",
            "           5.9860e+01, 5.9870e+01, 5.9780e+01, 5.9890e+01, 6.0010e+01,\n",
            "           5.9850e+01, 5.9520e+01, 5.9450e+01, 5.9160e+01, 5.9100e+01,\n",
            "           5.8940e+01, 5.9250e+01, 5.9230e+01, 5.9510e+01],\n",
            "          [6.0410e+01, 6.0300e+01, 6.0270e+01, 6.0300e+01, 6.0120e+01,\n",
            "           6.0000e+01, 6.0100e+01, 5.9850e+01, 6.0000e+01, 5.9990e+01,\n",
            "           5.9910e+01, 5.9920e+01, 6.0020e+01, 6.0140e+01, 6.0020e+01,\n",
            "           5.9880e+01, 5.9540e+01, 5.9450e+01, 5.9195e+01, 5.9150e+01,\n",
            "           5.9320e+01, 5.9290e+01, 5.9510e+01, 5.9590e+01],\n",
            "          [7.5200e+02, 1.0230e+03, 1.5020e+03, 7.8420e+03, 5.1280e+03,\n",
            "           2.4580e+03, 1.4730e+03, 2.8630e+04, 2.4071e+04, 1.0040e+03,\n",
            "           2.2411e+04, 1.3474e+04, 2.0762e+05, 1.9979e+05, 9.0873e+04,\n",
            "           5.5319e+04, 2.0143e+05, 1.1350e+05, 3.6080e+05, 2.5801e+05,\n",
            "           2.5964e+05, 1.2175e+05, 6.8351e+04, 2.6049e+05]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5410, 2.7353, 0.2168]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0935, 0.8389, 0.0676]], device='cuda:0')\n",
            "[tensor([[[[5.9590e+01, 5.9680e+01, 5.9740e+01, 5.9840e+01, 5.9660e+01,\n",
            "           5.9720e+01, 5.9590e+01, 5.9470e+01, 5.9361e+01, 5.9110e+01,\n",
            "           5.9230e+01, 5.9310e+01, 5.9400e+01, 5.9470e+01, 5.9200e+01,\n",
            "           5.9105e+01, 5.8940e+01, 5.9180e+01, 5.9160e+01, 5.8880e+01,\n",
            "           5.9150e+01, 5.9050e+01, 5.8970e+01, 5.9060e+01],\n",
            "          [5.9750e+01, 5.9810e+01, 5.9860e+01, 5.9850e+01, 5.9770e+01,\n",
            "           5.9750e+01, 5.9590e+01, 5.9470e+01, 5.9380e+01, 5.9250e+01,\n",
            "           5.9415e+01, 5.9470e+01, 5.9525e+01, 5.9500e+01, 5.9210e+01,\n",
            "           5.9120e+01, 5.9180e+01, 5.9290e+01, 5.9160e+01, 5.9140e+01,\n",
            "           5.9190e+01, 5.9050e+01, 5.9100e+01, 5.9210e+01],\n",
            "          [5.9550e+01, 5.9640e+01, 5.9700e+01, 5.9645e+01, 5.9600e+01,\n",
            "           5.9560e+01, 5.9460e+01, 5.9280e+01, 5.9080e+01, 5.9095e+01,\n",
            "           5.9180e+01, 5.9270e+01, 5.9300e+01, 5.9190e+01, 5.9040e+01,\n",
            "           5.8890e+01, 5.8903e+01, 5.9110e+01, 5.8810e+01, 5.8880e+01,\n",
            "           5.8984e+01, 5.8850e+01, 5.8967e+01, 5.9040e+01],\n",
            "          [5.9690e+01, 5.9750e+01, 5.9860e+01, 5.9670e+01, 5.9720e+01,\n",
            "           5.9590e+01, 5.9470e+01, 5.9370e+01, 5.9110e+01, 5.9240e+01,\n",
            "           5.9320e+01, 5.9390e+01, 5.9442e+01, 5.9200e+01, 5.9100e+01,\n",
            "           5.8950e+01, 5.9180e+01, 5.9170e+01, 5.8870e+01, 5.9140e+01,\n",
            "           5.9054e+01, 5.9010e+01, 5.9030e+01, 5.9160e+01],\n",
            "          [8.4294e+04, 1.0466e+05, 6.3859e+04, 9.4619e+04, 7.4849e+04,\n",
            "           7.2728e+04, 8.2924e+04, 6.5086e+04, 6.6662e+04, 4.5543e+05,\n",
            "           1.1072e+06, 2.0837e+05, 4.4581e+04, 4.9887e+04, 5.8583e+04,\n",
            "           5.9913e+04, 2.7444e+05, 1.0542e+05, 8.6991e+04, 8.7918e+04,\n",
            "           4.2483e+04, 7.9211e+04, 1.9201e+05, 6.0795e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5378, 2.7065, 0.2158]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0955, 0.8353, 0.0692]], device='cuda:0')\n",
            "[tensor([[[[5.9150e+01, 5.9230e+01, 5.9220e+01, 5.9520e+01, 5.9460e+01,\n",
            "           5.9670e+01, 5.9700e+01, 5.9810e+01, 5.9830e+01, 5.9900e+01,\n",
            "           5.9910e+01, 5.9730e+01, 5.9630e+01, 5.9910e+01, 5.9820e+01,\n",
            "           5.9720e+01, 5.9880e+01, 5.9780e+01, 5.9920e+01, 5.9980e+01,\n",
            "           5.9930e+01, 5.9730e+01, 5.9780e+01, 5.9680e+01],\n",
            "          [5.9230e+01, 5.9240e+01, 5.9520e+01, 5.9520e+01, 5.9680e+01,\n",
            "           5.9740e+01, 5.9834e+01, 5.9890e+01, 5.9930e+01, 5.9930e+01,\n",
            "           5.9910e+01, 5.9770e+01, 5.9910e+01, 5.9910e+01, 5.9830e+01,\n",
            "           5.9890e+01, 5.9915e+01, 5.9920e+01, 6.0010e+01, 6.0020e+01,\n",
            "           5.9985e+01, 5.9810e+01, 5.9850e+01, 5.9810e+01],\n",
            "          [5.9100e+01, 5.9130e+01, 5.9190e+01, 5.9410e+01, 5.9410e+01,\n",
            "           5.9660e+01, 5.9660e+01, 5.9770e+01, 5.9800e+01, 5.9860e+01,\n",
            "           5.9730e+01, 5.9630e+01, 5.9630e+01, 5.9720e+01, 5.9680e+01,\n",
            "           5.9720e+01, 5.9740e+01, 5.9760e+01, 5.9910e+01, 5.9920e+01,\n",
            "           5.9710e+01, 5.9700e+01, 5.9670e+01, 5.9670e+01],\n",
            "          [5.9190e+01, 5.9230e+01, 5.9510e+01, 5.9460e+01, 5.9660e+01,\n",
            "           5.9700e+01, 5.9810e+01, 5.9830e+01, 5.9920e+01, 5.9930e+01,\n",
            "           5.9730e+01, 5.9630e+01, 5.9910e+01, 5.9840e+01, 5.9710e+01,\n",
            "           5.9880e+01, 5.9790e+01, 5.9910e+01, 5.9974e+01, 5.9920e+01,\n",
            "           5.9720e+01, 5.9770e+01, 5.9710e+01, 5.9780e+01],\n",
            "          [4.3634e+04, 3.7408e+04, 9.4516e+04, 7.0461e+04, 9.0148e+04,\n",
            "           4.4515e+04, 1.9145e+05, 1.2333e+05, 8.5476e+04, 6.2444e+04,\n",
            "           4.8423e+04, 5.3487e+04, 4.6364e+04, 4.8508e+04, 3.7714e+04,\n",
            "           3.3011e+04, 4.2717e+04, 7.1393e+04, 9.9554e+04, 5.6247e+04,\n",
            "           8.3068e+04, 4.2325e+04, 2.6540e+04, 7.4543e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5361, 2.7302, 0.2083]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0935, 0.8391, 0.0674]], device='cuda:0')\n",
            "[tensor([[[[5.9740e+01, 5.9580e+01, 5.9420e+01, 5.9370e+01, 5.9440e+01,\n",
            "           5.9480e+01, 5.9610e+01, 5.9729e+01, 5.9790e+01, 5.9880e+01,\n",
            "           5.9860e+01, 5.9900e+01, 5.9900e+01, 5.9990e+01, 6.0035e+01,\n",
            "           5.9970e+01, 6.0130e+01, 6.0120e+01, 6.0110e+01, 6.0110e+01,\n",
            "           6.0150e+01, 6.0290e+01, 6.0280e+01, 6.0280e+01],\n",
            "          [5.9875e+01, 5.9580e+01, 5.9460e+01, 5.9450e+01, 5.9500e+01,\n",
            "           5.9620e+01, 5.9790e+01, 5.9780e+01, 5.9890e+01, 5.9950e+01,\n",
            "           5.9930e+01, 5.9953e+01, 6.0030e+01, 6.0070e+01, 6.0050e+01,\n",
            "           6.0080e+01, 6.0140e+01, 6.0140e+01, 6.0110e+01, 6.0140e+01,\n",
            "           6.0150e+01, 6.0290e+01, 6.0280e+01, 6.0280e+01],\n",
            "          [5.9570e+01, 5.9390e+01, 5.9370e+01, 5.9290e+01, 5.9420e+01,\n",
            "           5.9420e+01, 5.9610e+01, 5.9710e+01, 5.9790e+01, 5.9830e+01,\n",
            "           5.9850e+01, 5.9880e+01, 5.9870e+01, 5.9940e+01, 5.9958e+01,\n",
            "           5.9970e+01, 6.0080e+01, 6.0095e+01, 6.0110e+01, 6.0110e+01,\n",
            "           6.0110e+01, 6.0280e+01, 6.0280e+01, 6.0280e+01],\n",
            "          [5.9570e+01, 5.9440e+01, 5.9383e+01, 5.9450e+01, 5.9490e+01,\n",
            "           5.9610e+01, 5.9730e+01, 5.9780e+01, 5.9870e+01, 5.9850e+01,\n",
            "           5.9900e+01, 5.9910e+01, 6.0000e+01, 6.0040e+01, 5.9970e+01,\n",
            "           6.0080e+01, 6.0120e+01, 6.0120e+01, 6.0110e+01, 6.0140e+01,\n",
            "           6.0150e+01, 6.0280e+01, 6.0280e+01, 6.0280e+01],\n",
            "          [6.5162e+04, 5.7843e+04, 3.0976e+04, 2.2792e+04, 2.2543e+04,\n",
            "           3.7076e+04, 2.1626e+04, 1.3803e+04, 2.5418e+04, 8.5054e+04,\n",
            "           3.9782e+04, 6.1174e+04, 8.3274e+04, 1.0729e+05, 8.8420e+04,\n",
            "           5.0846e+04, 6.2292e+04, 1.4023e+05, 2.5985e+04, 1.1000e+03,\n",
            "           4.2270e+03, 2.7400e+02, 3.4430e+03, 1.3340e+03]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5369, 2.7376, 0.2039]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0930, 0.8403, 0.0667]], device='cuda:0')\n",
            "[tensor([[[[5.9930e+01, 5.9990e+01, 6.0060e+01, 6.0100e+01, 6.0080e+01,\n",
            "           6.0080e+01, 6.0130e+01, 6.0130e+01, 6.0010e+01, 6.0000e+01,\n",
            "           6.0000e+01, 5.9890e+01, 5.9910e+01, 5.9960e+01, 6.0150e+01,\n",
            "           6.0020e+01, 6.0120e+01, 6.0200e+01, 6.0160e+01, 5.9910e+01,\n",
            "           6.0040e+01, 6.0260e+01, 6.0310e+01, 6.0250e+01],\n",
            "          [5.9930e+01, 6.0190e+01, 6.0100e+01, 6.0100e+01, 6.0080e+01,\n",
            "           6.0080e+01, 6.0130e+01, 6.0130e+01, 6.0010e+01, 6.0000e+01,\n",
            "           6.0000e+01, 5.9900e+01, 6.0180e+01, 6.0240e+01, 6.0210e+01,\n",
            "           6.0170e+01, 6.0320e+01, 6.0270e+01, 6.0180e+01, 6.0060e+01,\n",
            "           6.0270e+01, 6.0400e+01, 6.0360e+01, 6.0380e+01],\n",
            "          [5.9930e+01, 5.9990e+01, 6.0040e+01, 6.0100e+01, 6.0080e+01,\n",
            "           6.0080e+01, 6.0060e+01, 6.0060e+01, 6.0000e+01, 6.0000e+01,\n",
            "           5.9910e+01, 5.9890e+01, 5.9880e+01, 5.9900e+01, 5.9970e+01,\n",
            "           5.9950e+01, 6.0110e+01, 6.0160e+01, 5.9890e+01, 5.9880e+01,\n",
            "           5.9920e+01, 6.0230e+01, 6.0180e+01, 6.0250e+01],\n",
            "          [5.9930e+01, 6.0190e+01, 6.0100e+01, 6.0100e+01, 6.0080e+01,\n",
            "           6.0080e+01, 6.0070e+01, 6.0070e+01, 6.0000e+01, 6.0000e+01,\n",
            "           5.9910e+01, 5.9900e+01, 6.0000e+01, 6.0190e+01, 6.0050e+01,\n",
            "           6.0130e+01, 6.0170e+01, 6.0160e+01, 5.9910e+01, 6.0050e+01,\n",
            "           6.0260e+01, 6.0320e+01, 6.0250e+01, 6.0370e+01],\n",
            "          [1.0200e+03, 2.0300e+04, 2.0776e+04, 2.0000e+02, 1.0000e+02,\n",
            "           0.0000e+00, 7.8800e+02, 0.0000e+00, 2.2050e+03, 1.0000e+02,\n",
            "           2.1020e+03, 5.8700e+02, 1.3358e+05, 1.6027e+05, 2.6214e+05,\n",
            "           1.6456e+05, 9.9344e+04, 8.7198e+04, 9.8719e+04, 8.5469e+04,\n",
            "           1.0382e+05, 8.1586e+04, 8.6717e+04, 8.1529e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5404, 2.7471, 0.2089]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0926, 0.8410, 0.0664]], device='cuda:0')\n",
            "[tensor([[[[6.0384e+01, 6.0410e+01, 6.0387e+01, 6.0430e+01, 6.0540e+01,\n",
            "           6.0490e+01, 6.0520e+01, 6.0560e+01, 6.0590e+01, 6.0460e+01,\n",
            "           6.0620e+01, 6.0720e+01, 6.0630e+01, 6.0660e+01, 6.0580e+01,\n",
            "           6.0670e+01, 6.0793e+01, 6.0870e+01, 6.0750e+01, 6.0830e+01,\n",
            "           6.0780e+01, 6.0790e+01, 6.0840e+01, 6.0890e+01],\n",
            "          [6.0470e+01, 6.0450e+01, 6.0430e+01, 6.0540e+01, 6.0590e+01,\n",
            "           6.0560e+01, 6.0590e+01, 6.0630e+01, 6.0600e+01, 6.0640e+01,\n",
            "           6.0750e+01, 6.0720e+01, 6.0760e+01, 6.0700e+01, 6.0665e+01,\n",
            "           6.0840e+01, 6.0875e+01, 6.0880e+01, 6.0830e+01, 6.0900e+01,\n",
            "           6.0810e+01, 6.0850e+01, 6.0930e+01, 6.0950e+01],\n",
            "          [6.0335e+01, 6.0300e+01, 6.0340e+01, 6.0370e+01, 6.0470e+01,\n",
            "           6.0420e+01, 6.0490e+01, 6.0490e+01, 6.0440e+01, 6.0460e+01,\n",
            "           6.0610e+01, 6.0626e+01, 6.0630e+01, 6.0510e+01, 6.0540e+01,\n",
            "           6.0670e+01, 6.0780e+01, 6.0730e+01, 6.0721e+01, 6.0780e+01,\n",
            "           6.0750e+01, 6.0730e+01, 6.0820e+01, 6.0850e+01],\n",
            "          [6.0410e+01, 6.0380e+01, 6.0420e+01, 6.0530e+01, 6.0470e+01,\n",
            "           6.0525e+01, 6.0560e+01, 6.0590e+01, 6.0460e+01, 6.0600e+01,\n",
            "           6.0690e+01, 6.0640e+01, 6.0670e+01, 6.0570e+01, 6.0665e+01,\n",
            "           6.0790e+01, 6.0860e+01, 6.0755e+01, 6.0830e+01, 6.0790e+01,\n",
            "           6.0790e+01, 6.0830e+01, 6.0900e+01, 6.0865e+01],\n",
            "          [7.7856e+04, 9.1395e+04, 4.0637e+04, 1.8964e+05, 6.7806e+04,\n",
            "           8.3638e+04, 8.6750e+04, 9.8253e+04, 8.5427e+04, 6.6647e+04,\n",
            "           1.5542e+05, 7.0439e+04, 1.0076e+05, 6.6516e+04, 2.4537e+04,\n",
            "           1.0086e+05, 5.7678e+04, 9.2989e+04, 3.4932e+04, 4.3347e+04,\n",
            "           2.2130e+04, 5.9499e+04, 7.6010e+04, 5.8905e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5429, 2.7729, 0.2083]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0908, 0.8443, 0.0650]], device='cuda:0')\n",
            "[tensor([[[[6.0860e+01, 6.0780e+01, 6.0780e+01, 6.0840e+01, 6.0790e+01,\n",
            "           6.0780e+01, 6.0830e+01, 6.0870e+01, 6.0840e+01, 6.0850e+01,\n",
            "           6.0920e+01, 6.0870e+01, 6.0870e+01, 6.0810e+01, 6.0780e+01,\n",
            "           6.0880e+01, 6.0860e+01, 6.0840e+01, 6.0880e+01, 6.0830e+01,\n",
            "           6.0790e+01, 6.0920e+01, 6.0950e+01, 6.0980e+01],\n",
            "          [6.0860e+01, 6.0800e+01, 6.0840e+01, 6.0850e+01, 6.0800e+01,\n",
            "           6.0845e+01, 6.0870e+01, 6.0870e+01, 6.0865e+01, 6.0930e+01,\n",
            "           6.0934e+01, 6.0930e+01, 6.0880e+01, 6.0840e+01, 6.0870e+01,\n",
            "           6.0910e+01, 6.0865e+01, 6.0894e+01, 6.0880e+01, 6.0870e+01,\n",
            "           6.0920e+01, 6.0960e+01, 6.0995e+01, 6.1120e+01],\n",
            "          [6.0750e+01, 6.0770e+01, 6.0750e+01, 6.0740e+01, 6.0740e+01,\n",
            "           6.0770e+01, 6.0800e+01, 6.0780e+01, 6.0821e+01, 6.0850e+01,\n",
            "           6.0880e+01, 6.0870e+01, 6.0790e+01, 6.0770e+01, 6.0778e+01,\n",
            "           6.0830e+01, 6.0800e+01, 6.0820e+01, 6.0790e+01, 6.0786e+01,\n",
            "           6.0780e+01, 6.0920e+01, 6.0930e+01, 6.0900e+01],\n",
            "          [6.0780e+01, 6.0780e+01, 6.0840e+01, 6.0760e+01, 6.0780e+01,\n",
            "           6.0830e+01, 6.0860e+01, 6.0850e+01, 6.0850e+01, 6.0910e+01,\n",
            "           6.0880e+01, 6.0870e+01, 6.0810e+01, 6.0785e+01, 6.0850e+01,\n",
            "           6.0860e+01, 6.0850e+01, 6.0880e+01, 6.0820e+01, 6.0786e+01,\n",
            "           6.0920e+01, 6.0945e+01, 6.0990e+01, 6.1115e+01],\n",
            "          [2.0370e+04, 2.5494e+04, 1.2908e+05, 3.9699e+04, 2.5213e+04,\n",
            "           3.7256e+04, 3.1236e+04, 2.1578e+04, 1.0205e+04, 2.1327e+04,\n",
            "           1.6023e+04, 4.4391e+04, 2.7210e+04, 4.2530e+04, 1.5632e+04,\n",
            "           2.3041e+04, 2.9300e+04, 2.9576e+04, 2.1959e+04, 2.1256e+04,\n",
            "           2.4580e+04, 1.1642e+05, 8.2694e+04, 1.2776e+05]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5452, 2.7769, 0.2109]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0906, 0.8445, 0.0649]], device='cuda:0')\n",
            "[tensor([[[[6.1120e+01, 6.1030e+01, 6.1110e+01, 6.1060e+01, 6.1070e+01,\n",
            "           6.1010e+01, 6.0980e+01, 6.0935e+01, 6.0920e+01, 6.0953e+01,\n",
            "           6.1020e+01, 6.0870e+01, 6.0880e+01, 6.0930e+01, 6.0980e+01,\n",
            "           6.0960e+01, 6.0940e+01, 6.0895e+01, 6.0970e+01, 6.0970e+01,\n",
            "           6.0850e+01, 6.0870e+01, 6.0870e+01, 6.0830e+01],\n",
            "          [6.1170e+01, 6.1170e+01, 6.1110e+01, 6.1110e+01, 6.1095e+01,\n",
            "           6.1010e+01, 6.0990e+01, 6.0945e+01, 6.0980e+01, 6.1041e+01,\n",
            "           6.1020e+01, 6.0880e+01, 6.0920e+01, 6.1000e+01, 6.1010e+01,\n",
            "           6.1000e+01, 6.0940e+01, 6.0980e+01, 6.0970e+01, 6.0970e+01,\n",
            "           6.0850e+01, 6.0870e+01, 6.0870e+01, 6.0840e+01],\n",
            "          [6.1000e+01, 6.1022e+01, 6.1020e+01, 6.1060e+01, 6.1010e+01,\n",
            "           6.0930e+01, 6.0925e+01, 6.0895e+01, 6.0910e+01, 6.0950e+01,\n",
            "           6.0870e+01, 6.0800e+01, 6.0840e+01, 6.0900e+01, 6.0940e+01,\n",
            "           6.0900e+01, 6.0880e+01, 6.0890e+01, 6.0970e+01, 6.0970e+01,\n",
            "           6.0850e+01, 6.0870e+01, 6.0870e+01, 6.0830e+01],\n",
            "          [6.1000e+01, 6.1090e+01, 6.1060e+01, 6.1070e+01, 6.1020e+01,\n",
            "           6.0970e+01, 6.0935e+01, 6.0930e+01, 6.0930e+01, 6.1025e+01,\n",
            "           6.0880e+01, 6.0870e+01, 6.0920e+01, 6.0975e+01, 6.0950e+01,\n",
            "           6.0940e+01, 6.0890e+01, 6.0970e+01, 6.0970e+01, 6.0970e+01,\n",
            "           6.0850e+01, 6.0870e+01, 6.0870e+01, 6.0840e+01],\n",
            "          [3.5497e+05, 3.9852e+04, 3.3583e+04, 4.4316e+04, 2.1760e+04,\n",
            "           7.8375e+04, 5.9419e+04, 7.1716e+04, 2.1368e+04, 7.4999e+04,\n",
            "           3.8361e+04, 4.9087e+04, 3.6614e+04, 1.1201e+05, 3.1894e+04,\n",
            "           1.0284e+05, 1.4216e+05, 1.3747e+05, 3.7749e+04, 0.0000e+00,\n",
            "           1.6000e+02, 1.0000e+02, 0.0000e+00, 4.6000e+02]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5472, 2.7813, 0.2157]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0904, 0.8446, 0.0649]], device='cuda:0')\n",
            "[tensor([[[[6.1960e+01, 6.1920e+01, 6.1910e+01, 6.1980e+01, 6.2000e+01,\n",
            "           6.1850e+01, 6.1980e+01, 6.1900e+01, 6.1840e+01, 6.1690e+01,\n",
            "           6.1700e+01, 6.1700e+01, 6.1670e+01, 6.1640e+01, 6.1720e+01,\n",
            "           6.1770e+01, 6.1970e+01, 6.2110e+01, 6.2205e+01, 6.2130e+01,\n",
            "           6.2020e+01, 6.2050e+01, 6.2130e+01, 6.2070e+01],\n",
            "          [6.2100e+01, 6.1950e+01, 6.1979e+01, 6.1980e+01, 6.2000e+01,\n",
            "           6.1850e+01, 6.2000e+01, 6.1900e+01, 6.1840e+01, 6.1730e+01,\n",
            "           6.1700e+01, 6.1700e+01, 6.1680e+01, 6.1760e+01, 6.1860e+01,\n",
            "           6.1980e+01, 6.2140e+01, 6.2224e+01, 6.2240e+01, 6.2140e+01,\n",
            "           6.2095e+01, 6.2150e+01, 6.2160e+01, 6.2101e+01],\n",
            "          [6.1840e+01, 6.1920e+01, 6.1900e+01, 6.1950e+01, 6.1910e+01,\n",
            "           6.1850e+01, 6.1880e+01, 6.1840e+01, 6.1670e+01, 6.1690e+01,\n",
            "           6.1640e+01, 6.1640e+01, 6.1585e+01, 6.1620e+01, 6.1720e+01,\n",
            "           6.1770e+01, 6.1964e+01, 6.2012e+01, 6.2083e+01, 6.2010e+01,\n",
            "           6.2020e+01, 6.2000e+01, 6.2070e+01, 6.1870e+01],\n",
            "          [6.1840e+01, 6.1950e+01, 6.1979e+01, 6.1950e+01, 6.1910e+01,\n",
            "           6.1850e+01, 6.1900e+01, 6.1840e+01, 6.1710e+01, 6.1710e+01,\n",
            "           6.1640e+01, 6.1640e+01, 6.1640e+01, 6.1720e+01, 6.1760e+01,\n",
            "           6.1970e+01, 6.2100e+01, 6.2190e+01, 6.2120e+01, 6.2040e+01,\n",
            "           6.2060e+01, 6.2130e+01, 6.2090e+01, 6.1870e+01],\n",
            "          [1.9940e+03, 8.5400e+02, 5.0000e+02, 8.1900e+02, 8.7200e+02,\n",
            "           2.1600e+02, 1.1431e+04, 1.0730e+03, 2.0570e+03, 1.5690e+03,\n",
            "           2.3860e+03, 0.0000e+00, 5.9839e+04, 6.6792e+04, 5.4808e+04,\n",
            "           3.0311e+04, 7.0947e+04, 6.0546e+04, 5.6601e+04, 3.2068e+04,\n",
            "           2.6345e+04, 3.0058e+04, 3.2767e+04, 2.9938e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5548, 2.8338, 0.2162]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0871, 0.8508, 0.0621]], device='cuda:0')\n",
            "[tensor([[[[6.1980e+01, 6.2030e+01, 6.2159e+01, 6.2140e+01, 6.2160e+01,\n",
            "           6.2130e+01, 6.2290e+01, 6.2220e+01, 6.2350e+01, 6.2380e+01,\n",
            "           6.2430e+01, 6.2440e+01, 6.2380e+01, 6.2320e+01, 6.2250e+01,\n",
            "           6.2247e+01, 6.2110e+01, 6.2256e+01, 6.2360e+01, 6.2350e+01,\n",
            "           6.2370e+01, 6.2340e+01, 6.2410e+01, 6.2385e+01],\n",
            "          [6.2088e+01, 6.2270e+01, 6.2230e+01, 6.2150e+01, 6.2200e+01,\n",
            "           6.2310e+01, 6.2330e+01, 6.2390e+01, 6.2420e+01, 6.2520e+01,\n",
            "           6.2450e+01, 6.2500e+01, 6.2440e+01, 6.2330e+01, 6.2310e+01,\n",
            "           6.2247e+01, 6.2290e+01, 6.2370e+01, 6.2370e+01, 6.2380e+01,\n",
            "           6.2380e+01, 6.2425e+01, 6.2440e+01, 6.2450e+01],\n",
            "          [6.1850e+01, 6.2000e+01, 6.2093e+01, 6.2010e+01, 6.2100e+01,\n",
            "           6.2090e+01, 6.2200e+01, 6.2220e+01, 6.2330e+01, 6.2360e+01,\n",
            "           6.2370e+01, 6.2380e+01, 6.2300e+01, 6.2210e+01, 6.2220e+01,\n",
            "           6.2090e+01, 6.2100e+01, 6.2250e+01, 6.2340e+01, 6.2310e+01,\n",
            "           6.2315e+01, 6.2330e+01, 6.2360e+01, 6.2370e+01],\n",
            "          [6.2010e+01, 6.2140e+01, 6.2130e+01, 6.2150e+01, 6.2130e+01,\n",
            "           6.2299e+01, 6.2210e+01, 6.2350e+01, 6.2370e+01, 6.2440e+01,\n",
            "           6.2440e+01, 6.2390e+01, 6.2330e+01, 6.2240e+01, 6.2235e+01,\n",
            "           6.2090e+01, 6.2260e+01, 6.2360e+01, 6.2350e+01, 6.2380e+01,\n",
            "           6.2360e+01, 6.2410e+01, 6.2380e+01, 6.2415e+01],\n",
            "          [7.5983e+04, 1.1582e+05, 3.6780e+04, 4.1991e+04, 4.2228e+04,\n",
            "           8.6765e+04, 4.7611e+04, 7.6787e+04, 7.4549e+04, 1.4886e+05,\n",
            "           4.9122e+04, 8.1521e+04, 1.3845e+05, 5.0576e+04, 6.7734e+04,\n",
            "           7.0290e+04, 7.0827e+04, 5.7648e+04, 2.7351e+04, 3.1589e+04,\n",
            "           3.6474e+04, 6.6344e+04, 4.4238e+04, 3.8112e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5568, 2.8431, 0.2173]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0866, 0.8518, 0.0617]], device='cuda:0')\n",
            "[tensor([[[[6.2420e+01, 6.2430e+01, 6.2340e+01, 6.2460e+01, 6.2410e+01,\n",
            "           6.2440e+01, 6.2420e+01, 6.2120e+01, 6.2070e+01, 6.1985e+01,\n",
            "           6.2080e+01, 6.2140e+01, 6.2245e+01, 6.2220e+01, 6.2190e+01,\n",
            "           6.2130e+01, 6.2100e+01, 6.2113e+01, 6.2050e+01, 6.2170e+01,\n",
            "           6.2120e+01, 6.2160e+01, 6.2160e+01, 6.2190e+01],\n",
            "          [6.2445e+01, 6.2440e+01, 6.2460e+01, 6.2470e+01, 6.2440e+01,\n",
            "           6.2510e+01, 6.2440e+01, 6.2180e+01, 6.2070e+01, 6.2080e+01,\n",
            "           6.2190e+01, 6.2280e+01, 6.2310e+01, 6.2250e+01, 6.2200e+01,\n",
            "           6.2150e+01, 6.2110e+01, 6.2130e+01, 6.2220e+01, 6.2181e+01,\n",
            "           6.2190e+01, 6.2182e+01, 6.2195e+01, 6.2260e+01],\n",
            "          [6.2370e+01, 6.2330e+01, 6.2340e+01, 6.2400e+01, 6.2390e+01,\n",
            "           6.2400e+01, 6.2110e+01, 6.2060e+01, 6.1980e+01, 6.1970e+01,\n",
            "           6.2080e+01, 6.2140e+01, 6.2210e+01, 6.2140e+01, 6.2090e+01,\n",
            "           6.2090e+01, 6.2070e+01, 6.1990e+01, 6.1974e+01, 6.2100e+01,\n",
            "           6.2090e+01, 6.2125e+01, 6.2090e+01, 6.2090e+01],\n",
            "          [6.2431e+01, 6.2340e+01, 6.2460e+01, 6.2410e+01, 6.2430e+01,\n",
            "           6.2440e+01, 6.2140e+01, 6.2090e+01, 6.1985e+01, 6.2070e+01,\n",
            "           6.2140e+01, 6.2265e+01, 6.2220e+01, 6.2200e+01, 6.2130e+01,\n",
            "           6.2130e+01, 6.2110e+01, 6.2010e+01, 6.2170e+01, 6.2110e+01,\n",
            "           6.2140e+01, 6.2160e+01, 6.2183e+01, 6.2130e+01],\n",
            "          [3.7983e+04, 5.4619e+04, 2.2760e+04, 3.9468e+04, 2.9581e+05,\n",
            "           1.0534e+05, 8.1928e+05, 2.2380e+05, 1.5570e+05, 1.8706e+05,\n",
            "           5.3936e+04, 1.1186e+05, 4.1070e+04, 3.6663e+04, 5.2976e+04,\n",
            "           5.6987e+04, 2.4127e+04, 4.0660e+04, 4.2120e+04, 2.1054e+04,\n",
            "           7.5022e+04, 4.9301e+04, 5.8182e+04, 1.0325e+05]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5582, 2.8387, 0.2207]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0870, 0.8509, 0.0621]], device='cuda:0')\n",
            "[tensor([[[[6.2130e+01, 6.2140e+01, 6.2230e+01, 6.2090e+01, 6.1800e+01,\n",
            "           6.1930e+01, 6.1900e+01, 6.1740e+01, 6.1610e+01, 6.1660e+01,\n",
            "           6.1570e+01, 6.1460e+01, 6.1720e+01, 6.1660e+01, 6.1560e+01,\n",
            "           6.1560e+01, 6.1540e+01, 6.1700e+01, 6.1700e+01, 6.1830e+01,\n",
            "           6.1920e+01, 6.1950e+01, 6.1850e+01, 6.1860e+01],\n",
            "          [6.2240e+01, 6.2250e+01, 6.2230e+01, 6.2120e+01, 6.1980e+01,\n",
            "           6.1970e+01, 6.1910e+01, 6.1760e+01, 6.1790e+01, 6.1710e+01,\n",
            "           6.1610e+01, 6.1739e+01, 6.1850e+01, 6.1690e+01, 6.1690e+01,\n",
            "           6.1650e+01, 6.1720e+01, 6.1760e+01, 6.1810e+01, 6.1910e+01,\n",
            "           6.1920e+01, 6.1950e+01, 6.1850e+01, 6.1900e+01],\n",
            "          [6.2110e+01, 6.2040e+01, 6.2100e+01, 6.1780e+01, 6.1770e+01,\n",
            "           6.1810e+01, 6.1730e+01, 6.1590e+01, 6.1610e+01, 6.1550e+01,\n",
            "           6.1410e+01, 6.1410e+01, 6.1645e+01, 6.1560e+01, 6.1510e+01,\n",
            "           6.1485e+01, 6.1520e+01, 6.1620e+01, 6.1680e+01, 6.1830e+01,\n",
            "           6.1920e+01, 6.1950e+01, 6.1850e+01, 6.1860e+01],\n",
            "          [6.2150e+01, 6.2230e+01, 6.2100e+01, 6.1800e+01, 6.1980e+01,\n",
            "           6.1900e+01, 6.1750e+01, 6.1600e+01, 6.1680e+01, 6.1560e+01,\n",
            "           6.1470e+01, 6.1730e+01, 6.1670e+01, 6.1560e+01, 6.1560e+01,\n",
            "           6.1530e+01, 6.1710e+01, 6.1700e+01, 6.1800e+01, 6.1900e+01,\n",
            "           6.1920e+01, 6.1950e+01, 6.1850e+01, 6.1900e+01],\n",
            "          [7.9443e+04, 1.1144e+05, 6.3693e+04, 1.0766e+05, 6.8240e+04,\n",
            "           5.3679e+04, 9.9582e+04, 1.0057e+05, 6.7568e+04, 5.6062e+04,\n",
            "           1.1999e+05, 1.2924e+05, 1.0353e+05, 1.2520e+05, 7.3083e+04,\n",
            "           6.5173e+04, 8.6073e+04, 1.2411e+05, 3.0087e+04, 1.1550e+03,\n",
            "           1.0300e+02, 4.0300e+02, 2.0000e+03, 6.0000e+03]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5559, 2.8250, 0.2193]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0878, 0.8494, 0.0627]], device='cuda:0')\n",
            "[tensor([[[[6.2500e+01, 6.2520e+01, 6.2520e+01, 6.2520e+01, 6.2520e+01,\n",
            "           6.2520e+01, 6.2750e+01, 6.2800e+01, 6.2760e+01, 6.2800e+01,\n",
            "           6.2809e+01, 6.2700e+01, 6.2660e+01, 6.2500e+01, 6.2630e+01,\n",
            "           6.2600e+01, 6.2660e+01, 6.2440e+01, 6.2440e+01, 6.2410e+01,\n",
            "           6.2500e+01, 6.2410e+01, 6.2370e+01, 6.2270e+01],\n",
            "          [6.2500e+01, 6.2560e+01, 6.2560e+01, 6.2560e+01, 6.2560e+01,\n",
            "           6.2560e+01, 6.2820e+01, 6.2800e+01, 6.2800e+01, 6.2800e+01,\n",
            "           6.2810e+01, 6.2730e+01, 6.2690e+01, 6.2635e+01, 6.2680e+01,\n",
            "           6.2710e+01, 6.2690e+01, 6.2510e+01, 6.2470e+01, 6.2500e+01,\n",
            "           6.2540e+01, 6.2450e+01, 6.2390e+01, 6.2270e+01],\n",
            "          [6.2500e+01, 6.2520e+01, 6.2520e+01, 6.2520e+01, 6.2520e+01,\n",
            "           6.2520e+01, 6.2750e+01, 6.2770e+01, 6.2720e+01, 6.2800e+01,\n",
            "           6.2730e+01, 6.2630e+01, 6.2490e+01, 6.2490e+01, 6.2570e+01,\n",
            "           6.2570e+01, 6.2450e+01, 6.2370e+01, 6.2336e+01, 6.2370e+01,\n",
            "           6.2420e+01, 6.2310e+01, 6.2270e+01, 6.1770e+01],\n",
            "          [6.2500e+01, 6.2560e+01, 6.2560e+01, 6.2560e+01, 6.2560e+01,\n",
            "           6.2560e+01, 6.2820e+01, 6.2790e+01, 6.2800e+01, 6.2800e+01,\n",
            "           6.2730e+01, 6.2630e+01, 6.2490e+01, 6.2620e+01, 6.2585e+01,\n",
            "           6.2650e+01, 6.2450e+01, 6.2430e+01, 6.2420e+01, 6.2490e+01,\n",
            "           6.2420e+01, 6.2360e+01, 6.2270e+01, 6.1770e+01],\n",
            "          [4.0000e+02, 3.8500e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "           0.0000e+00, 1.4290e+03, 6.1200e+02, 4.4250e+03, 1.8020e+03,\n",
            "           8.7600e+02, 3.7210e+03, 1.4148e+05, 5.6939e+04, 4.8269e+04,\n",
            "           8.8059e+04, 9.2366e+04, 1.0093e+05, 1.2942e+05, 4.8578e+04,\n",
            "           8.0218e+04, 3.1352e+05, 1.1458e+05, 2.7937e+05]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5597, 2.8526, 0.2218]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0861, 0.8525, 0.0614]], device='cuda:0')\n",
            "[tensor([[[[6.1799e+01, 6.1600e+01, 6.1790e+01, 6.1920e+01, 6.1930e+01,\n",
            "           6.1966e+01, 6.2120e+01, 6.2180e+01, 6.1950e+01, 6.2220e+01,\n",
            "           6.2055e+01, 6.2080e+01, 6.2050e+01, 6.2220e+01, 6.2210e+01,\n",
            "           6.2040e+01, 6.2000e+01, 6.2110e+01, 6.2160e+01, 6.2140e+01,\n",
            "           6.1810e+01, 6.1860e+01, 6.1860e+01, 6.1880e+01],\n",
            "          [6.1910e+01, 6.1900e+01, 6.1940e+01, 6.2040e+01, 6.2040e+01,\n",
            "           6.2140e+01, 6.2250e+01, 6.2210e+01, 6.2270e+01, 6.2220e+01,\n",
            "           6.2150e+01, 6.2150e+01, 6.2230e+01, 6.2300e+01, 6.2290e+01,\n",
            "           6.2100e+01, 6.2120e+01, 6.2220e+01, 6.2210e+01, 6.2140e+01,\n",
            "           6.1872e+01, 6.1930e+01, 6.1880e+01, 6.1950e+01],\n",
            "          [6.1600e+01, 6.1600e+01, 6.1760e+01, 6.1920e+01, 6.1930e+01,\n",
            "           6.1966e+01, 6.2110e+01, 6.1935e+01, 6.1940e+01, 6.1990e+01,\n",
            "           6.2020e+01, 6.1990e+01, 6.2040e+01, 6.2180e+01, 6.2010e+01,\n",
            "           6.2000e+01, 6.1980e+01, 6.2090e+01, 6.2090e+01, 6.1800e+01,\n",
            "           6.1700e+01, 6.1830e+01, 6.1780e+01, 6.1800e+01],\n",
            "          [6.1600e+01, 6.1800e+01, 6.1918e+01, 6.1940e+01, 6.1954e+01,\n",
            "           6.2120e+01, 6.2200e+01, 6.1935e+01, 6.2210e+01, 6.2080e+01,\n",
            "           6.2080e+01, 6.2050e+01, 6.2225e+01, 6.2195e+01, 6.2010e+01,\n",
            "           6.2007e+01, 6.2110e+01, 6.2170e+01, 6.2145e+01, 6.1810e+01,\n",
            "           6.1870e+01, 6.1870e+01, 6.1870e+01, 6.1880e+01],\n",
            "          [1.2183e+05, 1.3913e+05, 7.7532e+04, 8.2733e+04, 3.7511e+04,\n",
            "           1.1937e+05, 8.5354e+04, 6.8760e+04, 5.0101e+04, 4.5916e+04,\n",
            "           3.6525e+04, 7.6813e+04, 7.7003e+04, 4.2470e+04, 6.1241e+04,\n",
            "           2.8155e+04, 3.5220e+04, 2.5351e+04, 2.2779e+04, 5.5937e+04,\n",
            "           5.4247e+04, 4.7512e+04, 4.6042e+04, 4.4883e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5563, 2.8322, 0.2197]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0873, 0.8503, 0.0624]], device='cuda:0')\n",
            "[tensor([[[[6.1870e+01, 6.1810e+01, 6.1730e+01, 6.1780e+01, 6.1770e+01,\n",
            "           6.2010e+01, 6.2010e+01, 6.1840e+01, 6.1880e+01, 6.1870e+01,\n",
            "           6.1980e+01, 6.1740e+01, 6.1670e+01, 6.1790e+01, 6.1730e+01,\n",
            "           6.1810e+01, 6.1830e+01, 6.1790e+01, 6.1980e+01, 6.2110e+01,\n",
            "           6.2090e+01, 6.2060e+01, 6.1880e+01, 6.1790e+01],\n",
            "          [6.1910e+01, 6.1830e+01, 6.1840e+01, 6.1780e+01, 6.2010e+01,\n",
            "           6.2060e+01, 6.2040e+01, 6.1890e+01, 6.1910e+01, 6.2040e+01,\n",
            "           6.1983e+01, 6.1780e+01, 6.1790e+01, 6.1830e+01, 6.1820e+01,\n",
            "           6.1870e+01, 6.1850e+01, 6.1990e+01, 6.2140e+01, 6.2150e+01,\n",
            "           6.2120e+01, 6.2080e+01, 6.1920e+01, 6.1800e+01],\n",
            "          [6.1790e+01, 6.1730e+01, 6.1730e+01, 6.1690e+01, 6.1760e+01,\n",
            "           6.1970e+01, 6.1845e+01, 6.1715e+01, 6.1830e+01, 6.1860e+01,\n",
            "           6.1720e+01, 6.1660e+01, 6.1635e+01, 6.1705e+01, 6.1700e+01,\n",
            "           6.1740e+01, 6.1765e+01, 6.1790e+01, 6.1960e+01, 6.2050e+01,\n",
            "           6.2045e+01, 6.1860e+01, 6.1770e+01, 6.1610e+01],\n",
            "          [6.1820e+01, 6.1740e+01, 6.1785e+01, 6.1760e+01, 6.1980e+01,\n",
            "           6.2010e+01, 6.1850e+01, 6.1880e+01, 6.1875e+01, 6.2020e+01,\n",
            "           6.1740e+01, 6.1660e+01, 6.1790e+01, 6.1710e+01, 6.1820e+01,\n",
            "           6.1850e+01, 6.1790e+01, 6.1970e+01, 6.2110e+01, 6.2100e+01,\n",
            "           6.2070e+01, 6.1900e+01, 6.1780e+01, 6.1620e+01],\n",
            "          [4.6768e+04, 3.0869e+04, 2.7113e+04, 4.5920e+04, 1.4165e+05,\n",
            "           4.7393e+04, 4.5098e+04, 7.9293e+04, 3.1910e+04, 3.7452e+04,\n",
            "           4.8671e+04, 6.2079e+04, 1.3273e+05, 5.8776e+04, 3.5171e+04,\n",
            "           3.8797e+04, 2.2440e+04, 5.6621e+04, 4.7618e+04, 3.0353e+04,\n",
            "           5.0788e+04, 5.8688e+04, 3.2251e+04, 6.2858e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5537, 2.8282, 0.2161]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0874, 0.8502, 0.0624]], device='cuda:0')\n",
            "[tensor([[[[6.1640e+01, 6.1490e+01, 6.1450e+01, 6.1459e+01, 6.1430e+01,\n",
            "           6.1370e+01, 6.1390e+01, 6.1520e+01, 6.1570e+01, 6.1550e+01,\n",
            "           6.1560e+01, 6.1560e+01, 6.1650e+01, 6.1610e+01, 6.1660e+01,\n",
            "           6.1720e+01, 6.1750e+01, 6.1890e+01, 6.1860e+01, 6.1940e+01,\n",
            "           6.1940e+01, 6.1940e+01, 6.1940e+01, 6.1940e+01],\n",
            "          [6.1640e+01, 6.1510e+01, 6.1520e+01, 6.1500e+01, 6.1440e+01,\n",
            "           6.1430e+01, 6.1530e+01, 6.1610e+01, 6.1580e+01, 6.1570e+01,\n",
            "           6.1590e+01, 6.1690e+01, 6.1660e+01, 6.1670e+01, 6.1770e+01,\n",
            "           6.1785e+01, 6.1940e+01, 6.1925e+01, 6.1920e+01, 6.1950e+01,\n",
            "           6.1950e+01, 6.1950e+01, 6.1950e+01, 6.1950e+01],\n",
            "          [6.1370e+01, 6.1440e+01, 6.1430e+01, 6.1370e+01, 6.1360e+01,\n",
            "           6.1360e+01, 6.1390e+01, 6.1490e+01, 6.1500e+01, 6.1520e+01,\n",
            "           6.1520e+01, 6.1560e+01, 6.1590e+01, 6.1580e+01, 6.1640e+01,\n",
            "           6.1710e+01, 6.1745e+01, 6.1810e+01, 6.1860e+01, 6.1940e+01,\n",
            "           6.1940e+01, 6.1940e+01, 6.1940e+01, 6.1940e+01],\n",
            "          [6.1480e+01, 6.1460e+01, 6.1450e+01, 6.1450e+01, 6.1380e+01,\n",
            "           6.1370e+01, 6.1520e+01, 6.1570e+01, 6.1550e+01, 6.1550e+01,\n",
            "           6.1560e+01, 6.1650e+01, 6.1600e+01, 6.1660e+01, 6.1710e+01,\n",
            "           6.1770e+01, 6.1890e+01, 6.1880e+01, 6.1920e+01, 6.1940e+01,\n",
            "           6.1940e+01, 6.1940e+01, 6.1940e+01, 6.1940e+01],\n",
            "          [8.2911e+04, 6.2015e+04, 4.5654e+04, 8.2873e+04, 1.1207e+05,\n",
            "           3.3103e+04, 4.2327e+04, 4.6397e+04, 3.1513e+04, 2.3666e+04,\n",
            "           4.4382e+04, 6.6699e+04, 4.8848e+04, 3.0833e+04, 7.4281e+04,\n",
            "           7.7496e+04, 2.4838e+05, 1.0004e+05, 1.2297e+04, 9.1100e+02,\n",
            "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5517, 2.8205, 0.2115]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0879, 0.8496, 0.0625]], device='cuda:0')\n",
            "[tensor([[[[6.2380e+01, 6.2500e+01, 6.2550e+01, 6.2610e+01, 6.2600e+01,\n",
            "           6.2580e+01, 6.2670e+01, 6.2760e+01, 6.2600e+01, 6.2630e+01,\n",
            "           6.2590e+01, 6.2500e+01, 6.2640e+01, 6.2830e+01, 6.2750e+01,\n",
            "           6.2765e+01, 6.2810e+01, 6.2915e+01, 6.2940e+01, 6.2470e+01,\n",
            "           6.2685e+01, 6.2675e+01, 6.2620e+01, 6.2560e+01],\n",
            "          [6.2380e+01, 6.2540e+01, 6.2660e+01, 6.2610e+01, 6.2600e+01,\n",
            "           6.2580e+01, 6.2880e+01, 6.2760e+01, 6.2650e+01, 6.2630e+01,\n",
            "           6.2590e+01, 6.2640e+01, 6.2848e+01, 6.2839e+01, 6.2800e+01,\n",
            "           6.2840e+01, 6.2970e+01, 6.2940e+01, 6.2990e+01, 6.2700e+01,\n",
            "           6.2735e+01, 6.2730e+01, 6.2690e+01, 6.2610e+01],\n",
            "          [6.2380e+01, 6.2500e+01, 6.2550e+01, 6.2570e+01, 6.2600e+01,\n",
            "           6.2580e+01, 6.2670e+01, 6.2600e+01, 6.2600e+01, 6.2550e+01,\n",
            "           6.2590e+01, 6.2490e+01, 6.2536e+01, 6.2670e+01, 6.2720e+01,\n",
            "           6.2750e+01, 6.2810e+01, 6.2830e+01, 6.2370e+01, 6.2440e+01,\n",
            "           6.2620e+01, 6.2560e+01, 6.2510e+01, 6.2520e+01],\n",
            "          [6.2380e+01, 6.2540e+01, 6.2660e+01, 6.2570e+01, 6.2600e+01,\n",
            "           6.2580e+01, 6.2880e+01, 6.2600e+01, 6.2610e+01, 6.2550e+01,\n",
            "           6.2590e+01, 6.2640e+01, 6.2815e+01, 6.2740e+01, 6.2775e+01,\n",
            "           6.2807e+01, 6.2910e+01, 6.2930e+01, 6.2440e+01, 6.2695e+01,\n",
            "           6.2680e+01, 6.2630e+01, 6.2570e+01, 6.2590e+01],\n",
            "          [1.0000e+02, 5.5000e+02, 2.1510e+03, 4.7900e+02, 8.5100e+02,\n",
            "           4.0000e+02, 7.7230e+03, 3.3700e+03, 2.8240e+03, 3.5100e+02,\n",
            "           2.0000e+02, 2.1860e+03, 1.7214e+05, 4.9870e+04, 4.5954e+04,\n",
            "           5.9517e+04, 8.4170e+04, 3.5788e+04, 1.3231e+05, 6.8885e+04,\n",
            "           6.7496e+04, 4.5718e+04, 4.6649e+04, 3.1901e+04]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5605, 2.8665, 0.2204]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0851, 0.8543, 0.0606]], device='cuda:0')\n",
            "[tensor([[[[6.2580e+01, 6.2400e+01, 6.2395e+01, 6.2340e+01, 6.2350e+01,\n",
            "           6.2350e+01, 6.2270e+01, 6.2190e+01, 6.2200e+01, 6.2190e+01,\n",
            "           6.2280e+01, 6.2490e+01, 6.2470e+01, 6.2270e+01, 6.2180e+01,\n",
            "           6.2210e+01, 6.2140e+01, 6.2140e+01, 6.2310e+01, 6.2355e+01,\n",
            "           6.2303e+01, 6.2260e+01, 6.2200e+01, 6.2090e+01],\n",
            "          [6.2600e+01, 6.2450e+01, 6.2410e+01, 6.2400e+01, 6.2380e+01,\n",
            "           6.2350e+01, 6.2330e+01, 6.2280e+01, 6.2235e+01, 6.2315e+01,\n",
            "           6.2500e+01, 6.2560e+01, 6.2480e+01, 6.2280e+01, 6.2270e+01,\n",
            "           6.2220e+01, 6.2150e+01, 6.2345e+01, 6.2360e+01, 6.2370e+01,\n",
            "           6.2330e+01, 6.2260e+01, 6.2200e+01, 6.2130e+01],\n",
            "          [6.2380e+01, 6.2350e+01, 6.2190e+01, 6.2270e+01, 6.2280e+01,\n",
            "           6.2210e+01, 6.2140e+01, 6.2120e+01, 6.2090e+01, 6.2190e+01,\n",
            "           6.2280e+01, 6.2420e+01, 6.2245e+01, 6.2180e+01, 6.2120e+01,\n",
            "           6.2110e+01, 6.2050e+01, 6.2140e+01, 6.2288e+01, 6.2270e+01,\n",
            "           6.2210e+01, 6.2140e+01, 6.2070e+01, 6.1910e+01],\n",
            "          [6.2380e+01, 6.2393e+01, 6.2330e+01, 6.2340e+01, 6.2340e+01,\n",
            "           6.2270e+01, 6.2190e+01, 6.2190e+01, 6.2190e+01, 6.2270e+01,\n",
            "           6.2500e+01, 6.2437e+01, 6.2265e+01, 6.2190e+01, 6.2200e+01,\n",
            "           6.2150e+01, 6.2150e+01, 6.2310e+01, 6.2360e+01, 6.2280e+01,\n",
            "           6.2230e+01, 6.2210e+01, 6.2105e+01, 6.1918e+01],\n",
            "          [3.3050e+04, 3.3678e+04, 8.5269e+04, 2.7567e+04, 2.7555e+04,\n",
            "           3.1279e+04, 8.0575e+04, 4.9644e+04, 6.2234e+04, 3.2788e+04,\n",
            "           4.7060e+04, 7.8595e+04, 6.5015e+04, 3.9133e+04, 4.4612e+04,\n",
            "           1.8845e+04, 5.0835e+04, 2.8545e+04, 9.8830e+03, 1.4346e+04,\n",
            "           2.0507e+04, 2.1357e+04, 4.0139e+04, 4.5782e+04]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5580, 2.8440, 0.2194]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0866, 0.8517, 0.0617]], device='cuda:0')\n",
            "[tensor([[[[6.1910e+01, 6.1730e+01, 6.1454e+01, 6.1790e+01, 6.1790e+01,\n",
            "           6.1740e+01, 6.1780e+01, 6.1840e+01, 6.1950e+01, 6.1940e+01,\n",
            "           6.1920e+01, 6.1920e+01, 6.2110e+01, 6.2015e+01, 6.1930e+01,\n",
            "           6.1920e+01, 6.1870e+01, 6.1910e+01, 6.1855e+01, 6.1870e+01,\n",
            "           6.1615e+01, 6.1530e+01, 6.1690e+01, 6.1670e+01],\n",
            "          [6.1950e+01, 6.1740e+01, 6.1810e+01, 6.1830e+01, 6.1800e+01,\n",
            "           6.1840e+01, 6.1870e+01, 6.1980e+01, 6.1990e+01, 6.1995e+01,\n",
            "           6.2000e+01, 6.2100e+01, 6.2115e+01, 6.2045e+01, 6.1940e+01,\n",
            "           6.1930e+01, 6.1910e+01, 6.1940e+01, 6.1920e+01, 6.1890e+01,\n",
            "           6.1630e+01, 6.1720e+01, 6.1740e+01, 6.1800e+01],\n",
            "          [6.1710e+01, 6.1420e+01, 6.1450e+01, 6.1760e+01, 6.1720e+01,\n",
            "           6.1740e+01, 6.1770e+01, 6.1840e+01, 6.1900e+01, 6.1910e+01,\n",
            "           6.1910e+01, 6.1920e+01, 6.1990e+01, 6.1880e+01, 6.1860e+01,\n",
            "           6.1840e+01, 6.1850e+01, 6.1840e+01, 6.1835e+01, 6.1600e+01,\n",
            "           6.1510e+01, 6.1515e+01, 6.1620e+01, 6.1610e+01],\n",
            "          [6.1720e+01, 6.1440e+01, 6.1810e+01, 6.1800e+01, 6.1740e+01,\n",
            "           6.1780e+01, 6.1850e+01, 6.1970e+01, 6.1940e+01, 6.1920e+01,\n",
            "           6.1920e+01, 6.2100e+01, 6.1990e+01, 6.1920e+01, 6.1925e+01,\n",
            "           6.1860e+01, 6.1910e+01, 6.1840e+01, 6.1870e+01, 6.1600e+01,\n",
            "           6.1530e+01, 6.1700e+01, 6.1642e+01, 6.1640e+01],\n",
            "          [4.0705e+04, 7.1009e+04, 1.0254e+05, 7.5467e+04, 2.3275e+04,\n",
            "           3.2931e+04, 3.0948e+04, 7.8716e+04, 6.6083e+04, 2.2298e+04,\n",
            "           2.3014e+04, 2.6600e+04, 3.1629e+04, 2.0076e+04, 2.3697e+04,\n",
            "           1.1617e+04, 2.2053e+04, 2.2129e+04, 1.6064e+04, 5.1081e+04,\n",
            "           2.3448e+04, 8.9122e+04, 2.8968e+04, 7.0167e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5548, 2.8221, 0.2173]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0880, 0.8492, 0.0628]], device='cuda:0')\n",
            "[tensor([[[[6.1620e+01, 6.1510e+01, 6.1620e+01, 6.1670e+01, 6.1700e+01,\n",
            "           6.1660e+01, 6.1783e+01, 6.1750e+01, 6.1770e+01, 6.1810e+01,\n",
            "           6.1840e+01, 6.1820e+01, 6.1790e+01, 6.1800e+01, 6.1810e+01,\n",
            "           6.1850e+01, 6.1940e+01, 6.1915e+01, 6.1960e+01, 6.2000e+01,\n",
            "           6.2000e+01, 6.2020e+01, 6.1990e+01, 6.1990e+01],\n",
            "          [6.1640e+01, 6.1620e+01, 6.1696e+01, 6.1700e+01, 6.1720e+01,\n",
            "           6.1800e+01, 6.1810e+01, 6.1810e+01, 6.1810e+01, 6.1850e+01,\n",
            "           6.1860e+01, 6.1840e+01, 6.1810e+01, 6.1812e+01, 6.1885e+01,\n",
            "           6.1940e+01, 6.1970e+01, 6.1980e+01, 6.1970e+01, 6.2000e+01,\n",
            "           6.2000e+01, 6.2030e+01, 6.1990e+01, 6.1990e+01],\n",
            "          [6.1520e+01, 6.1510e+01, 6.1610e+01, 6.1621e+01, 6.1650e+01,\n",
            "           6.1660e+01, 6.1730e+01, 6.1710e+01, 6.1735e+01, 6.1810e+01,\n",
            "           6.1799e+01, 6.1790e+01, 6.1710e+01, 6.1765e+01, 6.1790e+01,\n",
            "           6.1845e+01, 6.1895e+01, 6.1900e+01, 6.1960e+01, 6.2000e+01,\n",
            "           6.2000e+01, 6.1994e+01, 6.1990e+01, 6.1990e+01],\n",
            "          [6.1520e+01, 6.1590e+01, 6.1670e+01, 6.1690e+01, 6.1670e+01,\n",
            "           6.1775e+01, 6.1765e+01, 6.1780e+01, 6.1810e+01, 6.1850e+01,\n",
            "           6.1820e+01, 6.1797e+01, 6.1810e+01, 6.1810e+01, 6.1860e+01,\n",
            "           6.1935e+01, 6.1910e+01, 6.1960e+01, 6.1970e+01, 6.2000e+01,\n",
            "           6.2000e+01, 6.1994e+01, 6.1990e+01, 6.1990e+01],\n",
            "          [4.9780e+04, 1.3063e+04, 5.2381e+04, 2.6168e+04, 1.9974e+04,\n",
            "           3.3330e+04, 2.2134e+04, 2.6133e+04, 2.9369e+04, 1.0949e+04,\n",
            "           1.6580e+04, 2.4162e+04, 5.9351e+04, 1.4472e+04, 4.1337e+04,\n",
            "           3.7019e+04, 6.8987e+04, 1.4338e+05, 4.6360e+03, 1.0000e+02,\n",
            "           4.0000e+02, 9.9600e+02, 1.6000e+02, 0.0000e+00]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5525, 2.8233, 0.2139]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0877, 0.8497, 0.0625]], device='cuda:0')\n",
            "[tensor([[[[6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01],\n",
            "          [6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01],\n",
            "          [6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01],\n",
            "          [6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01,\n",
            "           6.1970e+01, 6.1970e+01, 6.1970e+01, 6.1970e+01],\n",
            "          [2.2000e+05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5543, 2.8251, 0.2169]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0877, 0.8497, 0.0626]], device='cuda:0')\n",
            "[tensor([[[[61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5543, 2.8251, 0.2169]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0877, 0.8497, 0.0626]], device='cuda:0')\n",
            "[tensor([[[[61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5543, 2.8251, 0.2169]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0877, 0.8497, 0.0626]], device='cuda:0')\n",
            "[tensor([[[[61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5543, 2.8251, 0.2169]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0877, 0.8497, 0.0626]], device='cuda:0')\n",
            "[tensor([[[[61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5543, 2.8251, 0.2169]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0877, 0.8497, 0.0626]], device='cuda:0')\n",
            "[tensor([[[[61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5543, 2.8251, 0.2169]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0877, 0.8497, 0.0626]], device='cuda:0')\n",
            "[tensor([[[[61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5543, 2.8251, 0.2169]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0877, 0.8497, 0.0626]], device='cuda:0')\n",
            "[tensor([[[[61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700, 61.9700,\n",
            "           61.9700, 61.9700, 61.9700],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([0])]\n",
            "Logits: tensor([[0.5543, 2.8251, 0.2169]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0877, 0.8497, 0.0626]], device='cuda:0')\n",
            "[tensor([[[[6.1970e+01, 6.2160e+01, 6.2160e+01, 6.2100e+01, 6.2060e+01,\n",
            "           6.2200e+01, 6.2020e+01, 6.2110e+01, 6.2150e+01, 6.2130e+01,\n",
            "           6.2150e+01, 6.2150e+01, 6.2190e+01, 6.2030e+01, 6.1930e+01,\n",
            "           6.2020e+01, 6.1860e+01, 6.1680e+01, 6.1670e+01, 6.1770e+01,\n",
            "           6.1790e+01, 6.1650e+01, 6.1600e+01, 6.1650e+01],\n",
            "          [6.1970e+01, 6.2160e+01, 6.2160e+01, 6.2130e+01, 6.2060e+01,\n",
            "           6.2200e+01, 6.2020e+01, 6.2110e+01, 6.2150e+01, 6.2130e+01,\n",
            "           6.2150e+01, 6.2150e+01, 6.2240e+01, 6.2030e+01, 6.2070e+01,\n",
            "           6.2030e+01, 6.1870e+01, 6.1720e+01, 6.1885e+01, 6.1800e+01,\n",
            "           6.1790e+01, 6.1660e+01, 6.1680e+01, 6.1690e+01],\n",
            "          [6.1970e+01, 6.2160e+01, 6.2160e+01, 6.2100e+01, 6.2060e+01,\n",
            "           6.2150e+01, 6.2018e+01, 6.2110e+01, 6.2120e+01, 6.2130e+01,\n",
            "           6.2150e+01, 6.2150e+01, 6.1950e+01, 6.1880e+01, 6.1910e+01,\n",
            "           6.1810e+01, 6.1600e+01, 6.1540e+01, 6.1630e+01, 6.1730e+01,\n",
            "           6.1650e+01, 6.1570e+01, 6.1560e+01, 6.1580e+01],\n",
            "          [6.1970e+01, 6.2160e+01, 6.2160e+01, 6.2100e+01, 6.2060e+01,\n",
            "           6.2150e+01, 6.2018e+01, 6.2110e+01, 6.2120e+01, 6.2130e+01,\n",
            "           6.2150e+01, 6.2150e+01, 6.2030e+01, 6.1950e+01, 6.2020e+01,\n",
            "           6.1850e+01, 6.1670e+01, 6.1680e+01, 6.1795e+01, 6.1770e+01,\n",
            "           6.1650e+01, 6.1610e+01, 6.1655e+01, 6.1620e+01],\n",
            "          [3.0850e+04, 1.0000e+02, 0.0000e+00, 1.3000e+04, 1.0000e+02,\n",
            "           4.3400e+02, 1.0050e+03, 3.5950e+03, 3.6000e+02, 2.0000e+02,\n",
            "           2.5020e+03, 0.0000e+00, 4.9601e+04, 5.1847e+04, 9.2655e+04,\n",
            "           4.6771e+04, 1.3866e+05, 7.1213e+04, 5.4361e+04, 2.7123e+04,\n",
            "           3.0325e+04, 3.9932e+04, 4.8018e+04, 2.5561e+04]]]]), tensor([1])]\n",
            "Logits: tensor([[0.5546, 2.8241, 0.2214]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0878, 0.8493, 0.0629]], device='cuda:0')\n",
            "[tensor([[[[6.1640e+01, 6.1730e+01, 6.1620e+01, 6.1600e+01, 6.1600e+01,\n",
            "           6.1720e+01, 6.1990e+01, 6.1970e+01, 6.2020e+01, 6.2130e+01,\n",
            "           6.2050e+01, 6.2090e+01, 6.2050e+01, 6.1930e+01, 6.1880e+01,\n",
            "           6.1960e+01, 6.1960e+01, 6.1950e+01, 6.2020e+01, 6.2070e+01,\n",
            "           6.1975e+01, 6.2030e+01, 6.2030e+01, 6.2030e+01],\n",
            "          [6.1740e+01, 6.1730e+01, 6.1675e+01, 6.1610e+01, 6.1740e+01,\n",
            "           6.2030e+01, 6.2000e+01, 6.2030e+01, 6.2135e+01, 6.2170e+01,\n",
            "           6.2100e+01, 6.2120e+01, 6.2090e+01, 6.1933e+01, 6.1960e+01,\n",
            "           6.2020e+01, 6.2025e+01, 6.2040e+01, 6.2120e+01, 6.2080e+01,\n",
            "           6.2030e+01, 6.2045e+01, 6.2045e+01, 6.2045e+01],\n",
            "          [6.1630e+01, 6.1600e+01, 6.1560e+01, 6.1360e+01, 6.1574e+01,\n",
            "           6.1680e+01, 6.1920e+01, 6.1970e+01, 6.1990e+01, 6.1980e+01,\n",
            "           6.1985e+01, 6.2020e+01, 6.1940e+01, 6.1870e+01, 6.1880e+01,\n",
            "           6.1960e+01, 6.1900e+01, 6.1950e+01, 6.2000e+01, 6.1960e+01,\n",
            "           6.1975e+01, 6.2030e+01, 6.2030e+01, 6.2030e+01],\n",
            "          [6.1720e+01, 6.1640e+01, 6.1570e+01, 6.1590e+01, 6.1725e+01,\n",
            "           6.2000e+01, 6.1980e+01, 6.2000e+01, 6.2130e+01, 6.2055e+01,\n",
            "           6.2077e+01, 6.2030e+01, 6.1990e+01, 6.1880e+01, 6.1960e+01,\n",
            "           6.1985e+01, 6.1970e+01, 6.2030e+01, 6.2060e+01, 6.1970e+01,\n",
            "           6.2020e+01, 6.2040e+01, 6.2040e+01, 6.2040e+01],\n",
            "          [2.4486e+04, 3.6963e+04, 2.4873e+04, 1.1054e+05, 4.5210e+04,\n",
            "           1.0238e+05, 3.9184e+04, 2.2793e+04, 6.4587e+04, 6.0623e+04,\n",
            "           3.8200e+04, 4.0679e+04, 4.5996e+04, 2.1053e+04, 9.9810e+03,\n",
            "           1.2250e+04, 2.2704e+04, 2.8843e+04, 1.8086e+04, 1.6339e+04,\n",
            "           7.6250e+03, 1.0035e+04, 0.0000e+00, 0.0000e+00]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5536, 2.8265, 0.2155]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0876, 0.8500, 0.0624]], device='cuda:0')\n",
            "[tensor([[[[62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300],\n",
            "          [62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450,\n",
            "           62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450,\n",
            "           62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450,\n",
            "           62.0450, 62.0450, 62.0450],\n",
            "          [62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300],\n",
            "          [62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400,\n",
            "           62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400,\n",
            "           62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400,\n",
            "           62.0400, 62.0400, 62.0400],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5549, 2.8285, 0.2172]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0875, 0.8501, 0.0624]], device='cuda:0')\n",
            "[tensor([[[[62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300],\n",
            "          [62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450,\n",
            "           62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450,\n",
            "           62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450, 62.0450,\n",
            "           62.0450, 62.0450, 62.0450],\n",
            "          [62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300, 62.0300,\n",
            "           62.0300, 62.0300, 62.0300],\n",
            "          [62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400,\n",
            "           62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400,\n",
            "           62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400, 62.0400,\n",
            "           62.0400, 62.0400, 62.0400],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000]]]]), tensor([2])]\n",
            "Logits: tensor([[0.5549, 2.8285, 0.2172]], device='cuda:0')\n",
            "Probs after LogSoft: tensor([[0.0875, 0.8501, 0.0624]], device='cuda:0')\n",
            "Test set accuracy is 0.273\n",
            "For class 0, recall is 0.0\n",
            "For class 1, recall is 1.0\n",
            "For class 2, recall is 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working Code"
      ],
      "metadata": {
        "id": "6BCMz6zXgtxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Preparing The Data"
      ],
      "metadata": {
        "id": "IMY3MYh4D7sR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mulitclass Classification (None CDT 1D CNN)"
      ],
      "metadata": {
        "id": "W-hurH5w70Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TfD1r6R9IbN",
        "outputId": "fde42bac-23b9-4821-e276-e62a1e05ccff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Time', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
              "       'VolumeWeightedAvgPrice'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full[\"Open\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KybVva6t9Xwx",
        "outputId": "04188c38-aa11-4833-85de-6ad39f479301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "timestamp\n",
              "2016-04-25 10:30:00-04:00     68.81\n",
              "2016-04-25 10:35:00-04:00     68.88\n",
              "2016-04-25 10:40:00-04:00     68.91\n",
              "2016-04-25 10:45:00-04:00     68.90\n",
              "2016-04-25 10:50:00-04:00     68.94\n",
              "                              ...  \n",
              "2021-01-19 08:50:00-05:00    145.00\n",
              "2021-01-19 09:00:00-05:00    144.98\n",
              "2021-01-19 09:10:00-05:00    144.98\n",
              "2021-01-19 09:15:00-05:00    144.93\n",
              "2021-01-19 09:20:00-05:00    144.81\n",
              "Name: Open, Length: 124174, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaled_df = pd.DataFrame()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaled_train = scaler.fit_transform(train[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
        "scaled_val = scaler.fit_transform(val[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
        "scaled_test = scaler.fit_transform(test[['Open', 'High', 'Low', 'Close', 'Volume']])"
      ],
      "metadata": {
        "id": "YYCBKN4uu-FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_targets_df = pd.DataFrame(train_targets)\n",
        "val_targets_df = pd.DataFrame(val_targets)\n",
        "test_targets_df = pd.DataFrame(test_targets)\n",
        "\n",
        "class2idx = {\n",
        "    \"up\":0,\n",
        "    \"flat\":1,\n",
        "    \"down\":2,\n",
        "}\n",
        "\n",
        "idx2class = {v: k for k, v in class2idx.items()}\n",
        "\n",
        "train_targets_df.replace(class2idx, inplace=True)\n",
        "val_targets_df.replace(class2idx, inplace=True)\n",
        "test_targets_df.replace(class2idx, inplace=True)"
      ],
      "metadata": {
        "id": "TCETOevJpk81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_targets_df[0].value_counts().plot(kind = 'bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "V9bV2_jpp6Qx",
        "outputId": "bde9e731-1d9c-448f-d877-e65c51fe7cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f40c529f910>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
        "    \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum() / len(correct_pred)\n",
        "    \n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "metadata": {
        "id": "Jx5CwK8Qvxos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_stats = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}\n",
        "loss_stats = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}"
      ],
      "metadata": {
        "id": "wYRwPyN5vzAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Begin training.\")\n",
        "\n",
        "for e in tqdm(range(1, EPOCHS+1)):\n",
        "  \n",
        "  # TRAINING\n",
        "  train_epoch_loss = 0\n",
        "  train_epoch_acc = 0\n",
        "\n",
        "\n",
        "  model.train()\n",
        "  for X_train_batch, y_train_batch in train_loader:\n",
        "      X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      y_train_pred = model(X_train_batch)\n",
        "      \n",
        "      train_loss = criterion(y_train_pred, y_train_batch)\n",
        "      train_acc = multi_acc(y_train_pred, y_train_batch)\n",
        "      \n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      train_epoch_loss += train_loss.item()\n",
        "      train_epoch_acc += train_acc.item()\n",
        "      \n",
        "      \n",
        "  # VALIDATION    \n",
        "  with torch.no_grad():\n",
        "      \n",
        "      val_epoch_loss = 0\n",
        "      val_epoch_acc = 0\n",
        "      \n",
        "      model.eval()\n",
        "      for X_val_batch, y_val_batch in val_loader:\n",
        "          X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
        "          \n",
        "          y_val_pred = model(X_val_batch)\n",
        "                      \n",
        "          val_loss = criterion(y_val_pred, y_val_batch)\n",
        "          val_acc = multi_acc(y_val_pred, y_val_batch)\n",
        "          \n",
        "          val_epoch_loss += val_loss.item()\n",
        "          val_epoch_acc += val_acc.item()\n",
        "\n",
        "  loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
        "  loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
        "  accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
        "  accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
        "                            \n",
        "\n",
        "  print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "35b0c6a641f74b7a8a5a17696c771999",
            "5435c22875e1449bba6f514dc362fb86",
            "2174b8eaf379476aa207a7d3553a23cb",
            "d2eea602e1f44679b9dca81d02cef6a9",
            "4c4ee8d44be44753b86d2334ed5201d9",
            "2d07aa40726741bba6d08a741f239b2a",
            "ae9e58658d6e45a0ae4f071d65facbd8",
            "39c656c52a3b41f4912ae2f141bf1291",
            "101532c20c604f9cbddaae38f83cb611",
            "a809155bf81340c88a359f8e8b52b1a7",
            "8a927038a7cb49a6a64673ce556a0c8e"
          ]
        },
        "id": "8f5oKsuRvz21",
        "outputId": "b29c559b-8c71-422a-eb0f-83e583c0dd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35b0c6a641f74b7a8a5a17696c771999",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001: | Train Loss: 1.03773 | Val Loss: 18.28548 | Train Acc: 46.339| Val Acc: 35.978\n",
            "Epoch 002: | Train Loss: 1.03568 | Val Loss: 14.71919 | Train Acc: 46.572| Val Acc: 35.846\n",
            "Epoch 003: | Train Loss: 1.03342 | Val Loss: 16.51808 | Train Acc: 46.793| Val Acc: 36.061\n",
            "Epoch 004: | Train Loss: 1.03213 | Val Loss: 21.83980 | Train Acc: 46.823| Val Acc: 36.041\n",
            "Epoch 005: | Train Loss: 1.03002 | Val Loss: 22.58325 | Train Acc: 47.167| Val Acc: 35.862\n",
            "Epoch 006: | Train Loss: 1.02964 | Val Loss: 22.80922 | Train Acc: 47.228| Val Acc: 35.958\n",
            "Epoch 007: | Train Loss: 1.02630 | Val Loss: 22.72420 | Train Acc: 47.528| Val Acc: 35.934\n",
            "Epoch 008: | Train Loss: 1.02479 | Val Loss: 22.38807 | Train Acc: 47.576| Val Acc: 35.902\n",
            "Epoch 009: | Train Loss: 1.02515 | Val Loss: 22.53223 | Train Acc: 47.479| Val Acc: 36.077\n",
            "Epoch 010: | Train Loss: 1.02227 | Val Loss: 23.79687 | Train Acc: 47.802| Val Acc: 35.974\n",
            "Epoch 011: | Train Loss: 1.02061 | Val Loss: 24.85404 | Train Acc: 47.934| Val Acc: 35.866\n",
            "Epoch 012: | Train Loss: 1.01874 | Val Loss: 25.26233 | Train Acc: 48.206| Val Acc: 35.902\n",
            "Epoch 013: | Train Loss: 1.01619 | Val Loss: 21.64190 | Train Acc: 48.439| Val Acc: 36.133\n",
            "Epoch 014: | Train Loss: 1.01631 | Val Loss: 27.45609 | Train Acc: 48.294| Val Acc: 35.802\n",
            "Epoch 015: | Train Loss: 1.01460 | Val Loss: 22.39434 | Train Acc: 48.581| Val Acc: 36.010\n",
            "Epoch 016: | Train Loss: 1.01442 | Val Loss: 27.13374 | Train Acc: 48.710| Val Acc: 35.890\n",
            "Epoch 017: | Train Loss: 1.01151 | Val Loss: 32.04726 | Train Acc: 48.914| Val Acc: 35.802\n",
            "Epoch 018: | Train Loss: 1.01259 | Val Loss: 34.88230 | Train Acc: 48.686| Val Acc: 35.886\n",
            "Epoch 019: | Train Loss: 1.00837 | Val Loss: 42.48577 | Train Acc: 49.032| Val Acc: 35.758\n",
            "Epoch 020: | Train Loss: 1.00575 | Val Loss: 36.52548 | Train Acc: 49.444| Val Acc: 35.850\n",
            "Epoch 021: | Train Loss: 1.00665 | Val Loss: 35.56726 | Train Acc: 49.083| Val Acc: 35.814\n",
            "Epoch 022: | Train Loss: 1.00381 | Val Loss: 35.14205 | Train Acc: 49.472| Val Acc: 35.846\n",
            "Epoch 023: | Train Loss: 1.00146 | Val Loss: 38.23703 | Train Acc: 49.552| Val Acc: 35.886\n",
            "Epoch 024: | Train Loss: 1.00012 | Val Loss: 39.01895 | Train Acc: 49.718| Val Acc: 35.906\n",
            "Epoch 025: | Train Loss: 1.00085 | Val Loss: 42.14128 | Train Acc: 49.702| Val Acc: 35.846\n",
            "Epoch 026: | Train Loss: 0.99834 | Val Loss: 48.55490 | Train Acc: 49.822| Val Acc: 35.890\n",
            "Epoch 027: | Train Loss: 0.99707 | Val Loss: 39.29040 | Train Acc: 49.774| Val Acc: 35.878\n",
            "Epoch 028: | Train Loss: 0.99660 | Val Loss: 41.46110 | Train Acc: 50.079| Val Acc: 35.954\n",
            "Epoch 029: | Train Loss: 0.99407 | Val Loss: 46.91596 | Train Acc: 50.052| Val Acc: 36.029\n",
            "Epoch 030: | Train Loss: 0.99352 | Val Loss: 42.53436 | Train Acc: 50.019| Val Acc: 35.938\n",
            "Epoch 031: | Train Loss: 0.99270 | Val Loss: 41.23104 | Train Acc: 50.393| Val Acc: 35.268\n",
            "Epoch 032: | Train Loss: 0.99107 | Val Loss: 46.56323 | Train Acc: 50.326| Val Acc: 35.846\n",
            "Epoch 033: | Train Loss: 0.99041 | Val Loss: 46.38457 | Train Acc: 50.346| Val Acc: 35.870\n",
            "Epoch 034: | Train Loss: 0.98960 | Val Loss: 38.29024 | Train Acc: 50.368| Val Acc: 35.862\n",
            "Epoch 035: | Train Loss: 0.98835 | Val Loss: 48.10986 | Train Acc: 50.696| Val Acc: 35.946\n",
            "Epoch 036: | Train Loss: 0.98682 | Val Loss: 50.63705 | Train Acc: 50.424| Val Acc: 35.918\n",
            "Epoch 037: | Train Loss: 0.98614 | Val Loss: 54.64801 | Train Acc: 50.604| Val Acc: 35.830\n",
            "Epoch 038: | Train Loss: 0.98347 | Val Loss: 56.06499 | Train Acc: 50.920| Val Acc: 35.659\n",
            "Epoch 039: | Train Loss: 0.98360 | Val Loss: 55.96591 | Train Acc: 50.815| Val Acc: 35.954\n",
            "Epoch 040: | Train Loss: 0.98382 | Val Loss: 49.68804 | Train Acc: 51.094| Val Acc: 35.986\n",
            "Epoch 041: | Train Loss: 0.98386 | Val Loss: 50.84728 | Train Acc: 50.751| Val Acc: 35.970\n",
            "Epoch 042: | Train Loss: 0.97935 | Val Loss: 56.94556 | Train Acc: 51.201| Val Acc: 35.906\n",
            "Epoch 043: | Train Loss: 0.97944 | Val Loss: 61.34190 | Train Acc: 51.260| Val Acc: 35.902\n",
            "Epoch 044: | Train Loss: 0.97816 | Val Loss: 48.00104 | Train Acc: 51.431| Val Acc: 35.790\n",
            "Epoch 045: | Train Loss: 0.97301 | Val Loss: 52.67190 | Train Acc: 51.501| Val Acc: 36.117\n",
            "Epoch 046: | Train Loss: 0.97485 | Val Loss: 59.17818 | Train Acc: 51.496| Val Acc: 35.906\n",
            "Epoch 047: | Train Loss: 0.97499 | Val Loss: 65.28648 | Train Acc: 51.647| Val Acc: 35.882\n",
            "Epoch 048: | Train Loss: 0.97311 | Val Loss: 54.39216 | Train Acc: 51.569| Val Acc: 36.026\n",
            "Epoch 049: | Train Loss: 0.97351 | Val Loss: 44.34307 | Train Acc: 51.847| Val Acc: 35.727\n",
            "Epoch 050: | Train Loss: 0.96935 | Val Loss: 57.58184 | Train Acc: 52.052| Val Acc: 35.958\n",
            "Epoch 051: | Train Loss: 0.96926 | Val Loss: 65.54543 | Train Acc: 51.996| Val Acc: 35.898\n",
            "Epoch 052: | Train Loss: 0.96741 | Val Loss: 42.53718 | Train Acc: 52.229| Val Acc: 35.886\n",
            "Epoch 053: | Train Loss: 0.96689 | Val Loss: 56.03723 | Train Acc: 52.268| Val Acc: 36.093\n",
            "Epoch 054: | Train Loss: 0.96595 | Val Loss: 54.89665 | Train Acc: 52.240| Val Acc: 36.010\n",
            "Epoch 055: | Train Loss: 0.96384 | Val Loss: 55.37905 | Train Acc: 52.521| Val Acc: 35.830\n",
            "Epoch 056: | Train Loss: 0.96428 | Val Loss: 58.25829 | Train Acc: 52.276| Val Acc: 36.026\n",
            "Epoch 057: | Train Loss: 0.96330 | Val Loss: 57.48329 | Train Acc: 52.342| Val Acc: 36.029\n",
            "Epoch 058: | Train Loss: 0.96121 | Val Loss: 47.57709 | Train Acc: 52.694| Val Acc: 35.998\n",
            "Epoch 059: | Train Loss: 0.96057 | Val Loss: 50.21600 | Train Acc: 52.605| Val Acc: 35.838\n",
            "Epoch 060: | Train Loss: 0.95756 | Val Loss: 55.00718 | Train Acc: 53.107| Val Acc: 36.006\n",
            "Epoch 061: | Train Loss: 0.95794 | Val Loss: 61.02519 | Train Acc: 52.805| Val Acc: 35.822\n",
            "Epoch 062: | Train Loss: 0.95516 | Val Loss: 51.33713 | Train Acc: 53.103| Val Acc: 35.938\n",
            "Epoch 063: | Train Loss: 0.95546 | Val Loss: 55.24835 | Train Acc: 53.142| Val Acc: 35.970\n",
            "Epoch 064: | Train Loss: 0.95535 | Val Loss: 60.38786 | Train Acc: 53.043| Val Acc: 35.882\n",
            "Epoch 065: | Train Loss: 0.95326 | Val Loss: 61.13352 | Train Acc: 53.405| Val Acc: 36.014\n",
            "Epoch 066: | Train Loss: 0.95002 | Val Loss: 67.09717 | Train Acc: 53.337| Val Acc: 36.006\n",
            "Epoch 067: | Train Loss: 0.94862 | Val Loss: 48.98560 | Train Acc: 53.654| Val Acc: 35.918\n",
            "Epoch 068: | Train Loss: 0.94942 | Val Loss: 50.85423 | Train Acc: 53.552| Val Acc: 35.982\n",
            "Epoch 069: | Train Loss: 0.95021 | Val Loss: 55.76363 | Train Acc: 53.528| Val Acc: 35.922\n",
            "Epoch 070: | Train Loss: 0.94842 | Val Loss: 64.29850 | Train Acc: 53.530| Val Acc: 35.938\n",
            "Epoch 071: | Train Loss: 0.94498 | Val Loss: 65.09526 | Train Acc: 53.623| Val Acc: 35.727\n",
            "Epoch 072: | Train Loss: 0.94611 | Val Loss: 53.36845 | Train Acc: 53.795| Val Acc: 35.073\n",
            "Epoch 073: | Train Loss: 0.94559 | Val Loss: 53.11786 | Train Acc: 53.801| Val Acc: 36.053\n",
            "Epoch 074: | Train Loss: 0.94210 | Val Loss: 59.21576 | Train Acc: 54.012| Val Acc: 36.049\n",
            "Epoch 075: | Train Loss: 0.94273 | Val Loss: 66.27225 | Train Acc: 53.881| Val Acc: 36.057\n",
            "Epoch 076: | Train Loss: 0.94513 | Val Loss: 53.46854 | Train Acc: 53.835| Val Acc: 36.281\n",
            "Epoch 077: | Train Loss: 0.93879 | Val Loss: 46.96310 | Train Acc: 54.409| Val Acc: 36.137\n",
            "Epoch 078: | Train Loss: 0.93832 | Val Loss: 52.83578 | Train Acc: 54.327| Val Acc: 35.639\n",
            "Epoch 079: | Train Loss: 0.93885 | Val Loss: 42.54730 | Train Acc: 54.417| Val Acc: 36.177\n",
            "Epoch 080: | Train Loss: 0.93529 | Val Loss: 50.41648 | Train Acc: 54.734| Val Acc: 36.137\n",
            "Epoch 081: | Train Loss: 0.93607 | Val Loss: 46.55207 | Train Acc: 54.076| Val Acc: 36.073\n",
            "Epoch 082: | Train Loss: 0.93454 | Val Loss: 76.95360 | Train Acc: 54.491| Val Acc: 35.934\n",
            "Epoch 083: | Train Loss: 0.93377 | Val Loss: 68.89742 | Train Acc: 54.645| Val Acc: 35.994\n",
            "Epoch 084: | Train Loss: 0.93435 | Val Loss: 57.23074 | Train Acc: 54.493| Val Acc: 36.261\n",
            "Epoch 085: | Train Loss: 0.92999 | Val Loss: 73.35243 | Train Acc: 54.959| Val Acc: 36.137\n",
            "Epoch 086: | Train Loss: 0.92828 | Val Loss: 74.65684 | Train Acc: 54.931| Val Acc: 36.217\n",
            "Epoch 087: | Train Loss: 0.92981 | Val Loss: 58.95812 | Train Acc: 54.781| Val Acc: 36.141\n",
            "Epoch 088: | Train Loss: 0.92561 | Val Loss: 71.39651 | Train Acc: 54.954| Val Acc: 36.336\n",
            "Epoch 089: | Train Loss: 0.92389 | Val Loss: 59.62870 | Train Acc: 55.071| Val Acc: 36.352\n",
            "Epoch 090: | Train Loss: 0.92331 | Val Loss: 38.46428 | Train Acc: 55.271| Val Acc: 36.201\n",
            "Epoch 091: | Train Loss: 0.92517 | Val Loss: 42.62886 | Train Acc: 55.228| Val Acc: 36.213\n",
            "Epoch 092: | Train Loss: 0.91907 | Val Loss: 51.41695 | Train Acc: 55.352| Val Acc: 36.117\n",
            "Epoch 093: | Train Loss: 0.92204 | Val Loss: 48.36184 | Train Acc: 55.327| Val Acc: 36.464\n",
            "Epoch 094: | Train Loss: 0.92134 | Val Loss: 45.72194 | Train Acc: 55.610| Val Acc: 36.205\n",
            "Epoch 095: | Train Loss: 0.91856 | Val Loss: 50.06196 | Train Acc: 55.715| Val Acc: 36.229\n",
            "Epoch 096: | Train Loss: 0.91479 | Val Loss: 53.72951 | Train Acc: 55.969| Val Acc: 36.372\n",
            "Epoch 097: | Train Loss: 0.91685 | Val Loss: 31.64838 | Train Acc: 55.743| Val Acc: 36.121\n",
            "Epoch 098: | Train Loss: 0.91438 | Val Loss: 63.94009 | Train Acc: 55.661| Val Acc: 36.241\n",
            "Epoch 099: | Train Loss: 0.91564 | Val Loss: 31.72633 | Train Acc: 55.733| Val Acc: 36.037\n",
            "Epoch 100: | Train Loss: 0.91364 | Val Loss: 48.22221 | Train Acc: 55.620| Val Acc: 36.225\n",
            "Epoch 101: | Train Loss: 0.91095 | Val Loss: 54.42397 | Train Acc: 56.062| Val Acc: 36.269\n",
            "Epoch 102: | Train Loss: 0.91041 | Val Loss: 50.81663 | Train Acc: 56.208| Val Acc: 36.189\n",
            "Epoch 103: | Train Loss: 0.90579 | Val Loss: 49.51678 | Train Acc: 56.250| Val Acc: 36.181\n",
            "Epoch 104: | Train Loss: 0.91100 | Val Loss: 57.90573 | Train Acc: 56.148| Val Acc: 36.097\n",
            "Epoch 105: | Train Loss: 0.91013 | Val Loss: 48.70327 | Train Acc: 56.116| Val Acc: 36.249\n",
            "Epoch 106: | Train Loss: 0.90439 | Val Loss: 53.61910 | Train Acc: 56.474| Val Acc: 36.400\n",
            "Epoch 107: | Train Loss: 0.90536 | Val Loss: 53.45957 | Train Acc: 56.655| Val Acc: 36.085\n",
            "Epoch 108: | Train Loss: 0.90200 | Val Loss: 43.10108 | Train Acc: 56.489| Val Acc: 36.364\n",
            "Epoch 109: | Train Loss: 0.90089 | Val Loss: 40.50897 | Train Acc: 56.572| Val Acc: 36.332\n",
            "Epoch 110: | Train Loss: 0.90226 | Val Loss: 57.36740 | Train Acc: 56.627| Val Acc: 36.133\n",
            "Epoch 111: | Train Loss: 0.89964 | Val Loss: 41.31016 | Train Acc: 56.814| Val Acc: 36.125\n",
            "Epoch 112: | Train Loss: 0.90043 | Val Loss: 44.83579 | Train Acc: 56.405| Val Acc: 36.173\n",
            "Epoch 113: | Train Loss: 0.89853 | Val Loss: 43.95112 | Train Acc: 56.914| Val Acc: 36.328\n",
            "Epoch 114: | Train Loss: 0.89548 | Val Loss: 48.75519 | Train Acc: 57.081| Val Acc: 36.412\n",
            "Epoch 115: | Train Loss: 0.89465 | Val Loss: 41.63435 | Train Acc: 56.929| Val Acc: 36.500\n",
            "Epoch 116: | Train Loss: 0.89509 | Val Loss: 67.38322 | Train Acc: 56.954| Val Acc: 36.384\n",
            "Epoch 117: | Train Loss: 0.89713 | Val Loss: 52.03984 | Train Acc: 57.014| Val Acc: 36.205\n",
            "Epoch 118: | Train Loss: 0.89351 | Val Loss: 45.97796 | Train Acc: 56.879| Val Acc: 36.448\n",
            "Epoch 119: | Train Loss: 0.89223 | Val Loss: 65.18914 | Train Acc: 57.305| Val Acc: 36.293\n",
            "Epoch 120: | Train Loss: 0.88792 | Val Loss: 39.41584 | Train Acc: 57.549| Val Acc: 36.053\n",
            "Epoch 121: | Train Loss: 0.88764 | Val Loss: 37.83593 | Train Acc: 57.646| Val Acc: 36.360\n",
            "Epoch 122: | Train Loss: 0.88669 | Val Loss: 36.00223 | Train Acc: 57.638| Val Acc: 36.317\n",
            "Epoch 123: | Train Loss: 0.88559 | Val Loss: 31.98377 | Train Acc: 57.677| Val Acc: 36.396\n",
            "Epoch 124: | Train Loss: 0.88573 | Val Loss: 40.24111 | Train Acc: 57.835| Val Acc: 36.237\n",
            "Epoch 125: | Train Loss: 0.88257 | Val Loss: 59.22653 | Train Acc: 57.817| Val Acc: 36.324\n",
            "Epoch 126: | Train Loss: 0.88364 | Val Loss: 42.74998 | Train Acc: 57.798| Val Acc: 36.372\n",
            "Epoch 127: | Train Loss: 0.88062 | Val Loss: 42.72222 | Train Acc: 58.098| Val Acc: 36.472\n",
            "Epoch 128: | Train Loss: 0.88004 | Val Loss: 41.00631 | Train Acc: 57.767| Val Acc: 36.201\n",
            "Epoch 129: | Train Loss: 0.88109 | Val Loss: 34.59373 | Train Acc: 58.119| Val Acc: 36.336\n",
            "Epoch 130: | Train Loss: 0.87749 | Val Loss: 38.29935 | Train Acc: 58.275| Val Acc: 36.253\n",
            "Epoch 131: | Train Loss: 0.87694 | Val Loss: 29.02172 | Train Acc: 57.956| Val Acc: 36.404\n",
            "Epoch 132: | Train Loss: 0.87692 | Val Loss: 32.72198 | Train Acc: 58.161| Val Acc: 36.392\n",
            "Epoch 133: | Train Loss: 0.87265 | Val Loss: 40.77891 | Train Acc: 58.397| Val Acc: 36.512\n",
            "Epoch 134: | Train Loss: 0.87513 | Val Loss: 37.43953 | Train Acc: 58.242| Val Acc: 36.261\n",
            "Epoch 135: | Train Loss: 0.87333 | Val Loss: 34.67797 | Train Acc: 58.597| Val Acc: 36.416\n",
            "Epoch 136: | Train Loss: 0.87301 | Val Loss: 40.11558 | Train Acc: 58.622| Val Acc: 36.069\n",
            "Epoch 137: | Train Loss: 0.87193 | Val Loss: 36.48601 | Train Acc: 58.376| Val Acc: 36.340\n",
            "Epoch 138: | Train Loss: 0.86881 | Val Loss: 44.89180 | Train Acc: 58.507| Val Acc: 36.249\n",
            "Epoch 139: | Train Loss: 0.86902 | Val Loss: 36.81583 | Train Acc: 58.889| Val Acc: 36.257\n",
            "Epoch 140: | Train Loss: 0.87121 | Val Loss: 32.80822 | Train Acc: 58.475| Val Acc: 36.400\n",
            "Epoch 141: | Train Loss: 0.87340 | Val Loss: 36.92319 | Train Acc: 58.488| Val Acc: 36.452\n",
            "Epoch 142: | Train Loss: 0.86699 | Val Loss: 28.78332 | Train Acc: 58.645| Val Acc: 36.285\n",
            "Epoch 143: | Train Loss: 0.87130 | Val Loss: 41.32294 | Train Acc: 58.467| Val Acc: 36.197\n",
            "Epoch 144: | Train Loss: 0.86106 | Val Loss: 41.97705 | Train Acc: 59.151| Val Acc: 36.157\n",
            "Epoch 145: | Train Loss: 0.87009 | Val Loss: 49.16172 | Train Acc: 58.592| Val Acc: 36.301\n",
            "Epoch 146: | Train Loss: 0.86423 | Val Loss: 52.38777 | Train Acc: 59.114| Val Acc: 36.121\n",
            "Epoch 147: | Train Loss: 0.86333 | Val Loss: 51.05564 | Train Acc: 59.116| Val Acc: 36.169\n",
            "Epoch 148: | Train Loss: 0.86276 | Val Loss: 30.99604 | Train Acc: 59.183| Val Acc: 36.081\n",
            "Epoch 149: | Train Loss: 0.85988 | Val Loss: 51.52852 | Train Acc: 59.279| Val Acc: 36.265\n",
            "Epoch 150: | Train Loss: 0.86540 | Val Loss: 53.16078 | Train Acc: 58.780| Val Acc: 36.313\n",
            "Epoch 151: | Train Loss: 0.85481 | Val Loss: 60.12736 | Train Acc: 59.525| Val Acc: 36.081\n",
            "Epoch 152: | Train Loss: 0.86499 | Val Loss: 37.30025 | Train Acc: 58.743| Val Acc: 36.041\n",
            "Epoch 153: | Train Loss: 0.85688 | Val Loss: 41.30300 | Train Acc: 59.365| Val Acc: 36.201\n",
            "Epoch 154: | Train Loss: 0.85733 | Val Loss: 40.48661 | Train Acc: 59.557| Val Acc: 36.153\n",
            "Epoch 155: | Train Loss: 0.85468 | Val Loss: 33.74834 | Train Acc: 59.677| Val Acc: 36.225\n",
            "Epoch 156: | Train Loss: 0.85272 | Val Loss: 34.98886 | Train Acc: 59.542| Val Acc: 36.153\n",
            "Epoch 157: | Train Loss: 0.85270 | Val Loss: 48.54581 | Train Acc: 59.723| Val Acc: 36.065\n",
            "Epoch 158: | Train Loss: 0.85048 | Val Loss: 42.49513 | Train Acc: 59.692| Val Acc: 36.153\n",
            "Epoch 159: | Train Loss: 0.84920 | Val Loss: 35.11881 | Train Acc: 59.665| Val Acc: 36.261\n",
            "Epoch 160: | Train Loss: 0.85216 | Val Loss: 29.53816 | Train Acc: 59.648| Val Acc: 36.412\n",
            "Epoch 161: | Train Loss: 0.85149 | Val Loss: 40.91609 | Train Acc: 59.619| Val Acc: 36.057\n",
            "Epoch 162: | Train Loss: 0.85031 | Val Loss: 46.43221 | Train Acc: 59.607| Val Acc: 36.201\n",
            "Epoch 163: | Train Loss: 0.84934 | Val Loss: 49.58376 | Train Acc: 59.905| Val Acc: 36.037\n",
            "Epoch 164: | Train Loss: 0.84644 | Val Loss: 35.32785 | Train Acc: 60.108| Val Acc: 36.097\n",
            "Epoch 165: | Train Loss: 0.84282 | Val Loss: 45.99948 | Train Acc: 60.381| Val Acc: 35.982\n",
            "Epoch 166: | Train Loss: 0.84430 | Val Loss: 60.52897 | Train Acc: 60.116| Val Acc: 36.041\n",
            "Epoch 167: | Train Loss: 0.84157 | Val Loss: 50.27751 | Train Acc: 60.304| Val Acc: 35.966\n",
            "Epoch 168: | Train Loss: 0.84110 | Val Loss: 44.85651 | Train Acc: 60.211| Val Acc: 36.177\n",
            "Epoch 169: | Train Loss: 0.84410 | Val Loss: 37.01279 | Train Acc: 60.181| Val Acc: 36.029\n",
            "Epoch 170: | Train Loss: 0.84234 | Val Loss: 46.77090 | Train Acc: 60.224| Val Acc: 36.313\n",
            "Epoch 171: | Train Loss: 0.84089 | Val Loss: 48.12755 | Train Acc: 60.470| Val Acc: 36.117\n",
            "Epoch 172: | Train Loss: 0.84329 | Val Loss: 52.33008 | Train Acc: 60.501| Val Acc: 36.233\n",
            "Epoch 173: | Train Loss: 0.83895 | Val Loss: 50.74819 | Train Acc: 60.462| Val Acc: 36.277\n",
            "Epoch 174: | Train Loss: 0.83892 | Val Loss: 40.94375 | Train Acc: 60.491| Val Acc: 36.364\n",
            "Epoch 175: | Train Loss: 0.84176 | Val Loss: 53.58597 | Train Acc: 60.583| Val Acc: 36.281\n",
            "Epoch 176: | Train Loss: 0.83454 | Val Loss: 53.97118 | Train Acc: 60.559| Val Acc: 36.301\n",
            "Epoch 177: | Train Loss: 0.83481 | Val Loss: 44.03920 | Train Acc: 60.746| Val Acc: 36.376\n",
            "Epoch 178: | Train Loss: 0.83578 | Val Loss: 48.62105 | Train Acc: 60.689| Val Acc: 36.265\n",
            "Epoch 179: | Train Loss: 0.83304 | Val Loss: 62.92916 | Train Acc: 60.652| Val Acc: 36.396\n",
            "Epoch 180: | Train Loss: 0.83344 | Val Loss: 53.76933 | Train Acc: 60.517| Val Acc: 36.460\n",
            "Epoch 181: | Train Loss: 0.83127 | Val Loss: 77.82663 | Train Acc: 60.987| Val Acc: 36.344\n",
            "Epoch 182: | Train Loss: 0.83671 | Val Loss: 37.98298 | Train Acc: 60.579| Val Acc: 36.221\n",
            "Epoch 183: | Train Loss: 0.82852 | Val Loss: 51.25410 | Train Acc: 61.028| Val Acc: 36.424\n",
            "Epoch 184: | Train Loss: 0.82652 | Val Loss: 48.26266 | Train Acc: 61.196| Val Acc: 36.372\n",
            "Epoch 185: | Train Loss: 0.83206 | Val Loss: 56.82527 | Train Acc: 60.879| Val Acc: 36.169\n",
            "Epoch 186: | Train Loss: 0.82996 | Val Loss: 48.34464 | Train Acc: 60.903| Val Acc: 36.213\n",
            "Epoch 187: | Train Loss: 0.82605 | Val Loss: 41.21401 | Train Acc: 61.087| Val Acc: 36.344\n",
            "Epoch 188: | Train Loss: 0.82225 | Val Loss: 60.16166 | Train Acc: 61.396| Val Acc: 36.113\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-5748e27f82c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m           \u001b[0mX_val_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_val_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m           \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m           \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-5d63d3fdec13>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# APPENDIX"
      ],
      "metadata": {
        "id": "CdPrjLX4u2u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_df = pd.DataFrame(full_targets, columns=[\"FuturePrice\"])"
      ],
      "metadata": {
        "id": "kO0RlwtEvavG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_df[\"FuturePrice\"].value_counts().plot(kind = 'bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "o4DstDh7v61B",
        "outputId": "9fb82a04-9a72-4e9f-acc0-e71b745dfc7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74d1325d10>"
            ]
          },
          "metadata": {},
          "execution_count": 338
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEJCAYAAAB2T0usAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVBklEQVR4nO3dfZBd9X3f8fenIhCPbQVhNirRg4Ud2TPAxLJRMK0NQ0IMArsRzmQIzMQoLmOZAFN7kplUTv7AxaWDUz+0dFw8clERUwdMgwkaR5QoGhdCW4wWmwICUy0YhlWFpCACTnBwhL/94/7WPZZ3pdXu6t4V+37NnLnnfM/T986O9qPztCdVhSRpbvtHg25AkjR4hoEkyTCQJBkGkiQMA0kScMygG5iqE088sZYtWzboNiTpqPLQQw/9dVUNHVg/asNg2bJlDA8PD7oNSTqqJHl2vLqniSRJhoEkyTCQJGEYSJIwDCRJGAaSJCYRBkmWJPlmkseTbE/yiVY/IcmWJDva54JWT5IbkowkeSTJezrbWtOW35FkTad+epJH2zo3JMmR+LKSpPFN5shgP/D7VXUKcCZwVZJTgHXA1qpaDmxt0wAXAMvbsBa4EXrhAVwDvBc4A7hmLEDaMh/rrLdq+l9NkjRZhwyDqtpVVd9u498HngAWAauBjW2xjcBFbXw1cEv1PAAcn+Qk4HxgS1Xtq6oXgS3AqjZvflU9UL2XK9zS2ZYkqQ8O6wnkJMuAdwPfAhZW1a4263lgYRtfBDzXWW201Q5WHx2nPt7+19I72mDp0qWH0/q0LVv3533dX789c/0HB92CpAGa9AXkJG8C7gA+WVUvd+e1/9Ef8VemVdX6qlpZVSuHhn7qT2tIkqZoUmGQ5GfoBcFXq+rrrby7neKhfe5p9Z3Aks7qi1vtYPXF49QlSX0ymbuJAtwEPFFVX+jM2gSM3RG0BrirU7+s3VV0JvBSO510D3BekgXtwvF5wD1t3stJzmz7uqyzLUlSH0zmmsH7gI8AjyZ5uNX+ELgeuD3J5cCzwMVt3mbgQmAEeAX4KEBV7UvyGWBbW+7aqtrXxq8EbgbeANzdBklSnxwyDKrqfmCi+/7PHWf5Aq6aYFsbgA3j1IeB0w7ViyTpyPAJZEmSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDvNNZ9LRyLfUSYfmkYEkySMDSbObR3b94ZGBJGlSr73ckGRPksc6ta8lebgNz4y9AS3JsiQ/6Mz7cmed05M8mmQkyQ3tFZckOSHJliQ72ueCI/FFJUkTm8yRwc3Aqm6hqn6rqlZU1QrgDuDrndlPjc2rqis69RuBjwHL2zC2zXXA1qpaDmxt05KkPjpkGFTVfcC+8ea1/91fDNx6sG0kOQmYX1UPtNdi3gJc1GavBja28Y2duiSpT6Z7zeAsYHdV7ejUTk7ynST3Jjmr1RYBo51lRlsNYGFV7WrjzwMLp9mTJOkwTfduokv5yaOCXcDSqnohyenAnyU5dbIbq6pKUhPNT7IWWAuwdOnSKbYsSTrQlI8MkhwD/AbwtbFaVb1aVS+08YeAp4B3ADuBxZ3VF7cawO52GmnsdNKeifZZVeuramVVrRwaGppq65KkA0znNNGvAd+tqh+f/kkylGReG38bvQvFT7fTQC8nObNdZ7gMuKuttglY08bXdOqSpD6ZzK2ltwL/C3hnktEkl7dZl/DTF47PBh5pt5r+KXBFVY1dfL4S+E/ACL0jhrtb/XrgA0l20AuY66fxfSRJU3DIawZVdekE9d8Zp3YHvVtNx1t+GDhtnPoLwLmH6kOSdOT4BLIkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJKY3GsvNyTZk+SxTu3TSXYmebgNF3bmfSrJSJInk5zfqa9qtZEk6zr1k5N8q9W/luTYmfyCkqRDm8yRwc3AqnHqX6yqFW3YDJDkFHrvRj61rfMfk8xLMg/4EnABcApwaVsW4LNtW78IvAhcfuCOJElH1iHDoKruA/YdarlmNXBbVb1aVd8DRoAz2jBSVU9X1Q+B24DVSQL8KvCnbf2NwEWH+R0kSdM0nWsGVyd5pJ1GWtBqi4DnOsuMttpE9bcAf1NV+w+oS5L6aKphcCPwdmAFsAv4/Ix1dBBJ1iYZTjK8d+/efuxSkuaEKYVBVe2uqteq6kfAV+idBgLYCSzpLLq41SaqvwAcn+SYA+oT7Xd9Va2sqpVDQ0NTaV2SNI4phUGSkzqTHwbG7jTaBFyS5LgkJwPLgQeBbcDydufQsfQuMm+qqgK+CfxmW38NcNdUepIkTd0xh1ogya3AOcCJSUaBa4BzkqwACngG+DhAVW1PcjvwOLAfuKqqXmvbuRq4B5gHbKiq7W0X/xK4Lcm/Br4D3DRj306SNCmHDIOqunSc8oS/sKvqOuC6ceqbgc3j1J/m/59mkiQNgE8gS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkiUmEQZINSfYkeaxT+7dJvpvkkSR3Jjm+1Zcl+UGSh9vw5c46pyd5NMlIkhuSpNVPSLIlyY72ueBIfFFJ0sQmc2RwM7DqgNoW4LSq+iXg/wCf6sx7qqpWtOGKTv1G4GPA8jaMbXMdsLWqlgNb27QkqY8OGQZVdR+w74DaX1TV/jb5ALD4YNtIchIwv6oeqKoCbgEuarNXAxvb+MZOXZLUJzNxzeCfA3d3pk9O8p0k9yY5q9UWAaOdZUZbDWBhVe1q488DCyfaUZK1SYaTDO/du3cGWpckwTTDIMkfAfuBr7bSLmBpVb0b+D3gT5LMn+z22lFDHWT++qpaWVUrh4aGptG5JKnrmKmumOR3gA8B57Zf4lTVq8CrbfyhJE8B7wB28pOnkha3GsDuJCdV1a52OmnPVHuSJE3NlI4MkqwC/gD49ap6pVMfSjKvjb+N3oXip9tpoJeTnNnuIroMuKuttglY08bXdOqSpD455JFBkluBc4ATk4wC19C7e+g4YEu7Q/SBdufQ2cC1Sf4B+BFwRVWNXXy+kt6dSW+gd41h7DrD9cDtSS4HngUunpFvJkmatEOGQVVdOk75pgmWvQO4Y4J5w8Bp49RfAM49VB+SpCPHJ5AlSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJLEJMMgyYYke5I81qmdkGRLkh3tc0GrJ8kNSUaSPJLkPZ111rTldyRZ06mfnuTRts4N7T3JkqQ+meyRwc3AqgNq64CtVbUc2NqmAS4AlrdhLXAj9MKD3vuT3wucAVwzFiBtmY911jtwX5KkI2hSYVBV9wH7DiivBja28Y3ARZ36LdXzAHB8kpOA84EtVbWvql4EtgCr2rz5VfVAVRVwS2dbkqQ+mM41g4VVtauNPw8sbOOLgOc6y4222sHqo+PUf0qStUmGkwzv3bt3Gq1Lkrpm5AJy+x99zcS2DrGf9VW1sqpWDg0NHendSdKcMZ0w2N1O8dA+97T6TmBJZ7nFrXaw+uJx6pKkPplOGGwCxu4IWgPc1alf1u4qOhN4qZ1Ougc4L8mCduH4POCeNu/lJGe2u4gu62xLktQHx0xmoSS3AucAJyYZpXdX0PXA7UkuB54FLm6LbwYuBEaAV4CPAlTVviSfAba15a6tqrGL0lfSu2PpDcDdbZAk9cmkwqCqLp1g1rnjLFvAVRNsZwOwYZz6MHDaZHqRJM08n0CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kS0wiDJO9M8nBneDnJJ5N8OsnOTv3CzjqfSjKS5Mkk53fqq1ptJMm66X4pSdLhmdRrL8dTVU8CKwCSzAN2AnfSe+fxF6vqc93lk5wCXAKcCvwC8JdJ3tFmfwn4ADAKbEuyqaoen2pvkqTDM+UwOMC5wFNV9WySiZZZDdxWVa8C30syApzR5o1U1dMASW5ryxoGktQnM3XN4BLg1s701UkeSbIhyYJWWwQ811lmtNUmqv+UJGuTDCcZ3rt37wy1LkmadhgkORb4deC/ttKNwNvpnULaBXx+uvsYU1Xrq2plVa0cGhqaqc1K0pw3E6eJLgC+XVW7AcY+AZJ8BfhGm9wJLOmst7jVOEhdktQHM3Ga6FI6p4iSnNSZ92HgsTa+CbgkyXFJTgaWAw8C24DlSU5uRxmXtGUlSX0yrSODJG+kdxfQxzvlP06yAijgmbF5VbU9ye30LgzvB66qqtfadq4G7gHmARuqavt0+pIkHZ5phUFV/R3wlgNqHznI8tcB141T3wxsnk4vkqSp8wlkSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkMQNhkOSZJI8meTjJcKudkGRLkh3tc0GrJ8kNSUaSPJLkPZ3trGnL70iyZrp9SZImb6aODH6lqlZU1co2vQ7YWlXLga1tGuACYHkb1gI3Qi88gGuA9wJnANeMBYgk6cg7UqeJVgMb2/hG4KJO/ZbqeQA4PslJwPnAlqraV1UvAluAVUeoN0nSAWYiDAr4iyQPJVnbaguralcbfx5Y2MYXAc911h1ttYnqPyHJ2iTDSYb37t07A61LkgCOmYFtvL+qdib5eWBLku92Z1ZVJakZ2A9VtR5YD7By5coZ2aYkaQaODKpqZ/vcA9xJ75z/7nb6h/a5py2+E1jSWX1xq01UlyT1wbTCIMkbk7x5bBw4D3gM2ASM3RG0BrirjW8CLmt3FZ0JvNROJ90DnJdkQbtwfF6rSZL6YLqniRYCdyYZ29afVNV/S7INuD3J5cCzwMVt+c3AhcAI8ArwUYCq2pfkM8C2tty1VbVvmr1JkiZpWmFQVU8D7xqn/gJw7jj1Aq6aYFsbgA3T6UeSNDU+gSxJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiSmEQZJliT5ZpLHk2xP8olW/3SSnUkebsOFnXU+lWQkyZNJzu/UV7XaSJJ10/tKkqTDNZ3XXu4Hfr+qvp3kzcBDSba0eV+sqs91F05yCnAJcCrwC8BfJnlHm/0l4APAKLAtyaaqenwavUmSDsOUw6CqdgG72vj3kzwBLDrIKquB26rqVeB7SUaAM9q8kfY+ZZLc1pY1DCSpT2bkmkGSZcC7gW+10tVJHkmyIcmCVlsEPNdZbbTVJqqPt5+1SYaTDO/du3cmWpckMQNhkORNwB3AJ6vqZeBG4O3ACnpHDp+f7j7GVNX6qlpZVSuHhoZmarOSNOdN55oBSX6GXhB8taq+DlBVuzvzvwJ8o03uBJZ0Vl/cahykLknqg+ncTRTgJuCJqvpCp35SZ7EPA4+18U3AJUmOS3IysBx4ENgGLE9ycpJj6V1k3jTVviRJh286RwbvAz4CPJrk4Vb7Q+DSJCuAAp4BPg5QVduT3E7vwvB+4Kqqeg0gydXAPcA8YENVbZ9GX5KkwzSdu4nuBzLOrM0HWec64Lpx6psPtp4k6cjyCWRJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCQxi8IgyaokTyYZSbJu0P1I0lwyK8IgyTzgS8AFwCn03qN8ymC7kqS5Y1aEAXAGMFJVT1fVD4HbgNUD7kmS5oxjBt1Aswh4rjM9Crz3wIWSrAXWtsm/TfJkH3oblBOBv+7XzvLZfu1pTvBnd3R7vf/83jpecbaEwaRU1Xpg/aD76Ickw1W1ctB96PD5szu6zdWf32w5TbQTWNKZXtxqkqQ+mC1hsA1YnuTkJMcClwCbBtyTJM0Zs+I0UVXtT3I1cA8wD9hQVdsH3NagzYnTYa9T/uyObnPy55eqGnQPkqQBmy2niSRJA2QYSJIMA0mSYTArJZmf5M2D7kOTk+R9k6lJs5lhMIsk+eUkjwKPAI8l+d9JTh90Xzqk/zDJmjRrzYpbS/VjNwFXVtVfASR5P/CfgV8aaFcaV5J/AvxTYCjJ73Vmzad3i7SOAkl+A/gs8PNA2lBVNX+gjfWZYTC7vDYWBABVdX+S/YNsSAd1LPAmev+Ouqf1XgZ+cyAdaSr+GPhnVfXEoBsZJJ8zmEWS/DvgDcCtQAG/Bfw98F8Aqurbg+tOE0ny1qp6dtB9aGqS/I+qmvPXeAyDWSTJN9vo2A8lbXzssPVXB9KYDirJEPAHwKnAz47V/XkdHZL8e+AfA38GvDpWr6qvD6ypAfA00ezy3w+YLoCqurb/regwfBX4GvAh4ApgDbB3oB3pcMwHXgHO69QKMAw0MH/bGf9Zer9c5vR5zKPEW6rqpiSfqKp7gXuTbBt0U5q0362qvx90E4NmGMwiVfX57nSSz9H7432a3f6hfe5K8kHg/wInDLAfHZ7HkuwG/qoN91fVSwPuqe+8ZjCLJVkAbKuqXxx0L5pYkg/R+yWyhN7zBfOBf1VV/hn2o0SSpcBZwPuAC4G/qaoVg+2qvzwymEXaA2dj6TwPGAK8XjDLVdU32uhLwK8MshcdviSL6YXAWcC7gO3A/QNtagA8MphFknTfTbof2F1VPmcwSyW54WDzq+pf9KsXTV2SH9F7wda/qaq7Bt3PoBgG0hQlGQX+CFgAvHjg/Kra2PemdNiSvAt4P3A2sBTYAdxbVTcNtLE+MwykKUryOPBrwN3AOfSeB/mxqto3gLY0BUneRC8QzgJ+G6Cq3nrQlV5nvGYgTd2Xga3A24CHOvWxhwXfNoimdHiSDAPHAf+T3o0AZ8/FJ8o9MpCmKcmNVfW7g+5DU5NkqKrm/EOChoGkOS3JzwHX0LtmAHAvcO1ce9bA9xlImus2AN8HLm7Dy/T+dPyc4pGBpDktycMHPmA2Xu31ziMDSXPdD9qLpIAfv7L0BwPsZyA8MpA0p7XnDG4Bfq6VXgTWVNUjg+uq/wwDSXPSAa8qDfDGNv539N4f8oX+dzU4Pmcgaa4ae1XpO4FfBu6iFwq/DTw4qKYGxSMDSXNakvuAD1bV99v0m4E/r6qzD77m64sXkCXNdQuBH3amf9hqc4qniSTNdbcADya5s01fBNw8uHYGw9NEkua8JO+h90fqAO6rqu8Msp9BMAwkSV4zkCQZBpIkDANJEoaBJAn4f7n9TafLSVZiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildTargets_VolOnly(full_df = full, train_observations = train.shape[0], \n",
        "                         val_observations = val.shape[0], \n",
        "                         test_observations = test.shape[0], \n",
        "                         alph = 0.55, volity_int = 10):\n",
        "\n",
        "  \"\"\" \n",
        "  This function will take a complete set of train, val, and test data and return the targets.\n",
        "  Volitility will be calculated over the 252 5min incriments \n",
        "  The Target shift is looking at 2 hours shift from current time\n",
        "  \"\"\"\n",
        "\n",
        "  returns = np.log(full_df['Close']/(full_df['Close'].shift(1)))\n",
        "  returns.fillna(0, inplace=True)\n",
        "  #volatility = returns.std()*np.sqrt(volity_int)\n",
        "  volatility = returns.rolling(window=volity_int).std()*np.sqrt(volity_int)\n",
        "\n",
        "\n",
        "\n",
        "  return volatility\n",
        "  #return train_targets, val_targets, test_targets, full_targets\n",
        "\n",
        "volatility = buildTargets_VolOnly()\n",
        "\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "ax1 = fig.add_subplot(1, 1, 1)\n",
        "volatility.plot(ax=ax1, color = \"red\")\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Volatility', color = \"red\")\n",
        "ax1.set_title(f'Annualized volatility for {ticker}')\n",
        "ax2 = ax1.twinx()\n",
        "full.Close.plot(ax=ax2, color = \"blue\")\n",
        "ax2.set_ylabel('Close', color = \"blue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "qUSks6bebTnk",
        "outputId": "95096d69-9fee-4d57-cdf8-870bbf0b9abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y=data.data,data.target\n",
        "# Since the default in the file is 0=malignant 1=benign we want to reverse these\n",
        "y=(y==0).astype(int)\n",
        "X,y= np.array(X),np.array(y)\n",
        "\n",
        "# Let's set aside a test set and use the remainder for training and cross-validation\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0,test_size=0.2)\n",
        "\n",
        "# Let's scale our data to help the algorithm converge faster\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "UViHHQXtEB7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full.drop(columns=['Time', ])"
      ],
      "metadata": {
        "id": "DxdD_w9pRfO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ],
      "metadata": {
        "id": "TKu0iaKZSnyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=load_breast_cancer(as_frame=True)"
      ],
      "metadata": {
        "id": "K23hvV9cWb96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuBc_eiVWedQ",
        "outputId": "fda35b37-d263-4822-e472-46c94d9d2a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "564    0\n",
              "565    0\n",
              "566    0\n",
              "567    0\n",
              "568    1\n",
              "Name: target, Length: 569, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rCar6GOuWe6f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}